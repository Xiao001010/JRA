{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tqdm\n",
    "import tensorboardX\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 11:38:15,297 - INFO - task: Fixed_Res_VAE-sigma_0.001-larger-latentdim_64\n",
      "2023-07-19 11:38:15,298 - INFO - device: cuda\n",
      "2023-07-19 11:38:15,299 - INFO - batch_size: 128\n",
      "2023-07-19 11:38:15,299 - INFO - learning_rate: 0.001\n",
      "2023-07-19 11:38:15,300 - INFO - num_epochs: 600\n",
      "2023-07-19 11:38:15,300 - INFO - latent_dim: 64\n",
      "2023-07-19 11:38:15,301 - INFO - layer_list: [2, 2, 2, 2]\n",
      "2023-07-19 11:38:15,301 - INFO - input_dim: 4\n",
      "2023-07-19 11:38:15,302 - INFO - sigma: 0.001\n"
     ]
    }
   ],
   "source": [
    "# set hyperparameters\n",
    "task = 'Fixed_Res_VAE-sigma_0.001-larger-latentdim_64'\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 600\n",
    "latent_dim = 64\n",
    "# hidden_dim = [32, 64, 128]\n",
    "layer_list = [2, 2, 2, 2]\n",
    "in_channels = 4\n",
    "sigma = 0.001\n",
    "\n",
    "time_stamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n",
    "\n",
    "checkpoint_dir = os.path.join('checkpoints', task, time_stamp)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "log_dir = os.path.join('logs', task, time_stamp)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.FileHandler(os.path.join(log_dir, 'log.txt')))\n",
    "logger.info('task: {}'.format(task))\n",
    "logger.info('device: {}'.format(device))\n",
    "logger.info('batch_size: {}'.format(batch_size))\n",
    "logger.info('learning_rate: {}'.format(learning_rate))\n",
    "logger.info('num_epochs: {}'.format(num_epochs))\n",
    "logger.info('latent_dim: {}'.format(latent_dim))\n",
    "logger.info('layer_list: {}'.format(layer_list))\n",
    "logger.info('input_dim: {}'.format(in_channels))\n",
    "logger.info('sigma: {}'.format(sigma))\n",
    "# logger.info('num_classes: {}'.format(num_classes))\n",
    "\n",
    "writer = tensorboardX.SummaryWriter(log_dir)\n",
    "\n",
    "# tensorboard --logdir=logs --port=6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hx57\\AppData\\Local\\anaconda3\\envs\\jra\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 32]) torch.float32\n",
      "tensor([-0.9341, -0.9329, -0.9286, -0.9242, -0.9234, -0.9235, -0.9220, -0.9173,\n",
      "        -0.9127, -0.9032, -0.8932, -0.8876, -0.8879, -0.8883, -0.8824, -0.8763,\n",
      "        -0.8806, -0.8952, -0.9093, -0.9107, -0.9121, -0.9146, -0.9180, -0.9220,\n",
      "        -0.9307, -0.9394, -0.9440, -0.9462, -0.9478, -0.9461, -0.9444, -0.9439])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "mean = torch.tensor([6076.685883679818, 1350.9691095158794, 5090.145564947434, 5019.978020658786])\n",
    "std = torch.tensor([5504.395544161098, 1145.6356702621574, 663.3312283427825, 706.0040270727409])\n",
    "data_path = os.path.join(os.getcwd(), 'data/single_cell_data/')\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std), transforms.Resize((32, 32))])\n",
    "\n",
    "class CellDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data_path = data_path\n",
    "        self.data = os.listdir(data_path)\n",
    "        self.data.sort()\n",
    "        self.data = [os.path.join(data_path, i) for i in self.data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = tifffile.imread(self.data[idx])\n",
    "        img = img.astype(np.float32)\n",
    "        # print(img[0][0])\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    \n",
    "dataset = CellDataset(data_path, transform=trans)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# test CellDataset\n",
    "idx = 3\n",
    "img = dataset[idx]\n",
    "print(img.shape, img.dtype)\n",
    "print(img[0][0])\n",
    "fig = plt.figure()\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(img[1], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(img[2], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(img[3], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define VAE model\n",
    "import math\n",
    "def calc_activation_shape(dim, ksize=(5, 5), stride=(1, 1), padding=(0, 0), dilation=(1, 1), output_padding=(0, 0),\n",
    "                          transposed=False):\n",
    "    def shape_each_dim(i):\n",
    "        if transposed:\n",
    "            odim_i = (dim[i] - 1) * stride[i] - 2 * padding[i] + dilation[i] * (ksize[i] - 1) + 1 + output_padding[i]\n",
    "        else:\n",
    "            odim_i = dim[i] + 2 * padding[i] - dilation[i] * (ksize[i] - 1) - 1\n",
    "            odim_i = odim_i / stride[i] + 1\n",
    "        return math.floor(odim_i)\n",
    "\n",
    "    return shape_each_dim(0), shape_each_dim(1)\n",
    "\n",
    "\n",
    "\n",
    "class EncoderBottleneckBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, ln_shape, use_batch_norm=True, stride=1, downsample=None):\n",
    "        super(EncoderBottleneckBlock, self).__init__()\n",
    "        ln_shape = calc_activation_shape(ln_shape, ksize=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.conv_1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.norm_1 = nn.BatchNorm2d(planes) if use_batch_norm else nn.LayerNorm([planes, *ln_shape])\n",
    "\n",
    "        ln_shape = calc_activation_shape(ln_shape, ksize=(5, 5), stride=(stride, stride), padding=(2, 2))\n",
    "        self.conv_2 = nn.Conv2d(planes, planes, kernel_size=5, stride=stride, padding=2, bias=False)\n",
    "        self.norm_2 = nn.BatchNorm2d(planes) if use_batch_norm else nn.LayerNorm([planes, *ln_shape])\n",
    "\n",
    "        ln_shape = calc_activation_shape(ln_shape, ksize=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.conv_3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.norm_3 = nn.BatchNorm2d(planes * self.expansion) if use_batch_norm else nn.LayerNorm([planes * self.expansion, *ln_shape])\n",
    "\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv_1(x)\n",
    "\n",
    "        out = self.norm_1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv_2(out)\n",
    "        out = self.norm_2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv_3(out)\n",
    "        out = self.norm_3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim, use_batch_norm, dropout, layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout = dropout\n",
    "        self.layers = layers\n",
    "\n",
    "        self.ln_shape = (32, 32)\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.inplanes = 8\n",
    "\n",
    "        self.ln_shape = calc_activation_shape(self.ln_shape, ksize=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.norm_layer_1 = nn.BatchNorm2d(8) if use_batch_norm else nn.LayerNorm([8, *self.ln_shape])\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        self.layer_1 = self._make_layer(8, layers[0], stride=2)\n",
    "        self.layer_2 = self._make_layer(8, layers[1], stride=2)\n",
    "        self.layer_3 = self._make_layer(16, layers[2], stride=2)\n",
    "        self.layer_4 = self._make_layer(32, layers[3])\n",
    "\n",
    "        self.conv_1x1 = nn.Sequential(nn.Conv2d(128, 16, kernel_size=1),\n",
    "                                      nn.BatchNorm2d(16) if use_batch_norm else nn.LayerNorm([16, *self.ln_shape]),\n",
    "                                      nn.LeakyReLU(inplace=True))\n",
    "\n",
    "        linear_dim = 16 * self.ln_shape[0] * self.ln_shape[1]\n",
    "        self.fc_mu = nn.Linear(linear_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(linear_dim, latent_dim)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        ln_shape = calc_activation_shape(self.ln_shape, ksize=(5, 5), stride=(stride, stride), padding=(2, 2))\n",
    "        if stride != 1 or self.inplanes != planes * EncoderBottleneckBlock.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * EncoderBottleneckBlock.expansion,\n",
    "                          kernel_size=5, padding=2, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * EncoderBottleneckBlock.expansion) if self.use_batch_norm else nn.LayerNorm([planes * EncoderBottleneckBlock.expansion, *ln_shape]),\n",
    "            )\n",
    "\n",
    "        layers = [EncoderBottleneckBlock(self.inplanes, planes, self.ln_shape, self.use_batch_norm, stride, downsample)]\n",
    "\n",
    "        self.inplanes = planes * EncoderBottleneckBlock.expansion\n",
    "\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(EncoderBottleneckBlock(self.inplanes, planes, ln_shape, self.use_batch_norm))\n",
    "\n",
    "        self.ln_shape = ln_shape\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Pass the input to the encoder and get the latent distribution\n",
    "        :param x: input of shape (B, C, H, W)\n",
    "        :return: vectors mu and log_var produced by the encoder\n",
    "        \"\"\"\n",
    "        # Compute encoder output\n",
    "        x = self.conv_1(x)\n",
    "        x = self.norm_layer_1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.layer_4(x)\n",
    "        x = self.conv_1x1(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        mu = self.fc_mu(x)\n",
    "        log_var = self.fc_var(x)\n",
    "\n",
    "        return mu, log_var\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Get the latent encoding of the data_loaders and sample z from a learned distribution\n",
    "        :param x: input of shape (B, C, H, W)\n",
    "        :return: sample from the distribution q_zx,\n",
    "                 a list containing mu and sigma vectors\n",
    "        \"\"\"\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "\n",
    "        return [z, mu, log_var]\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        Reparameterization trick\n",
    "        :param mu: vector of means produced by the encoder\n",
    "        :param log_var: vector of log variances produced by the encoder\n",
    "        :return: sample from the distribution parametrized by mu and var\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        return mu + std * eps\n",
    "\n",
    "\n",
    "class DecoderBottleneckBlock(nn.Module):\n",
    "    expansion = 4  # expansion factor\n",
    "\n",
    "    def __init__(self, in_channels, planes, ln_shape, use_batch_norm=False, upsample=None, stride=2, output_padding=0):\n",
    "        super(DecoderBottleneckBlock, self).__init__()\n",
    "\n",
    "        self.upsample = upsample\n",
    "        self.stride = stride\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "\n",
    "        ln_shape = calc_activation_shape(ln_shape, ksize=(1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1), output_padding=(0, 0), transposed=True)\n",
    "        self.conv_1 = nn.ConvTranspose2d(in_channels, planes, kernel_size=1, stride=1, padding=0)\n",
    "        self.norm_1 = nn.BatchNorm2d(planes) if self.use_batch_norm else nn.LayerNorm([planes, *ln_shape])\n",
    "\n",
    "        ln_shape = calc_activation_shape(ln_shape, ksize=(5, 5), stride=(stride, stride), padding=(2, 2), dilation=(1, 1), output_padding=(output_padding, output_padding), transposed=True)\n",
    "        self.conv_2 = nn.ConvTranspose2d(planes, planes, kernel_size=5, stride=self.stride, padding=2, output_padding=output_padding)\n",
    "        self.norm_2 = nn.BatchNorm2d(planes) if self.use_batch_norm else nn.LayerNorm([planes, *ln_shape])\n",
    "\n",
    "        ln_shape = calc_activation_shape(ln_shape, ksize=(1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1), output_padding=(0, 0), transposed=True)\n",
    "        self.conv_3 = nn.ConvTranspose2d(planes, planes * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.norm_3 = nn.BatchNorm2d(planes * self.expansion) if self.use_batch_norm else nn.LayerNorm([planes * self.expansion, *ln_shape])\n",
    "\n",
    "        self.relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.relu(self.norm_1(self.conv_1(x)))\n",
    "        x = self.relu(self.norm_2(self.conv_2(x)))\n",
    "        x = self.relu(self.norm_3(self.conv_3(x)))\n",
    "\n",
    "        if self.upsample is not None:\n",
    "            identity = self.upsample(identity)\n",
    "\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim, use_batch_norm, dropout, layers=[1, 1, 1, 1]):\n",
    "        \"\"\"\n",
    "        :param latent_dim: size of the latent space\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout = dropout\n",
    "        self.layers = layers\n",
    "        # self.ln_shape = (8, 8)\n",
    "        self.ln_shape = (2, 2)\n",
    "\n",
    "        self.in_channels = 16\n",
    "        linear_dim = self.in_channels * self.ln_shape[0] * self.ln_shape[1]\n",
    "        self.dense_1 = nn.Linear(latent_dim, linear_dim)\n",
    "\n",
    "        # Build the residual decoder\n",
    "        self.layer_1 = self._make_layer(layers[3], planes=32)\n",
    "        self.layer_2 = self._make_layer(layers[2], planes=32, stride=2, output_padding=1)\n",
    "        self.layer_3 = self._make_layer(layers[1], planes=16, stride=2, output_padding=1)\n",
    "        self.layer_4 = self._make_layer(layers[0], planes=8, stride=2, output_padding=1)\n",
    "        self.layer_5 = self._make_layer(1, planes=8, stride=2, output_padding=1)\n",
    "\n",
    "        self.upconv_1 = nn.ConvTranspose2d(32, 4, kernel_size=1)\n",
    "\n",
    "    def _make_layer(self, stack, planes, stride=1, output_padding=0):\n",
    "        sub_layers = []\n",
    "        upsample = None\n",
    "\n",
    "        # Initialize upsampling\n",
    "        ln_shape = calc_activation_shape(self.ln_shape, ksize=(1, 1), stride=(stride, stride), padding=(0, 0), dilation=(1, 1), output_padding=(output_padding, output_padding), transposed=True)\n",
    "        upsample = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.in_channels, planes * DecoderBottleneckBlock.expansion, kernel_size=1,\n",
    "                               stride=stride, output_padding=output_padding),\n",
    "            nn.BatchNorm2d(planes * DecoderBottleneckBlock.expansion) if self.use_batch_norm else nn.LayerNorm([planes * DecoderBottleneckBlock.expansion, *ln_shape])\n",
    "        )\n",
    "\n",
    "        # First stack layer\n",
    "        sub_layers.append(DecoderBottleneckBlock(self.in_channels, planes, self.ln_shape, use_batch_norm=self.use_batch_norm, upsample=upsample, stride=stride,\n",
    "                                                 output_padding=output_padding))\n",
    "        self.in_channels = planes * DecoderBottleneckBlock.expansion\n",
    "\n",
    "        # Other stack layers\n",
    "        for i in range(stack - 1):\n",
    "            sub_layers.append(DecoderBottleneckBlock(self.in_channels, planes, ln_shape, use_batch_norm=self.use_batch_norm, upsample=None, stride=1))\n",
    "\n",
    "        self.ln_shape = ln_shape\n",
    "\n",
    "        return nn.Sequential(*sub_layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Reconstruct the image from the latent code\n",
    "        :param z: sample from the latent distribution\n",
    "        :return: reconstruction of the sample z\n",
    "        \"\"\"\n",
    "        x = self.dense_1(z)\n",
    "        x = x.reshape(-1, 16, 2, 2)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.layer_4(x)\n",
    "        x = self.layer_5(x)\n",
    "        x_hat = self.upconv_1(x)\n",
    "\n",
    "        # return torch.sigmoid(x_hat)\n",
    "        return x_hat\n",
    "\n",
    "\n",
    "class ResVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim, use_batch_norm=False, dropout=0.0, layer_list=None):\n",
    "        super(ResVAE, self).__init__()\n",
    "\n",
    "        if layer_list is None:\n",
    "            layer_list = [3, 4, 6, 3]\n",
    "\n",
    "        self.encoder = Encoder(latent_dim, use_batch_norm, dropout, layer_list)\n",
    "        self.decoder = Decoder(latent_dim, use_batch_norm, dropout, layer_list)\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def encode(self, x):\n",
    "        z, _, _ = self.encoder(x)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, log_var = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mu, log_var\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        z = torch.randn(num_samples, self.latent_dim)\n",
    "        z = z.to(device)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 11:38:16,002 - INFO - model: ResVAE(\n",
      "  (encoder): Encoder(\n",
      "    (conv_1): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (norm_layer_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (layer_1): Sequential(\n",
      "      (0): EncoderBottleneckBlock(\n",
      "        (conv_1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): Conv2d(8, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "        (norm_2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(8, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderBottleneckBlock(\n",
      "        (conv_1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (norm_2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_2): Sequential(\n",
      "      (0): EncoderBottleneckBlock(\n",
      "        (conv_1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): Conv2d(8, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "        (norm_2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderBottleneckBlock(\n",
      "        (conv_1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (norm_2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_3): Sequential(\n",
      "      (0): EncoderBottleneckBlock(\n",
      "        (conv_1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): Conv2d(16, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "        (norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderBottleneckBlock(\n",
      "        (conv_1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_4): Sequential(\n",
      "      (0): EncoderBottleneckBlock(\n",
      "        (conv_1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderBottleneckBlock(\n",
      "        (conv_1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_1x1): Sequential(\n",
      "      (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    )\n",
      "    (fc_mu): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (fc_var): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (dense_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (layer_1): Sequential(\n",
      "      (0): DecoderBottleneckBlock(\n",
      "        (upsample): Sequential(\n",
      "          (0): ConvTranspose2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv_1): ConvTranspose2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): ConvTranspose2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (1): DecoderBottleneckBlock(\n",
      "        (conv_1): ConvTranspose2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): ConvTranspose2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "    (layer_2): Sequential(\n",
      "      (0): DecoderBottleneckBlock(\n",
      "        (upsample): Sequential(\n",
      "          (0): ConvTranspose2d(128, 128, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv_1): ConvTranspose2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "        (norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): ConvTranspose2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (1): DecoderBottleneckBlock(\n",
      "        (conv_1): ConvTranspose2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): ConvTranspose2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "    (layer_3): Sequential(\n",
      "      (0): DecoderBottleneckBlock(\n",
      "        (upsample): Sequential(\n",
      "          (0): ConvTranspose2d(128, 64, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv_1): ConvTranspose2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): ConvTranspose2d(16, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "        (norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): ConvTranspose2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (1): DecoderBottleneckBlock(\n",
      "        (conv_1): ConvTranspose2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): ConvTranspose2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): ConvTranspose2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "    (layer_4): Sequential(\n",
      "      (0): DecoderBottleneckBlock(\n",
      "        (upsample): Sequential(\n",
      "          (0): ConvTranspose2d(64, 32, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv_1): ConvTranspose2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): ConvTranspose2d(8, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "        (norm_2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): ConvTranspose2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (1): DecoderBottleneckBlock(\n",
      "        (conv_1): ConvTranspose2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): ConvTranspose2d(8, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (norm_2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): ConvTranspose2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "    (layer_5): Sequential(\n",
      "      (0): DecoderBottleneckBlock(\n",
      "        (upsample): Sequential(\n",
      "          (0): ConvTranspose2d(32, 32, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv_1): ConvTranspose2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_2): ConvTranspose2d(8, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "        (norm_2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv_3): ConvTranspose2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (norm_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "    (upconv_1): ConvTranspose2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 4, 32, 32])\n",
      "torch.Size([128, 4, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# test VAE model\n",
    "# test_layer_list = [2, 2, 2, 2]\n",
    "model = ResVAE(latent_dim=latent_dim, use_batch_norm=True, dropout=0.0, layer_list=layer_list)\n",
    "model.to(device)\n",
    "# print(model)\n",
    "logger.info('model: {}'.format(model))\n",
    "\n",
    "# test model\n",
    "for i, (img) in enumerate(dataloader):\n",
    "    img = img.to(device)\n",
    "    print(img.shape)\n",
    "    out, mu, log_var = model(img)\n",
    "    print(out.shape)\n",
    "    # print(out[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) torch.Size([]) torch.Size([])\n",
      "tensor(4.0872e+09, device='cuda:0') tensor(53.1153, device='cuda:0') tensor(4.0872e+09, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# define loss function\n",
    "class LossVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, sigma=0.1):\n",
    "        super(LossVAE, self).__init__()\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, x_hat, x, mu, log_var):\n",
    "        kl_loss = self.kl_divergence(mu, log_var)\n",
    "        recon_loss = self.reconstruction_loss(x_hat, x)\n",
    "        loss = kl_loss + recon_loss\n",
    "        return loss, kl_loss, recon_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def kl_divergence(mu, log_var):\n",
    "        \"\"\"\n",
    "        Compute the KL divergence between given distribution q(z|x) and standard normal distribution\n",
    "        :param mu: mean vector produced by the encoder, tensor of shape (B, latent_dim)\n",
    "        :param log_var: log sigma vector produced by the encoder, tensor of shape (B, latent_dim)\n",
    "        :return: KL divergence between q(z|x) and p(z), where p(z)~N(0,I).\n",
    "        \"\"\"\n",
    "        kl = 0.5 * torch.sum((torch.exp(log_var) + torch.square(mu) - 1 - log_var), -1)\n",
    "        return torch.mean(kl)\n",
    "\n",
    "    def reconstruction_loss(self, x_hat, x):\n",
    "        \"\"\"\n",
    "        Compute the reconstruction loss\n",
    "        :param x: 2D\n",
    "        :param x_hat: output of the decoder, considered as the mean of a distribution\n",
    "        :return: reconstruction\n",
    "        \"\"\"\n",
    "        var = torch.ones(x.size()).to(device) * self.sigma * self.sigma\n",
    "\n",
    "        criterion = nn.GaussianNLLLoss(reduction='none').to(device)\n",
    "        loss = torch.mean(torch.sum(criterion(x, x_hat, var).reshape(x.shape[0], -1), dim=1))\n",
    "        return loss\n",
    "\n",
    "# test loss function\n",
    "out = torch.randn(128, 4, 32, 32).to(device)\n",
    "input = torch.randn(128, 4, 32, 32).to(device)\n",
    "mu = torch.randn(128, latent_dim).to(device)\n",
    "log_var = torch.randn(128, latent_dim).to(device)\n",
    "criterion = LossVAE(sigma=sigma)\n",
    "loss, kl_loss, recon_loss = criterion(out, input, mu, log_var)\n",
    "print(loss.shape, kl_loss.shape, recon_loss.shape)\n",
    "print(loss, kl_loss, recon_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define criterion and optimizer\n",
    "criterion = LossVAE(sigma=sigma)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2023-07-19 11:38:18,718 - INFO - Epoch: [1/600], Step: [1/591], Loss: 12936635392.0, KL Divergence: 8.679123878479004, Reconstruction Loss: 12936635392.0\n",
      "117it [00:10, 10.72it/s]2023-07-19 11:38:29,487 - INFO - Epoch: [1/600], Step: [119/591], Loss: 2632132864.0, KL Divergence: 65.56005096435547, Reconstruction Loss: 2632132864.0\n",
      "235it [00:21, 10.81it/s]2023-07-19 11:38:40,616 - INFO - Epoch: [1/600], Step: [237/591], Loss: 2513092352.0, KL Divergence: 99.12726593017578, Reconstruction Loss: 2513092352.0\n",
      "353it [00:33, 10.92it/s]2023-07-19 11:38:51,660 - INFO - Epoch: [1/600], Step: [355/591], Loss: 2332226560.0, KL Divergence: 109.3049545288086, Reconstruction Loss: 2332226560.0\n",
      "471it [00:44, 10.34it/s]2023-07-19 11:39:02,902 - INFO - Epoch: [1/600], Step: [473/591], Loss: 2445491712.0, KL Divergence: 128.39047241210938, Reconstruction Loss: 2445491456.0\n",
      "589it [00:55, 10.33it/s]2023-07-19 11:39:14,097 - INFO - Epoch: [1/600], Step: [591/591], Loss: 2585629184.0, KL Divergence: 141.20054626464844, Reconstruction Loss: 2585628928.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 11:39:14,099 - INFO - Epoch: [1/600], Total Loss: 206997075861504.0, Total KL Divergence: 7296352.5896606445, Total Reconstruction Loss: 206997070651392.0\n",
      "2023-07-19 11:39:14,140 - INFO - Save model at epoch 1\n",
      "0it [00:00, ?it/s]2023-07-19 11:39:14,248 - INFO - Epoch: [2/600], Step: [1/591], Loss: 1357828736.0, KL Divergence: 143.59703063964844, Reconstruction Loss: 1357828608.0\n",
      "117it [00:10, 10.36it/s]2023-07-19 11:39:25,252 - INFO - Epoch: [2/600], Step: [119/591], Loss: 1559901056.0, KL Divergence: 154.877197265625, Reconstruction Loss: 1559900928.0\n",
      "235it [00:21, 10.91it/s]2023-07-19 11:39:36,251 - INFO - Epoch: [2/600], Step: [237/591], Loss: 1456820864.0, KL Divergence: 168.4811248779297, Reconstruction Loss: 1456820736.0\n",
      "353it [00:32, 11.42it/s]2023-07-19 11:39:47,262 - INFO - Epoch: [2/600], Step: [355/591], Loss: 1350846080.0, KL Divergence: 179.5888671875, Reconstruction Loss: 1350845952.0\n",
      "471it [00:43, 11.24it/s]2023-07-19 11:39:57,713 - INFO - Epoch: [2/600], Step: [473/591], Loss: 1524101376.0, KL Divergence: 187.91207885742188, Reconstruction Loss: 1524101248.0\n",
      "589it [00:54, 11.00it/s]2023-07-19 11:40:08,338 - INFO - Epoch: [2/600], Step: [591/591], Loss: 2294132480.0, KL Divergence: 183.71908569335938, Reconstruction Loss: 2294132224.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 11:40:08,340 - INFO - Epoch: [2/600], Total Loss: 114576070672384.0, Total KL Divergence: 13021032.119140625, Total Reconstruction Loss: 114576059121664.0\n",
      "2023-07-19 11:40:08,378 - INFO - Save model at epoch 2\n",
      "0it [00:00, ?it/s]2023-07-19 11:40:08,482 - INFO - Epoch: [3/600], Step: [1/591], Loss: 1179656192.0, KL Divergence: 183.64254760742188, Reconstruction Loss: 1179656064.0\n",
      "117it [00:10, 10.75it/s]2023-07-19 11:40:19,413 - INFO - Epoch: [3/600], Step: [119/591], Loss: 1396027136.0, KL Divergence: 193.005615234375, Reconstruction Loss: 1396026880.0\n",
      "235it [00:21, 10.83it/s]2023-07-19 11:40:30,253 - INFO - Epoch: [3/600], Step: [237/591], Loss: 1284333696.0, KL Divergence: 201.12158203125, Reconstruction Loss: 1284333440.0\n",
      "353it [00:32, 10.59it/s]2023-07-19 11:40:41,243 - INFO - Epoch: [3/600], Step: [355/591], Loss: 1141966848.0, KL Divergence: 210.433837890625, Reconstruction Loss: 1141966592.0\n",
      "471it [00:43, 10.60it/s]2023-07-19 11:40:52,334 - INFO - Epoch: [3/600], Step: [473/591], Loss: 1276697600.0, KL Divergence: 218.385986328125, Reconstruction Loss: 1276697344.0\n",
      "589it [00:54, 10.94it/s]2023-07-19 11:41:03,266 - INFO - Epoch: [3/600], Step: [591/591], Loss: 2024033920.0, KL Divergence: 225.2133026123047, Reconstruction Loss: 2024033664.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 11:41:03,268 - INFO - Epoch: [3/600], Total Loss: 97639553949696.0, Total KL Divergence: 15545978.880859375, Total Reconstruction Loss: 97639537508352.0\n",
      "2023-07-19 11:41:03,317 - INFO - Save model at epoch 3\n",
      "0it [00:00, ?it/s]2023-07-19 11:41:03,420 - INFO - Epoch: [4/600], Step: [1/591], Loss: 991416512.0, KL Divergence: 222.53567504882812, Reconstruction Loss: 991416320.0\n",
      "118it [00:10, 10.88it/s]2023-07-19 11:41:14,208 - INFO - Epoch: [4/600], Step: [119/591], Loss: 1319126784.0, KL Divergence: 230.47402954101562, Reconstruction Loss: 1319126528.0\n",
      "236it [00:21, 11.00it/s]2023-07-19 11:41:25,026 - INFO - Epoch: [4/600], Step: [237/591], Loss: 1245000064.0, KL Divergence: 239.2243194580078, Reconstruction Loss: 1244999808.0\n",
      "354it [00:32, 10.45it/s]2023-07-19 11:41:35,951 - INFO - Epoch: [4/600], Step: [355/591], Loss: 1107281664.0, KL Divergence: 245.9215850830078, Reconstruction Loss: 1107281408.0\n",
      "472it [00:43, 10.94it/s]2023-07-19 11:41:46,871 - INFO - Epoch: [4/600], Step: [473/591], Loss: 1197194496.0, KL Divergence: 253.93406677246094, Reconstruction Loss: 1197194240.0\n",
      "590it [00:54, 11.16it/s]2023-07-19 11:41:57,543 - INFO - Epoch: [4/600], Step: [591/591], Loss: 1797744768.0, KL Divergence: 256.9109802246094, Reconstruction Loss: 1797744512.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 11:41:57,545 - INFO - Epoch: [4/600], Total Loss: 89503702351872.0, Total KL Divergence: 18280682.73046875, Total Reconstruction Loss: 89503683026944.0\n",
      "2023-07-19 11:41:57,584 - INFO - Save model at epoch 4\n",
      "0it [00:00, ?it/s]2023-07-19 11:41:57,691 - INFO - Epoch: [5/600], Step: [1/591], Loss: 896195392.0, KL Divergence: 253.06210327148438, Reconstruction Loss: 896195136.0\n",
      "117it [00:10, 11.10it/s]2023-07-19 11:42:08,506 - INFO - Epoch: [5/600], Step: [119/591], Loss: 1293282176.0, KL Divergence: 260.34564208984375, Reconstruction Loss: 1293281920.0\n",
      "235it [00:21, 10.64it/s]2023-07-19 11:42:19,355 - INFO - Epoch: [5/600], Step: [237/591], Loss: 1256530048.0, KL Divergence: 264.92230224609375, Reconstruction Loss: 1256529792.0\n",
      "353it [00:32, 10.80it/s]2023-07-19 11:42:30,219 - INFO - Epoch: [5/600], Step: [355/591], Loss: 1082647680.0, KL Divergence: 268.9570007324219, Reconstruction Loss: 1082647424.0\n",
      "471it [00:43, 11.14it/s]2023-07-19 11:42:41,142 - INFO - Epoch: [5/600], Step: [473/591], Loss: 1122946944.0, KL Divergence: 277.1739501953125, Reconstruction Loss: 1122946688.0\n",
      "589it [00:54, 11.02it/s]2023-07-19 11:42:51,763 - INFO - Epoch: [5/600], Step: [591/591], Loss: 1586335744.0, KL Divergence: 278.10540771484375, Reconstruction Loss: 1586335488.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 11:42:51,765 - INFO - Epoch: [5/600], Total Loss: 83567007817728.0, Total KL Divergence: 20216984.037109375, Total Reconstruction Loss: 83566988451840.0\n",
      "2023-07-19 11:42:51,803 - INFO - Save model at epoch 5\n",
      "0it [00:00, ?it/s]2023-07-19 11:42:51,904 - INFO - Epoch: [6/600], Step: [1/591], Loss: 769891072.0, KL Divergence: 273.41107177734375, Reconstruction Loss: 769890816.0\n",
      "118it [00:10, 10.94it/s]2023-07-19 11:43:02,701 - INFO - Epoch: [6/600], Step: [119/591], Loss: 1281569024.0, KL Divergence: 279.2955017089844, Reconstruction Loss: 1281568768.0\n",
      "236it [00:21, 10.45it/s]2023-07-19 11:43:13,523 - INFO - Epoch: [6/600], Step: [237/591], Loss: 1270176896.0, KL Divergence: 285.8858337402344, Reconstruction Loss: 1270176640.0\n",
      "354it [00:32, 10.89it/s]2023-07-19 11:43:24,700 - INFO - Epoch: [6/600], Step: [355/591], Loss: 1081971328.0, KL Divergence: 290.89251708984375, Reconstruction Loss: 1081971072.0\n",
      "472it [00:43, 11.13it/s]2023-07-19 11:43:35,341 - INFO - Epoch: [6/600], Step: [473/591], Loss: 1081983744.0, KL Divergence: 296.11083984375, Reconstruction Loss: 1081983488.0\n",
      "590it [00:54, 10.83it/s]2023-07-19 11:43:46,070 - INFO - Epoch: [6/600], Step: [591/591], Loss: 1468170240.0, KL Divergence: 300.45428466796875, Reconstruction Loss: 1468169984.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 11:43:46,072 - INFO - Epoch: [6/600], Total Loss: 79238806667264.0, Total KL Divergence: 21697452.703125, Total Reconstruction Loss: 79238785875968.0\n",
      "2023-07-19 11:43:46,110 - INFO - Save model at epoch 6\n",
      "0it [00:00, ?it/s]2023-07-19 11:43:46,215 - INFO - Epoch: [7/600], Step: [1/591], Loss: 708806848.0, KL Divergence: 295.67529296875, Reconstruction Loss: 708806528.0\n",
      "117it [00:10, 11.03it/s]2023-07-19 11:43:57,025 - INFO - Epoch: [7/600], Step: [119/591], Loss: 1297468160.0, KL Divergence: 298.51953125, Reconstruction Loss: 1297467904.0\n",
      "235it [00:21, 10.95it/s]2023-07-19 11:44:07,850 - INFO - Epoch: [7/600], Step: [237/591], Loss: 1295309696.0, KL Divergence: 303.96148681640625, Reconstruction Loss: 1295309440.0\n",
      "353it [00:32, 10.76it/s]2023-07-19 11:44:18,766 - INFO - Epoch: [7/600], Step: [355/591], Loss: 1093577344.0, KL Divergence: 306.51922607421875, Reconstruction Loss: 1093577088.0\n",
      "471it [00:43, 10.90it/s]2023-07-19 11:44:29,484 - INFO - Epoch: [7/600], Step: [473/591], Loss: 1053877376.0, KL Divergence: 311.4697265625, Reconstruction Loss: 1053877056.0\n",
      "589it [00:53, 10.77it/s]2023-07-19 11:44:40,230 - INFO - Epoch: [7/600], Step: [591/591], Loss: 1320721920.0, KL Divergence: 314.20294189453125, Reconstruction Loss: 1320721664.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 11:44:40,232 - INFO - Epoch: [7/600], Total Loss: 76297055469568.0, Total KL Divergence: 22998303.43359375, Total Reconstruction Loss: 76297032687616.0\n",
      "2023-07-19 11:44:40,270 - INFO - Save model at epoch 7\n",
      "0it [00:00, ?it/s]2023-07-19 11:44:40,390 - INFO - Epoch: [8/600], Step: [1/591], Loss: 633055488.0, KL Divergence: 309.8797302246094, Reconstruction Loss: 633055168.0\n",
      "117it [00:11, 10.62it/s]2023-07-19 11:44:51,503 - INFO - Epoch: [8/600], Step: [119/591], Loss: 1289523328.0, KL Divergence: 311.23358154296875, Reconstruction Loss: 1289523072.0\n",
      "235it [00:22, 10.81it/s]2023-07-19 11:45:02,528 - INFO - Epoch: [8/600], Step: [237/591], Loss: 1271025280.0, KL Divergence: 309.7062683105469, Reconstruction Loss: 1271025024.0\n",
      "353it [00:33, 11.03it/s]2023-07-19 11:45:13,500 - INFO - Epoch: [8/600], Step: [355/591], Loss: 1042167616.0, KL Divergence: 310.15423583984375, Reconstruction Loss: 1042167296.0\n",
      "471it [00:43, 11.09it/s]2023-07-19 11:45:24,298 - INFO - Epoch: [8/600], Step: [473/591], Loss: 990745216.0, KL Divergence: 315.43206787109375, Reconstruction Loss: 990744896.0\n",
      "589it [00:54, 11.17it/s]2023-07-19 11:45:34,959 - INFO - Epoch: [8/600], Step: [591/591], Loss: 1228846976.0, KL Divergence: 324.72344970703125, Reconstruction Loss: 1228846592.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 11:45:34,961 - INFO - Epoch: [8/600], Total Loss: 72148570460160.0, Total KL Divergence: 23669716.36328125, Total Reconstruction Loss: 72148547260416.0\n",
      "2023-07-19 11:45:35,002 - INFO - Save model at epoch 8\n",
      "0it [00:00, ?it/s]2023-07-19 11:45:35,124 - INFO - Epoch: [9/600], Step: [1/591], Loss: 577707072.0, KL Divergence: 321.3485107421875, Reconstruction Loss: 577706752.0\n",
      "117it [00:10, 11.07it/s]2023-07-19 11:45:45,889 - INFO - Epoch: [9/600], Step: [119/591], Loss: 1248188800.0, KL Divergence: 326.4468078613281, Reconstruction Loss: 1248188416.0\n",
      "235it [00:21, 10.88it/s]2023-07-19 11:45:56,815 - INFO - Epoch: [9/600], Step: [237/591], Loss: 1218618752.0, KL Divergence: 328.53753662109375, Reconstruction Loss: 1218618368.0\n",
      "353it [00:32, 10.77it/s]2023-07-19 11:46:07,676 - INFO - Epoch: [9/600], Step: [355/591], Loss: 1017565760.0, KL Divergence: 334.4824523925781, Reconstruction Loss: 1017565440.0\n",
      "471it [00:43, 10.82it/s]2023-07-19 11:46:18,505 - INFO - Epoch: [9/600], Step: [473/591], Loss: 972870336.0, KL Divergence: 337.0976257324219, Reconstruction Loss: 972870016.0\n",
      "589it [00:54, 11.13it/s]2023-07-19 11:46:29,247 - INFO - Epoch: [9/600], Step: [591/591], Loss: 1006381760.0, KL Divergence: 344.5189208984375, Reconstruction Loss: 1006381440.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 11:46:29,248 - INFO - Epoch: [9/600], Total Loss: 68348369981440.0, Total KL Divergence: 25071909.3125, Total Reconstruction Loss: 68348345057280.0\n",
      "2023-07-19 11:46:29,287 - INFO - Save model at epoch 9\n",
      "0it [00:00, ?it/s]2023-07-19 11:46:29,400 - INFO - Epoch: [10/600], Step: [1/591], Loss: 530425856.0, KL Divergence: 341.4751281738281, Reconstruction Loss: 530425504.0\n",
      "118it [00:10, 11.00it/s]2023-07-19 11:46:40,242 - INFO - Epoch: [10/600], Step: [119/591], Loss: 1257187328.0, KL Divergence: 346.16131591796875, Reconstruction Loss: 1257186944.0\n",
      "236it [00:21, 10.70it/s]2023-07-19 11:46:51,004 - INFO - Epoch: [10/600], Step: [237/591], Loss: 1172149504.0, KL Divergence: 347.73797607421875, Reconstruction Loss: 1172149120.0\n",
      "354it [00:32, 10.85it/s]2023-07-19 11:47:01,862 - INFO - Epoch: [10/600], Step: [355/591], Loss: 1007793664.0, KL Divergence: 352.66845703125, Reconstruction Loss: 1007793280.0\n",
      "472it [00:43, 11.01it/s]2023-07-19 11:47:12,656 - INFO - Epoch: [10/600], Step: [473/591], Loss: 951414976.0, KL Divergence: 356.0850524902344, Reconstruction Loss: 951414592.0\n",
      "590it [00:54, 10.83it/s]2023-07-19 11:47:23,420 - INFO - Epoch: [10/600], Step: [591/591], Loss: 957674112.0, KL Divergence: 362.53094482421875, Reconstruction Loss: 957673728.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 11:47:23,422 - INFO - Epoch: [10/600], Total Loss: 66199783407616.0, Total KL Divergence: 26512579.65234375, Total Reconstruction Loss: 66199756754944.0\n",
      "2023-07-19 11:47:23,460 - INFO - Save model at epoch 10\n",
      "0it [00:00, ?it/s]2023-07-19 11:47:23,576 - INFO - Epoch: [11/600], Step: [1/591], Loss: 512121056.0, KL Divergence: 359.2582092285156, Reconstruction Loss: 512120704.0\n",
      "117it [00:10, 10.98it/s]2023-07-19 11:47:34,411 - INFO - Epoch: [11/600], Step: [119/591], Loss: 1241984512.0, KL Divergence: 364.10076904296875, Reconstruction Loss: 1241984128.0\n",
      "235it [00:21, 10.93it/s]2023-07-19 11:47:45,255 - INFO - Epoch: [11/600], Step: [237/591], Loss: 1149311232.0, KL Divergence: 363.78070068359375, Reconstruction Loss: 1149310848.0\n",
      "353it [00:32, 10.68it/s]2023-07-19 11:47:56,137 - INFO - Epoch: [11/600], Step: [355/591], Loss: 983416512.0, KL Divergence: 369.31402587890625, Reconstruction Loss: 983416128.0\n",
      "471it [00:43, 10.84it/s]2023-07-19 11:48:06,922 - INFO - Epoch: [11/600], Step: [473/591], Loss: 933940288.0, KL Divergence: 370.31787109375, Reconstruction Loss: 933939904.0\n",
      "589it [00:54, 10.77it/s]2023-07-19 11:48:17,827 - INFO - Epoch: [11/600], Step: [591/591], Loss: 921088768.0, KL Divergence: 378.6497497558594, Reconstruction Loss: 921088384.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 11:48:17,829 - INFO - Epoch: [11/600], Total Loss: 64540496744448.0, Total KL Divergence: 27700665.63671875, Total Reconstruction Loss: 64540467793920.0\n",
      "2023-07-19 11:48:17,868 - INFO - Save model at epoch 11\n",
      "0it [00:00, ?it/s]2023-07-19 11:48:17,985 - INFO - Epoch: [12/600], Step: [1/591], Loss: 496482656.0, KL Divergence: 372.691650390625, Reconstruction Loss: 496482272.0\n",
      "117it [00:10, 11.15it/s]2023-07-19 11:48:28,997 - INFO - Epoch: [12/600], Step: [119/591], Loss: 1258007808.0, KL Divergence: 378.876953125, Reconstruction Loss: 1258007424.0\n",
      "235it [00:21, 11.06it/s]2023-07-19 11:48:39,847 - INFO - Epoch: [12/600], Step: [237/591], Loss: 1078682496.0, KL Divergence: 377.845947265625, Reconstruction Loss: 1078682112.0\n",
      "353it [00:32, 10.86it/s]2023-07-19 11:48:50,648 - INFO - Epoch: [12/600], Step: [355/591], Loss: 979073408.0, KL Divergence: 381.8180847167969, Reconstruction Loss: 979073024.0\n",
      "471it [00:43, 10.90it/s]2023-07-19 11:49:01,457 - INFO - Epoch: [12/600], Step: [473/591], Loss: 865047936.0, KL Divergence: 381.44219970703125, Reconstruction Loss: 865047552.0\n",
      "589it [00:54, 11.03it/s]2023-07-19 11:49:12,170 - INFO - Epoch: [12/600], Step: [591/591], Loss: 860383552.0, KL Divergence: 391.01739501953125, Reconstruction Loss: 860383168.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 11:49:12,172 - INFO - Epoch: [12/600], Total Loss: 62152934219776.0, Total KL Divergence: 28716959.30078125, Total Reconstruction Loss: 62152905207808.0\n",
      "2023-07-19 11:49:12,211 - INFO - Save model at epoch 12\n",
      "0it [00:00, ?it/s]2023-07-19 11:49:12,329 - INFO - Epoch: [13/600], Step: [1/591], Loss: 477683840.0, KL Divergence: 385.7271728515625, Reconstruction Loss: 477683456.0\n",
      "118it [00:10, 10.92it/s]2023-07-19 11:49:23,235 - INFO - Epoch: [13/600], Step: [119/591], Loss: 1236257408.0, KL Divergence: 386.68804931640625, Reconstruction Loss: 1236257024.0\n",
      "236it [00:21, 10.83it/s]2023-07-19 11:49:34,151 - INFO - Epoch: [13/600], Step: [237/591], Loss: 1054030144.0, KL Divergence: 381.03857421875, Reconstruction Loss: 1054029760.0\n",
      "354it [00:32, 10.78it/s]2023-07-19 11:49:45,090 - INFO - Epoch: [13/600], Step: [355/591], Loss: 933429248.0, KL Divergence: 390.6932373046875, Reconstruction Loss: 933428864.0\n",
      "472it [00:43, 10.86it/s]2023-07-19 11:49:55,952 - INFO - Epoch: [13/600], Step: [473/591], Loss: 840691328.0, KL Divergence: 391.13812255859375, Reconstruction Loss: 840690944.0\n",
      "590it [00:54, 10.81it/s]2023-07-19 11:50:06,814 - INFO - Epoch: [13/600], Step: [591/591], Loss: 810409088.0, KL Divergence: 405.9760437011719, Reconstruction Loss: 810408704.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 11:50:06,816 - INFO - Epoch: [13/600], Total Loss: 59172441804800.0, Total KL Divergence: 29367867.73828125, Total Reconstruction Loss: 59172412747776.0\n",
      "2023-07-19 11:50:06,858 - INFO - Save model at epoch 13\n",
      "0it [00:00, ?it/s]2023-07-19 11:50:06,983 - INFO - Epoch: [14/600], Step: [1/591], Loss: 450998752.0, KL Divergence: 397.0689697265625, Reconstruction Loss: 450998368.0\n",
      "117it [00:10, 10.40it/s]2023-07-19 11:50:18,024 - INFO - Epoch: [14/600], Step: [119/591], Loss: 1207429760.0, KL Divergence: 401.4375915527344, Reconstruction Loss: 1207429376.0\n",
      "235it [00:21, 10.92it/s]2023-07-19 11:50:28,925 - INFO - Epoch: [14/600], Step: [237/591], Loss: 995333760.0, KL Divergence: 395.494140625, Reconstruction Loss: 995333376.0\n",
      "353it [00:32, 10.34it/s]2023-07-19 11:50:39,827 - INFO - Epoch: [14/600], Step: [355/591], Loss: 906991104.0, KL Divergence: 402.87115478515625, Reconstruction Loss: 906990720.0\n",
      "471it [00:43, 10.62it/s]2023-07-19 11:50:50,744 - INFO - Epoch: [14/600], Step: [473/591], Loss: 815153408.0, KL Divergence: 406.76409912109375, Reconstruction Loss: 815153024.0\n",
      "589it [00:54, 10.91it/s]2023-07-19 11:51:01,679 - INFO - Epoch: [14/600], Step: [591/591], Loss: 709648768.0, KL Divergence: 419.227294921875, Reconstruction Loss: 709648320.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 11:51:01,681 - INFO - Epoch: [14/600], Total Loss: 57388307677184.0, Total KL Divergence: 30450401.88671875, Total Reconstruction Loss: 57388278452224.0\n",
      "2023-07-19 11:51:01,720 - INFO - Save model at epoch 14\n",
      "0it [00:00, ?it/s]2023-07-19 11:51:01,837 - INFO - Epoch: [15/600], Step: [1/591], Loss: 441726432.0, KL Divergence: 410.6351623535156, Reconstruction Loss: 441726016.0\n",
      "117it [00:10, 10.80it/s]2023-07-19 11:51:12,717 - INFO - Epoch: [15/600], Step: [119/591], Loss: 1192346624.0, KL Divergence: 409.3809814453125, Reconstruction Loss: 1192346240.0\n",
      "235it [00:21, 10.59it/s]2023-07-19 11:51:23,878 - INFO - Epoch: [15/600], Step: [237/591], Loss: 898365760.0, KL Divergence: 396.4682922363281, Reconstruction Loss: 898365376.0\n",
      "353it [00:32, 10.73it/s]2023-07-19 11:51:34,911 - INFO - Epoch: [15/600], Step: [355/591], Loss: 863718144.0, KL Divergence: 399.47332763671875, Reconstruction Loss: 863717760.0\n",
      "471it [00:43, 10.83it/s]2023-07-19 11:51:45,929 - INFO - Epoch: [15/600], Step: [473/591], Loss: 774944256.0, KL Divergence: 400.0762939453125, Reconstruction Loss: 774943872.0\n",
      "589it [00:55, 10.81it/s]2023-07-19 11:51:56,876 - INFO - Epoch: [15/600], Step: [591/591], Loss: 682032384.0, KL Divergence: 416.72503662109375, Reconstruction Loss: 682031936.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 11:51:56,878 - INFO - Epoch: [15/600], Total Loss: 54595892588544.0, Total KL Divergence: 30532502.73046875, Total Reconstruction Loss: 54595863146496.0\n",
      "2023-07-19 11:51:56,917 - INFO - Save model at epoch 15\n",
      "0it [00:00, ?it/s]2023-07-19 11:51:57,017 - INFO - Epoch: [16/600], Step: [1/591], Loss: 423908576.0, KL Divergence: 408.6930236816406, Reconstruction Loss: 423908160.0\n",
      "118it [00:10, 11.21it/s]2023-07-19 11:52:07,911 - INFO - Epoch: [16/600], Step: [119/591], Loss: 1153908864.0, KL Divergence: 411.0001220703125, Reconstruction Loss: 1153908480.0\n",
      "236it [00:21, 10.88it/s]2023-07-19 11:52:18,810 - INFO - Epoch: [16/600], Step: [237/591], Loss: 906310144.0, KL Divergence: 405.04833984375, Reconstruction Loss: 906309760.0\n",
      "354it [00:32, 10.45it/s]2023-07-19 11:52:29,610 - INFO - Epoch: [16/600], Step: [355/591], Loss: 817379328.0, KL Divergence: 414.61651611328125, Reconstruction Loss: 817378944.0\n",
      "472it [00:43, 11.01it/s]2023-07-19 11:52:40,415 - INFO - Epoch: [16/600], Step: [473/591], Loss: 749712320.0, KL Divergence: 418.8720703125, Reconstruction Loss: 749711872.0\n",
      "590it [00:54, 10.48it/s]2023-07-19 11:52:51,216 - INFO - Epoch: [16/600], Step: [591/591], Loss: 695205824.0, KL Divergence: 434.15447998046875, Reconstruction Loss: 695205376.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 11:52:51,217 - INFO - Epoch: [16/600], Total Loss: 51900054528000.0, Total KL Divergence: 31258939.60546875, Total Reconstruction Loss: 51900023853056.0\n",
      "2023-07-19 11:52:51,258 - INFO - Save model at epoch 16\n",
      "0it [00:00, ?it/s]2023-07-19 11:52:51,377 - INFO - Epoch: [17/600], Step: [1/591], Loss: 430454624.0, KL Divergence: 426.48956298828125, Reconstruction Loss: 430454208.0\n",
      "117it [00:10, 11.27it/s]2023-07-19 11:53:02,332 - INFO - Epoch: [17/600], Step: [119/591], Loss: 1152297344.0, KL Divergence: 426.75140380859375, Reconstruction Loss: 1152296960.0\n",
      "235it [00:21, 11.13it/s]2023-07-19 11:53:13,005 - INFO - Epoch: [17/600], Step: [237/591], Loss: 812457024.0, KL Divergence: 421.45953369140625, Reconstruction Loss: 812456576.0\n",
      "353it [00:32, 10.31it/s]2023-07-19 11:53:23,793 - INFO - Epoch: [17/600], Step: [355/591], Loss: 792606912.0, KL Divergence: 425.7321472167969, Reconstruction Loss: 792606464.0\n",
      "471it [00:43, 10.99it/s]2023-07-19 11:53:34,521 - INFO - Epoch: [17/600], Step: [473/591], Loss: 708296512.0, KL Divergence: 424.70050048828125, Reconstruction Loss: 708296064.0\n",
      "589it [00:53, 10.99it/s]2023-07-19 11:53:45,121 - INFO - Epoch: [17/600], Step: [591/591], Loss: 615674944.0, KL Divergence: 437.9703063964844, Reconstruction Loss: 615674496.0\n",
      "591it [00:53, 10.98it/s]\n",
      "2023-07-19 11:53:45,123 - INFO - Epoch: [17/600], Total Loss: 50276126285824.0, Total KL Divergence: 32201087.84375, Total Reconstruction Loss: 50276093218816.0\n",
      "2023-07-19 11:53:45,161 - INFO - Save model at epoch 17\n",
      "0it [00:00, ?it/s]2023-07-19 11:53:45,272 - INFO - Epoch: [18/600], Step: [1/591], Loss: 388139680.0, KL Divergence: 430.712890625, Reconstruction Loss: 388139264.0\n",
      "118it [00:10, 11.03it/s]2023-07-19 11:53:55,998 - INFO - Epoch: [18/600], Step: [119/591], Loss: 1083585024.0, KL Divergence: 427.41363525390625, Reconstruction Loss: 1083584640.0\n",
      "235it [00:21, 10.44it/s]2023-07-19 11:54:06,948 - INFO - Epoch: [18/600], Step: [237/591], Loss: 774989248.0, KL Divergence: 429.075927734375, Reconstruction Loss: 774988800.0\n",
      "353it [00:32, 10.87it/s]2023-07-19 11:54:17,931 - INFO - Epoch: [18/600], Step: [355/591], Loss: 765569728.0, KL Divergence: 441.1201171875, Reconstruction Loss: 765569280.0\n",
      "471it [00:43, 10.88it/s]2023-07-19 11:54:28,816 - INFO - Epoch: [18/600], Step: [473/591], Loss: 669167296.0, KL Divergence: 441.936767578125, Reconstruction Loss: 669166848.0\n",
      "589it [00:54, 10.30it/s]2023-07-19 11:54:39,805 - INFO - Epoch: [18/600], Step: [591/591], Loss: 590471552.0, KL Divergence: 458.27386474609375, Reconstruction Loss: 590471104.0\n",
      "591it [00:54, 10.82it/s]\n",
      "2023-07-19 11:54:39,808 - INFO - Epoch: [18/600], Total Loss: 47756910272512.0, Total KL Divergence: 32904052.6953125, Total Reconstruction Loss: 47756876775424.0\n",
      "2023-07-19 11:54:39,847 - INFO - Save model at epoch 18\n",
      "0it [00:00, ?it/s]2023-07-19 11:54:39,965 - INFO - Epoch: [19/600], Step: [1/591], Loss: 368367968.0, KL Divergence: 451.70947265625, Reconstruction Loss: 368367520.0\n",
      "118it [00:11, 10.81it/s]2023-07-19 11:54:51,069 - INFO - Epoch: [19/600], Step: [119/591], Loss: 1084386176.0, KL Divergence: 448.31268310546875, Reconstruction Loss: 1084385664.0\n",
      "236it [00:22, 10.79it/s]2023-07-19 11:55:02,129 - INFO - Epoch: [19/600], Step: [237/591], Loss: 783220800.0, KL Divergence: 443.91448974609375, Reconstruction Loss: 783220352.0\n",
      "354it [00:33, 10.94it/s]2023-07-19 11:55:13,155 - INFO - Epoch: [19/600], Step: [355/591], Loss: 740411520.0, KL Divergence: 453.0997314453125, Reconstruction Loss: 740411072.0\n",
      "472it [00:44, 10.89it/s]2023-07-19 11:55:24,245 - INFO - Epoch: [19/600], Step: [473/591], Loss: 660262464.0, KL Divergence: 455.08984375, Reconstruction Loss: 660262016.0\n",
      "590it [00:55, 10.97it/s]2023-07-19 11:55:35,123 - INFO - Epoch: [19/600], Step: [591/591], Loss: 580370688.0, KL Divergence: 470.37298583984375, Reconstruction Loss: 580370240.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 11:55:35,124 - INFO - Epoch: [19/600], Total Loss: 46512033423360.0, Total KL Divergence: 34070662.12890625, Total Reconstruction Loss: 46511999545344.0\n",
      "2023-07-19 11:55:35,163 - INFO - Save model at epoch 19\n",
      "0it [00:00, ?it/s]2023-07-19 11:55:35,271 - INFO - Epoch: [20/600], Step: [1/591], Loss: 361562272.0, KL Divergence: 463.87158203125, Reconstruction Loss: 361561824.0\n",
      "117it [00:10, 10.93it/s]2023-07-19 11:55:46,078 - INFO - Epoch: [20/600], Step: [119/591], Loss: 1067110784.0, KL Divergence: 463.8514404296875, Reconstruction Loss: 1067110336.0\n",
      "235it [00:21, 10.27it/s]2023-07-19 11:55:57,218 - INFO - Epoch: [20/600], Step: [237/591], Loss: 714721920.0, KL Divergence: 461.7619934082031, Reconstruction Loss: 714721472.0\n",
      "354it [00:33, 10.73it/s]2023-07-19 11:56:08,518 - INFO - Epoch: [20/600], Step: [355/591], Loss: 720798016.0, KL Divergence: 467.5220031738281, Reconstruction Loss: 720797568.0\n",
      "472it [00:44, 10.89it/s]2023-07-19 11:56:19,409 - INFO - Epoch: [20/600], Step: [473/591], Loss: 643234752.0, KL Divergence: 471.7952880859375, Reconstruction Loss: 643234304.0\n",
      "590it [00:55, 10.98it/s]2023-07-19 11:56:30,407 - INFO - Epoch: [20/600], Step: [591/591], Loss: 578711296.0, KL Divergence: 486.868408203125, Reconstruction Loss: 578710784.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 11:56:30,409 - INFO - Epoch: [20/600], Total Loss: 45431595339776.0, Total KL Divergence: 35291797.94921875, Total Reconstruction Loss: 45431560544256.0\n",
      "2023-07-19 11:56:30,448 - INFO - Save model at epoch 20\n",
      "0it [00:00, ?it/s]2023-07-19 11:56:30,558 - INFO - Epoch: [21/600], Step: [1/591], Loss: 359510304.0, KL Divergence: 479.50567626953125, Reconstruction Loss: 359509824.0\n",
      "118it [00:10, 10.79it/s]2023-07-19 11:56:41,470 - INFO - Epoch: [21/600], Step: [119/591], Loss: 1054320192.0, KL Divergence: 477.56195068359375, Reconstruction Loss: 1054319744.0\n",
      "236it [00:22, 10.94it/s]2023-07-19 11:56:52,570 - INFO - Epoch: [21/600], Step: [237/591], Loss: 731434560.0, KL Divergence: 471.12921142578125, Reconstruction Loss: 731434112.0\n",
      "354it [00:32, 11.15it/s]2023-07-19 11:57:03,419 - INFO - Epoch: [21/600], Step: [355/591], Loss: 723642176.0, KL Divergence: 477.8428955078125, Reconstruction Loss: 723641728.0\n",
      "472it [00:43, 11.03it/s]2023-07-19 11:57:14,172 - INFO - Epoch: [21/600], Step: [473/591], Loss: 627207808.0, KL Divergence: 483.839111328125, Reconstruction Loss: 627207296.0\n",
      "590it [00:54, 10.94it/s]2023-07-19 11:57:24,984 - INFO - Epoch: [21/600], Step: [591/591], Loss: 531142144.0, KL Divergence: 500.25482177734375, Reconstruction Loss: 531141632.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 11:57:24,986 - INFO - Epoch: [21/600], Total Loss: 44562694144000.0, Total KL Divergence: 36163396.12890625, Total Reconstruction Loss: 44562658234368.0\n",
      "2023-07-19 11:57:25,025 - INFO - Save model at epoch 21\n",
      "0it [00:00, ?it/s]2023-07-19 11:57:25,137 - INFO - Epoch: [22/600], Step: [1/591], Loss: 351149056.0, KL Divergence: 494.2541809082031, Reconstruction Loss: 351148576.0\n",
      "118it [00:10, 11.04it/s]2023-07-19 11:57:35,905 - INFO - Epoch: [22/600], Step: [119/591], Loss: 1052402496.0, KL Divergence: 489.5428466796875, Reconstruction Loss: 1052401984.0\n",
      "236it [00:21, 10.88it/s]2023-07-19 11:57:46,561 - INFO - Epoch: [22/600], Step: [237/591], Loss: 666252544.0, KL Divergence: 485.4544982910156, Reconstruction Loss: 666252032.0\n",
      "354it [00:32, 10.87it/s]2023-07-19 11:57:57,229 - INFO - Epoch: [22/600], Step: [355/591], Loss: 678840576.0, KL Divergence: 491.6686706542969, Reconstruction Loss: 678840064.0\n",
      "472it [00:42, 10.95it/s]2023-07-19 11:58:08,019 - INFO - Epoch: [22/600], Step: [473/591], Loss: 614182016.0, KL Divergence: 495.62872314453125, Reconstruction Loss: 614181504.0\n",
      "590it [00:53, 10.95it/s]2023-07-19 11:58:18,670 - INFO - Epoch: [22/600], Step: [591/591], Loss: 539985088.0, KL Divergence: 510.7914733886719, Reconstruction Loss: 539984576.0\n",
      "591it [00:53, 11.02it/s]\n",
      "2023-07-19 11:58:18,672 - INFO - Epoch: [22/600], Total Loss: 43549871316992.0, Total KL Divergence: 37205605.9296875, Total Reconstruction Loss: 43549833469952.0\n",
      "2023-07-19 11:58:18,712 - INFO - Save model at epoch 22\n",
      "0it [00:00, ?it/s]2023-07-19 11:58:18,823 - INFO - Epoch: [23/600], Step: [1/591], Loss: 331125888.0, KL Divergence: 506.47991943359375, Reconstruction Loss: 331125376.0\n",
      "117it [00:10, 11.04it/s]2023-07-19 11:58:29,510 - INFO - Epoch: [23/600], Step: [119/591], Loss: 1040129984.0, KL Divergence: 502.54852294921875, Reconstruction Loss: 1040129472.0\n",
      "235it [00:21, 11.15it/s]2023-07-19 11:58:40,131 - INFO - Epoch: [23/600], Step: [237/591], Loss: 668283520.0, KL Divergence: 500.6603698730469, Reconstruction Loss: 668283008.0\n",
      "353it [00:31, 11.08it/s]2023-07-19 11:58:50,807 - INFO - Epoch: [23/600], Step: [355/591], Loss: 669108352.0, KL Divergence: 509.2396545410156, Reconstruction Loss: 669107840.0\n",
      "471it [00:42, 11.20it/s]2023-07-19 11:59:01,597 - INFO - Epoch: [23/600], Step: [473/591], Loss: 590344320.0, KL Divergence: 509.7647399902344, Reconstruction Loss: 590343808.0\n",
      "589it [00:53, 11.16it/s]2023-07-19 11:59:12,161 - INFO - Epoch: [23/600], Step: [591/591], Loss: 525908608.0, KL Divergence: 527.1698608398438, Reconstruction Loss: 525908096.0\n",
      "591it [00:53, 11.06it/s]\n",
      "2023-07-19 11:59:12,164 - INFO - Epoch: [23/600], Total Loss: 42480332517376.0, Total KL Divergence: 38314587.35546875, Total Reconstruction Loss: 42480293879808.0\n",
      "2023-07-19 11:59:12,202 - INFO - Save model at epoch 23\n",
      "0it [00:00, ?it/s]2023-07-19 11:59:12,321 - INFO - Epoch: [24/600], Step: [1/591], Loss: 340967680.0, KL Divergence: 519.2515258789062, Reconstruction Loss: 340967168.0\n",
      "117it [00:10, 11.06it/s]2023-07-19 11:59:23,155 - INFO - Epoch: [24/600], Step: [119/591], Loss: 1025077312.0, KL Divergence: 517.7637939453125, Reconstruction Loss: 1025076800.0\n",
      "235it [00:21, 11.18it/s]2023-07-19 11:59:33,851 - INFO - Epoch: [24/600], Step: [237/591], Loss: 658672576.0, KL Divergence: 512.5372924804688, Reconstruction Loss: 658672064.0\n",
      "353it [00:32, 11.02it/s]2023-07-19 11:59:44,526 - INFO - Epoch: [24/600], Step: [355/591], Loss: 663476608.0, KL Divergence: 513.1080322265625, Reconstruction Loss: 663476096.0\n",
      "471it [00:42, 11.14it/s]2023-07-19 11:59:55,234 - INFO - Epoch: [24/600], Step: [473/591], Loss: 586641792.0, KL Divergence: 517.68798828125, Reconstruction Loss: 586641280.0\n",
      "589it [00:53, 11.11it/s]2023-07-19 12:00:05,967 - INFO - Epoch: [24/600], Step: [591/591], Loss: 524287872.0, KL Divergence: 537.7555541992188, Reconstruction Loss: 524287328.0\n",
      "591it [00:53, 11.00it/s]\n",
      "2023-07-19 12:00:05,970 - INFO - Epoch: [24/600], Total Loss: 41545228144640.0, Total KL Divergence: 39149911.46484375, Total Reconstruction Loss: 41545189273600.0\n",
      "2023-07-19 12:00:06,011 - INFO - Save model at epoch 24\n",
      "0it [00:00, ?it/s]2023-07-19 12:00:06,117 - INFO - Epoch: [25/600], Step: [1/591], Loss: 324102208.0, KL Divergence: 531.0890502929688, Reconstruction Loss: 324101664.0\n",
      "117it [00:10, 10.88it/s]2023-07-19 12:00:17,076 - INFO - Epoch: [25/600], Step: [119/591], Loss: 1016827072.0, KL Divergence: 526.2893676757812, Reconstruction Loss: 1016826560.0\n",
      "235it [00:21, 11.03it/s]2023-07-19 12:00:27,953 - INFO - Epoch: [25/600], Step: [237/591], Loss: 618606464.0, KL Divergence: 520.2019653320312, Reconstruction Loss: 618605952.0\n",
      "353it [00:32, 10.97it/s]2023-07-19 12:00:38,660 - INFO - Epoch: [25/600], Step: [355/591], Loss: 650930304.0, KL Divergence: 522.36669921875, Reconstruction Loss: 650929792.0\n",
      "471it [00:43, 11.03it/s]2023-07-19 12:00:49,374 - INFO - Epoch: [25/600], Step: [473/591], Loss: 568573440.0, KL Divergence: 523.61181640625, Reconstruction Loss: 568572928.0\n",
      "589it [00:53, 10.91it/s]2023-07-19 12:01:00,043 - INFO - Epoch: [25/600], Step: [591/591], Loss: 524307488.0, KL Divergence: 543.683837890625, Reconstruction Loss: 524306944.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 12:01:00,045 - INFO - Epoch: [25/600], Total Loss: 40751686758400.0, Total KL Divergence: 39769279.765625, Total Reconstruction Loss: 40751647342592.0\n",
      "2023-07-19 12:01:00,084 - INFO - Save model at epoch 25\n",
      "0it [00:00, ?it/s]2023-07-19 12:01:00,188 - INFO - Epoch: [26/600], Step: [1/591], Loss: 316482336.0, KL Divergence: 535.62451171875, Reconstruction Loss: 316481792.0\n",
      "118it [00:10, 11.08it/s]2023-07-19 12:01:11,019 - INFO - Epoch: [26/600], Step: [119/591], Loss: 999404096.0, KL Divergence: 533.1837768554688, Reconstruction Loss: 999403584.0\n",
      "236it [00:21, 10.87it/s]2023-07-19 12:01:21,918 - INFO - Epoch: [26/600], Step: [237/591], Loss: 608172032.0, KL Divergence: 520.8803100585938, Reconstruction Loss: 608171520.0\n",
      "354it [00:32, 11.04it/s]2023-07-19 12:01:32,684 - INFO - Epoch: [26/600], Step: [355/591], Loss: 627766144.0, KL Divergence: 526.0152587890625, Reconstruction Loss: 627765632.0\n",
      "472it [00:43, 11.16it/s]2023-07-19 12:01:43,308 - INFO - Epoch: [26/600], Step: [473/591], Loss: 544374272.0, KL Divergence: 523.53369140625, Reconstruction Loss: 544373760.0\n",
      "590it [00:53, 11.16it/s]2023-07-19 12:01:53,874 - INFO - Epoch: [26/600], Step: [591/591], Loss: 504038656.0, KL Divergence: 545.0595092773438, Reconstruction Loss: 504038112.0\n",
      "591it [00:53, 10.99it/s]\n",
      "2023-07-19 12:01:53,875 - INFO - Epoch: [26/600], Total Loss: 39185794994176.0, Total KL Divergence: 39910454.84375, Total Reconstruction Loss: 39185755299840.0\n",
      "2023-07-19 12:01:53,913 - INFO - Save model at epoch 26\n",
      "0it [00:00, ?it/s]2023-07-19 12:01:54,017 - INFO - Epoch: [27/600], Step: [1/591], Loss: 298584384.0, KL Divergence: 535.97265625, Reconstruction Loss: 298583840.0\n",
      "118it [00:10, 11.15it/s]2023-07-19 12:02:04,697 - INFO - Epoch: [27/600], Step: [119/591], Loss: 976272640.0, KL Divergence: 533.50244140625, Reconstruction Loss: 976272128.0\n",
      "236it [00:21, 11.14it/s]2023-07-19 12:02:15,305 - INFO - Epoch: [27/600], Step: [237/591], Loss: 620772480.0, KL Divergence: 527.7501831054688, Reconstruction Loss: 620771968.0\n",
      "354it [00:32, 11.05it/s]2023-07-19 12:02:26,058 - INFO - Epoch: [27/600], Step: [355/591], Loss: 612851584.0, KL Divergence: 531.82763671875, Reconstruction Loss: 612851072.0\n",
      "472it [00:42, 10.92it/s]2023-07-19 12:02:36,767 - INFO - Epoch: [27/600], Step: [473/591], Loss: 538549120.0, KL Divergence: 529.660400390625, Reconstruction Loss: 538548608.0\n",
      "590it [00:53, 11.02it/s]2023-07-19 12:02:47,360 - INFO - Epoch: [27/600], Step: [591/591], Loss: 481404640.0, KL Divergence: 548.3909301757812, Reconstruction Loss: 481404096.0\n",
      "591it [00:53, 11.06it/s]\n",
      "2023-07-19 12:02:47,362 - INFO - Epoch: [27/600], Total Loss: 38331265167360.0, Total KL Divergence: 40220333.84375, Total Reconstruction Loss: 38331225141248.0\n",
      "2023-07-19 12:02:47,401 - INFO - Save model at epoch 27\n",
      "0it [00:00, ?it/s]2023-07-19 12:02:47,516 - INFO - Epoch: [28/600], Step: [1/591], Loss: 282112032.0, KL Divergence: 539.7068481445312, Reconstruction Loss: 282111488.0\n",
      "117it [00:10, 11.01it/s]2023-07-19 12:02:58,248 - INFO - Epoch: [28/600], Step: [119/591], Loss: 944498368.0, KL Divergence: 537.4957885742188, Reconstruction Loss: 944497856.0\n",
      "235it [00:21, 10.96it/s]2023-07-19 12:03:08,891 - INFO - Epoch: [28/600], Step: [237/591], Loss: 570833152.0, KL Divergence: 530.44189453125, Reconstruction Loss: 570832640.0\n",
      "353it [00:31, 11.04it/s]2023-07-19 12:03:19,580 - INFO - Epoch: [28/600], Step: [355/591], Loss: 587590528.0, KL Divergence: 537.6615600585938, Reconstruction Loss: 587590016.0\n",
      "471it [00:42, 10.66it/s]2023-07-19 12:03:30,464 - INFO - Epoch: [28/600], Step: [473/591], Loss: 510288672.0, KL Divergence: 537.9642333984375, Reconstruction Loss: 510288128.0\n",
      "589it [00:53, 10.99it/s]2023-07-19 12:03:41,278 - INFO - Epoch: [28/600], Step: [591/591], Loss: 490400480.0, KL Divergence: 558.0354614257812, Reconstruction Loss: 490399936.0\n",
      "591it [00:53, 10.97it/s]\n",
      "2023-07-19 12:03:41,280 - INFO - Epoch: [28/600], Total Loss: 36987650742272.0, Total KL Divergence: 40644514.109375, Total Reconstruction Loss: 36987610329088.0\n",
      "2023-07-19 12:03:41,331 - INFO - Save model at epoch 28\n",
      "0it [00:00, ?it/s]2023-07-19 12:03:41,438 - INFO - Epoch: [29/600], Step: [1/591], Loss: 272176160.0, KL Divergence: 550.321533203125, Reconstruction Loss: 272175616.0\n",
      "117it [00:10, 10.74it/s]2023-07-19 12:03:52,371 - INFO - Epoch: [29/600], Step: [119/591], Loss: 925545152.0, KL Divergence: 550.9144287109375, Reconstruction Loss: 925544576.0\n",
      "235it [00:21, 10.94it/s]2023-07-19 12:04:03,061 - INFO - Epoch: [29/600], Step: [237/591], Loss: 558141312.0, KL Divergence: 540.9794921875, Reconstruction Loss: 558140800.0\n",
      "353it [00:32, 11.22it/s]2023-07-19 12:04:13,663 - INFO - Epoch: [29/600], Step: [355/591], Loss: 569652864.0, KL Divergence: 543.6494140625, Reconstruction Loss: 569652352.0\n",
      "471it [00:42, 11.00it/s]2023-07-19 12:04:24,325 - INFO - Epoch: [29/600], Step: [473/591], Loss: 521661504.0, KL Divergence: 544.173095703125, Reconstruction Loss: 521660960.0\n",
      "589it [00:53, 10.86it/s]2023-07-19 12:04:34,972 - INFO - Epoch: [29/600], Step: [591/591], Loss: 455494976.0, KL Divergence: 563.156982421875, Reconstruction Loss: 455494400.0\n",
      "591it [00:53, 11.02it/s]\n",
      "2023-07-19 12:04:34,974 - INFO - Epoch: [29/600], Total Loss: 36113455071232.0, Total KL Divergence: 41349743.9765625, Total Reconstruction Loss: 36113414041600.0\n",
      "2023-07-19 12:04:35,013 - INFO - Save model at epoch 29\n",
      "0it [00:00, ?it/s]2023-07-19 12:04:35,118 - INFO - Epoch: [30/600], Step: [1/591], Loss: 256872000.0, KL Divergence: 554.9649047851562, Reconstruction Loss: 256871440.0\n",
      "117it [00:10, 11.17it/s]2023-07-19 12:04:45,847 - INFO - Epoch: [30/600], Step: [119/591], Loss: 921389888.0, KL Divergence: 557.3912963867188, Reconstruction Loss: 921389312.0\n",
      "235it [00:21, 11.11it/s]2023-07-19 12:04:56,488 - INFO - Epoch: [30/600], Step: [237/591], Loss: 537234240.0, KL Divergence: 546.0459594726562, Reconstruction Loss: 537233664.0\n",
      "353it [00:31, 11.09it/s]2023-07-19 12:05:07,166 - INFO - Epoch: [30/600], Step: [355/591], Loss: 556504768.0, KL Divergence: 551.5179443359375, Reconstruction Loss: 556504192.0\n",
      "471it [00:42, 10.93it/s]2023-07-19 12:05:17,971 - INFO - Epoch: [30/600], Step: [473/591], Loss: 487578464.0, KL Divergence: 551.8704833984375, Reconstruction Loss: 487577920.0\n",
      "589it [00:53, 10.73it/s]2023-07-19 12:05:28,810 - INFO - Epoch: [30/600], Step: [591/591], Loss: 436472192.0, KL Divergence: 571.7437744140625, Reconstruction Loss: 436471616.0\n",
      "591it [00:53, 10.99it/s]\n",
      "2023-07-19 12:05:28,812 - INFO - Epoch: [30/600], Total Loss: 35089887727616.0, Total KL Divergence: 41907822.1328125, Total Reconstruction Loss: 35089845913600.0\n",
      "2023-07-19 12:05:28,858 - INFO - Save model at epoch 30\n",
      "0it [00:00, ?it/s]2023-07-19 12:05:28,974 - INFO - Epoch: [31/600], Step: [1/591], Loss: 247366992.0, KL Divergence: 563.5680541992188, Reconstruction Loss: 247366432.0\n",
      "117it [00:10, 10.43it/s]2023-07-19 12:05:39,996 - INFO - Epoch: [31/600], Step: [119/591], Loss: 900846272.0, KL Divergence: 565.5459594726562, Reconstruction Loss: 900845696.0\n",
      "235it [00:21, 10.96it/s]2023-07-19 12:05:50,936 - INFO - Epoch: [31/600], Step: [237/591], Loss: 526608768.0, KL Divergence: 553.576416015625, Reconstruction Loss: 526608224.0\n",
      "353it [00:32, 10.99it/s]2023-07-19 12:06:01,781 - INFO - Epoch: [31/600], Step: [355/591], Loss: 542372096.0, KL Divergence: 559.4817504882812, Reconstruction Loss: 542371520.0\n",
      "471it [00:43, 10.67it/s]2023-07-19 12:06:12,565 - INFO - Epoch: [31/600], Step: [473/591], Loss: 475534816.0, KL Divergence: 558.4852294921875, Reconstruction Loss: 475534272.0\n",
      "589it [00:54, 11.17it/s]2023-07-19 12:06:23,224 - INFO - Epoch: [31/600], Step: [591/591], Loss: 476118688.0, KL Divergence: 578.5354614257812, Reconstruction Loss: 476118112.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 12:06:23,226 - INFO - Epoch: [31/600], Total Loss: 34160722165760.0, Total KL Divergence: 42470008.1640625, Total Reconstruction Loss: 34160679294976.0\n",
      "2023-07-19 12:06:23,265 - INFO - Save model at epoch 31\n",
      "0it [00:00, ?it/s]2023-07-19 12:06:23,380 - INFO - Epoch: [32/600], Step: [1/591], Loss: 242221376.0, KL Divergence: 571.11328125, Reconstruction Loss: 242220800.0\n",
      "117it [00:10, 11.04it/s]2023-07-19 12:06:34,125 - INFO - Epoch: [32/600], Step: [119/591], Loss: 883339008.0, KL Divergence: 576.5074462890625, Reconstruction Loss: 883338432.0\n",
      "235it [00:21, 11.04it/s]2023-07-19 12:06:44,796 - INFO - Epoch: [32/600], Step: [237/591], Loss: 519191424.0, KL Divergence: 567.3123168945312, Reconstruction Loss: 519190848.0\n",
      "353it [00:32, 11.07it/s]2023-07-19 12:06:55,500 - INFO - Epoch: [32/600], Step: [355/591], Loss: 534228448.0, KL Divergence: 570.615234375, Reconstruction Loss: 534227872.0\n",
      "471it [00:42, 11.11it/s]2023-07-19 12:07:06,128 - INFO - Epoch: [32/600], Step: [473/591], Loss: 468727776.0, KL Divergence: 569.6229248046875, Reconstruction Loss: 468727200.0\n",
      "589it [00:53, 11.04it/s]2023-07-19 12:07:16,776 - INFO - Epoch: [32/600], Step: [591/591], Loss: 469824384.0, KL Divergence: 588.7772216796875, Reconstruction Loss: 469823808.0\n",
      "591it [00:53, 11.05it/s]\n",
      "2023-07-19 12:07:16,778 - INFO - Epoch: [32/600], Total Loss: 33477523763200.0, Total KL Divergence: 43280025.5, Total Reconstruction Loss: 33477480298496.0\n",
      "2023-07-19 12:07:16,817 - INFO - Save model at epoch 32\n",
      "0it [00:00, ?it/s]2023-07-19 12:07:16,931 - INFO - Epoch: [33/600], Step: [1/591], Loss: 239805472.0, KL Divergence: 580.9952392578125, Reconstruction Loss: 239804896.0\n",
      "117it [00:10, 11.10it/s]2023-07-19 12:07:27,662 - INFO - Epoch: [33/600], Step: [119/591], Loss: 871947072.0, KL Divergence: 582.10009765625, Reconstruction Loss: 871946496.0\n",
      "235it [00:21, 11.10it/s]2023-07-19 12:07:38,272 - INFO - Epoch: [33/600], Step: [237/591], Loss: 504878912.0, KL Divergence: 569.3736572265625, Reconstruction Loss: 504878336.0\n",
      "353it [00:32, 10.79it/s]2023-07-19 12:07:49,176 - INFO - Epoch: [33/600], Step: [355/591], Loss: 526056512.0, KL Divergence: 577.7494506835938, Reconstruction Loss: 526055936.0\n",
      "471it [00:42, 11.12it/s]2023-07-19 12:07:59,908 - INFO - Epoch: [33/600], Step: [473/591], Loss: 450420288.0, KL Divergence: 577.16796875, Reconstruction Loss: 450419712.0\n",
      "589it [00:53, 11.22it/s]2023-07-19 12:08:10,461 - INFO - Epoch: [33/600], Step: [591/591], Loss: 410136160.0, KL Divergence: 598.662353515625, Reconstruction Loss: 410135552.0\n",
      "591it [00:53, 11.02it/s]\n",
      "2023-07-19 12:08:10,464 - INFO - Epoch: [33/600], Total Loss: 32723759028224.0, Total KL Divergence: 43790024.8671875, Total Reconstruction Loss: 32723715373056.0\n",
      "2023-07-19 12:08:10,502 - INFO - Save model at epoch 33\n",
      "0it [00:00, ?it/s]2023-07-19 12:08:10,617 - INFO - Epoch: [34/600], Step: [1/591], Loss: 232822256.0, KL Divergence: 591.1025390625, Reconstruction Loss: 232821664.0\n",
      "117it [00:10, 10.99it/s]2023-07-19 12:08:21,375 - INFO - Epoch: [34/600], Step: [119/591], Loss: 867786560.0, KL Divergence: 592.4483032226562, Reconstruction Loss: 867785984.0\n",
      "235it [00:21, 11.18it/s]2023-07-19 12:08:32,020 - INFO - Epoch: [34/600], Step: [237/591], Loss: 510219968.0, KL Divergence: 581.033935546875, Reconstruction Loss: 510219392.0\n",
      "353it [00:31, 11.10it/s]2023-07-19 12:08:42,653 - INFO - Epoch: [34/600], Step: [355/591], Loss: 513612192.0, KL Divergence: 585.3280029296875, Reconstruction Loss: 513611616.0\n",
      "471it [00:42, 11.25it/s]2023-07-19 12:08:53,316 - INFO - Epoch: [34/600], Step: [473/591], Loss: 448208128.0, KL Divergence: 585.5684814453125, Reconstruction Loss: 448207552.0\n",
      "589it [00:53, 11.22it/s]2023-07-19 12:09:03,887 - INFO - Epoch: [34/600], Step: [591/591], Loss: 405955776.0, KL Divergence: 601.9942626953125, Reconstruction Loss: 405955168.0\n",
      "591it [00:53, 11.07it/s]\n",
      "2023-07-19 12:09:03,889 - INFO - Epoch: [34/600], Total Loss: 32474462509056.0, Total KL Divergence: 44480990.6875, Total Reconstruction Loss: 32474418276352.0\n",
      "2023-07-19 12:09:03,927 - INFO - Save model at epoch 34\n",
      "0it [00:00, ?it/s]2023-07-19 12:09:04,029 - INFO - Epoch: [35/600], Step: [1/591], Loss: 235181712.0, KL Divergence: 594.6140747070312, Reconstruction Loss: 235181120.0\n",
      "118it [00:10, 11.07it/s]2023-07-19 12:09:14,753 - INFO - Epoch: [35/600], Step: [119/591], Loss: 865842112.0, KL Divergence: 597.1861572265625, Reconstruction Loss: 865841536.0\n",
      "236it [00:21, 11.27it/s]2023-07-19 12:09:25,420 - INFO - Epoch: [35/600], Step: [237/591], Loss: 481892544.0, KL Divergence: 584.7503051757812, Reconstruction Loss: 481891968.0\n",
      "354it [00:32, 11.09it/s]2023-07-19 12:09:36,039 - INFO - Epoch: [35/600], Step: [355/591], Loss: 506789760.0, KL Divergence: 588.9238891601562, Reconstruction Loss: 506789184.0\n",
      "472it [00:42, 11.21it/s]2023-07-19 12:09:46,704 - INFO - Epoch: [35/600], Step: [473/591], Loss: 433496832.0, KL Divergence: 589.0879516601562, Reconstruction Loss: 433496256.0\n",
      "590it [00:53, 11.15it/s]2023-07-19 12:09:57,256 - INFO - Epoch: [35/600], Step: [591/591], Loss: 402612640.0, KL Divergence: 608.37744140625, Reconstruction Loss: 402612032.0\n",
      "591it [00:53, 11.08it/s]\n",
      "2023-07-19 12:09:57,257 - INFO - Epoch: [35/600], Total Loss: 31691893766144.0, Total KL Divergence: 44845125.421875, Total Reconstruction Loss: 31691848876032.0\n",
      "2023-07-19 12:09:57,307 - INFO - Save model at epoch 35\n",
      "0it [00:00, ?it/s]2023-07-19 12:09:57,421 - INFO - Epoch: [36/600], Step: [1/591], Loss: 224175856.0, KL Divergence: 601.3461303710938, Reconstruction Loss: 224175248.0\n",
      "117it [00:10, 11.15it/s]2023-07-19 12:10:08,122 - INFO - Epoch: [36/600], Step: [119/591], Loss: 838075392.0, KL Divergence: 602.8404541015625, Reconstruction Loss: 838074816.0\n",
      "235it [00:21, 10.97it/s]2023-07-19 12:10:18,850 - INFO - Epoch: [36/600], Step: [237/591], Loss: 490958080.0, KL Divergence: 590.7301025390625, Reconstruction Loss: 490957504.0\n",
      "353it [00:32, 11.17it/s]2023-07-19 12:10:29,542 - INFO - Epoch: [36/600], Step: [355/591], Loss: 500809024.0, KL Divergence: 593.6990966796875, Reconstruction Loss: 500808416.0\n",
      "471it [00:42, 11.10it/s]2023-07-19 12:10:40,190 - INFO - Epoch: [36/600], Step: [473/591], Loss: 431443488.0, KL Divergence: 595.604248046875, Reconstruction Loss: 431442880.0\n",
      "589it [00:53, 11.19it/s]2023-07-19 12:10:50,743 - INFO - Epoch: [36/600], Step: [591/591], Loss: 380726848.0, KL Divergence: 615.7471923828125, Reconstruction Loss: 380726240.0\n",
      "591it [00:53, 11.06it/s]\n",
      "2023-07-19 12:10:50,745 - INFO - Epoch: [36/600], Total Loss: 31197144872960.0, Total KL Divergence: 45264384.0546875, Total Reconstruction Loss: 31197099419648.0\n",
      "2023-07-19 12:10:50,784 - INFO - Save model at epoch 36\n",
      "0it [00:00, ?it/s]2023-07-19 12:10:50,898 - INFO - Epoch: [37/600], Step: [1/591], Loss: 217964784.0, KL Divergence: 607.9796142578125, Reconstruction Loss: 217964176.0\n",
      "117it [00:10, 11.04it/s]2023-07-19 12:11:01,608 - INFO - Epoch: [37/600], Step: [119/591], Loss: 826264960.0, KL Divergence: 607.8067016601562, Reconstruction Loss: 826264384.0\n",
      "235it [00:21, 10.93it/s]2023-07-19 12:11:12,279 - INFO - Epoch: [37/600], Step: [237/591], Loss: 464734368.0, KL Divergence: 593.8892211914062, Reconstruction Loss: 464733760.0\n",
      "353it [00:31, 11.18it/s]2023-07-19 12:11:22,954 - INFO - Epoch: [37/600], Step: [355/591], Loss: 490387232.0, KL Divergence: 601.698486328125, Reconstruction Loss: 490386624.0\n",
      "471it [00:42, 11.12it/s]2023-07-19 12:11:33,616 - INFO - Epoch: [37/600], Step: [473/591], Loss: 428417952.0, KL Divergence: 603.4398193359375, Reconstruction Loss: 428417344.0\n",
      "589it [00:53, 11.13it/s]2023-07-19 12:11:44,165 - INFO - Epoch: [37/600], Step: [591/591], Loss: 388131552.0, KL Divergence: 620.2362060546875, Reconstruction Loss: 388130944.0\n",
      "591it [00:53, 11.07it/s]\n",
      "2023-07-19 12:11:44,166 - INFO - Epoch: [37/600], Total Loss: 30839321200640.0, Total KL Divergence: 45761543.5234375, Total Reconstruction Loss: 30839275452416.0\n",
      "2023-07-19 12:11:44,207 - INFO - Save model at epoch 37\n",
      "0it [00:00, ?it/s]2023-07-19 12:11:44,311 - INFO - Epoch: [38/600], Step: [1/591], Loss: 219874928.0, KL Divergence: 611.9789428710938, Reconstruction Loss: 219874320.0\n",
      "117it [00:10, 11.20it/s]2023-07-19 12:11:55,000 - INFO - Epoch: [38/600], Step: [119/591], Loss: 818452608.0, KL Divergence: 613.9454345703125, Reconstruction Loss: 818451968.0\n",
      "235it [00:21, 11.12it/s]2023-07-19 12:12:05,587 - INFO - Epoch: [38/600], Step: [237/591], Loss: 476499296.0, KL Divergence: 600.798583984375, Reconstruction Loss: 476498688.0\n",
      "353it [00:31, 10.76it/s]2023-07-19 12:12:16,252 - INFO - Epoch: [38/600], Step: [355/591], Loss: 490284800.0, KL Divergence: 606.2623291015625, Reconstruction Loss: 490284192.0\n",
      "471it [00:42, 10.82it/s]2023-07-19 12:12:27,021 - INFO - Epoch: [38/600], Step: [473/591], Loss: 428088736.0, KL Divergence: 605.7549438476562, Reconstruction Loss: 428088128.0\n",
      "589it [00:53, 11.12it/s]2023-07-19 12:12:37,600 - INFO - Epoch: [38/600], Step: [591/591], Loss: 393894080.0, KL Divergence: 625.846435546875, Reconstruction Loss: 393893440.0\n",
      "591it [00:53, 11.07it/s]\n",
      "2023-07-19 12:12:37,602 - INFO - Epoch: [38/600], Total Loss: 30496500883456.0, Total KL Divergence: 46106115.7265625, Total Reconstruction Loss: 30496454928384.0\n",
      "2023-07-19 12:12:37,642 - INFO - Save model at epoch 38\n",
      "0it [00:00, ?it/s]2023-07-19 12:12:37,757 - INFO - Epoch: [39/600], Step: [1/591], Loss: 219395552.0, KL Divergence: 617.4656982421875, Reconstruction Loss: 219394928.0\n",
      "117it [00:10, 10.92it/s]2023-07-19 12:12:48,427 - INFO - Epoch: [39/600], Step: [119/591], Loss: 794041856.0, KL Divergence: 620.8856201171875, Reconstruction Loss: 794041216.0\n",
      "235it [00:21, 11.21it/s]2023-07-19 12:12:58,998 - INFO - Epoch: [39/600], Step: [237/591], Loss: 473236064.0, KL Divergence: 608.6181640625, Reconstruction Loss: 473235456.0\n",
      "353it [00:31, 11.14it/s]2023-07-19 12:13:09,572 - INFO - Epoch: [39/600], Step: [355/591], Loss: 480162912.0, KL Divergence: 613.5303344726562, Reconstruction Loss: 480162304.0\n",
      "471it [00:42, 11.03it/s]2023-07-19 12:13:20,247 - INFO - Epoch: [39/600], Step: [473/591], Loss: 420292736.0, KL Divergence: 611.210693359375, Reconstruction Loss: 420292128.0\n",
      "589it [00:53, 11.13it/s]2023-07-19 12:13:30,894 - INFO - Epoch: [39/600], Step: [591/591], Loss: 367956864.0, KL Divergence: 631.47265625, Reconstruction Loss: 367956224.0\n",
      "591it [00:53, 11.10it/s]\n",
      "2023-07-19 12:13:30,896 - INFO - Epoch: [39/600], Total Loss: 30020056299520.0, Total KL Divergence: 46598660.171875, Total Reconstruction Loss: 30020010004480.0\n",
      "2023-07-19 12:13:30,935 - INFO - Save model at epoch 39\n",
      "0it [00:00, ?it/s]2023-07-19 12:13:31,048 - INFO - Epoch: [40/600], Step: [1/591], Loss: 216926976.0, KL Divergence: 622.9014892578125, Reconstruction Loss: 216926352.0\n",
      "118it [00:10, 10.83it/s]2023-07-19 12:13:41,698 - INFO - Epoch: [40/600], Step: [119/591], Loss: 783920384.0, KL Divergence: 622.661865234375, Reconstruction Loss: 783919744.0\n",
      "236it [00:21, 11.09it/s]2023-07-19 12:13:52,354 - INFO - Epoch: [40/600], Step: [237/591], Loss: 467863200.0, KL Divergence: 614.8714599609375, Reconstruction Loss: 467862592.0\n",
      "354it [00:31, 11.17it/s]2023-07-19 12:14:02,975 - INFO - Epoch: [40/600], Step: [355/591], Loss: 475212032.0, KL Divergence: 618.8438720703125, Reconstruction Loss: 475211424.0\n",
      "472it [00:42, 10.97it/s]2023-07-19 12:14:13,635 - INFO - Epoch: [40/600], Step: [473/591], Loss: 421917088.0, KL Divergence: 620.1259765625, Reconstruction Loss: 421916480.0\n",
      "590it [00:53, 11.11it/s]2023-07-19 12:14:24,295 - INFO - Epoch: [40/600], Step: [591/591], Loss: 363968384.0, KL Divergence: 640.2888793945312, Reconstruction Loss: 363967744.0\n",
      "591it [00:53, 11.08it/s]\n",
      "2023-07-19 12:14:24,296 - INFO - Epoch: [40/600], Total Loss: 29683103657984.0, Total KL Divergence: 47034469.0859375, Total Reconstruction Loss: 29683056619520.0\n",
      "2023-07-19 12:14:24,344 - INFO - Save model at epoch 40\n",
      "0it [00:00, ?it/s]2023-07-19 12:14:24,448 - INFO - Epoch: [41/600], Step: [1/591], Loss: 210978160.0, KL Divergence: 631.855224609375, Reconstruction Loss: 210977536.0\n",
      "118it [00:10, 10.94it/s]2023-07-19 12:14:35,253 - INFO - Epoch: [41/600], Step: [119/591], Loss: 808059008.0, KL Divergence: 632.9583740234375, Reconstruction Loss: 808058368.0\n",
      "236it [00:21, 11.07it/s]2023-07-19 12:14:45,891 - INFO - Epoch: [41/600], Step: [237/591], Loss: 466745184.0, KL Divergence: 619.89599609375, Reconstruction Loss: 466744576.0\n",
      "354it [00:32, 11.13it/s]2023-07-19 12:14:56,545 - INFO - Epoch: [41/600], Step: [355/591], Loss: 474716768.0, KL Divergence: 622.9464111328125, Reconstruction Loss: 474716160.0\n",
      "472it [00:42, 11.15it/s]2023-07-19 12:15:07,239 - INFO - Epoch: [41/600], Step: [473/591], Loss: 416236736.0, KL Divergence: 623.0728759765625, Reconstruction Loss: 416236128.0\n",
      "590it [00:53, 11.07it/s]2023-07-19 12:15:17,817 - INFO - Epoch: [41/600], Step: [591/591], Loss: 350679360.0, KL Divergence: 644.6798095703125, Reconstruction Loss: 350678720.0\n",
      "591it [00:53, 11.05it/s]\n",
      "2023-07-19 12:15:17,818 - INFO - Epoch: [41/600], Total Loss: 29489097900032.0, Total KL Divergence: 47513375.2109375, Total Reconstruction Loss: 29489049976832.0\n",
      "2023-07-19 12:15:17,857 - INFO - Save model at epoch 41\n",
      "0it [00:00, ?it/s]2023-07-19 12:15:17,972 - INFO - Epoch: [42/600], Step: [1/591], Loss: 207762176.0, KL Divergence: 635.1351928710938, Reconstruction Loss: 207761536.0\n",
      "117it [00:10, 10.90it/s]2023-07-19 12:15:28,690 - INFO - Epoch: [42/600], Step: [119/591], Loss: 835120896.0, KL Divergence: 637.6865234375, Reconstruction Loss: 835120256.0\n",
      "235it [00:21, 11.06it/s]2023-07-19 12:15:39,391 - INFO - Epoch: [42/600], Step: [237/591], Loss: 444441760.0, KL Divergence: 623.979248046875, Reconstruction Loss: 444441152.0\n",
      "353it [00:32, 11.05it/s]2023-07-19 12:15:50,115 - INFO - Epoch: [42/600], Step: [355/591], Loss: 469095744.0, KL Divergence: 631.7752685546875, Reconstruction Loss: 469095104.0\n",
      "471it [00:42, 11.13it/s]2023-07-19 12:16:00,816 - INFO - Epoch: [42/600], Step: [473/591], Loss: 406607264.0, KL Divergence: 631.614501953125, Reconstruction Loss: 406606624.0\n",
      "589it [00:53, 11.13it/s]2023-07-19 12:16:11,359 - INFO - Epoch: [42/600], Step: [591/591], Loss: 338598816.0, KL Divergence: 652.9964599609375, Reconstruction Loss: 338598176.0\n",
      "591it [00:53, 11.05it/s]\n",
      "2023-07-19 12:16:11,361 - INFO - Epoch: [42/600], Total Loss: 29098312439808.0, Total KL Divergence: 48021020.1796875, Total Reconstruction Loss: 29098264172544.0\n",
      "2023-07-19 12:16:11,399 - INFO - Save model at epoch 42\n",
      "0it [00:00, ?it/s]2023-07-19 12:16:11,503 - INFO - Epoch: [43/600], Step: [1/591], Loss: 198172544.0, KL Divergence: 643.7109375, Reconstruction Loss: 198171904.0\n",
      "118it [00:10, 10.67it/s]2023-07-19 12:16:22,318 - INFO - Epoch: [43/600], Step: [119/591], Loss: 773052352.0, KL Divergence: 648.267822265625, Reconstruction Loss: 773051712.0\n",
      "236it [00:21, 10.91it/s]2023-07-19 12:16:32,932 - INFO - Epoch: [43/600], Step: [237/591], Loss: 431754816.0, KL Divergence: 629.334228515625, Reconstruction Loss: 431754176.0\n",
      "354it [00:32, 11.07it/s]2023-07-19 12:16:43,641 - INFO - Epoch: [43/600], Step: [355/591], Loss: 461869952.0, KL Divergence: 634.6917114257812, Reconstruction Loss: 461869312.0\n",
      "472it [00:42, 11.15it/s]2023-07-19 12:16:54,318 - INFO - Epoch: [43/600], Step: [473/591], Loss: 407400384.0, KL Divergence: 635.0407104492188, Reconstruction Loss: 407399744.0\n",
      "590it [00:53, 11.22it/s]2023-07-19 12:17:04,856 - INFO - Epoch: [43/600], Step: [591/591], Loss: 346803232.0, KL Divergence: 656.3370361328125, Reconstruction Loss: 346802560.0\n",
      "591it [00:53, 11.06it/s]\n",
      "2023-07-19 12:17:04,857 - INFO - Epoch: [43/600], Total Loss: 28807766257664.0, Total KL Divergence: 48417784.90625, Total Reconstruction Loss: 28807717830656.0\n",
      "2023-07-19 12:17:04,895 - INFO - Save model at epoch 43\n",
      "0it [00:00, ?it/s]2023-07-19 12:17:05,009 - INFO - Epoch: [44/600], Step: [1/591], Loss: 201520160.0, KL Divergence: 646.843994140625, Reconstruction Loss: 201519520.0\n",
      "117it [00:10, 10.10it/s]2023-07-19 12:17:15,719 - INFO - Epoch: [44/600], Step: [119/591], Loss: 747611264.0, KL Divergence: 647.3197021484375, Reconstruction Loss: 747610624.0\n",
      "235it [00:21, 11.24it/s]2023-07-19 12:17:26,368 - INFO - Epoch: [44/600], Step: [237/591], Loss: 447381088.0, KL Divergence: 633.103271484375, Reconstruction Loss: 447380448.0\n",
      "353it [00:31, 11.12it/s]2023-07-19 12:17:36,986 - INFO - Epoch: [44/600], Step: [355/591], Loss: 453704896.0, KL Divergence: 640.297119140625, Reconstruction Loss: 453704256.0\n",
      "471it [00:42, 11.16it/s]2023-07-19 12:17:47,669 - INFO - Epoch: [44/600], Step: [473/591], Loss: 401461120.0, KL Divergence: 641.1255493164062, Reconstruction Loss: 401460480.0\n",
      "589it [00:53, 10.93it/s]2023-07-19 12:17:58,237 - INFO - Epoch: [44/600], Step: [591/591], Loss: 338039872.0, KL Divergence: 664.607666015625, Reconstruction Loss: 338039200.0\n",
      "591it [00:53, 11.08it/s]\n",
      "2023-07-19 12:17:58,239 - INFO - Epoch: [44/600], Total Loss: 28356662448128.0, Total KL Divergence: 48713119.6484375, Total Reconstruction Loss: 28356613931008.0\n",
      "2023-07-19 12:17:58,278 - INFO - Save model at epoch 44\n",
      "0it [00:00, ?it/s]2023-07-19 12:17:58,386 - INFO - Epoch: [45/600], Step: [1/591], Loss: 198564560.0, KL Divergence: 654.42822265625, Reconstruction Loss: 198563904.0\n",
      "117it [00:10, 11.05it/s]2023-07-19 12:18:09,104 - INFO - Epoch: [45/600], Step: [119/591], Loss: 738012928.0, KL Divergence: 657.2932739257812, Reconstruction Loss: 738012288.0\n",
      "235it [00:21, 10.97it/s]2023-07-19 12:18:19,803 - INFO - Epoch: [45/600], Step: [237/591], Loss: 450592064.0, KL Divergence: 642.98388671875, Reconstruction Loss: 450591424.0\n",
      "353it [00:32, 11.09it/s]2023-07-19 12:18:30,499 - INFO - Epoch: [45/600], Step: [355/591], Loss: 447078496.0, KL Divergence: 644.5983276367188, Reconstruction Loss: 447077856.0\n",
      "471it [00:42, 11.13it/s]2023-07-19 12:18:41,141 - INFO - Epoch: [45/600], Step: [473/591], Loss: 397034624.0, KL Divergence: 646.9371337890625, Reconstruction Loss: 397033984.0\n",
      "589it [00:53, 11.06it/s]2023-07-19 12:18:51,770 - INFO - Epoch: [45/600], Step: [591/591], Loss: 325477952.0, KL Divergence: 670.43017578125, Reconstruction Loss: 325477280.0\n",
      "591it [00:53, 11.05it/s]\n",
      "2023-07-19 12:18:51,772 - INFO - Epoch: [45/600], Total Loss: 27900651175936.0, Total KL Divergence: 49274377.0234375, Total Reconstruction Loss: 27900602204160.0\n",
      "2023-07-19 12:18:51,811 - INFO - Save model at epoch 45\n",
      "0it [00:00, ?it/s]2023-07-19 12:18:51,926 - INFO - Epoch: [46/600], Step: [1/591], Loss: 188308272.0, KL Divergence: 660.39990234375, Reconstruction Loss: 188307616.0\n",
      "117it [00:10, 10.52it/s]2023-07-19 12:19:02,610 - INFO - Epoch: [46/600], Step: [119/591], Loss: 734448512.0, KL Divergence: 665.482177734375, Reconstruction Loss: 734447872.0\n",
      "235it [00:21, 11.14it/s]2023-07-19 12:19:13,239 - INFO - Epoch: [46/600], Step: [237/591], Loss: 431038976.0, KL Divergence: 648.4210205078125, Reconstruction Loss: 431038336.0\n",
      "353it [00:31, 10.99it/s]2023-07-19 12:19:23,947 - INFO - Epoch: [46/600], Step: [355/591], Loss: 441545792.0, KL Divergence: 651.3963012695312, Reconstruction Loss: 441545152.0\n",
      "471it [00:42, 11.21it/s]2023-07-19 12:19:34,616 - INFO - Epoch: [46/600], Step: [473/591], Loss: 389982656.0, KL Divergence: 652.0307006835938, Reconstruction Loss: 389982016.0\n",
      "589it [00:53, 11.13it/s]2023-07-19 12:19:45,189 - INFO - Epoch: [46/600], Step: [591/591], Loss: 324076960.0, KL Divergence: 674.9398803710938, Reconstruction Loss: 324076288.0\n",
      "591it [00:53, 11.07it/s]\n",
      "2023-07-19 12:19:45,191 - INFO - Epoch: [46/600], Total Loss: 27487169931264.0, Total KL Divergence: 49743604.078125, Total Reconstruction Loss: 27487120095232.0\n",
      "2023-07-19 12:19:45,230 - INFO - Save model at epoch 46\n",
      "0it [00:00, ?it/s]2023-07-19 12:19:45,343 - INFO - Epoch: [47/600], Step: [1/591], Loss: 187543232.0, KL Divergence: 664.8682861328125, Reconstruction Loss: 187542560.0\n",
      "118it [00:10, 10.61it/s]2023-07-19 12:19:56,071 - INFO - Epoch: [47/600], Step: [119/591], Loss: 754578688.0, KL Divergence: 666.80908203125, Reconstruction Loss: 754578048.0\n",
      "236it [00:21, 10.97it/s]2023-07-19 12:20:06,720 - INFO - Epoch: [47/600], Step: [237/591], Loss: 439476544.0, KL Divergence: 650.5556640625, Reconstruction Loss: 439475904.0\n",
      "354it [00:31, 11.11it/s]2023-07-19 12:20:17,343 - INFO - Epoch: [47/600], Step: [355/591], Loss: 433238816.0, KL Divergence: 653.6793823242188, Reconstruction Loss: 433238176.0\n",
      "472it [00:42, 10.91it/s]2023-07-19 12:20:28,098 - INFO - Epoch: [47/600], Step: [473/591], Loss: 386727424.0, KL Divergence: 655.3643798828125, Reconstruction Loss: 386726784.0\n",
      "590it [00:53, 11.19it/s]2023-07-19 12:20:38,659 - INFO - Epoch: [47/600], Step: [591/591], Loss: 322318816.0, KL Divergence: 679.9420166015625, Reconstruction Loss: 322318144.0\n",
      "591it [00:53, 11.06it/s]\n",
      "2023-07-19 12:20:38,660 - INFO - Epoch: [47/600], Total Loss: 27269521616896.0, Total KL Divergence: 49921902.34375, Total Reconstruction Loss: 27269471522816.0\n",
      "2023-07-19 12:20:38,698 - INFO - Save model at epoch 47\n",
      "0it [00:00, ?it/s]2023-07-19 12:20:38,805 - INFO - Epoch: [48/600], Step: [1/591], Loss: 186306496.0, KL Divergence: 669.08203125, Reconstruction Loss: 186305824.0\n",
      "117it [00:10, 10.29it/s]2023-07-19 12:20:49,500 - INFO - Epoch: [48/600], Step: [119/591], Loss: 747673856.0, KL Divergence: 671.9266357421875, Reconstruction Loss: 747673216.0\n",
      "235it [00:21, 11.13it/s]2023-07-19 12:21:00,094 - INFO - Epoch: [48/600], Step: [237/591], Loss: 426701984.0, KL Divergence: 654.0955810546875, Reconstruction Loss: 426701344.0\n",
      "353it [00:31, 11.03it/s]2023-07-19 12:21:10,780 - INFO - Epoch: [48/600], Step: [355/591], Loss: 433998560.0, KL Divergence: 659.3759765625, Reconstruction Loss: 433997888.0\n",
      "471it [00:42, 11.17it/s]2023-07-19 12:21:21,460 - INFO - Epoch: [48/600], Step: [473/591], Loss: 388581856.0, KL Divergence: 659.4105224609375, Reconstruction Loss: 388581184.0\n",
      "589it [00:53, 11.09it/s]2023-07-19 12:21:32,039 - INFO - Epoch: [48/600], Step: [591/591], Loss: 312521024.0, KL Divergence: 680.4267578125, Reconstruction Loss: 312520352.0\n",
      "591it [00:53, 11.08it/s]\n",
      "2023-07-19 12:21:32,040 - INFO - Epoch: [48/600], Total Loss: 26931699431424.0, Total KL Divergence: 50270191.171875, Total Reconstruction Loss: 26931648870400.0\n",
      "2023-07-19 12:21:32,079 - INFO - Save model at epoch 48\n",
      "0it [00:00, ?it/s]2023-07-19 12:21:32,194 - INFO - Epoch: [49/600], Step: [1/591], Loss: 184272016.0, KL Divergence: 669.8031005859375, Reconstruction Loss: 184271344.0\n",
      "118it [00:10, 11.05it/s]2023-07-19 12:21:42,875 - INFO - Epoch: [49/600], Step: [119/591], Loss: 700732288.0, KL Divergence: 674.0901489257812, Reconstruction Loss: 700731584.0\n",
      "236it [00:21, 11.20it/s]2023-07-19 12:21:53,532 - INFO - Epoch: [49/600], Step: [237/591], Loss: 409684448.0, KL Divergence: 656.5413818359375, Reconstruction Loss: 409683776.0\n",
      "354it [00:31, 11.05it/s]2023-07-19 12:22:04,173 - INFO - Epoch: [49/600], Step: [355/591], Loss: 430819360.0, KL Divergence: 662.0054321289062, Reconstruction Loss: 430818688.0\n",
      "472it [00:42, 11.19it/s]2023-07-19 12:22:14,868 - INFO - Epoch: [49/600], Step: [473/591], Loss: 381256000.0, KL Divergence: 662.2055053710938, Reconstruction Loss: 381255328.0\n",
      "590it [00:53, 11.19it/s]2023-07-19 12:22:25,455 - INFO - Epoch: [49/600], Step: [591/591], Loss: 311417120.0, KL Divergence: 683.6962280273438, Reconstruction Loss: 311416448.0\n",
      "591it [00:53, 11.08it/s]\n",
      "2023-07-19 12:22:25,456 - INFO - Epoch: [49/600], Total Loss: 26547018465280.0, Total KL Divergence: 50423665.6171875, Total Reconstruction Loss: 26546967812096.0\n",
      "2023-07-19 12:22:25,494 - INFO - Save model at epoch 49\n",
      "0it [00:00, ?it/s]2023-07-19 12:22:25,608 - INFO - Epoch: [50/600], Step: [1/591], Loss: 180621872.0, KL Divergence: 671.7191162109375, Reconstruction Loss: 180621200.0\n",
      "117it [00:10, 11.16it/s]2023-07-19 12:22:36,298 - INFO - Epoch: [50/600], Step: [119/591], Loss: 696579712.0, KL Divergence: 676.9415283203125, Reconstruction Loss: 696579008.0\n",
      "235it [00:21, 11.01it/s]2023-07-19 12:22:46,968 - INFO - Epoch: [50/600], Step: [237/591], Loss: 410272192.0, KL Divergence: 654.3880004882812, Reconstruction Loss: 410271552.0\n",
      "353it [00:31, 11.06it/s]2023-07-19 12:22:57,644 - INFO - Epoch: [50/600], Step: [355/591], Loss: 425877152.0, KL Divergence: 656.2415161132812, Reconstruction Loss: 425876480.0\n",
      "471it [00:42, 11.00it/s]2023-07-19 12:23:08,348 - INFO - Epoch: [50/600], Step: [473/591], Loss: 375310560.0, KL Divergence: 657.63134765625, Reconstruction Loss: 375309888.0\n",
      "589it [00:53, 11.01it/s]2023-07-19 12:23:18,974 - INFO - Epoch: [50/600], Step: [591/591], Loss: 313328832.0, KL Divergence: 675.5466918945312, Reconstruction Loss: 313328160.0\n",
      "591it [00:53, 11.05it/s]\n",
      "2023-07-19 12:23:18,975 - INFO - Epoch: [50/600], Total Loss: 26267000295424.0, Total KL Divergence: 50261611.2265625, Total Reconstruction Loss: 26266949769216.0\n",
      "2023-07-19 12:23:19,015 - INFO - Save model at epoch 50\n",
      "0it [00:00, ?it/s]2023-07-19 12:23:19,129 - INFO - Epoch: [51/600], Step: [1/591], Loss: 177462112.0, KL Divergence: 664.6202392578125, Reconstruction Loss: 177461440.0\n",
      "117it [00:10, 11.08it/s]2023-07-19 12:23:29,863 - INFO - Epoch: [51/600], Step: [119/591], Loss: 686301696.0, KL Divergence: 667.6546020507812, Reconstruction Loss: 686301056.0\n",
      "235it [00:21, 11.13it/s]2023-07-19 12:23:40,557 - INFO - Epoch: [51/600], Step: [237/591], Loss: 405427968.0, KL Divergence: 647.5692138671875, Reconstruction Loss: 405427328.0\n",
      "353it [00:31, 11.25it/s]2023-07-19 12:23:51,166 - INFO - Epoch: [51/600], Step: [355/591], Loss: 421401600.0, KL Divergence: 652.0289916992188, Reconstruction Loss: 421400960.0\n",
      "471it [00:42, 11.34it/s]2023-07-19 12:24:01,763 - INFO - Epoch: [51/600], Step: [473/591], Loss: 377160160.0, KL Divergence: 651.3585205078125, Reconstruction Loss: 377159520.0\n",
      "589it [00:53, 11.13it/s]2023-07-19 12:24:12,267 - INFO - Epoch: [51/600], Step: [591/591], Loss: 309798144.0, KL Divergence: 672.7386474609375, Reconstruction Loss: 309797472.0\n",
      "591it [00:53, 11.10it/s]\n",
      "2023-07-19 12:24:12,268 - INFO - Epoch: [51/600], Total Loss: 26120824236032.0, Total KL Divergence: 49749388.140625, Total Reconstruction Loss: 26120774422528.0\n",
      "2023-07-19 12:24:12,307 - INFO - Save model at epoch 51\n",
      "0it [00:00, ?it/s]2023-07-19 12:24:12,423 - INFO - Epoch: [52/600], Step: [1/591], Loss: 172201168.0, KL Divergence: 661.6904296875, Reconstruction Loss: 172200512.0\n",
      "117it [00:10, 11.05it/s]2023-07-19 12:24:23,177 - INFO - Epoch: [52/600], Step: [119/591], Loss: 670765504.0, KL Divergence: 667.591552734375, Reconstruction Loss: 670764864.0\n",
      "235it [00:21, 11.04it/s]2023-07-19 12:24:33,859 - INFO - Epoch: [52/600], Step: [237/591], Loss: 402084928.0, KL Divergence: 648.1310424804688, Reconstruction Loss: 402084288.0\n",
      "353it [00:31, 11.21it/s]2023-07-19 12:24:44,469 - INFO - Epoch: [52/600], Step: [355/591], Loss: 418449472.0, KL Divergence: 650.7071533203125, Reconstruction Loss: 418448832.0\n",
      "471it [00:42, 11.25it/s]2023-07-19 12:24:55,129 - INFO - Epoch: [52/600], Step: [473/591], Loss: 372931968.0, KL Divergence: 649.719970703125, Reconstruction Loss: 372931328.0\n",
      "589it [00:53, 11.12it/s]2023-07-19 12:25:05,663 - INFO - Epoch: [52/600], Step: [591/591], Loss: 318632480.0, KL Divergence: 669.2119140625, Reconstruction Loss: 318631808.0\n",
      "591it [00:53, 11.08it/s]\n",
      "2023-07-19 12:25:05,665 - INFO - Epoch: [52/600], Total Loss: 25789054842880.0, Total KL Divergence: 49660140.5625, Total Reconstruction Loss: 25789005262848.0\n",
      "2023-07-19 12:25:05,705 - INFO - Save model at epoch 52\n",
      "0it [00:00, ?it/s]2023-07-19 12:25:05,821 - INFO - Epoch: [53/600], Step: [1/591], Loss: 173043984.0, KL Divergence: 658.6246948242188, Reconstruction Loss: 173043328.0\n",
      "117it [00:10, 11.21it/s]2023-07-19 12:25:16,399 - INFO - Epoch: [53/600], Step: [119/591], Loss: 662345088.0, KL Divergence: 666.8279418945312, Reconstruction Loss: 662344448.0\n",
      "235it [00:21, 11.11it/s]2023-07-19 12:25:27,119 - INFO - Epoch: [53/600], Step: [237/591], Loss: 389078496.0, KL Divergence: 649.4899291992188, Reconstruction Loss: 389077856.0\n",
      "353it [00:31, 10.88it/s]2023-07-19 12:25:37,759 - INFO - Epoch: [53/600], Step: [355/591], Loss: 417430272.0, KL Divergence: 651.120361328125, Reconstruction Loss: 417429632.0\n",
      "471it [00:42, 11.04it/s]2023-07-19 12:25:48,430 - INFO - Epoch: [53/600], Step: [473/591], Loss: 372133184.0, KL Divergence: 653.9422607421875, Reconstruction Loss: 372132544.0\n",
      "589it [00:53, 11.12it/s]2023-07-19 12:25:58,994 - INFO - Epoch: [53/600], Step: [591/591], Loss: 313739520.0, KL Divergence: 676.5751953125, Reconstruction Loss: 313738848.0\n",
      "591it [00:53, 11.09it/s]\n",
      "2023-07-19 12:25:58,996 - INFO - Epoch: [53/600], Total Loss: 25763900198912.0, Total KL Divergence: 49727281.1640625, Total Reconstruction Loss: 25763850430464.0\n",
      "2023-07-19 12:25:59,036 - INFO - Save model at epoch 53\n",
      "0it [00:00, ?it/s]2023-07-19 12:25:59,140 - INFO - Epoch: [54/600], Step: [1/591], Loss: 175489408.0, KL Divergence: 665.4827880859375, Reconstruction Loss: 175488736.0\n",
      "118it [00:10, 11.11it/s]2023-07-19 12:26:09,779 - INFO - Epoch: [54/600], Step: [119/591], Loss: 657423872.0, KL Divergence: 671.652587890625, Reconstruction Loss: 657423232.0\n",
      "236it [00:21, 11.02it/s]2023-07-19 12:26:20,472 - INFO - Epoch: [54/600], Step: [237/591], Loss: 391113856.0, KL Divergence: 650.9230346679688, Reconstruction Loss: 391113216.0\n",
      "354it [00:31, 11.14it/s]2023-07-19 12:26:31,113 - INFO - Epoch: [54/600], Step: [355/591], Loss: 414084192.0, KL Divergence: 659.1195068359375, Reconstruction Loss: 414083520.0\n",
      "472it [00:42, 11.21it/s]2023-07-19 12:26:41,770 - INFO - Epoch: [54/600], Step: [473/591], Loss: 382211360.0, KL Divergence: 659.6761474609375, Reconstruction Loss: 382210688.0\n",
      "590it [00:53, 11.17it/s]2023-07-19 12:26:52,415 - INFO - Epoch: [54/600], Step: [591/591], Loss: 297487936.0, KL Divergence: 681.8152465820312, Reconstruction Loss: 297487264.0\n",
      "591it [00:53, 11.07it/s]\n",
      "2023-07-19 12:26:52,417 - INFO - Epoch: [54/600], Total Loss: 25478188040192.0, Total KL Divergence: 50126679.2421875, Total Reconstruction Loss: 25478137663488.0\n",
      "2023-07-19 12:26:52,455 - INFO - Save model at epoch 54\n",
      "0it [00:00, ?it/s]2023-07-19 12:26:52,565 - INFO - Epoch: [55/600], Step: [1/591], Loss: 169781936.0, KL Divergence: 670.6582641601562, Reconstruction Loss: 169781264.0\n",
      "118it [00:10, 11.23it/s]2023-07-19 12:27:03,188 - INFO - Epoch: [55/600], Step: [119/591], Loss: 653905920.0, KL Divergence: 676.9690551757812, Reconstruction Loss: 653905216.0\n",
      "236it [00:21, 11.11it/s]2023-07-19 12:27:13,838 - INFO - Epoch: [55/600], Step: [237/591], Loss: 380348576.0, KL Divergence: 658.3240356445312, Reconstruction Loss: 380347904.0\n",
      "354it [00:31, 10.62it/s]2023-07-19 12:27:24,560 - INFO - Epoch: [55/600], Step: [355/591], Loss: 409976704.0, KL Divergence: 655.4503173828125, Reconstruction Loss: 409976064.0\n",
      "472it [00:42, 11.12it/s]2023-07-19 12:27:35,281 - INFO - Epoch: [55/600], Step: [473/591], Loss: 367591072.0, KL Divergence: 660.7879638671875, Reconstruction Loss: 367590400.0\n",
      "590it [00:53, 11.06it/s]2023-07-19 12:27:45,887 - INFO - Epoch: [55/600], Step: [591/591], Loss: 303265600.0, KL Divergence: 683.6657104492188, Reconstruction Loss: 303264928.0\n",
      "591it [00:53, 11.06it/s]\n",
      "2023-07-19 12:27:45,888 - INFO - Epoch: [55/600], Total Loss: 25363053643776.0, Total KL Divergence: 50332824.1171875, Total Reconstruction Loss: 25363003068416.0\n",
      "2023-07-19 12:27:45,928 - INFO - Save model at epoch 55\n",
      "0it [00:00, ?it/s]2023-07-19 12:27:46,042 - INFO - Epoch: [56/600], Step: [1/591], Loss: 172005840.0, KL Divergence: 671.8807373046875, Reconstruction Loss: 172005168.0\n",
      "117it [00:10, 11.01it/s]2023-07-19 12:27:56,738 - INFO - Epoch: [56/600], Step: [119/591], Loss: 659325120.0, KL Divergence: 672.85107421875, Reconstruction Loss: 659324416.0\n",
      "235it [00:21, 11.12it/s]2023-07-19 12:28:07,441 - INFO - Epoch: [56/600], Step: [237/591], Loss: 394053568.0, KL Divergence: 658.8736572265625, Reconstruction Loss: 394052896.0\n",
      "353it [00:32, 11.10it/s]2023-07-19 12:28:18,211 - INFO - Epoch: [56/600], Step: [355/591], Loss: 408780864.0, KL Divergence: 659.6771240234375, Reconstruction Loss: 408780192.0\n",
      "471it [00:42, 11.16it/s]2023-07-19 12:28:28,924 - INFO - Epoch: [56/600], Step: [473/591], Loss: 372300960.0, KL Divergence: 665.2557373046875, Reconstruction Loss: 372300288.0\n",
      "589it [00:53, 11.08it/s]2023-07-19 12:28:39,488 - INFO - Epoch: [56/600], Step: [591/591], Loss: 297932192.0, KL Divergence: 685.4122314453125, Reconstruction Loss: 297931520.0\n",
      "591it [00:53, 11.04it/s]\n",
      "2023-07-19 12:28:39,490 - INFO - Epoch: [56/600], Total Loss: 25250451408896.0, Total KL Divergence: 50482354.7265625, Total Reconstruction Loss: 25250400735232.0\n",
      "2023-07-19 12:28:39,531 - INFO - Save model at epoch 56\n",
      "0it [00:00, ?it/s]2023-07-19 12:28:39,638 - INFO - Epoch: [57/600], Step: [1/591], Loss: 172277264.0, KL Divergence: 673.6499633789062, Reconstruction Loss: 172276592.0\n",
      "117it [00:10, 11.07it/s]2023-07-19 12:28:50,304 - INFO - Epoch: [57/600], Step: [119/591], Loss: 665190272.0, KL Divergence: 676.8333740234375, Reconstruction Loss: 665189568.0\n",
      "235it [00:21, 11.04it/s]2023-07-19 12:29:01,065 - INFO - Epoch: [57/600], Step: [237/591], Loss: 394157312.0, KL Divergence: 663.680419921875, Reconstruction Loss: 394156640.0\n",
      "353it [00:31, 11.16it/s]2023-07-19 12:29:11,694 - INFO - Epoch: [57/600], Step: [355/591], Loss: 401051424.0, KL Divergence: 663.851318359375, Reconstruction Loss: 401050752.0\n",
      "471it [00:42, 11.01it/s]2023-07-19 12:29:22,403 - INFO - Epoch: [57/600], Step: [473/591], Loss: 368221536.0, KL Divergence: 665.5533447265625, Reconstruction Loss: 368220864.0\n",
      "589it [00:53, 11.07it/s]2023-07-19 12:29:33,035 - INFO - Epoch: [57/600], Step: [591/591], Loss: 299033728.0, KL Divergence: 686.70068359375, Reconstruction Loss: 299033056.0\n",
      "591it [00:53, 11.05it/s]\n",
      "2023-07-19 12:29:33,037 - INFO - Epoch: [57/600], Total Loss: 25048484106240.0, Total KL Divergence: 50671870.3125, Total Reconstruction Loss: 25048433348608.0\n",
      "2023-07-19 12:29:33,076 - INFO - Save model at epoch 57\n",
      "0it [00:00, ?it/s]2023-07-19 12:29:33,181 - INFO - Epoch: [58/600], Step: [1/591], Loss: 170583424.0, KL Divergence: 675.2408447265625, Reconstruction Loss: 170582752.0\n",
      "117it [00:10, 11.21it/s]2023-07-19 12:29:43,831 - INFO - Epoch: [58/600], Step: [119/591], Loss: 654381248.0, KL Divergence: 678.172119140625, Reconstruction Loss: 654380544.0\n",
      "235it [00:21, 11.15it/s]2023-07-19 12:29:54,578 - INFO - Epoch: [58/600], Step: [237/591], Loss: 381476224.0, KL Divergence: 664.3939208984375, Reconstruction Loss: 381475552.0\n",
      "353it [00:31, 11.07it/s]2023-07-19 12:30:05,188 - INFO - Epoch: [58/600], Step: [355/591], Loss: 398490016.0, KL Divergence: 663.49462890625, Reconstruction Loss: 398489344.0\n",
      "471it [00:42, 11.14it/s]2023-07-19 12:30:15,859 - INFO - Epoch: [58/600], Step: [473/591], Loss: 365896768.0, KL Divergence: 667.56396484375, Reconstruction Loss: 365896096.0\n",
      "589it [00:53, 10.98it/s]2023-07-19 12:30:26,467 - INFO - Epoch: [58/600], Step: [591/591], Loss: 295992960.0, KL Divergence: 687.56103515625, Reconstruction Loss: 295992288.0\n",
      "591it [00:53, 11.07it/s]\n",
      "2023-07-19 12:30:26,469 - INFO - Epoch: [58/600], Total Loss: 24882292400128.0, Total KL Divergence: 50748984.0234375, Total Reconstruction Loss: 24882241613824.0\n",
      "2023-07-19 12:30:26,510 - INFO - Save model at epoch 58\n",
      "0it [00:00, ?it/s]2023-07-19 12:30:26,624 - INFO - Epoch: [59/600], Step: [1/591], Loss: 169575216.0, KL Divergence: 676.459716796875, Reconstruction Loss: 169574544.0\n",
      "117it [00:10, 10.99it/s]2023-07-19 12:30:37,342 - INFO - Epoch: [59/600], Step: [119/591], Loss: 635097408.0, KL Divergence: 680.1920776367188, Reconstruction Loss: 635096704.0\n",
      "235it [00:21, 11.11it/s]2023-07-19 12:30:48,025 - INFO - Epoch: [59/600], Step: [237/591], Loss: 411931360.0, KL Divergence: 666.741455078125, Reconstruction Loss: 411930688.0\n",
      "353it [00:31, 10.97it/s]2023-07-19 12:30:58,663 - INFO - Epoch: [59/600], Step: [355/591], Loss: 393727776.0, KL Divergence: 664.2014770507812, Reconstruction Loss: 393727104.0\n",
      "471it [00:42, 11.21it/s]2023-07-19 12:31:09,319 - INFO - Epoch: [59/600], Step: [473/591], Loss: 359172128.0, KL Divergence: 667.5340576171875, Reconstruction Loss: 359171456.0\n",
      "589it [00:53, 11.06it/s]2023-07-19 12:31:19,897 - INFO - Epoch: [59/600], Step: [591/591], Loss: 288058048.0, KL Divergence: 691.5467529296875, Reconstruction Loss: 288057344.0\n",
      "591it [00:53, 11.07it/s]\n",
      "2023-07-19 12:31:19,899 - INFO - Epoch: [59/600], Total Loss: 24739439628288.0, Total KL Divergence: 50843892.375, Total Reconstruction Loss: 24739388784640.0\n",
      "2023-07-19 12:31:19,937 - INFO - Save model at epoch 59\n",
      "0it [00:00, ?it/s]2023-07-19 12:31:20,049 - INFO - Epoch: [60/600], Step: [1/591], Loss: 162337408.0, KL Divergence: 680.3424682617188, Reconstruction Loss: 162336720.0\n",
      "118it [00:10, 11.14it/s]2023-07-19 12:31:30,764 - INFO - Epoch: [60/600], Step: [119/591], Loss: 617583040.0, KL Divergence: 681.9383544921875, Reconstruction Loss: 617582336.0\n",
      "236it [00:21, 11.13it/s]2023-07-19 12:31:41,418 - INFO - Epoch: [60/600], Step: [237/591], Loss: 384520992.0, KL Divergence: 669.1494750976562, Reconstruction Loss: 384520320.0\n",
      "354it [00:32, 11.05it/s]2023-07-19 12:31:52,080 - INFO - Epoch: [60/600], Step: [355/591], Loss: 401936832.0, KL Divergence: 667.4757690429688, Reconstruction Loss: 401936160.0\n",
      "472it [00:42, 11.03it/s]2023-07-19 12:32:02,763 - INFO - Epoch: [60/600], Step: [473/591], Loss: 363884096.0, KL Divergence: 666.5635986328125, Reconstruction Loss: 363883424.0\n",
      "590it [00:53, 11.23it/s]2023-07-19 12:32:13,443 - INFO - Epoch: [60/600], Step: [591/591], Loss: 285208160.0, KL Divergence: 691.2645263671875, Reconstruction Loss: 285207456.0\n",
      "591it [00:53, 11.05it/s]\n",
      "2023-07-19 12:32:13,445 - INFO - Epoch: [60/600], Total Loss: 24656428488704.0, Total KL Divergence: 50944062.484375, Total Reconstruction Loss: 24656377612288.0\n",
      "2023-07-19 12:32:13,485 - INFO - Save model at epoch 60\n",
      "0it [00:00, ?it/s]2023-07-19 12:32:13,596 - INFO - Epoch: [61/600], Step: [1/591], Loss: 171498416.0, KL Divergence: 680.2906494140625, Reconstruction Loss: 171497728.0\n",
      "118it [00:10, 11.03it/s]2023-07-19 12:32:24,490 - INFO - Epoch: [61/600], Step: [119/591], Loss: 625797888.0, KL Divergence: 684.205322265625, Reconstruction Loss: 625797184.0\n",
      "236it [00:21, 10.92it/s]2023-07-19 12:32:35,442 - INFO - Epoch: [61/600], Step: [237/591], Loss: 374446560.0, KL Divergence: 668.7166137695312, Reconstruction Loss: 374445888.0\n",
      "354it [00:32, 10.78it/s]2023-07-19 12:32:46,268 - INFO - Epoch: [61/600], Step: [355/591], Loss: 395138944.0, KL Divergence: 668.356201171875, Reconstruction Loss: 395138272.0\n",
      "472it [00:43, 11.18it/s]2023-07-19 12:32:57,034 - INFO - Epoch: [61/600], Step: [473/591], Loss: 362425888.0, KL Divergence: 673.642822265625, Reconstruction Loss: 362425216.0\n",
      "590it [00:54, 10.92it/s]2023-07-19 12:33:07,744 - INFO - Epoch: [61/600], Step: [591/591], Loss: 287908832.0, KL Divergence: 694.23046875, Reconstruction Loss: 287908128.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 12:33:07,745 - INFO - Epoch: [61/600], Total Loss: 24443427446784.0, Total KL Divergence: 51180672.7734375, Total Reconstruction Loss: 24443376441344.0\n",
      "2023-07-19 12:33:07,783 - INFO - Save model at epoch 61\n",
      "0it [00:00, ?it/s]2023-07-19 12:33:07,897 - INFO - Epoch: [62/600], Step: [1/591], Loss: 167869808.0, KL Divergence: 683.255615234375, Reconstruction Loss: 167869120.0\n",
      "117it [00:10, 10.91it/s]2023-07-19 12:33:18,675 - INFO - Epoch: [62/600], Step: [119/591], Loss: 656306432.0, KL Divergence: 684.0593872070312, Reconstruction Loss: 656305728.0\n",
      "235it [00:21, 10.62it/s]2023-07-19 12:33:29,526 - INFO - Epoch: [62/600], Step: [237/591], Loss: 373546176.0, KL Divergence: 671.21630859375, Reconstruction Loss: 373545504.0\n",
      "353it [00:32, 10.45it/s]2023-07-19 12:33:40,272 - INFO - Epoch: [62/600], Step: [355/591], Loss: 397678624.0, KL Divergence: 668.5177612304688, Reconstruction Loss: 397677952.0\n",
      "471it [00:43, 10.98it/s]2023-07-19 12:33:51,072 - INFO - Epoch: [62/600], Step: [473/591], Loss: 375072032.0, KL Divergence: 675.4616088867188, Reconstruction Loss: 375071360.0\n",
      "589it [00:53, 11.00it/s]2023-07-19 12:34:01,730 - INFO - Epoch: [62/600], Step: [591/591], Loss: 295736448.0, KL Divergence: 698.7699584960938, Reconstruction Loss: 295735744.0\n",
      "591it [00:53, 10.96it/s]\n",
      "2023-07-19 12:34:01,732 - INFO - Epoch: [62/600], Total Loss: 24359507757056.0, Total KL Divergence: 51253391.375, Total Reconstruction Loss: 24359456681984.0\n",
      "2023-07-19 12:34:01,780 - INFO - Save model at epoch 62\n",
      "0it [00:00, ?it/s]2023-07-19 12:34:01,888 - INFO - Epoch: [63/600], Step: [1/591], Loss: 158088880.0, KL Divergence: 687.726806640625, Reconstruction Loss: 158088192.0\n",
      "117it [00:10, 10.87it/s]2023-07-19 12:34:12,707 - INFO - Epoch: [63/600], Step: [119/591], Loss: 611894592.0, KL Divergence: 690.9283447265625, Reconstruction Loss: 611893888.0\n",
      "235it [00:21, 11.11it/s]2023-07-19 12:34:23,319 - INFO - Epoch: [63/600], Step: [237/591], Loss: 365523424.0, KL Divergence: 677.7420654296875, Reconstruction Loss: 365522752.0\n",
      "353it [00:32, 10.80it/s]2023-07-19 12:34:34,270 - INFO - Epoch: [63/600], Step: [355/591], Loss: 388397504.0, KL Divergence: 675.0603637695312, Reconstruction Loss: 388396832.0\n",
      "471it [00:43, 11.08it/s]2023-07-19 12:34:45,163 - INFO - Epoch: [63/600], Step: [473/591], Loss: 357804640.0, KL Divergence: 675.7420043945312, Reconstruction Loss: 357803968.0\n",
      "589it [00:54, 11.22it/s]2023-07-19 12:34:55,947 - INFO - Epoch: [63/600], Step: [591/591], Loss: 284104576.0, KL Divergence: 696.8330078125, Reconstruction Loss: 284103872.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 12:34:55,949 - INFO - Epoch: [63/600], Total Loss: 24099823069184.0, Total KL Divergence: 51625479.4140625, Total Reconstruction Loss: 24099771656192.0\n",
      "2023-07-19 12:34:55,990 - INFO - Save model at epoch 63\n",
      "0it [00:00, ?it/s]2023-07-19 12:34:56,092 - INFO - Epoch: [64/600], Step: [1/591], Loss: 167049072.0, KL Divergence: 686.4293212890625, Reconstruction Loss: 167048384.0\n",
      "118it [00:10, 10.83it/s]2023-07-19 12:35:06,941 - INFO - Epoch: [64/600], Step: [119/591], Loss: 593891200.0, KL Divergence: 687.738525390625, Reconstruction Loss: 593890496.0\n",
      "236it [00:21, 10.90it/s]2023-07-19 12:35:17,878 - INFO - Epoch: [64/600], Step: [237/591], Loss: 369485280.0, KL Divergence: 675.7432861328125, Reconstruction Loss: 369484608.0\n",
      "354it [00:32, 10.58it/s]2023-07-19 12:35:28,869 - INFO - Epoch: [64/600], Step: [355/591], Loss: 400755968.0, KL Divergence: 671.1204223632812, Reconstruction Loss: 400755296.0\n",
      "472it [00:43, 10.68it/s]2023-07-19 12:35:39,965 - INFO - Epoch: [64/600], Step: [473/591], Loss: 361340576.0, KL Divergence: 672.7321166992188, Reconstruction Loss: 361339904.0\n",
      "590it [00:54, 10.44it/s]2023-07-19 12:35:50,928 - INFO - Epoch: [64/600], Step: [591/591], Loss: 287650176.0, KL Divergence: 692.892822265625, Reconstruction Loss: 287649472.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 12:35:50,930 - INFO - Epoch: [64/600], Total Loss: 23980651208704.0, Total KL Divergence: 51327196.5390625, Total Reconstruction Loss: 23980600078336.0\n",
      "2023-07-19 12:35:50,970 - INFO - Save model at epoch 64\n",
      "0it [00:00, ?it/s]2023-07-19 12:35:51,088 - INFO - Epoch: [65/600], Step: [1/591], Loss: 159473952.0, KL Divergence: 682.03759765625, Reconstruction Loss: 159473264.0\n",
      "117it [00:10, 10.89it/s]2023-07-19 12:36:01,903 - INFO - Epoch: [65/600], Step: [119/591], Loss: 582042944.0, KL Divergence: 685.562255859375, Reconstruction Loss: 582042240.0\n",
      "235it [00:21, 10.85it/s]2023-07-19 12:36:12,815 - INFO - Epoch: [65/600], Step: [237/591], Loss: 365652032.0, KL Divergence: 675.35400390625, Reconstruction Loss: 365651360.0\n",
      "353it [00:32, 10.85it/s]2023-07-19 12:36:23,592 - INFO - Epoch: [65/600], Step: [355/591], Loss: 404614592.0, KL Divergence: 679.5443115234375, Reconstruction Loss: 404613920.0\n",
      "471it [00:43, 11.00it/s]2023-07-19 12:36:34,404 - INFO - Epoch: [65/600], Step: [473/591], Loss: 357144320.0, KL Divergence: 681.7186279296875, Reconstruction Loss: 357143648.0\n",
      "589it [00:53, 11.09it/s]2023-07-19 12:36:44,966 - INFO - Epoch: [65/600], Step: [591/591], Loss: 279101216.0, KL Divergence: 703.2001342773438, Reconstruction Loss: 279100512.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 12:36:44,968 - INFO - Epoch: [65/600], Total Loss: 23749181841408.0, Total KL Divergence: 51594357.703125, Total Reconstruction Loss: 23749130508288.0\n",
      "2023-07-19 12:36:45,010 - INFO - Save model at epoch 65\n",
      "0it [00:00, ?it/s]2023-07-19 12:36:45,129 - INFO - Epoch: [66/600], Step: [1/591], Loss: 158627904.0, KL Divergence: 692.3113403320312, Reconstruction Loss: 158627216.0\n",
      "117it [00:10, 10.98it/s]2023-07-19 12:36:55,951 - INFO - Epoch: [66/600], Step: [119/591], Loss: 576668224.0, KL Divergence: 695.197265625, Reconstruction Loss: 576667520.0\n",
      "235it [00:21, 11.05it/s]2023-07-19 12:37:06,772 - INFO - Epoch: [66/600], Step: [237/591], Loss: 371331360.0, KL Divergence: 676.6945190429688, Reconstruction Loss: 371330688.0\n",
      "353it [00:32, 10.83it/s]2023-07-19 12:37:17,541 - INFO - Epoch: [66/600], Step: [355/591], Loss: 386169024.0, KL Divergence: 675.0262451171875, Reconstruction Loss: 386168352.0\n",
      "471it [00:43, 11.09it/s]2023-07-19 12:37:28,472 - INFO - Epoch: [66/600], Step: [473/591], Loss: 358527776.0, KL Divergence: 677.34033203125, Reconstruction Loss: 358527104.0\n",
      "589it [00:54, 10.84it/s]2023-07-19 12:37:39,392 - INFO - Epoch: [66/600], Step: [591/591], Loss: 285634720.0, KL Divergence: 699.2272338867188, Reconstruction Loss: 285634016.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 12:37:39,395 - INFO - Epoch: [66/600], Total Loss: 23644681408512.0, Total KL Divergence: 51717520.6484375, Total Reconstruction Loss: 23644629893120.0\n",
      "2023-07-19 12:37:39,435 - INFO - Save model at epoch 66\n",
      "0it [00:00, ?it/s]2023-07-19 12:37:39,539 - INFO - Epoch: [67/600], Step: [1/591], Loss: 161846192.0, KL Divergence: 689.2288208007812, Reconstruction Loss: 161845504.0\n",
      "118it [00:10, 11.03it/s]2023-07-19 12:37:50,459 - INFO - Epoch: [67/600], Step: [119/591], Loss: 578510016.0, KL Divergence: 690.67578125, Reconstruction Loss: 578509312.0\n",
      "236it [00:21, 11.17it/s]2023-07-19 12:38:01,274 - INFO - Epoch: [67/600], Step: [237/591], Loss: 361265440.0, KL Divergence: 675.182861328125, Reconstruction Loss: 361264768.0\n",
      "354it [00:32, 11.12it/s]2023-07-19 12:38:12,105 - INFO - Epoch: [67/600], Step: [355/591], Loss: 389078592.0, KL Divergence: 677.0368041992188, Reconstruction Loss: 389077920.0\n",
      "472it [00:43, 10.94it/s]2023-07-19 12:38:23,003 - INFO - Epoch: [67/600], Step: [473/591], Loss: 354084640.0, KL Divergence: 676.6929931640625, Reconstruction Loss: 354083968.0\n",
      "590it [00:54, 10.90it/s]2023-07-19 12:38:33,734 - INFO - Epoch: [67/600], Step: [591/591], Loss: 280198400.0, KL Divergence: 700.7369995117188, Reconstruction Loss: 280197696.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 12:38:33,736 - INFO - Epoch: [67/600], Total Loss: 23530734735360.0, Total KL Divergence: 51662798.6953125, Total Reconstruction Loss: 23530683305984.0\n",
      "2023-07-19 12:38:33,774 - INFO - Save model at epoch 67\n",
      "0it [00:00, ?it/s]2023-07-19 12:38:33,892 - INFO - Epoch: [68/600], Step: [1/591], Loss: 165279120.0, KL Divergence: 688.6954345703125, Reconstruction Loss: 165278432.0\n",
      "117it [00:10, 10.80it/s]2023-07-19 12:38:44,908 - INFO - Epoch: [68/600], Step: [119/591], Loss: 563649280.0, KL Divergence: 691.406494140625, Reconstruction Loss: 563648576.0\n",
      "235it [00:21, 10.93it/s]2023-07-19 12:38:55,880 - INFO - Epoch: [68/600], Step: [237/591], Loss: 364522368.0, KL Divergence: 680.937744140625, Reconstruction Loss: 364521696.0\n",
      "353it [00:33, 10.65it/s]2023-07-19 12:39:07,033 - INFO - Epoch: [68/600], Step: [355/591], Loss: 384140640.0, KL Divergence: 675.1622314453125, Reconstruction Loss: 384139968.0\n",
      "471it [00:44, 10.17it/s]2023-07-19 12:39:18,112 - INFO - Epoch: [68/600], Step: [473/591], Loss: 354241440.0, KL Divergence: 677.6998291015625, Reconstruction Loss: 354240768.0\n",
      "589it [00:55, 10.76it/s]2023-07-19 12:39:29,119 - INFO - Epoch: [68/600], Step: [591/591], Loss: 280093216.0, KL Divergence: 700.0509643554688, Reconstruction Loss: 280092512.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 12:39:29,121 - INFO - Epoch: [68/600], Total Loss: 23442514835456.0, Total KL Divergence: 51689818.6796875, Total Reconstruction Loss: 23442463338496.0\n",
      "2023-07-19 12:39:29,161 - INFO - Save model at epoch 68\n",
      "0it [00:00, ?it/s]2023-07-19 12:39:29,277 - INFO - Epoch: [69/600], Step: [1/591], Loss: 159745152.0, KL Divergence: 688.7286376953125, Reconstruction Loss: 159744464.0\n",
      "117it [00:10, 10.88it/s]2023-07-19 12:39:40,137 - INFO - Epoch: [69/600], Step: [119/591], Loss: 574353856.0, KL Divergence: 689.79443359375, Reconstruction Loss: 574353152.0\n",
      "235it [00:21, 10.77it/s]2023-07-19 12:39:50,993 - INFO - Epoch: [69/600], Step: [237/591], Loss: 354541696.0, KL Divergence: 675.0780029296875, Reconstruction Loss: 354541024.0\n",
      "353it [00:32, 11.02it/s]2023-07-19 12:40:01,851 - INFO - Epoch: [69/600], Step: [355/591], Loss: 377396352.0, KL Divergence: 675.2838134765625, Reconstruction Loss: 377395680.0\n",
      "471it [00:43, 10.85it/s]2023-07-19 12:40:12,796 - INFO - Epoch: [69/600], Step: [473/591], Loss: 360810336.0, KL Divergence: 678.02294921875, Reconstruction Loss: 360809664.0\n",
      "589it [00:54, 11.21it/s]2023-07-19 12:40:23,476 - INFO - Epoch: [69/600], Step: [591/591], Loss: 282973120.0, KL Divergence: 701.712158203125, Reconstruction Loss: 282972416.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 12:40:23,478 - INFO - Epoch: [69/600], Total Loss: 23298964615168.0, Total KL Divergence: 51650268.828125, Total Reconstruction Loss: 23298913198080.0\n",
      "2023-07-19 12:40:23,519 - INFO - Save model at epoch 69\n",
      "0it [00:00, ?it/s]2023-07-19 12:40:23,634 - INFO - Epoch: [70/600], Step: [1/591], Loss: 160759440.0, KL Divergence: 690.6142578125, Reconstruction Loss: 160758752.0\n",
      "117it [00:10, 10.52it/s]2023-07-19 12:40:34,721 - INFO - Epoch: [70/600], Step: [119/591], Loss: 621335104.0, KL Divergence: 690.17431640625, Reconstruction Loss: 621334400.0\n",
      "235it [00:21, 10.92it/s]2023-07-19 12:40:45,656 - INFO - Epoch: [70/600], Step: [237/591], Loss: 360664608.0, KL Divergence: 676.5028076171875, Reconstruction Loss: 360663936.0\n",
      "353it [00:32, 10.93it/s]2023-07-19 12:40:56,438 - INFO - Epoch: [70/600], Step: [355/591], Loss: 383344608.0, KL Divergence: 677.1363525390625, Reconstruction Loss: 383343936.0\n",
      "471it [00:43, 10.61it/s]2023-07-19 12:41:07,302 - INFO - Epoch: [70/600], Step: [473/591], Loss: 353338144.0, KL Divergence: 678.13427734375, Reconstruction Loss: 353337472.0\n",
      "589it [00:54, 11.08it/s]2023-07-19 12:41:18,005 - INFO - Epoch: [70/600], Step: [591/591], Loss: 278032576.0, KL Divergence: 701.4156494140625, Reconstruction Loss: 278031872.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 12:41:18,007 - INFO - Epoch: [70/600], Total Loss: 23401381718016.0, Total KL Divergence: 51775881.875, Total Reconstruction Loss: 23401330100224.0\n",
      "2023-07-19 12:41:18,051 - INFO - Save model at epoch 70\n",
      "0it [00:00, ?it/s]2023-07-19 12:41:18,172 - INFO - Epoch: [71/600], Step: [1/591], Loss: 163662928.0, KL Divergence: 690.2750854492188, Reconstruction Loss: 163662240.0\n",
      "117it [00:10, 10.72it/s]2023-07-19 12:41:29,081 - INFO - Epoch: [71/600], Step: [119/591], Loss: 567385792.0, KL Divergence: 690.662841796875, Reconstruction Loss: 567385088.0\n",
      "235it [00:21, 11.04it/s]2023-07-19 12:41:39,983 - INFO - Epoch: [71/600], Step: [237/591], Loss: 363431424.0, KL Divergence: 679.834716796875, Reconstruction Loss: 363430752.0\n",
      "353it [00:32, 11.01it/s]2023-07-19 12:41:50,748 - INFO - Epoch: [71/600], Step: [355/591], Loss: 379176352.0, KL Divergence: 681.6588745117188, Reconstruction Loss: 379175680.0\n",
      "471it [00:43, 10.99it/s]2023-07-19 12:42:01,698 - INFO - Epoch: [71/600], Step: [473/591], Loss: 357754080.0, KL Divergence: 683.7301025390625, Reconstruction Loss: 357753408.0\n",
      "589it [00:54, 11.12it/s]2023-07-19 12:42:12,303 - INFO - Epoch: [71/600], Step: [591/591], Loss: 278013248.0, KL Divergence: 702.60546875, Reconstruction Loss: 278012544.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 12:42:12,305 - INFO - Epoch: [71/600], Total Loss: 23230216689664.0, Total KL Divergence: 51926642.765625, Total Reconstruction Loss: 23230164920320.0\n",
      "2023-07-19 12:42:12,353 - INFO - Save model at epoch 71\n",
      "0it [00:00, ?it/s]2023-07-19 12:42:12,463 - INFO - Epoch: [72/600], Step: [1/591], Loss: 159976944.0, KL Divergence: 691.7857666015625, Reconstruction Loss: 159976256.0\n",
      "117it [00:10, 10.93it/s]2023-07-19 12:42:23,284 - INFO - Epoch: [72/600], Step: [119/591], Loss: 539827648.0, KL Divergence: 691.60498046875, Reconstruction Loss: 539826944.0\n",
      "235it [00:21, 11.06it/s]2023-07-19 12:42:34,172 - INFO - Epoch: [72/600], Step: [237/591], Loss: 353578464.0, KL Divergence: 677.8287353515625, Reconstruction Loss: 353577792.0\n",
      "353it [00:32, 10.84it/s]2023-07-19 12:42:45,071 - INFO - Epoch: [72/600], Step: [355/591], Loss: 366809024.0, KL Divergence: 679.792724609375, Reconstruction Loss: 366808352.0\n",
      "471it [00:43, 10.63it/s]2023-07-19 12:42:55,991 - INFO - Epoch: [72/600], Step: [473/591], Loss: 388676256.0, KL Divergence: 684.6583251953125, Reconstruction Loss: 388675584.0\n",
      "589it [00:54, 10.94it/s]2023-07-19 12:43:06,703 - INFO - Epoch: [72/600], Step: [591/591], Loss: 273943488.0, KL Divergence: 705.8385620117188, Reconstruction Loss: 273942784.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 12:43:06,706 - INFO - Epoch: [72/600], Total Loss: 23131171117056.0, Total KL Divergence: 51932410.9765625, Total Reconstruction Loss: 23131119284224.0\n",
      "2023-07-19 12:43:06,745 - INFO - Save model at epoch 72\n",
      "0it [00:00, ?it/s]2023-07-19 12:43:06,865 - INFO - Epoch: [73/600], Step: [1/591], Loss: 165732208.0, KL Divergence: 695.02783203125, Reconstruction Loss: 165731520.0\n",
      "117it [00:10, 10.53it/s]2023-07-19 12:43:17,834 - INFO - Epoch: [73/600], Step: [119/591], Loss: 537946304.0, KL Divergence: 693.6041259765625, Reconstruction Loss: 537945600.0\n",
      "235it [00:21, 11.00it/s]2023-07-19 12:43:28,772 - INFO - Epoch: [73/600], Step: [237/591], Loss: 346561952.0, KL Divergence: 682.8541870117188, Reconstruction Loss: 346561280.0\n",
      "353it [00:32, 10.91it/s]2023-07-19 12:43:39,597 - INFO - Epoch: [73/600], Step: [355/591], Loss: 375988576.0, KL Divergence: 685.7320556640625, Reconstruction Loss: 375987904.0\n",
      "471it [00:43, 10.49it/s]2023-07-19 12:43:50,506 - INFO - Epoch: [73/600], Step: [473/591], Loss: 379021952.0, KL Divergence: 691.359130859375, Reconstruction Loss: 379021248.0\n",
      "589it [00:54, 10.59it/s]2023-07-19 12:44:01,338 - INFO - Epoch: [73/600], Step: [591/591], Loss: 272260608.0, KL Divergence: 714.2301635742188, Reconstruction Loss: 272259904.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 12:44:01,340 - INFO - Epoch: [73/600], Total Loss: 23028659736576.0, Total KL Divergence: 52277878.078125, Total Reconstruction Loss: 23028607356928.0\n",
      "2023-07-19 12:44:01,380 - INFO - Save model at epoch 73\n",
      "0it [00:00, ?it/s]2023-07-19 12:44:01,490 - INFO - Epoch: [74/600], Step: [1/591], Loss: 161306560.0, KL Divergence: 703.74365234375, Reconstruction Loss: 161305856.0\n",
      "117it [00:10, 10.75it/s]2023-07-19 12:44:12,517 - INFO - Epoch: [74/600], Step: [119/591], Loss: 551105600.0, KL Divergence: 703.7977294921875, Reconstruction Loss: 551104896.0\n",
      "235it [00:21, 10.86it/s]2023-07-19 12:44:23,549 - INFO - Epoch: [74/600], Step: [237/591], Loss: 342590592.0, KL Divergence: 693.7781372070312, Reconstruction Loss: 342589888.0\n",
      "353it [00:32, 10.98it/s]2023-07-19 12:44:34,492 - INFO - Epoch: [74/600], Step: [355/591], Loss: 366820096.0, KL Divergence: 697.1744384765625, Reconstruction Loss: 366819392.0\n",
      "471it [00:43, 10.33it/s]2023-07-19 12:44:45,573 - INFO - Epoch: [74/600], Step: [473/591], Loss: 384432704.0, KL Divergence: 699.4276733398438, Reconstruction Loss: 384432000.0\n",
      "589it [00:54, 10.21it/s]2023-07-19 12:44:56,349 - INFO - Epoch: [74/600], Step: [591/591], Loss: 276356800.0, KL Divergence: 720.8067626953125, Reconstruction Loss: 276356064.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 12:44:56,351 - INFO - Epoch: [74/600], Total Loss: 22951873992704.0, Total KL Divergence: 53052286.1640625, Total Reconstruction Loss: 22951820750848.0\n",
      "2023-07-19 12:44:56,391 - INFO - Save model at epoch 74\n",
      "0it [00:00, ?it/s]2023-07-19 12:44:56,508 - INFO - Epoch: [75/600], Step: [1/591], Loss: 162892608.0, KL Divergence: 709.8590087890625, Reconstruction Loss: 162891904.0\n",
      "117it [00:10, 10.90it/s]2023-07-19 12:45:07,497 - INFO - Epoch: [75/600], Step: [119/591], Loss: 541433088.0, KL Divergence: 708.6988525390625, Reconstruction Loss: 541432384.0\n",
      "235it [00:21, 10.83it/s]2023-07-19 12:45:18,326 - INFO - Epoch: [75/600], Step: [237/591], Loss: 334645248.0, KL Divergence: 693.7384643554688, Reconstruction Loss: 334644544.0\n",
      "353it [00:32, 11.30it/s]2023-07-19 12:45:29,061 - INFO - Epoch: [75/600], Step: [355/591], Loss: 360467616.0, KL Divergence: 692.9691772460938, Reconstruction Loss: 360466912.0\n",
      "472it [00:43,  9.80it/s]2023-07-19 12:45:39,755 - INFO - Epoch: [75/600], Step: [473/591], Loss: 378107296.0, KL Divergence: 693.8121337890625, Reconstruction Loss: 378106592.0\n",
      "589it [00:53, 11.06it/s]2023-07-19 12:45:50,409 - INFO - Epoch: [75/600], Step: [591/591], Loss: 279365536.0, KL Divergence: 718.58544921875, Reconstruction Loss: 279364832.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 12:45:50,411 - INFO - Epoch: [75/600], Total Loss: 22680886484992.0, Total KL Divergence: 53065878.5703125, Total Reconstruction Loss: 22680833241088.0\n",
      "2023-07-19 12:45:50,453 - INFO - Save model at epoch 75\n",
      "0it [00:00, ?it/s]2023-07-19 12:45:50,559 - INFO - Epoch: [76/600], Step: [1/591], Loss: 162337376.0, KL Divergence: 707.3888549804688, Reconstruction Loss: 162336672.0\n",
      "117it [00:10, 10.91it/s]2023-07-19 12:46:01,581 - INFO - Epoch: [76/600], Step: [119/591], Loss: 540939904.0, KL Divergence: 707.2667846679688, Reconstruction Loss: 540939200.0\n",
      "235it [00:21, 11.03it/s]2023-07-19 12:46:12,450 - INFO - Epoch: [76/600], Step: [237/591], Loss: 354854784.0, KL Divergence: 693.1019287109375, Reconstruction Loss: 354854080.0\n",
      "353it [00:32, 10.75it/s]2023-07-19 12:46:23,357 - INFO - Epoch: [76/600], Step: [355/591], Loss: 363155072.0, KL Divergence: 693.4907836914062, Reconstruction Loss: 363154368.0\n",
      "471it [00:43, 10.36it/s]2023-07-19 12:46:34,289 - INFO - Epoch: [76/600], Step: [473/591], Loss: 375130016.0, KL Divergence: 696.8703002929688, Reconstruction Loss: 375129312.0\n",
      "589it [00:54, 10.99it/s]2023-07-19 12:46:45,001 - INFO - Epoch: [76/600], Step: [591/591], Loss: 274071840.0, KL Divergence: 717.583984375, Reconstruction Loss: 274071136.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 12:46:45,004 - INFO - Epoch: [76/600], Total Loss: 22724412565504.0, Total KL Divergence: 53021213.4375, Total Reconstruction Loss: 22724359344128.0\n",
      "2023-07-19 12:46:45,043 - INFO - Save model at epoch 76\n",
      "0it [00:00, ?it/s]2023-07-19 12:46:45,159 - INFO - Epoch: [77/600], Step: [1/591], Loss: 172992864.0, KL Divergence: 706.339599609375, Reconstruction Loss: 172992160.0\n",
      "117it [00:10, 10.95it/s]2023-07-19 12:46:56,041 - INFO - Epoch: [77/600], Step: [119/591], Loss: 554752832.0, KL Divergence: 705.280029296875, Reconstruction Loss: 554752128.0\n",
      "235it [00:21, 10.92it/s]2023-07-19 12:47:06,947 - INFO - Epoch: [77/600], Step: [237/591], Loss: 353467840.0, KL Divergence: 693.0286865234375, Reconstruction Loss: 353467136.0\n",
      "353it [00:32, 10.91it/s]2023-07-19 12:47:17,905 - INFO - Epoch: [77/600], Step: [355/591], Loss: 360909248.0, KL Divergence: 690.4171752929688, Reconstruction Loss: 360908544.0\n",
      "471it [00:43,  9.99it/s]2023-07-19 12:47:28,825 - INFO - Epoch: [77/600], Step: [473/591], Loss: 357367200.0, KL Divergence: 694.0045166015625, Reconstruction Loss: 357366496.0\n",
      "589it [00:54, 10.82it/s]2023-07-19 12:47:39,639 - INFO - Epoch: [77/600], Step: [591/591], Loss: 284602560.0, KL Divergence: 717.5753173828125, Reconstruction Loss: 284601856.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 12:47:39,641 - INFO - Epoch: [77/600], Total Loss: 22653672472576.0, Total KL Divergence: 52919235.03125, Total Reconstruction Loss: 22653619343360.0\n",
      "2023-07-19 12:47:39,699 - INFO - Save model at epoch 77\n",
      "0it [00:00, ?it/s]2023-07-19 12:47:39,820 - INFO - Epoch: [78/600], Step: [1/591], Loss: 169011200.0, KL Divergence: 706.4522094726562, Reconstruction Loss: 169010496.0\n",
      "117it [00:10, 10.64it/s]2023-07-19 12:47:50,838 - INFO - Epoch: [78/600], Step: [119/591], Loss: 572589568.0, KL Divergence: 705.98486328125, Reconstruction Loss: 572588864.0\n",
      "235it [00:21, 10.92it/s]2023-07-19 12:48:01,813 - INFO - Epoch: [78/600], Step: [237/591], Loss: 344350592.0, KL Divergence: 694.181640625, Reconstruction Loss: 344349888.0\n",
      "353it [00:32, 11.02it/s]2023-07-19 12:48:12,593 - INFO - Epoch: [78/600], Step: [355/591], Loss: 356097824.0, KL Divergence: 696.5257568359375, Reconstruction Loss: 356097120.0\n",
      "471it [00:43, 10.15it/s]2023-07-19 12:48:23,511 - INFO - Epoch: [78/600], Step: [473/591], Loss: 355602944.0, KL Divergence: 699.2349853515625, Reconstruction Loss: 355602240.0\n",
      "589it [00:54, 11.20it/s]2023-07-19 12:48:34,303 - INFO - Epoch: [78/600], Step: [591/591], Loss: 278438240.0, KL Divergence: 720.6336669921875, Reconstruction Loss: 278437504.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 12:48:34,305 - INFO - Epoch: [78/600], Total Loss: 22469823612928.0, Total KL Divergence: 53086972.0703125, Total Reconstruction Loss: 22469770352640.0\n",
      "2023-07-19 12:48:34,346 - INFO - Save model at epoch 78\n",
      "0it [00:00, ?it/s]2023-07-19 12:48:34,456 - INFO - Epoch: [79/600], Step: [1/591], Loss: 171088384.0, KL Divergence: 710.0916137695312, Reconstruction Loss: 171087680.0\n",
      "117it [00:10, 10.76it/s]2023-07-19 12:48:45,534 - INFO - Epoch: [79/600], Step: [119/591], Loss: 526196608.0, KL Divergence: 709.3780517578125, Reconstruction Loss: 526195904.0\n",
      "235it [00:22, 10.66it/s]2023-07-19 12:48:56,630 - INFO - Epoch: [79/600], Step: [237/591], Loss: 367808576.0, KL Divergence: 698.6220092773438, Reconstruction Loss: 367807872.0\n",
      "353it [00:33, 11.01it/s]2023-07-19 12:49:07,612 - INFO - Epoch: [79/600], Step: [355/591], Loss: 362386528.0, KL Divergence: 696.3018798828125, Reconstruction Loss: 362385824.0\n",
      "471it [00:44, 10.35it/s]2023-07-19 12:49:18,779 - INFO - Epoch: [79/600], Step: [473/591], Loss: 342178656.0, KL Divergence: 701.1646728515625, Reconstruction Loss: 342177952.0\n",
      "589it [00:55, 10.43it/s]2023-07-19 12:49:30,325 - INFO - Epoch: [79/600], Step: [591/591], Loss: 273097888.0, KL Divergence: 724.525146484375, Reconstruction Loss: 273097152.0\n",
      "591it [00:55, 10.56it/s]\n",
      "2023-07-19 12:49:30,327 - INFO - Epoch: [79/600], Total Loss: 22449214877696.0, Total KL Divergence: 53318626.4609375, Total Reconstruction Loss: 22449161527296.0\n",
      "2023-07-19 12:49:30,378 - INFO - Save model at epoch 79\n",
      "0it [00:00, ?it/s]2023-07-19 12:49:30,492 - INFO - Epoch: [80/600], Step: [1/591], Loss: 174193744.0, KL Divergence: 714.9291381835938, Reconstruction Loss: 174193024.0\n",
      "117it [00:11,  8.88it/s]2023-07-19 12:49:42,286 - INFO - Epoch: [80/600], Step: [119/591], Loss: 531427264.0, KL Divergence: 712.9004516601562, Reconstruction Loss: 531426560.0\n",
      "235it [00:23, 10.09it/s]2023-07-19 12:49:54,139 - INFO - Epoch: [80/600], Step: [237/591], Loss: 372890688.0, KL Divergence: 703.678955078125, Reconstruction Loss: 372889984.0\n",
      "353it [00:34, 10.71it/s]2023-07-19 12:50:05,561 - INFO - Epoch: [80/600], Step: [355/591], Loss: 365143296.0, KL Divergence: 703.4661865234375, Reconstruction Loss: 365142592.0\n",
      "471it [00:45, 10.92it/s]2023-07-19 12:50:16,490 - INFO - Epoch: [80/600], Step: [473/591], Loss: 349997120.0, KL Divergence: 707.8458251953125, Reconstruction Loss: 349996416.0\n",
      "589it [00:57, 10.59it/s]2023-07-19 12:50:27,720 - INFO - Epoch: [80/600], Step: [591/591], Loss: 270075936.0, KL Divergence: 729.58984375, Reconstruction Loss: 270075200.0\n",
      "591it [00:57, 10.31it/s]\n",
      "2023-07-19 12:50:27,723 - INFO - Epoch: [80/600], Total Loss: 22377466269696.0, Total KL Divergence: 53713373.9375, Total Reconstruction Loss: 22377412706304.0\n",
      "2023-07-19 12:50:27,766 - INFO - Save model at epoch 80\n",
      "0it [00:00, ?it/s]2023-07-19 12:50:27,876 - INFO - Epoch: [81/600], Step: [1/591], Loss: 169540848.0, KL Divergence: 720.0396728515625, Reconstruction Loss: 169540128.0\n",
      "117it [00:11, 10.54it/s]2023-07-19 12:50:39,063 - INFO - Epoch: [81/600], Step: [119/591], Loss: 543287680.0, KL Divergence: 719.2007446289062, Reconstruction Loss: 543286976.0\n",
      "235it [00:22, 10.86it/s]2023-07-19 12:50:50,357 - INFO - Epoch: [81/600], Step: [237/591], Loss: 404884224.0, KL Divergence: 707.6471557617188, Reconstruction Loss: 404883520.0\n",
      "353it [00:33, 11.08it/s]2023-07-19 12:51:01,286 - INFO - Epoch: [81/600], Step: [355/591], Loss: 348828928.0, KL Divergence: 706.4654541015625, Reconstruction Loss: 348828224.0\n",
      "471it [00:44, 10.80it/s]2023-07-19 12:51:12,225 - INFO - Epoch: [81/600], Step: [473/591], Loss: 337716384.0, KL Divergence: 710.5233764648438, Reconstruction Loss: 337715680.0\n",
      "589it [00:55, 11.02it/s]2023-07-19 12:51:23,417 - INFO - Epoch: [81/600], Step: [591/591], Loss: 281995712.0, KL Divergence: 732.3988647460938, Reconstruction Loss: 281994976.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 12:51:23,420 - INFO - Epoch: [81/600], Total Loss: 22424552157184.0, Total KL Divergence: 54017143.6796875, Total Reconstruction Loss: 22424498345984.0\n",
      "2023-07-19 12:51:23,464 - INFO - Save model at epoch 81\n",
      "0it [00:00, ?it/s]2023-07-19 12:51:23,573 - INFO - Epoch: [82/600], Step: [1/591], Loss: 167957952.0, KL Divergence: 722.5333251953125, Reconstruction Loss: 167957232.0\n",
      "117it [00:10, 10.60it/s]2023-07-19 12:51:34,540 - INFO - Epoch: [82/600], Step: [119/591], Loss: 530712384.0, KL Divergence: 719.9754028320312, Reconstruction Loss: 530711680.0\n",
      "235it [00:21, 10.76it/s]2023-07-19 12:51:45,557 - INFO - Epoch: [82/600], Step: [237/591], Loss: 367521440.0, KL Divergence: 708.637451171875, Reconstruction Loss: 367520736.0\n",
      "353it [00:33, 10.65it/s]2023-07-19 12:51:56,690 - INFO - Epoch: [82/600], Step: [355/591], Loss: 350239360.0, KL Divergence: 710.7727661132812, Reconstruction Loss: 350238656.0\n",
      "471it [00:44, 10.79it/s]2023-07-19 12:52:07,820 - INFO - Epoch: [82/600], Step: [473/591], Loss: 331117632.0, KL Divergence: 715.4744873046875, Reconstruction Loss: 331116928.0\n",
      "589it [00:55, 11.03it/s]2023-07-19 12:52:18,779 - INFO - Epoch: [82/600], Step: [591/591], Loss: 268426496.0, KL Divergence: 737.0771484375, Reconstruction Loss: 268425760.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 12:52:18,781 - INFO - Epoch: [82/600], Total Loss: 22250935318528.0, Total KL Divergence: 54261340.359375, Total Reconstruction Loss: 22250881218560.0\n",
      "2023-07-19 12:52:18,822 - INFO - Save model at epoch 82\n",
      "0it [00:00, ?it/s]2023-07-19 12:52:18,926 - INFO - Epoch: [83/600], Step: [1/591], Loss: 162689232.0, KL Divergence: 727.4519653320312, Reconstruction Loss: 162688512.0\n",
      "118it [00:11, 10.63it/s]2023-07-19 12:52:30,019 - INFO - Epoch: [83/600], Step: [119/591], Loss: 500740192.0, KL Divergence: 723.9651489257812, Reconstruction Loss: 500739456.0\n",
      "236it [00:21, 10.94it/s]2023-07-19 12:52:40,925 - INFO - Epoch: [83/600], Step: [237/591], Loss: 368488384.0, KL Divergence: 712.9593505859375, Reconstruction Loss: 368487680.0\n",
      "354it [00:33, 10.33it/s]2023-07-19 12:52:52,056 - INFO - Epoch: [83/600], Step: [355/591], Loss: 368830208.0, KL Divergence: 716.8372192382812, Reconstruction Loss: 368829504.0\n",
      "472it [00:44,  9.95it/s]2023-07-19 12:53:03,088 - INFO - Epoch: [83/600], Step: [473/591], Loss: 336800000.0, KL Divergence: 715.8995361328125, Reconstruction Loss: 336799296.0\n",
      "589it [00:55, 10.91it/s]2023-07-19 12:53:14,078 - INFO - Epoch: [83/600], Step: [591/591], Loss: 270795232.0, KL Divergence: 734.5709228515625, Reconstruction Loss: 270794496.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 12:53:14,080 - INFO - Epoch: [83/600], Total Loss: 22228371478528.0, Total KL Divergence: 54460739.171875, Total Reconstruction Loss: 22228317177856.0\n",
      "2023-07-19 12:53:14,120 - INFO - Save model at epoch 83\n",
      "0it [00:00, ?it/s]2023-07-19 12:53:14,250 - INFO - Epoch: [84/600], Step: [1/591], Loss: 157568496.0, KL Divergence: 724.9564208984375, Reconstruction Loss: 157567776.0\n",
      "117it [00:10, 11.11it/s]2023-07-19 12:53:24,986 - INFO - Epoch: [84/600], Step: [119/591], Loss: 499952160.0, KL Divergence: 725.263427734375, Reconstruction Loss: 499951424.0\n",
      "235it [00:21, 10.84it/s]2023-07-19 12:53:35,940 - INFO - Epoch: [84/600], Step: [237/591], Loss: 353291136.0, KL Divergence: 711.2495727539062, Reconstruction Loss: 353290432.0\n",
      "353it [00:32, 10.66it/s]2023-07-19 12:53:46,759 - INFO - Epoch: [84/600], Step: [355/591], Loss: 355067776.0, KL Divergence: 710.2783203125, Reconstruction Loss: 355067072.0\n",
      "471it [00:43, 10.92it/s]2023-07-19 12:53:57,661 - INFO - Epoch: [84/600], Step: [473/591], Loss: 328133856.0, KL Divergence: 714.0533447265625, Reconstruction Loss: 328133152.0\n",
      "589it [00:54, 10.98it/s]2023-07-19 12:54:08,534 - INFO - Epoch: [84/600], Step: [591/591], Loss: 264457600.0, KL Divergence: 732.15625, Reconstruction Loss: 264456864.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 12:54:08,536 - INFO - Epoch: [84/600], Total Loss: 21898555492352.0, Total KL Divergence: 54312036.484375, Total Reconstruction Loss: 21898501386240.0\n",
      "2023-07-19 12:54:08,576 - INFO - Save model at epoch 84\n",
      "0it [00:00, ?it/s]2023-07-19 12:54:08,706 - INFO - Epoch: [85/600], Step: [1/591], Loss: 158313888.0, KL Divergence: 722.4273681640625, Reconstruction Loss: 158313168.0\n",
      "117it [00:10, 11.09it/s]2023-07-19 12:54:19,492 - INFO - Epoch: [85/600], Step: [119/591], Loss: 490568320.0, KL Divergence: 717.4931640625, Reconstruction Loss: 490567616.0\n",
      "236it [00:21, 10.97it/s]2023-07-19 12:54:30,476 - INFO - Epoch: [85/600], Step: [237/591], Loss: 352115584.0, KL Divergence: 705.3001098632812, Reconstruction Loss: 352114880.0\n",
      "354it [00:32, 11.13it/s]2023-07-19 12:54:41,304 - INFO - Epoch: [85/600], Step: [355/591], Loss: 350643936.0, KL Divergence: 709.3515014648438, Reconstruction Loss: 350643232.0\n",
      "472it [00:43, 10.28it/s]2023-07-19 12:54:52,305 - INFO - Epoch: [85/600], Step: [473/591], Loss: 328560576.0, KL Divergence: 712.9268798828125, Reconstruction Loss: 328559872.0\n",
      "590it [00:54, 11.09it/s]2023-07-19 12:55:03,052 - INFO - Epoch: [85/600], Step: [591/591], Loss: 254090304.0, KL Divergence: 732.08154296875, Reconstruction Loss: 254089568.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 12:55:03,054 - INFO - Epoch: [85/600], Total Loss: 21749075501056.0, Total KL Divergence: 54031461.5625, Total Reconstruction Loss: 21749021667328.0\n",
      "2023-07-19 12:55:03,093 - INFO - Save model at epoch 85\n",
      "0it [00:00, ?it/s]2023-07-19 12:55:03,210 - INFO - Epoch: [86/600], Step: [1/591], Loss: 164361808.0, KL Divergence: 722.1514892578125, Reconstruction Loss: 164361088.0\n",
      "117it [00:10, 10.50it/s]2023-07-19 12:55:14,166 - INFO - Epoch: [86/600], Step: [119/591], Loss: 486681504.0, KL Divergence: 720.96142578125, Reconstruction Loss: 486680768.0\n",
      "235it [00:21, 11.03it/s]2023-07-19 12:55:25,195 - INFO - Epoch: [86/600], Step: [237/591], Loss: 347981824.0, KL Divergence: 706.2298583984375, Reconstruction Loss: 347981120.0\n",
      "353it [00:32, 10.49it/s]2023-07-19 12:55:36,257 - INFO - Epoch: [86/600], Step: [355/591], Loss: 349218016.0, KL Divergence: 703.7218017578125, Reconstruction Loss: 349217312.0\n",
      "471it [00:44, 10.86it/s]2023-07-19 12:55:47,390 - INFO - Epoch: [86/600], Step: [473/591], Loss: 335277376.0, KL Divergence: 704.0963745117188, Reconstruction Loss: 335276672.0\n",
      "589it [00:55, 10.79it/s]2023-07-19 12:55:58,370 - INFO - Epoch: [86/600], Step: [591/591], Loss: 258673552.0, KL Divergence: 726.525390625, Reconstruction Loss: 258672832.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 12:55:58,371 - INFO - Epoch: [86/600], Total Loss: 21605616955392.0, Total KL Divergence: 53863419.7578125, Total Reconstruction Loss: 21605563164672.0\n",
      "2023-07-19 12:55:58,413 - INFO - Save model at epoch 86\n",
      "0it [00:00, ?it/s]2023-07-19 12:55:58,531 - INFO - Epoch: [87/600], Step: [1/591], Loss: 154093968.0, KL Divergence: 716.0216674804688, Reconstruction Loss: 154093248.0\n",
      "117it [00:11, 10.91it/s]2023-07-19 12:56:09,664 - INFO - Epoch: [87/600], Step: [119/591], Loss: 488704224.0, KL Divergence: 712.046875, Reconstruction Loss: 488703520.0\n",
      "235it [00:22, 10.70it/s]2023-07-19 12:56:20,683 - INFO - Epoch: [87/600], Step: [237/591], Loss: 349730624.0, KL Divergence: 698.9955444335938, Reconstruction Loss: 349729920.0\n",
      "353it [00:33, 10.82it/s]2023-07-19 12:56:31,649 - INFO - Epoch: [87/600], Step: [355/591], Loss: 358873152.0, KL Divergence: 696.9646606445312, Reconstruction Loss: 358872448.0\n",
      "471it [00:44, 10.95it/s]2023-07-19 12:56:42,675 - INFO - Epoch: [87/600], Step: [473/591], Loss: 325093408.0, KL Divergence: 705.721923828125, Reconstruction Loss: 325092704.0\n",
      "589it [00:55, 10.96it/s]2023-07-19 12:56:53,611 - INFO - Epoch: [87/600], Step: [591/591], Loss: 248243600.0, KL Divergence: 725.2482299804688, Reconstruction Loss: 248242880.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 12:56:53,612 - INFO - Epoch: [87/600], Total Loss: 21514972510208.0, Total KL Divergence: 53484582.8359375, Total Reconstruction Loss: 21514919006208.0\n",
      "2023-07-19 12:56:53,658 - INFO - Save model at epoch 87\n",
      "0it [00:00, ?it/s]2023-07-19 12:56:53,772 - INFO - Epoch: [88/600], Step: [1/591], Loss: 156287120.0, KL Divergence: 714.439697265625, Reconstruction Loss: 156286400.0\n",
      "118it [00:10, 10.89it/s]2023-07-19 12:57:04,658 - INFO - Epoch: [88/600], Step: [119/591], Loss: 487742272.0, KL Divergence: 712.2398681640625, Reconstruction Loss: 487741568.0\n",
      "236it [00:21, 10.94it/s]2023-07-19 12:57:15,549 - INFO - Epoch: [88/600], Step: [237/591], Loss: 343403008.0, KL Divergence: 704.0810546875, Reconstruction Loss: 343402304.0\n",
      "353it [00:32, 10.52it/s]2023-07-19 12:57:26,550 - INFO - Epoch: [88/600], Step: [355/591], Loss: 356129856.0, KL Divergence: 704.705322265625, Reconstruction Loss: 356129152.0\n",
      "472it [00:43, 10.98it/s]2023-07-19 12:57:37,713 - INFO - Epoch: [88/600], Step: [473/591], Loss: 330680192.0, KL Divergence: 708.49072265625, Reconstruction Loss: 330679488.0\n",
      "590it [00:55, 10.65it/s]2023-07-19 12:57:48,765 - INFO - Epoch: [88/600], Step: [591/591], Loss: 254217600.0, KL Divergence: 725.4833984375, Reconstruction Loss: 254216880.0\n",
      "591it [00:55, 10.73it/s]\n",
      "2023-07-19 12:57:48,767 - INFO - Epoch: [88/600], Total Loss: 21351229634560.0, Total KL Divergence: 53733017.2890625, Total Reconstruction Loss: 21351176024064.0\n",
      "2023-07-19 12:57:48,805 - INFO - Save model at epoch 88\n",
      "0it [00:00, ?it/s]2023-07-19 12:57:48,913 - INFO - Epoch: [89/600], Step: [1/591], Loss: 153767664.0, KL Divergence: 715.6988525390625, Reconstruction Loss: 153766944.0\n",
      "118it [00:11, 10.66it/s]2023-07-19 12:58:00,116 - INFO - Epoch: [89/600], Step: [119/591], Loss: 501428032.0, KL Divergence: 712.3232421875, Reconstruction Loss: 501427328.0\n",
      "236it [00:22, 10.74it/s]2023-07-19 12:58:11,158 - INFO - Epoch: [89/600], Step: [237/591], Loss: 346876288.0, KL Divergence: 703.0594482421875, Reconstruction Loss: 346875584.0\n",
      "354it [00:33, 10.53it/s]2023-07-19 12:58:22,120 - INFO - Epoch: [89/600], Step: [355/591], Loss: 351197568.0, KL Divergence: 703.4208374023438, Reconstruction Loss: 351196864.0\n",
      "472it [00:44, 10.89it/s]2023-07-19 12:58:32,999 - INFO - Epoch: [89/600], Step: [473/591], Loss: 338802304.0, KL Divergence: 708.288818359375, Reconstruction Loss: 338801600.0\n",
      "590it [00:54, 10.86it/s]2023-07-19 12:58:43,807 - INFO - Epoch: [89/600], Step: [591/591], Loss: 254758768.0, KL Divergence: 726.838623046875, Reconstruction Loss: 254758048.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 12:58:43,808 - INFO - Epoch: [89/600], Total Loss: 21417365616640.0, Total KL Divergence: 53748155.890625, Total Reconstruction Loss: 21417311987712.0\n",
      "2023-07-19 12:58:43,849 - INFO - Save model at epoch 89\n",
      "0it [00:00, ?it/s]2023-07-19 12:58:43,969 - INFO - Epoch: [90/600], Step: [1/591], Loss: 154214832.0, KL Divergence: 716.7127685546875, Reconstruction Loss: 154214112.0\n",
      "117it [00:10, 10.98it/s]2023-07-19 12:58:54,849 - INFO - Epoch: [90/600], Step: [119/591], Loss: 480822400.0, KL Divergence: 713.4605712890625, Reconstruction Loss: 480821696.0\n",
      "236it [00:22, 10.45it/s]2023-07-19 12:59:06,203 - INFO - Epoch: [90/600], Step: [237/591], Loss: 358466432.0, KL Divergence: 704.6984252929688, Reconstruction Loss: 358465728.0\n",
      "354it [00:33, 10.71it/s]2023-07-19 12:59:17,240 - INFO - Epoch: [90/600], Step: [355/591], Loss: 354826176.0, KL Divergence: 702.95458984375, Reconstruction Loss: 354825472.0\n",
      "472it [00:44, 10.78it/s]2023-07-19 12:59:28,264 - INFO - Epoch: [90/600], Step: [473/591], Loss: 331112448.0, KL Divergence: 706.83349609375, Reconstruction Loss: 331111744.0\n",
      "590it [00:55, 11.04it/s]2023-07-19 12:59:39,260 - INFO - Epoch: [90/600], Step: [591/591], Loss: 251372032.0, KL Divergence: 728.564208984375, Reconstruction Loss: 251371296.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 12:59:39,262 - INFO - Epoch: [90/600], Total Loss: 21331660228608.0, Total KL Divergence: 53773053.6015625, Total Reconstruction Loss: 21331606599680.0\n",
      "2023-07-19 12:59:39,301 - INFO - Save model at epoch 90\n",
      "0it [00:00, ?it/s]2023-07-19 12:59:39,412 - INFO - Epoch: [91/600], Step: [1/591], Loss: 150721360.0, KL Divergence: 717.405517578125, Reconstruction Loss: 150720640.0\n",
      "117it [00:10, 11.05it/s]2023-07-19 12:59:50,314 - INFO - Epoch: [91/600], Step: [119/591], Loss: 487762528.0, KL Divergence: 713.47607421875, Reconstruction Loss: 487761824.0\n",
      "235it [00:21, 10.97it/s]2023-07-19 13:00:01,222 - INFO - Epoch: [91/600], Step: [237/591], Loss: 343654784.0, KL Divergence: 704.1572265625, Reconstruction Loss: 343654080.0\n",
      "353it [00:32, 11.07it/s]2023-07-19 13:00:12,033 - INFO - Epoch: [91/600], Step: [355/591], Loss: 360877664.0, KL Divergence: 701.6065063476562, Reconstruction Loss: 360876960.0\n",
      "471it [00:43, 10.58it/s]2023-07-19 13:00:23,034 - INFO - Epoch: [91/600], Step: [473/591], Loss: 323394208.0, KL Divergence: 703.89892578125, Reconstruction Loss: 323393504.0\n",
      "589it [00:54, 11.08it/s]2023-07-19 13:00:33,990 - INFO - Epoch: [91/600], Step: [591/591], Loss: 275084128.0, KL Divergence: 728.7199096679688, Reconstruction Loss: 275083392.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 13:00:33,992 - INFO - Epoch: [91/600], Total Loss: 21282833670144.0, Total KL Divergence: 53704450.90625, Total Reconstruction Loss: 21282780033024.0\n",
      "2023-07-19 13:00:34,032 - INFO - Save model at epoch 91\n",
      "0it [00:00, ?it/s]2023-07-19 13:00:34,149 - INFO - Epoch: [92/600], Step: [1/591], Loss: 151271488.0, KL Divergence: 717.8138427734375, Reconstruction Loss: 151270768.0\n",
      "117it [00:10, 10.95it/s]2023-07-19 13:00:45,085 - INFO - Epoch: [92/600], Step: [119/591], Loss: 469660096.0, KL Divergence: 713.8887329101562, Reconstruction Loss: 469659392.0\n",
      "235it [00:21, 10.48it/s]2023-07-19 13:00:56,167 - INFO - Epoch: [92/600], Step: [237/591], Loss: 353400000.0, KL Divergence: 706.4804077148438, Reconstruction Loss: 353399296.0\n",
      "353it [00:32, 10.97it/s]2023-07-19 13:01:07,121 - INFO - Epoch: [92/600], Step: [355/591], Loss: 349817216.0, KL Divergence: 706.4576416015625, Reconstruction Loss: 349816512.0\n",
      "471it [00:43, 11.08it/s]2023-07-19 13:01:17,918 - INFO - Epoch: [92/600], Step: [473/591], Loss: 323956864.0, KL Divergence: 709.8175659179688, Reconstruction Loss: 323956160.0\n",
      "589it [00:54, 10.98it/s]2023-07-19 13:01:28,668 - INFO - Epoch: [92/600], Step: [591/591], Loss: 259507968.0, KL Divergence: 733.8944091796875, Reconstruction Loss: 259507232.0\n",
      "591it [00:54, 10.82it/s]\n",
      "2023-07-19 13:01:28,670 - INFO - Epoch: [92/600], Total Loss: 21195026188288.0, Total KL Divergence: 53912722.546875, Total Reconstruction Loss: 21194972454912.0\n",
      "2023-07-19 13:01:28,709 - INFO - Save model at epoch 92\n",
      "0it [00:00, ?it/s]2023-07-19 13:01:28,826 - INFO - Epoch: [93/600], Step: [1/591], Loss: 147895872.0, KL Divergence: 722.6680908203125, Reconstruction Loss: 147895152.0\n",
      "117it [00:10, 10.75it/s]2023-07-19 13:01:39,750 - INFO - Epoch: [93/600], Step: [119/591], Loss: 489777760.0, KL Divergence: 720.0170288085938, Reconstruction Loss: 489777024.0\n",
      "235it [00:21, 11.08it/s]2023-07-19 13:01:50,677 - INFO - Epoch: [93/600], Step: [237/591], Loss: 340603648.0, KL Divergence: 715.818359375, Reconstruction Loss: 340602944.0\n",
      "353it [00:32, 11.01it/s]2023-07-19 13:02:01,581 - INFO - Epoch: [93/600], Step: [355/591], Loss: 354882112.0, KL Divergence: 715.3629150390625, Reconstruction Loss: 354881408.0\n",
      "471it [00:43, 11.03it/s]2023-07-19 13:02:12,437 - INFO - Epoch: [93/600], Step: [473/591], Loss: 328056928.0, KL Divergence: 721.1820678710938, Reconstruction Loss: 328056192.0\n",
      "589it [00:54, 10.86it/s]2023-07-19 13:02:23,518 - INFO - Epoch: [93/600], Step: [591/591], Loss: 265002112.0, KL Divergence: 741.7518310546875, Reconstruction Loss: 265001376.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 13:02:23,519 - INFO - Epoch: [93/600], Total Loss: 21064320337920.0, Total KL Divergence: 54571603.8203125, Total Reconstruction Loss: 21064265838592.0\n",
      "2023-07-19 13:02:23,560 - INFO - Save model at epoch 93\n",
      "0it [00:00, ?it/s]2023-07-19 13:02:23,687 - INFO - Epoch: [94/600], Step: [1/591], Loss: 149336944.0, KL Divergence: 731.9653930664062, Reconstruction Loss: 149336208.0\n",
      "117it [00:10, 10.79it/s]2023-07-19 13:02:34,718 - INFO - Epoch: [94/600], Step: [119/591], Loss: 465411584.0, KL Divergence: 728.6834716796875, Reconstruction Loss: 465410848.0\n",
      "235it [00:22, 10.79it/s]2023-07-19 13:02:45,841 - INFO - Epoch: [94/600], Step: [237/591], Loss: 356624416.0, KL Divergence: 718.3417358398438, Reconstruction Loss: 356623712.0\n",
      "353it [00:33, 11.09it/s]2023-07-19 13:02:56,853 - INFO - Epoch: [94/600], Step: [355/591], Loss: 345991808.0, KL Divergence: 715.2387084960938, Reconstruction Loss: 345991104.0\n",
      "471it [00:43, 10.66it/s]2023-07-19 13:03:07,688 - INFO - Epoch: [94/600], Step: [473/591], Loss: 346755136.0, KL Divergence: 717.1114501953125, Reconstruction Loss: 346754432.0\n",
      "589it [00:54, 11.07it/s]2023-07-19 13:03:18,591 - INFO - Epoch: [94/600], Step: [591/591], Loss: 244543328.0, KL Divergence: 739.4198608398438, Reconstruction Loss: 244542592.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 13:03:18,592 - INFO - Epoch: [94/600], Total Loss: 21050682009600.0, Total KL Divergence: 54608531.875, Total Reconstruction Loss: 21050627481600.0\n",
      "2023-07-19 13:03:18,634 - INFO - Save model at epoch 94\n",
      "0it [00:00, ?it/s]2023-07-19 13:03:18,739 - INFO - Epoch: [95/600], Step: [1/591], Loss: 154190768.0, KL Divergence: 726.875732421875, Reconstruction Loss: 154190048.0\n",
      "117it [00:10, 10.82it/s]2023-07-19 13:03:29,661 - INFO - Epoch: [95/600], Step: [119/591], Loss: 458349632.0, KL Divergence: 718.7008056640625, Reconstruction Loss: 458348928.0\n",
      "235it [00:21, 10.94it/s]2023-07-19 13:03:40,571 - INFO - Epoch: [95/600], Step: [237/591], Loss: 319288416.0, KL Divergence: 708.543701171875, Reconstruction Loss: 319287712.0\n",
      "353it [00:32, 10.91it/s]2023-07-19 13:03:51,382 - INFO - Epoch: [95/600], Step: [355/591], Loss: 339968192.0, KL Divergence: 710.031494140625, Reconstruction Loss: 339967488.0\n",
      "471it [00:43, 11.00it/s]2023-07-19 13:04:02,256 - INFO - Epoch: [95/600], Step: [473/591], Loss: 334224576.0, KL Divergence: 715.6881103515625, Reconstruction Loss: 334223872.0\n",
      "589it [00:54, 10.96it/s]2023-07-19 13:04:13,159 - INFO - Epoch: [95/600], Step: [591/591], Loss: 250617632.0, KL Divergence: 737.1657104492188, Reconstruction Loss: 250616896.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 13:04:13,161 - INFO - Epoch: [95/600], Total Loss: 20949949216768.0, Total KL Divergence: 54230573.671875, Total Reconstruction Loss: 20949895157760.0\n",
      "2023-07-19 13:04:13,201 - INFO - Save model at epoch 95\n",
      "0it [00:00, ?it/s]2023-07-19 13:04:13,325 - INFO - Epoch: [96/600], Step: [1/591], Loss: 148670992.0, KL Divergence: 726.9112548828125, Reconstruction Loss: 148670272.0\n",
      "117it [00:10, 10.53it/s]2023-07-19 13:04:24,382 - INFO - Epoch: [96/600], Step: [119/591], Loss: 466794176.0, KL Divergence: 722.901123046875, Reconstruction Loss: 466793440.0\n",
      "235it [00:21, 10.76it/s]2023-07-19 13:04:35,411 - INFO - Epoch: [96/600], Step: [237/591], Loss: 326263648.0, KL Divergence: 712.4619140625, Reconstruction Loss: 326262944.0\n",
      "354it [00:33, 10.79it/s]2023-07-19 13:04:46,568 - INFO - Epoch: [96/600], Step: [355/591], Loss: 357292224.0, KL Divergence: 712.21533203125, Reconstruction Loss: 357291520.0\n",
      "472it [00:44, 10.77it/s]2023-07-19 13:04:57,524 - INFO - Epoch: [96/600], Step: [473/591], Loss: 352027584.0, KL Divergence: 718.1664428710938, Reconstruction Loss: 352026880.0\n",
      "590it [00:55, 10.65it/s]2023-07-19 13:05:08,469 - INFO - Epoch: [96/600], Step: [591/591], Loss: 248851296.0, KL Divergence: 740.5651245117188, Reconstruction Loss: 248850560.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 13:05:08,471 - INFO - Epoch: [96/600], Total Loss: 20954726572032.0, Total KL Divergence: 54476219.1953125, Total Reconstruction Loss: 20954672207872.0\n",
      "2023-07-19 13:05:08,511 - INFO - Save model at epoch 96\n",
      "0it [00:00, ?it/s]2023-07-19 13:05:08,627 - INFO - Epoch: [97/600], Step: [1/591], Loss: 148962992.0, KL Divergence: 728.336669921875, Reconstruction Loss: 148962256.0\n",
      "117it [00:10, 10.68it/s]2023-07-19 13:05:19,716 - INFO - Epoch: [97/600], Step: [119/591], Loss: 455930528.0, KL Divergence: 725.5740356445312, Reconstruction Loss: 455929792.0\n",
      "235it [00:21, 10.97it/s]2023-07-19 13:05:30,628 - INFO - Epoch: [97/600], Step: [237/591], Loss: 329837120.0, KL Divergence: 720.1915283203125, Reconstruction Loss: 329836384.0\n",
      "353it [00:32, 11.05it/s]2023-07-19 13:05:41,449 - INFO - Epoch: [97/600], Step: [355/591], Loss: 340660928.0, KL Divergence: 722.4078369140625, Reconstruction Loss: 340660192.0\n",
      "472it [00:44, 10.52it/s]2023-07-19 13:05:52,812 - INFO - Epoch: [97/600], Step: [473/591], Loss: 363673728.0, KL Divergence: 725.269775390625, Reconstruction Loss: 363672992.0\n",
      "589it [00:55, 10.96it/s]2023-07-19 13:06:03,957 - INFO - Epoch: [97/600], Step: [591/591], Loss: 246109776.0, KL Divergence: 749.759033203125, Reconstruction Loss: 246109024.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 13:06:03,959 - INFO - Epoch: [97/600], Total Loss: 20911813003264.0, Total KL Divergence: 54913958.90625, Total Reconstruction Loss: 20911757918208.0\n",
      "2023-07-19 13:06:03,999 - INFO - Save model at epoch 97\n",
      "0it [00:00, ?it/s]2023-07-19 13:06:04,122 - INFO - Epoch: [98/600], Step: [1/591], Loss: 156519168.0, KL Divergence: 738.51025390625, Reconstruction Loss: 156518432.0\n",
      "117it [00:10, 10.92it/s]2023-07-19 13:06:15,113 - INFO - Epoch: [98/600], Step: [119/591], Loss: 443509280.0, KL Divergence: 731.6475219726562, Reconstruction Loss: 443508544.0\n",
      "235it [00:22, 10.74it/s]2023-07-19 13:06:26,288 - INFO - Epoch: [98/600], Step: [237/591], Loss: 344230592.0, KL Divergence: 724.7547607421875, Reconstruction Loss: 344229856.0\n",
      "354it [00:33, 10.67it/s]2023-07-19 13:06:37,350 - INFO - Epoch: [98/600], Step: [355/591], Loss: 341208608.0, KL Divergence: 723.1203002929688, Reconstruction Loss: 341207872.0\n",
      "472it [00:44, 11.20it/s]2023-07-19 13:06:48,435 - INFO - Epoch: [98/600], Step: [473/591], Loss: 347178752.0, KL Divergence: 728.3589477539062, Reconstruction Loss: 347178016.0\n",
      "590it [00:55, 10.62it/s]2023-07-19 13:06:59,527 - INFO - Epoch: [98/600], Step: [591/591], Loss: 245050400.0, KL Divergence: 753.1566772460938, Reconstruction Loss: 245049648.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 13:06:59,528 - INFO - Epoch: [98/600], Total Loss: 20961572136960.0, Total KL Divergence: 55272272.21875, Total Reconstruction Loss: 20961516664832.0\n",
      "2023-07-19 13:06:59,568 - INFO - Save model at epoch 98\n",
      "0it [00:00, ?it/s]2023-07-19 13:06:59,685 - INFO - Epoch: [99/600], Step: [1/591], Loss: 162958592.0, KL Divergence: 742.0686645507812, Reconstruction Loss: 162957856.0\n",
      "117it [00:10, 10.73it/s]2023-07-19 13:07:10,712 - INFO - Epoch: [99/600], Step: [119/591], Loss: 439067680.0, KL Divergence: 737.480712890625, Reconstruction Loss: 439066944.0\n",
      "235it [00:21, 10.83it/s]2023-07-19 13:07:21,690 - INFO - Epoch: [99/600], Step: [237/591], Loss: 315812128.0, KL Divergence: 728.439453125, Reconstruction Loss: 315811392.0\n",
      "353it [00:32, 10.65it/s]2023-07-19 13:07:32,603 - INFO - Epoch: [99/600], Step: [355/591], Loss: 368992992.0, KL Divergence: 725.255126953125, Reconstruction Loss: 368992256.0\n",
      "471it [00:43, 10.64it/s]2023-07-19 13:07:43,710 - INFO - Epoch: [99/600], Step: [473/591], Loss: 341529280.0, KL Divergence: 726.140625, Reconstruction Loss: 341528544.0\n",
      "589it [00:55, 11.04it/s]2023-07-19 13:07:54,726 - INFO - Epoch: [99/600], Step: [591/591], Loss: 253727472.0, KL Divergence: 751.7662353515625, Reconstruction Loss: 253726720.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 13:07:54,727 - INFO - Epoch: [99/600], Total Loss: 21156349927424.0, Total KL Divergence: 55377442.4375, Total Reconstruction Loss: 21156294379520.0\n",
      "2023-07-19 13:07:54,766 - INFO - Save model at epoch 99\n",
      "0it [00:00, ?it/s]2023-07-19 13:07:54,881 - INFO - Epoch: [100/600], Step: [1/591], Loss: 154383648.0, KL Divergence: 741.7257080078125, Reconstruction Loss: 154382912.0\n",
      "118it [00:11, 10.62it/s]2023-07-19 13:08:06,025 - INFO - Epoch: [100/600], Step: [119/591], Loss: 433205312.0, KL Divergence: 732.674072265625, Reconstruction Loss: 433204576.0\n",
      "236it [00:22, 10.85it/s]2023-07-19 13:08:16,989 - INFO - Epoch: [100/600], Step: [237/591], Loss: 328388416.0, KL Divergence: 719.3050537109375, Reconstruction Loss: 328387712.0\n",
      "354it [00:33, 10.73it/s]2023-07-19 13:08:27,883 - INFO - Epoch: [100/600], Step: [355/591], Loss: 367191360.0, KL Divergence: 716.1087036132812, Reconstruction Loss: 367190656.0\n",
      "472it [00:43, 11.07it/s]2023-07-19 13:08:38,689 - INFO - Epoch: [100/600], Step: [473/591], Loss: 323366560.0, KL Divergence: 716.5717163085938, Reconstruction Loss: 323365856.0\n",
      "590it [00:54, 11.08it/s]2023-07-19 13:08:49,549 - INFO - Epoch: [100/600], Step: [591/591], Loss: 264027568.0, KL Divergence: 745.880859375, Reconstruction Loss: 264026816.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 13:08:49,550 - INFO - Epoch: [100/600], Total Loss: 21122454761472.0, Total KL Divergence: 54827946.765625, Total Reconstruction Loss: 21122399850496.0\n",
      "2023-07-19 13:08:49,590 - INFO - Save model at epoch 100\n",
      "0it [00:00, ?it/s]2023-07-19 13:08:49,707 - INFO - Epoch: [101/600], Step: [1/591], Loss: 170554000.0, KL Divergence: 733.826416015625, Reconstruction Loss: 170553264.0\n",
      "117it [00:11, 10.43it/s]2023-07-19 13:09:00,801 - INFO - Epoch: [101/600], Step: [119/591], Loss: 454856064.0, KL Divergence: 727.6536865234375, Reconstruction Loss: 454855328.0\n",
      "235it [00:21, 11.02it/s]2023-07-19 13:09:11,745 - INFO - Epoch: [101/600], Step: [237/591], Loss: 316497216.0, KL Divergence: 716.8477783203125, Reconstruction Loss: 316496512.0\n",
      "353it [00:32, 10.83it/s]2023-07-19 13:09:22,595 - INFO - Epoch: [101/600], Step: [355/591], Loss: 352787328.0, KL Divergence: 717.3096313476562, Reconstruction Loss: 352786624.0\n",
      "471it [00:43, 11.16it/s]2023-07-19 13:09:33,663 - INFO - Epoch: [101/600], Step: [473/591], Loss: 308798176.0, KL Divergence: 716.0341796875, Reconstruction Loss: 308797472.0\n",
      "589it [00:54, 11.08it/s]2023-07-19 13:09:44,525 - INFO - Epoch: [101/600], Step: [591/591], Loss: 250838368.0, KL Divergence: 746.9125366210938, Reconstruction Loss: 250837616.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 13:09:44,527 - INFO - Epoch: [101/600], Total Loss: 21099185283072.0, Total KL Divergence: 54655556.4921875, Total Reconstruction Loss: 21099130630144.0\n",
      "2023-07-19 13:09:44,571 - INFO - Save model at epoch 101\n",
      "0it [00:00, ?it/s]2023-07-19 13:09:44,688 - INFO - Epoch: [102/600], Step: [1/591], Loss: 162755520.0, KL Divergence: 735.5354614257812, Reconstruction Loss: 162754784.0\n",
      "117it [00:10, 10.41it/s]2023-07-19 13:09:55,530 - INFO - Epoch: [102/600], Step: [119/591], Loss: 530937344.0, KL Divergence: 726.0189208984375, Reconstruction Loss: 530936608.0\n",
      "235it [00:21, 10.82it/s]2023-07-19 13:10:06,605 - INFO - Epoch: [102/600], Step: [237/591], Loss: 313792512.0, KL Divergence: 715.0775146484375, Reconstruction Loss: 313791808.0\n",
      "353it [00:32, 10.88it/s]2023-07-19 13:10:17,347 - INFO - Epoch: [102/600], Step: [355/591], Loss: 354995712.0, KL Divergence: 714.52294921875, Reconstruction Loss: 354995008.0\n",
      "471it [00:43, 10.87it/s]2023-07-19 13:10:28,208 - INFO - Epoch: [102/600], Step: [473/591], Loss: 317868256.0, KL Divergence: 717.0847778320312, Reconstruction Loss: 317867552.0\n",
      "589it [00:54, 10.99it/s]2023-07-19 13:10:39,021 - INFO - Epoch: [102/600], Step: [591/591], Loss: 244681296.0, KL Divergence: 744.5865478515625, Reconstruction Loss: 244680544.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 13:10:39,023 - INFO - Epoch: [102/600], Total Loss: 20891418036224.0, Total KL Divergence: 54583897.0, Total Reconstruction Loss: 20891363461120.0\n",
      "2023-07-19 13:10:39,078 - INFO - Save model at epoch 102\n",
      "0it [00:00, ?it/s]2023-07-19 13:10:39,197 - INFO - Epoch: [103/600], Step: [1/591], Loss: 155595888.0, KL Divergence: 732.5352172851562, Reconstruction Loss: 155595152.0\n",
      "117it [00:10, 10.93it/s]2023-07-19 13:10:50,024 - INFO - Epoch: [103/600], Step: [119/591], Loss: 447416512.0, KL Divergence: 730.7333374023438, Reconstruction Loss: 447415776.0\n",
      "235it [00:21, 11.02it/s]2023-07-19 13:11:00,910 - INFO - Epoch: [103/600], Step: [237/591], Loss: 309931232.0, KL Divergence: 720.6453247070312, Reconstruction Loss: 309930496.0\n",
      "353it [00:32, 11.03it/s]2023-07-19 13:11:11,827 - INFO - Epoch: [103/600], Step: [355/591], Loss: 345898432.0, KL Divergence: 717.447265625, Reconstruction Loss: 345897728.0\n",
      "471it [00:43, 10.37it/s]2023-07-19 13:11:22,766 - INFO - Epoch: [103/600], Step: [473/591], Loss: 308765472.0, KL Divergence: 720.700927734375, Reconstruction Loss: 308764736.0\n",
      "589it [00:54, 10.94it/s]2023-07-19 13:11:33,639 - INFO - Epoch: [103/600], Step: [591/591], Loss: 264363728.0, KL Divergence: 746.5567626953125, Reconstruction Loss: 264362976.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 13:11:33,641 - INFO - Epoch: [103/600], Total Loss: 20779514763264.0, Total KL Divergence: 54884841.84375, Total Reconstruction Loss: 20779459788800.0\n",
      "2023-07-19 13:11:33,681 - INFO - Save model at epoch 103\n",
      "0it [00:00, ?it/s]2023-07-19 13:11:33,795 - INFO - Epoch: [104/600], Step: [1/591], Loss: 156909216.0, KL Divergence: 736.4410400390625, Reconstruction Loss: 156908480.0\n",
      "117it [00:10, 10.50it/s]2023-07-19 13:11:44,855 - INFO - Epoch: [104/600], Step: [119/591], Loss: 431892896.0, KL Divergence: 729.5762329101562, Reconstruction Loss: 431892160.0\n",
      "235it [00:22, 10.16it/s]2023-07-19 13:11:55,963 - INFO - Epoch: [104/600], Step: [237/591], Loss: 310318976.0, KL Divergence: 724.9676513671875, Reconstruction Loss: 310318240.0\n",
      "353it [00:33, 11.05it/s]2023-07-19 13:12:06,922 - INFO - Epoch: [104/600], Step: [355/591], Loss: 350793248.0, KL Divergence: 720.4229736328125, Reconstruction Loss: 350792512.0\n",
      "471it [00:44, 10.61it/s]2023-07-19 13:12:17,932 - INFO - Epoch: [104/600], Step: [473/591], Loss: 309164352.0, KL Divergence: 715.8208618164062, Reconstruction Loss: 309163648.0\n",
      "589it [00:55, 10.83it/s]2023-07-19 13:12:28,892 - INFO - Epoch: [104/600], Step: [591/591], Loss: 251291968.0, KL Divergence: 743.5169677734375, Reconstruction Loss: 251291232.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 13:12:28,894 - INFO - Epoch: [104/600], Total Loss: 20538539071488.0, Total KL Divergence: 54894821.375, Total Reconstruction Loss: 20538484111360.0\n",
      "2023-07-19 13:12:28,937 - INFO - Save model at epoch 104\n",
      "0it [00:00, ?it/s]2023-07-19 13:12:29,040 - INFO - Epoch: [105/600], Step: [1/591], Loss: 158875920.0, KL Divergence: 731.5131225585938, Reconstruction Loss: 158875184.0\n",
      "118it [00:10, 11.08it/s]2023-07-19 13:12:39,783 - INFO - Epoch: [105/600], Step: [119/591], Loss: 427578432.0, KL Divergence: 726.5552368164062, Reconstruction Loss: 427577696.0\n",
      "236it [00:21, 10.75it/s]2023-07-19 13:12:50,785 - INFO - Epoch: [105/600], Step: [237/591], Loss: 317623296.0, KL Divergence: 718.160400390625, Reconstruction Loss: 317622592.0\n",
      "354it [00:32, 10.76it/s]2023-07-19 13:13:01,782 - INFO - Epoch: [105/600], Step: [355/591], Loss: 348665184.0, KL Divergence: 714.4844360351562, Reconstruction Loss: 348664480.0\n",
      "472it [00:43, 11.18it/s]2023-07-19 13:13:12,825 - INFO - Epoch: [105/600], Step: [473/591], Loss: 317831392.0, KL Divergence: 718.187255859375, Reconstruction Loss: 317830688.0\n",
      "590it [00:54, 10.62it/s]2023-07-19 13:13:23,813 - INFO - Epoch: [105/600], Step: [591/591], Loss: 251362256.0, KL Divergence: 749.766845703125, Reconstruction Loss: 251361504.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 13:13:23,816 - INFO - Epoch: [105/600], Total Loss: 20640125108224.0, Total KL Divergence: 54720796.4140625, Total Reconstruction Loss: 20640070406144.0\n",
      "2023-07-19 13:13:23,857 - INFO - Save model at epoch 105\n",
      "0it [00:00, ?it/s]2023-07-19 13:13:23,967 - INFO - Epoch: [106/600], Step: [1/591], Loss: 158007232.0, KL Divergence: 738.9183959960938, Reconstruction Loss: 158006496.0\n",
      "117it [00:11, 10.67it/s]2023-07-19 13:13:35,076 - INFO - Epoch: [106/600], Step: [119/591], Loss: 416139936.0, KL Divergence: 730.4024658203125, Reconstruction Loss: 416139200.0\n",
      "235it [00:21, 10.69it/s]2023-07-19 13:13:46,086 - INFO - Epoch: [106/600], Step: [237/591], Loss: 307941120.0, KL Divergence: 723.1388549804688, Reconstruction Loss: 307940384.0\n",
      "353it [00:33, 10.76it/s]2023-07-19 13:13:57,134 - INFO - Epoch: [106/600], Step: [355/591], Loss: 340786080.0, KL Divergence: 721.52734375, Reconstruction Loss: 340785344.0\n",
      "471it [00:44, 11.03it/s]2023-07-19 13:14:08,222 - INFO - Epoch: [106/600], Step: [473/591], Loss: 319728416.0, KL Divergence: 723.3948364257812, Reconstruction Loss: 319727680.0\n",
      "589it [00:55, 10.91it/s]2023-07-19 13:14:19,158 - INFO - Epoch: [106/600], Step: [591/591], Loss: 261719344.0, KL Divergence: 753.4340209960938, Reconstruction Loss: 261718592.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 13:14:19,161 - INFO - Epoch: [106/600], Total Loss: 20648320821248.0, Total KL Divergence: 55096816.5625, Total Reconstruction Loss: 20648265535488.0\n",
      "2023-07-19 13:14:19,204 - INFO - Save model at epoch 106\n",
      "0it [00:00, ?it/s]2023-07-19 13:14:19,344 - INFO - Epoch: [107/600], Step: [1/591], Loss: 152605680.0, KL Divergence: 742.6996459960938, Reconstruction Loss: 152604944.0\n",
      "117it [00:10, 11.18it/s]2023-07-19 13:14:30,238 - INFO - Epoch: [107/600], Step: [119/591], Loss: 429957248.0, KL Divergence: 735.331298828125, Reconstruction Loss: 429956512.0\n",
      "235it [00:21, 10.65it/s]2023-07-19 13:14:41,359 - INFO - Epoch: [107/600], Step: [237/591], Loss: 317719136.0, KL Divergence: 727.8833618164062, Reconstruction Loss: 317718400.0\n",
      "353it [00:32, 11.06it/s]2023-07-19 13:14:52,334 - INFO - Epoch: [107/600], Step: [355/591], Loss: 356784608.0, KL Divergence: 722.9532470703125, Reconstruction Loss: 356783872.0\n",
      "471it [00:44, 10.48it/s]2023-07-19 13:15:03,491 - INFO - Epoch: [107/600], Step: [473/591], Loss: 309969312.0, KL Divergence: 722.34619140625, Reconstruction Loss: 309968576.0\n",
      "589it [00:55, 11.03it/s]2023-07-19 13:15:14,518 - INFO - Epoch: [107/600], Step: [591/591], Loss: 250365552.0, KL Divergence: 751.0961303710938, Reconstruction Loss: 250364800.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 13:15:14,520 - INFO - Epoch: [107/600], Total Loss: 20601700646912.0, Total KL Divergence: 55236553.6484375, Total Reconstruction Loss: 20601645219840.0\n",
      "2023-07-19 13:15:14,560 - INFO - Save model at epoch 107\n",
      "0it [00:00, ?it/s]2023-07-19 13:15:14,700 - INFO - Epoch: [108/600], Step: [1/591], Loss: 168942112.0, KL Divergence: 740.1259765625, Reconstruction Loss: 168941376.0\n",
      "117it [00:10, 10.12it/s]2023-07-19 13:15:25,767 - INFO - Epoch: [108/600], Step: [119/591], Loss: 431473408.0, KL Divergence: 731.6688232421875, Reconstruction Loss: 431472672.0\n",
      "235it [00:21, 10.81it/s]2023-07-19 13:15:36,695 - INFO - Epoch: [108/600], Step: [237/591], Loss: 310999520.0, KL Divergence: 728.1888427734375, Reconstruction Loss: 310998784.0\n",
      "353it [00:32, 10.81it/s]2023-07-19 13:15:47,687 - INFO - Epoch: [108/600], Step: [355/591], Loss: 337515808.0, KL Divergence: 720.0385131835938, Reconstruction Loss: 337515072.0\n",
      "471it [00:43, 10.47it/s]2023-07-19 13:15:58,561 - INFO - Epoch: [108/600], Step: [473/591], Loss: 333303552.0, KL Divergence: 720.8780517578125, Reconstruction Loss: 333302816.0\n",
      "589it [00:55, 10.40it/s]2023-07-19 13:16:09,949 - INFO - Epoch: [108/600], Step: [591/591], Loss: 255607712.0, KL Divergence: 748.7460327148438, Reconstruction Loss: 255606960.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 13:16:09,951 - INFO - Epoch: [108/600], Total Loss: 20523498715136.0, Total KL Divergence: 55099420.625, Total Reconstruction Loss: 20523443433472.0\n",
      "2023-07-19 13:16:09,998 - INFO - Save model at epoch 108\n",
      "0it [00:00, ?it/s]2023-07-19 13:16:10,129 - INFO - Epoch: [109/600], Step: [1/591], Loss: 154664768.0, KL Divergence: 738.9559326171875, Reconstruction Loss: 154664032.0\n",
      "118it [00:11, 10.63it/s]2023-07-19 13:16:21,371 - INFO - Epoch: [109/600], Step: [119/591], Loss: 445574112.0, KL Divergence: 733.9797973632812, Reconstruction Loss: 445573376.0\n",
      "236it [00:22, 10.85it/s]2023-07-19 13:16:32,355 - INFO - Epoch: [109/600], Step: [237/591], Loss: 294886304.0, KL Divergence: 725.9105834960938, Reconstruction Loss: 294885568.0\n",
      "354it [00:33, 11.00it/s]2023-07-19 13:16:43,165 - INFO - Epoch: [109/600], Step: [355/591], Loss: 347882912.0, KL Divergence: 725.8363647460938, Reconstruction Loss: 347882176.0\n",
      "472it [00:43, 10.88it/s]2023-07-19 13:16:54,058 - INFO - Epoch: [109/600], Step: [473/591], Loss: 311097504.0, KL Divergence: 728.14794921875, Reconstruction Loss: 311096768.0\n",
      "590it [00:54, 10.98it/s]2023-07-19 13:17:04,885 - INFO - Epoch: [109/600], Step: [591/591], Loss: 246938592.0, KL Divergence: 759.7755737304688, Reconstruction Loss: 246937840.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 13:17:04,886 - INFO - Epoch: [109/600], Total Loss: 20549561088000.0, Total KL Divergence: 55385893.578125, Total Reconstruction Loss: 20549505529856.0\n",
      "2023-07-19 13:17:04,931 - INFO - Save model at epoch 109\n",
      "0it [00:00, ?it/s]2023-07-19 13:17:05,049 - INFO - Epoch: [110/600], Step: [1/591], Loss: 165827904.0, KL Divergence: 749.6802978515625, Reconstruction Loss: 165827152.0\n",
      "118it [00:11, 10.57it/s]2023-07-19 13:17:16,088 - INFO - Epoch: [110/600], Step: [119/591], Loss: 456439968.0, KL Divergence: 743.4364624023438, Reconstruction Loss: 456439232.0\n",
      "236it [00:22, 10.93it/s]2023-07-19 13:17:27,114 - INFO - Epoch: [110/600], Step: [237/591], Loss: 298163488.0, KL Divergence: 738.1399536132812, Reconstruction Loss: 298162752.0\n",
      "354it [00:32, 10.97it/s]2023-07-19 13:17:37,904 - INFO - Epoch: [110/600], Step: [355/591], Loss: 346864992.0, KL Divergence: 738.6459350585938, Reconstruction Loss: 346864256.0\n",
      "472it [00:43, 10.51it/s]2023-07-19 13:17:48,732 - INFO - Epoch: [110/600], Step: [473/591], Loss: 314060192.0, KL Divergence: 736.0836181640625, Reconstruction Loss: 314059456.0\n",
      "590it [00:54, 10.97it/s]2023-07-19 13:17:59,500 - INFO - Epoch: [110/600], Step: [591/591], Loss: 245470000.0, KL Divergence: 765.6903076171875, Reconstruction Loss: 245469232.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 13:17:59,501 - INFO - Epoch: [110/600], Total Loss: 20583234351104.0, Total KL Divergence: 56104177.75, Total Reconstruction Loss: 20583178379264.0\n",
      "2023-07-19 13:17:59,553 - INFO - Save model at epoch 110\n",
      "0it [00:00, ?it/s]2023-07-19 13:17:59,660 - INFO - Epoch: [111/600], Step: [1/591], Loss: 151755888.0, KL Divergence: 754.3218994140625, Reconstruction Loss: 151755136.0\n",
      "117it [00:10, 10.77it/s]2023-07-19 13:18:10,613 - INFO - Epoch: [111/600], Step: [119/591], Loss: 487522656.0, KL Divergence: 746.8890380859375, Reconstruction Loss: 487521920.0\n",
      "235it [00:21, 10.71it/s]2023-07-19 13:18:21,633 - INFO - Epoch: [111/600], Step: [237/591], Loss: 305210848.0, KL Divergence: 742.82958984375, Reconstruction Loss: 305210112.0\n",
      "353it [00:32, 10.58it/s]2023-07-19 13:18:32,507 - INFO - Epoch: [111/600], Step: [355/591], Loss: 355553120.0, KL Divergence: 743.9777221679688, Reconstruction Loss: 355552384.0\n",
      "471it [00:43, 10.68it/s]2023-07-19 13:18:43,516 - INFO - Epoch: [111/600], Step: [473/591], Loss: 314000032.0, KL Divergence: 742.86962890625, Reconstruction Loss: 313999296.0\n",
      "589it [00:55, 10.29it/s]2023-07-19 13:18:55,082 - INFO - Epoch: [111/600], Step: [591/591], Loss: 263217408.0, KL Divergence: 771.7099609375, Reconstruction Loss: 263216640.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 13:18:55,084 - INFO - Epoch: [111/600], Total Loss: 20406439888896.0, Total KL Divergence: 56505290.1015625, Total Reconstruction Loss: 20406383519744.0\n",
      "2023-07-19 13:18:55,127 - INFO - Save model at epoch 111\n",
      "0it [00:00, ?it/s]2023-07-19 13:18:55,243 - INFO - Epoch: [112/600], Step: [1/591], Loss: 153751216.0, KL Divergence: 761.804931640625, Reconstruction Loss: 153750448.0\n",
      "118it [00:11, 10.32it/s]2023-07-19 13:19:07,047 - INFO - Epoch: [112/600], Step: [119/591], Loss: 430512320.0, KL Divergence: 753.9523315429688, Reconstruction Loss: 430511552.0\n",
      "236it [00:23, 10.90it/s]2023-07-19 13:19:18,397 - INFO - Epoch: [112/600], Step: [237/591], Loss: 306781280.0, KL Divergence: 748.4940185546875, Reconstruction Loss: 306780544.0\n",
      "354it [00:34, 10.48it/s]2023-07-19 13:19:29,501 - INFO - Epoch: [112/600], Step: [355/591], Loss: 351483296.0, KL Divergence: 746.1268310546875, Reconstruction Loss: 351482560.0\n",
      "472it [00:45, 10.86it/s]2023-07-19 13:19:40,624 - INFO - Epoch: [112/600], Step: [473/591], Loss: 330293728.0, KL Divergence: 739.9943237304688, Reconstruction Loss: 330292992.0\n",
      "590it [00:56, 11.05it/s]2023-07-19 13:19:51,481 - INFO - Epoch: [112/600], Step: [591/591], Loss: 234555360.0, KL Divergence: 764.5843505859375, Reconstruction Loss: 234554592.0\n",
      "591it [00:56, 10.49it/s]\n",
      "2023-07-19 13:19:51,483 - INFO - Epoch: [112/600], Total Loss: 20413236845568.0, Total KL Divergence: 56594701.9453125, Total Reconstruction Loss: 20413180368896.0\n",
      "2023-07-19 13:19:51,522 - INFO - Save model at epoch 112\n",
      "0it [00:00, ?it/s]2023-07-19 13:19:51,645 - INFO - Epoch: [113/600], Step: [1/591], Loss: 143352240.0, KL Divergence: 753.3197021484375, Reconstruction Loss: 143351488.0\n",
      "117it [00:10, 10.45it/s]2023-07-19 13:20:02,562 - INFO - Epoch: [113/600], Step: [119/591], Loss: 415420352.0, KL Divergence: 748.9029541015625, Reconstruction Loss: 415419616.0\n",
      "235it [00:21, 10.81it/s]2023-07-19 13:20:13,725 - INFO - Epoch: [113/600], Step: [237/591], Loss: 304494336.0, KL Divergence: 742.8065185546875, Reconstruction Loss: 304493600.0\n",
      "353it [00:32, 10.84it/s]2023-07-19 13:20:24,665 - INFO - Epoch: [113/600], Step: [355/591], Loss: 361676512.0, KL Divergence: 735.7347412109375, Reconstruction Loss: 361675776.0\n",
      "471it [00:43, 10.95it/s]2023-07-19 13:20:35,507 - INFO - Epoch: [113/600], Step: [473/591], Loss: 311833504.0, KL Divergence: 734.24755859375, Reconstruction Loss: 311832768.0\n",
      "589it [00:54, 10.71it/s]2023-07-19 13:20:46,381 - INFO - Epoch: [113/600], Step: [591/591], Loss: 236884672.0, KL Divergence: 762.9149780273438, Reconstruction Loss: 236883904.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 13:20:46,383 - INFO - Epoch: [113/600], Total Loss: 20303530745856.0, Total KL Divergence: 56222427.90625, Total Reconstruction Loss: 20303474622464.0\n",
      "2023-07-19 13:20:46,425 - INFO - Save model at epoch 113\n",
      "0it [00:00, ?it/s]2023-07-19 13:20:46,529 - INFO - Epoch: [114/600], Step: [1/591], Loss: 145588304.0, KL Divergence: 750.8067016601562, Reconstruction Loss: 145587552.0\n",
      "118it [00:10, 11.01it/s]2023-07-19 13:20:57,269 - INFO - Epoch: [114/600], Step: [119/591], Loss: 404189920.0, KL Divergence: 744.44189453125, Reconstruction Loss: 404189184.0\n",
      "236it [00:21, 10.70it/s]2023-07-19 13:21:08,077 - INFO - Epoch: [114/600], Step: [237/591], Loss: 304238336.0, KL Divergence: 738.3800048828125, Reconstruction Loss: 304237600.0\n",
      "354it [00:32, 10.67it/s]2023-07-19 13:21:19,058 - INFO - Epoch: [114/600], Step: [355/591], Loss: 351663232.0, KL Divergence: 731.8380126953125, Reconstruction Loss: 351662496.0\n",
      "472it [00:43, 10.80it/s]2023-07-19 13:21:30,007 - INFO - Epoch: [114/600], Step: [473/591], Loss: 331419040.0, KL Divergence: 728.2463989257812, Reconstruction Loss: 331418304.0\n",
      "590it [00:54, 10.92it/s]2023-07-19 13:21:40,882 - INFO - Epoch: [114/600], Step: [591/591], Loss: 242774304.0, KL Divergence: 755.9039916992188, Reconstruction Loss: 242773552.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 13:21:40,883 - INFO - Epoch: [114/600], Total Loss: 20366341989376.0, Total KL Divergence: 55862311.3359375, Total Reconstruction Loss: 20366286125056.0\n",
      "2023-07-19 13:21:40,922 - INFO - Save model at epoch 114\n",
      "0it [00:00, ?it/s]2023-07-19 13:21:41,040 - INFO - Epoch: [115/600], Step: [1/591], Loss: 145064832.0, KL Divergence: 742.63037109375, Reconstruction Loss: 145064096.0\n",
      "118it [00:10, 10.92it/s]2023-07-19 13:21:51,996 - INFO - Epoch: [115/600], Step: [119/591], Loss: 412875264.0, KL Divergence: 740.441162109375, Reconstruction Loss: 412874528.0\n",
      "236it [00:21, 10.55it/s]2023-07-19 13:22:02,847 - INFO - Epoch: [115/600], Step: [237/591], Loss: 305184000.0, KL Divergence: 727.6962890625, Reconstruction Loss: 305183264.0\n",
      "354it [00:32, 11.06it/s]2023-07-19 13:22:13,679 - INFO - Epoch: [115/600], Step: [355/591], Loss: 342848352.0, KL Divergence: 724.8214111328125, Reconstruction Loss: 342847616.0\n",
      "472it [00:43, 10.85it/s]2023-07-19 13:22:24,522 - INFO - Epoch: [115/600], Step: [473/591], Loss: 320045504.0, KL Divergence: 725.7584228515625, Reconstruction Loss: 320044768.0\n",
      "590it [00:54, 11.20it/s]2023-07-19 13:22:35,425 - INFO - Epoch: [115/600], Step: [591/591], Loss: 258399392.0, KL Divergence: 751.0741577148438, Reconstruction Loss: 258398640.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 13:22:35,427 - INFO - Epoch: [115/600], Total Loss: 20488478113792.0, Total KL Divergence: 55403148.1953125, Total Reconstruction Loss: 20488422555648.0\n",
      "2023-07-19 13:22:35,471 - INFO - Save model at epoch 115\n",
      "0it [00:00, ?it/s]2023-07-19 13:22:35,581 - INFO - Epoch: [116/600], Step: [1/591], Loss: 168984288.0, KL Divergence: 740.5614013671875, Reconstruction Loss: 168983552.0\n",
      "117it [00:10, 10.50it/s]2023-07-19 13:22:46,562 - INFO - Epoch: [116/600], Step: [119/591], Loss: 407578560.0, KL Divergence: 734.28271484375, Reconstruction Loss: 407577824.0\n",
      "235it [00:21, 10.34it/s]2023-07-19 13:22:57,492 - INFO - Epoch: [116/600], Step: [237/591], Loss: 289832416.0, KL Divergence: 727.3881225585938, Reconstruction Loss: 289831680.0\n",
      "353it [00:32, 10.89it/s]2023-07-19 13:23:08,359 - INFO - Epoch: [116/600], Step: [355/591], Loss: 336190912.0, KL Divergence: 727.18212890625, Reconstruction Loss: 336190176.0\n",
      "471it [00:43, 10.46it/s]2023-07-19 13:23:19,357 - INFO - Epoch: [116/600], Step: [473/591], Loss: 326690976.0, KL Divergence: 729.7611083984375, Reconstruction Loss: 326690240.0\n",
      "589it [00:54, 10.33it/s]2023-07-19 13:23:30,527 - INFO - Epoch: [116/600], Step: [591/591], Loss: 232457056.0, KL Divergence: 757.4718627929688, Reconstruction Loss: 232456304.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 13:23:30,529 - INFO - Epoch: [116/600], Total Loss: 20362184476672.0, Total KL Divergence: 55439079.4140625, Total Reconstruction Loss: 20362128911360.0\n",
      "2023-07-19 13:23:30,570 - INFO - Save model at epoch 116\n",
      "0it [00:00, ?it/s]2023-07-19 13:23:30,679 - INFO - Epoch: [117/600], Step: [1/591], Loss: 146870480.0, KL Divergence: 747.071044921875, Reconstruction Loss: 146869728.0\n",
      "117it [00:11, 10.73it/s]2023-07-19 13:23:41,797 - INFO - Epoch: [117/600], Step: [119/591], Loss: 412412992.0, KL Divergence: 742.7125854492188, Reconstruction Loss: 412412256.0\n",
      "235it [00:21, 10.94it/s]2023-07-19 13:23:52,770 - INFO - Epoch: [117/600], Step: [237/591], Loss: 300666080.0, KL Divergence: 734.97412109375, Reconstruction Loss: 300665344.0\n",
      "353it [00:32, 10.87it/s]2023-07-19 13:24:03,644 - INFO - Epoch: [117/600], Step: [355/591], Loss: 401262688.0, KL Divergence: 734.4000244140625, Reconstruction Loss: 401261952.0\n",
      "471it [00:43, 10.62it/s]2023-07-19 13:24:14,553 - INFO - Epoch: [117/600], Step: [473/591], Loss: 343424288.0, KL Divergence: 733.1092529296875, Reconstruction Loss: 343423552.0\n",
      "589it [00:54, 11.01it/s]2023-07-19 13:24:25,408 - INFO - Epoch: [117/600], Step: [591/591], Loss: 238450576.0, KL Divergence: 759.9620971679688, Reconstruction Loss: 238449824.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 13:24:25,410 - INFO - Epoch: [117/600], Total Loss: 20741210939392.0, Total KL Divergence: 55776347.4140625, Total Reconstruction Loss: 20741155180544.0\n",
      "2023-07-19 13:24:25,456 - INFO - Save model at epoch 117\n",
      "0it [00:00, ?it/s]2023-07-19 13:24:25,567 - INFO - Epoch: [118/600], Step: [1/591], Loss: 151583888.0, KL Divergence: 748.6891479492188, Reconstruction Loss: 151583136.0\n",
      "117it [00:10, 10.97it/s]2023-07-19 13:24:36,556 - INFO - Epoch: [118/600], Step: [119/591], Loss: 414505184.0, KL Divergence: 742.3695068359375, Reconstruction Loss: 414504448.0\n",
      "235it [00:21, 10.04it/s]2023-07-19 13:24:47,658 - INFO - Epoch: [118/600], Step: [237/591], Loss: 341623200.0, KL Divergence: 735.6907958984375, Reconstruction Loss: 341622464.0\n",
      "353it [00:32, 10.98it/s]2023-07-19 13:24:58,624 - INFO - Epoch: [118/600], Step: [355/591], Loss: 372248864.0, KL Divergence: 728.885498046875, Reconstruction Loss: 372248128.0\n",
      "471it [00:43, 10.88it/s]2023-07-19 13:25:09,622 - INFO - Epoch: [118/600], Step: [473/591], Loss: 323076000.0, KL Divergence: 734.78759765625, Reconstruction Loss: 323075264.0\n",
      "589it [00:54, 10.73it/s]2023-07-19 13:25:20,500 - INFO - Epoch: [118/600], Step: [591/591], Loss: 253482688.0, KL Divergence: 766.0341796875, Reconstruction Loss: 253481920.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 13:25:20,502 - INFO - Epoch: [118/600], Total Loss: 20729276667904.0, Total KL Divergence: 55850473.0078125, Total Reconstruction Loss: 20729220858880.0\n",
      "2023-07-19 13:25:20,542 - INFO - Save model at epoch 118\n",
      "0it [00:00, ?it/s]2023-07-19 13:25:20,663 - INFO - Epoch: [119/600], Step: [1/591], Loss: 149977232.0, KL Divergence: 754.68798828125, Reconstruction Loss: 149976480.0\n",
      "117it [00:10, 10.99it/s]2023-07-19 13:25:31,641 - INFO - Epoch: [119/600], Step: [119/591], Loss: 430557984.0, KL Divergence: 748.945068359375, Reconstruction Loss: 430557248.0\n",
      "235it [00:21, 10.25it/s]2023-07-19 13:25:42,687 - INFO - Epoch: [119/600], Step: [237/591], Loss: 295681568.0, KL Divergence: 742.491943359375, Reconstruction Loss: 295680832.0\n",
      "353it [00:32, 10.84it/s]2023-07-19 13:25:53,724 - INFO - Epoch: [119/600], Step: [355/591], Loss: 364709600.0, KL Divergence: 737.5938720703125, Reconstruction Loss: 364708864.0\n",
      "471it [00:43, 11.06it/s]2023-07-19 13:26:04,624 - INFO - Epoch: [119/600], Step: [473/591], Loss: 312457536.0, KL Divergence: 739.8097534179688, Reconstruction Loss: 312456800.0\n",
      "589it [00:54, 10.46it/s]2023-07-19 13:26:15,481 - INFO - Epoch: [119/600], Step: [591/591], Loss: 237358144.0, KL Divergence: 769.2601318359375, Reconstruction Loss: 237357376.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 13:26:15,483 - INFO - Epoch: [119/600], Total Loss: 20395010052096.0, Total KL Divergence: 56479018.953125, Total Reconstruction Loss: 20394953750528.0\n",
      "2023-07-19 13:26:15,536 - INFO - Save model at epoch 119\n",
      "0it [00:00, ?it/s]2023-07-19 13:26:15,645 - INFO - Epoch: [120/600], Step: [1/591], Loss: 152725168.0, KL Divergence: 759.3658447265625, Reconstruction Loss: 152724416.0\n",
      "117it [00:10, 11.14it/s]2023-07-19 13:26:26,677 - INFO - Epoch: [120/600], Step: [119/591], Loss: 407681440.0, KL Divergence: 751.9093017578125, Reconstruction Loss: 407680704.0\n",
      "235it [00:21,  9.83it/s]2023-07-19 13:26:37,706 - INFO - Epoch: [120/600], Step: [237/591], Loss: 291921376.0, KL Divergence: 739.6168212890625, Reconstruction Loss: 291920640.0\n",
      "353it [00:32, 10.93it/s]2023-07-19 13:26:48,565 - INFO - Epoch: [120/600], Step: [355/591], Loss: 368401760.0, KL Divergence: 736.2908935546875, Reconstruction Loss: 368401024.0\n",
      "471it [00:43, 10.99it/s]2023-07-19 13:26:59,197 - INFO - Epoch: [120/600], Step: [473/591], Loss: 307308864.0, KL Divergence: 738.621337890625, Reconstruction Loss: 307308128.0\n",
      "589it [00:54, 10.65it/s]2023-07-19 13:27:09,985 - INFO - Epoch: [120/600], Step: [591/591], Loss: 233801664.0, KL Divergence: 767.58349609375, Reconstruction Loss: 233800896.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 13:27:09,987 - INFO - Epoch: [120/600], Total Loss: 20391888323584.0, Total KL Divergence: 56421800.796875, Total Reconstruction Loss: 20391832046592.0\n",
      "2023-07-19 13:27:10,028 - INFO - Save model at epoch 120\n",
      "0it [00:00, ?it/s]2023-07-19 13:27:10,132 - INFO - Epoch: [121/600], Step: [1/591], Loss: 139321392.0, KL Divergence: 757.0377197265625, Reconstruction Loss: 139320640.0\n",
      "118it [00:11, 10.90it/s]2023-07-19 13:27:21,154 - INFO - Epoch: [121/600], Step: [119/591], Loss: 439420672.0, KL Divergence: 754.1353759765625, Reconstruction Loss: 439419904.0\n",
      "236it [00:22,  9.97it/s]2023-07-19 13:27:32,341 - INFO - Epoch: [121/600], Step: [237/591], Loss: 296894368.0, KL Divergence: 740.1026000976562, Reconstruction Loss: 296893632.0\n",
      "354it [00:33, 10.61it/s]2023-07-19 13:27:43,220 - INFO - Epoch: [121/600], Step: [355/591], Loss: 375486560.0, KL Divergence: 733.774169921875, Reconstruction Loss: 375485824.0\n",
      "472it [00:43, 10.60it/s]2023-07-19 13:27:54,088 - INFO - Epoch: [121/600], Step: [473/591], Loss: 318488352.0, KL Divergence: 738.2503662109375, Reconstruction Loss: 318487616.0\n",
      "590it [00:54, 11.08it/s]2023-07-19 13:28:04,980 - INFO - Epoch: [121/600], Step: [591/591], Loss: 233887648.0, KL Divergence: 764.6650390625, Reconstruction Loss: 233886880.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 13:28:04,982 - INFO - Epoch: [121/600], Total Loss: 20568360896512.0, Total KL Divergence: 56370882.5703125, Total Reconstruction Loss: 20568304648192.0\n",
      "2023-07-19 13:28:05,021 - INFO - Save model at epoch 121\n",
      "0it [00:00, ?it/s]2023-07-19 13:28:05,136 - INFO - Epoch: [122/600], Step: [1/591], Loss: 149437328.0, KL Divergence: 754.408203125, Reconstruction Loss: 149436576.0\n",
      "117it [00:10, 10.68it/s]2023-07-19 13:28:16,073 - INFO - Epoch: [122/600], Step: [119/591], Loss: 407398080.0, KL Divergence: 741.14306640625, Reconstruction Loss: 407397344.0\n",
      "235it [00:21, 10.95it/s]2023-07-19 13:28:26,961 - INFO - Epoch: [122/600], Step: [237/591], Loss: 288276384.0, KL Divergence: 738.444091796875, Reconstruction Loss: 288275648.0\n",
      "353it [00:32, 10.87it/s]2023-07-19 13:28:37,894 - INFO - Epoch: [122/600], Step: [355/591], Loss: 351921056.0, KL Divergence: 731.5833740234375, Reconstruction Loss: 351920320.0\n",
      "471it [00:43, 10.92it/s]2023-07-19 13:28:48,720 - INFO - Epoch: [122/600], Step: [473/591], Loss: 306296096.0, KL Divergence: 732.1990966796875, Reconstruction Loss: 306295360.0\n",
      "589it [00:54, 10.89it/s]2023-07-19 13:28:59,641 - INFO - Epoch: [122/600], Step: [591/591], Loss: 259300000.0, KL Divergence: 761.6683349609375, Reconstruction Loss: 259299232.0\n",
      "591it [00:54, 10.82it/s]\n",
      "2023-07-19 13:28:59,644 - INFO - Epoch: [122/600], Total Loss: 20113013129216.0, Total KL Divergence: 56003202.984375, Total Reconstruction Loss: 20112957206528.0\n",
      "2023-07-19 13:28:59,686 - INFO - Save model at epoch 122\n",
      "0it [00:00, ?it/s]2023-07-19 13:28:59,817 - INFO - Epoch: [123/600], Step: [1/591], Loss: 137163216.0, KL Divergence: 749.9321899414062, Reconstruction Loss: 137162464.0\n",
      "117it [00:10, 11.02it/s]2023-07-19 13:29:10,655 - INFO - Epoch: [123/600], Step: [119/591], Loss: 398878880.0, KL Divergence: 745.744384765625, Reconstruction Loss: 398878144.0\n",
      "235it [00:21, 10.36it/s]2023-07-19 13:29:21,611 - INFO - Epoch: [123/600], Step: [237/591], Loss: 285075808.0, KL Divergence: 729.0614624023438, Reconstruction Loss: 285075072.0\n",
      "353it [00:32, 10.72it/s]2023-07-19 13:29:32,600 - INFO - Epoch: [123/600], Step: [355/591], Loss: 365949792.0, KL Divergence: 723.275390625, Reconstruction Loss: 365949056.0\n",
      "471it [00:43, 11.02it/s]2023-07-19 13:29:43,400 - INFO - Epoch: [123/600], Step: [473/591], Loss: 298201248.0, KL Divergence: 732.7176513671875, Reconstruction Loss: 298200512.0\n",
      "589it [00:54, 11.03it/s]2023-07-19 13:29:54,278 - INFO - Epoch: [123/600], Step: [591/591], Loss: 238678736.0, KL Divergence: 754.4396362304688, Reconstruction Loss: 238677984.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 13:29:54,280 - INFO - Epoch: [123/600], Total Loss: 20328265616384.0, Total KL Divergence: 55713791.03125, Total Reconstruction Loss: 20328209866752.0\n",
      "2023-07-19 13:29:54,324 - INFO - Save model at epoch 123\n",
      "0it [00:00, ?it/s]2023-07-19 13:29:54,429 - INFO - Epoch: [124/600], Step: [1/591], Loss: 138228128.0, KL Divergence: 744.9825439453125, Reconstruction Loss: 138227376.0\n",
      "117it [00:10, 10.87it/s]2023-07-19 13:30:05,383 - INFO - Epoch: [124/600], Step: [119/591], Loss: 400575392.0, KL Divergence: 735.669189453125, Reconstruction Loss: 400574656.0\n",
      "235it [00:21, 10.97it/s]2023-07-19 13:30:16,386 - INFO - Epoch: [124/600], Step: [237/591], Loss: 293599872.0, KL Divergence: 727.3109130859375, Reconstruction Loss: 293599136.0\n",
      "353it [00:33, 10.77it/s]2023-07-19 13:30:27,628 - INFO - Epoch: [124/600], Step: [355/591], Loss: 395340000.0, KL Divergence: 724.4118041992188, Reconstruction Loss: 395339264.0\n",
      "471it [00:44, 10.42it/s]2023-07-19 13:30:38,871 - INFO - Epoch: [124/600], Step: [473/591], Loss: 305108768.0, KL Divergence: 727.965087890625, Reconstruction Loss: 305108032.0\n",
      "589it [00:55, 10.78it/s]2023-07-19 13:30:49,778 - INFO - Epoch: [124/600], Step: [591/591], Loss: 237893152.0, KL Divergence: 753.86865234375, Reconstruction Loss: 237892400.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 13:30:49,781 - INFO - Epoch: [124/600], Total Loss: 20332634360832.0, Total KL Divergence: 55516202.9296875, Total Reconstruction Loss: 20332578715648.0\n",
      "2023-07-19 13:30:49,822 - INFO - Save model at epoch 124\n",
      "0it [00:00, ?it/s]2023-07-19 13:30:49,930 - INFO - Epoch: [125/600], Step: [1/591], Loss: 136842592.0, KL Divergence: 743.6360473632812, Reconstruction Loss: 136841856.0\n",
      "117it [00:10, 10.99it/s]2023-07-19 13:31:00,937 - INFO - Epoch: [125/600], Step: [119/591], Loss: 396780832.0, KL Divergence: 739.506103515625, Reconstruction Loss: 396780096.0\n",
      "235it [00:21, 11.16it/s]2023-07-19 13:31:11,958 - INFO - Epoch: [125/600], Step: [237/591], Loss: 285577216.0, KL Divergence: 732.234130859375, Reconstruction Loss: 285576480.0\n",
      "353it [00:33, 10.61it/s]2023-07-19 13:31:23,113 - INFO - Epoch: [125/600], Step: [355/591], Loss: 352866784.0, KL Divergence: 724.55712890625, Reconstruction Loss: 352866048.0\n",
      "471it [00:44, 11.05it/s]2023-07-19 13:31:34,215 - INFO - Epoch: [125/600], Step: [473/591], Loss: 298895904.0, KL Divergence: 726.94189453125, Reconstruction Loss: 298895168.0\n",
      "589it [00:55, 11.05it/s]2023-07-19 13:31:45,192 - INFO - Epoch: [125/600], Step: [591/591], Loss: 241215120.0, KL Divergence: 753.200927734375, Reconstruction Loss: 241214368.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 13:31:45,194 - INFO - Epoch: [125/600], Total Loss: 20024665624576.0, Total KL Divergence: 55521023.03125, Total Reconstruction Loss: 20024609989632.0\n",
      "2023-07-19 13:31:45,240 - INFO - Save model at epoch 125\n",
      "0it [00:00, ?it/s]2023-07-19 13:31:45,353 - INFO - Epoch: [126/600], Step: [1/591], Loss: 138235040.0, KL Divergence: 743.1065063476562, Reconstruction Loss: 138234304.0\n",
      "117it [00:10, 10.69it/s]2023-07-19 13:31:56,365 - INFO - Epoch: [126/600], Step: [119/591], Loss: 398659872.0, KL Divergence: 734.3115234375, Reconstruction Loss: 398659136.0\n",
      "235it [00:21, 10.96it/s]2023-07-19 13:32:07,298 - INFO - Epoch: [126/600], Step: [237/591], Loss: 286183552.0, KL Divergence: 725.0055541992188, Reconstruction Loss: 286182816.0\n",
      "353it [00:32, 10.63it/s]2023-07-19 13:32:18,230 - INFO - Epoch: [126/600], Step: [355/591], Loss: 344683328.0, KL Divergence: 718.1329345703125, Reconstruction Loss: 344682624.0\n",
      "471it [00:43, 10.43it/s]2023-07-19 13:32:29,228 - INFO - Epoch: [126/600], Step: [473/591], Loss: 291674592.0, KL Divergence: 725.6949462890625, Reconstruction Loss: 291673856.0\n",
      "589it [00:54, 10.47it/s]2023-07-19 13:32:40,208 - INFO - Epoch: [126/600], Step: [591/591], Loss: 233675152.0, KL Divergence: 756.1820068359375, Reconstruction Loss: 233674400.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 13:32:40,210 - INFO - Epoch: [126/600], Total Loss: 19849913824256.0, Total KL Divergence: 55184304.5078125, Total Reconstruction Loss: 19849858510848.0\n",
      "2023-07-19 13:32:40,263 - INFO - Save model at epoch 126\n",
      "0it [00:00, ?it/s]2023-07-19 13:32:40,388 - INFO - Epoch: [127/600], Step: [1/591], Loss: 137449072.0, KL Divergence: 746.0494995117188, Reconstruction Loss: 137448320.0\n",
      "118it [00:10, 10.97it/s]2023-07-19 13:32:51,304 - INFO - Epoch: [127/600], Step: [119/591], Loss: 398201312.0, KL Divergence: 741.675048828125, Reconstruction Loss: 398200576.0\n",
      "236it [00:21, 10.96it/s]2023-07-19 13:33:02,183 - INFO - Epoch: [127/600], Step: [237/591], Loss: 281052480.0, KL Divergence: 731.2696533203125, Reconstruction Loss: 281051744.0\n",
      "354it [00:32, 10.72it/s]2023-07-19 13:33:13,206 - INFO - Epoch: [127/600], Step: [355/591], Loss: 334487456.0, KL Divergence: 730.4569091796875, Reconstruction Loss: 334486720.0\n",
      "472it [00:43, 10.99it/s]2023-07-19 13:33:24,205 - INFO - Epoch: [127/600], Step: [473/591], Loss: 294693280.0, KL Divergence: 728.364501953125, Reconstruction Loss: 294692544.0\n",
      "590it [00:54, 11.14it/s]2023-07-19 13:33:35,049 - INFO - Epoch: [127/600], Step: [591/591], Loss: 236829808.0, KL Divergence: 759.0633544921875, Reconstruction Loss: 236829056.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 13:33:35,051 - INFO - Epoch: [127/600], Total Loss: 19696740629504.0, Total KL Divergence: 55642519.140625, Total Reconstruction Loss: 19696684913664.0\n",
      "2023-07-19 13:33:35,092 - INFO - Save model at epoch 127\n",
      "0it [00:00, ?it/s]2023-07-19 13:33:35,208 - INFO - Epoch: [128/600], Step: [1/591], Loss: 138356624.0, KL Divergence: 747.306884765625, Reconstruction Loss: 138355872.0\n",
      "117it [00:10, 10.99it/s]2023-07-19 13:33:46,159 - INFO - Epoch: [128/600], Step: [119/591], Loss: 405105536.0, KL Divergence: 737.04833984375, Reconstruction Loss: 405104800.0\n",
      "235it [00:21, 10.96it/s]2023-07-19 13:33:57,228 - INFO - Epoch: [128/600], Step: [237/591], Loss: 276353952.0, KL Divergence: 733.982421875, Reconstruction Loss: 276353216.0\n",
      "353it [00:32, 10.56it/s]2023-07-19 13:34:08,237 - INFO - Epoch: [128/600], Step: [355/591], Loss: 339315232.0, KL Divergence: 727.3223876953125, Reconstruction Loss: 339314496.0\n",
      "471it [00:44, 10.70it/s]2023-07-19 13:34:19,313 - INFO - Epoch: [128/600], Step: [473/591], Loss: 293298848.0, KL Divergence: 729.389892578125, Reconstruction Loss: 293298112.0\n",
      "589it [00:55, 10.68it/s]2023-07-19 13:34:30,833 - INFO - Epoch: [128/600], Step: [591/591], Loss: 222038624.0, KL Divergence: 755.4866943359375, Reconstruction Loss: 222037872.0\n",
      "591it [00:55, 10.60it/s]\n",
      "2023-07-19 13:34:30,835 - INFO - Epoch: [128/600], Total Loss: 19717575569408.0, Total KL Divergence: 55663097.390625, Total Reconstruction Loss: 19717519814656.0\n",
      "2023-07-19 13:34:30,886 - INFO - Save model at epoch 128\n",
      "0it [00:00, ?it/s]2023-07-19 13:34:31,005 - INFO - Epoch: [129/600], Step: [1/591], Loss: 145704080.0, KL Divergence: 744.67333984375, Reconstruction Loss: 145703328.0\n",
      "117it [00:11, 10.68it/s]2023-07-19 13:34:42,115 - INFO - Epoch: [129/600], Step: [119/591], Loss: 421959264.0, KL Divergence: 743.537353515625, Reconstruction Loss: 421958528.0\n",
      "235it [00:22, 10.64it/s]2023-07-19 13:34:53,456 - INFO - Epoch: [129/600], Step: [237/591], Loss: 285308800.0, KL Divergence: 730.033935546875, Reconstruction Loss: 285308064.0\n",
      "354it [00:33, 10.99it/s]2023-07-19 13:35:04,634 - INFO - Epoch: [129/600], Step: [355/591], Loss: 349436512.0, KL Divergence: 729.27490234375, Reconstruction Loss: 349435776.0\n",
      "472it [00:44, 10.71it/s]2023-07-19 13:35:15,699 - INFO - Epoch: [129/600], Step: [473/591], Loss: 306569312.0, KL Divergence: 735.676513671875, Reconstruction Loss: 306568576.0\n",
      "590it [00:55, 10.61it/s]2023-07-19 13:35:26,899 - INFO - Epoch: [129/600], Step: [591/591], Loss: 232713856.0, KL Divergence: 760.7958984375, Reconstruction Loss: 232713088.0\n",
      "591it [00:55, 10.55it/s]\n",
      "2023-07-19 13:35:26,901 - INFO - Epoch: [129/600], Total Loss: 19629180900352.0, Total KL Divergence: 55806851.609375, Total Reconstruction Loss: 19629125100544.0\n",
      "2023-07-19 13:35:26,944 - INFO - Save model at epoch 129\n",
      "0it [00:00, ?it/s]2023-07-19 13:35:27,055 - INFO - Epoch: [130/600], Step: [1/591], Loss: 136412816.0, KL Divergence: 751.4898071289062, Reconstruction Loss: 136412064.0\n",
      "117it [00:11, 10.56it/s]2023-07-19 13:35:38,394 - INFO - Epoch: [130/600], Step: [119/591], Loss: 392797856.0, KL Divergence: 745.008544921875, Reconstruction Loss: 392797120.0\n",
      "235it [00:22, 10.10it/s]2023-07-19 13:35:49,698 - INFO - Epoch: [130/600], Step: [237/591], Loss: 285145440.0, KL Divergence: 742.4224853515625, Reconstruction Loss: 285144704.0\n",
      "354it [00:36,  8.39it/s]2023-07-19 13:36:03,197 - INFO - Epoch: [130/600], Step: [355/591], Loss: 366800896.0, KL Divergence: 738.10205078125, Reconstruction Loss: 366800160.0\n",
      "472it [00:47, 10.46it/s]2023-07-19 13:36:14,555 - INFO - Epoch: [130/600], Step: [473/591], Loss: 289492160.0, KL Divergence: 740.6678466796875, Reconstruction Loss: 289491424.0\n",
      "590it [00:59, 10.37it/s]2023-07-19 13:36:26,098 - INFO - Epoch: [130/600], Step: [591/591], Loss: 243795232.0, KL Divergence: 769.740234375, Reconstruction Loss: 243794464.0\n",
      "591it [00:59,  9.99it/s]\n",
      "2023-07-19 13:36:26,100 - INFO - Epoch: [130/600], Total Loss: 19501588764672.0, Total KL Divergence: 56340310.6015625, Total Reconstruction Loss: 19501532538880.0\n",
      "2023-07-19 13:36:26,142 - INFO - Save model at epoch 130\n",
      "0it [00:00, ?it/s]2023-07-19 13:36:26,255 - INFO - Epoch: [131/600], Step: [1/591], Loss: 137814128.0, KL Divergence: 759.2533569335938, Reconstruction Loss: 137813376.0\n",
      "117it [00:11, 10.96it/s]2023-07-19 13:36:37,381 - INFO - Epoch: [131/600], Step: [119/591], Loss: 386982816.0, KL Divergence: 747.4900512695312, Reconstruction Loss: 386982080.0\n",
      "235it [00:22, 10.52it/s]2023-07-19 13:36:48,458 - INFO - Epoch: [131/600], Step: [237/591], Loss: 304905536.0, KL Divergence: 740.7330322265625, Reconstruction Loss: 304904800.0\n",
      "353it [00:33, 10.35it/s]2023-07-19 13:36:59,830 - INFO - Epoch: [131/600], Step: [355/591], Loss: 337931424.0, KL Divergence: 736.228271484375, Reconstruction Loss: 337930688.0\n",
      "471it [00:44, 10.51it/s]2023-07-19 13:37:11,210 - INFO - Epoch: [131/600], Step: [473/591], Loss: 299486752.0, KL Divergence: 740.413330078125, Reconstruction Loss: 299486016.0\n",
      "589it [00:56, 10.05it/s]2023-07-19 13:37:22,468 - INFO - Epoch: [131/600], Step: [591/591], Loss: 233503712.0, KL Divergence: 771.3955078125, Reconstruction Loss: 233502944.0\n",
      "591it [00:56, 10.49it/s]\n",
      "2023-07-19 13:37:22,469 - INFO - Epoch: [131/600], Total Loss: 19456300306432.0, Total KL Divergence: 56409760.7734375, Total Reconstruction Loss: 19456244021248.0\n",
      "2023-07-19 13:37:22,510 - INFO - Save model at epoch 131\n",
      "0it [00:00, ?it/s]2023-07-19 13:37:22,631 - INFO - Epoch: [132/600], Step: [1/591], Loss: 141794208.0, KL Divergence: 760.1465454101562, Reconstruction Loss: 141793440.0\n",
      "118it [00:11, 10.72it/s]2023-07-19 13:37:33,693 - INFO - Epoch: [132/600], Step: [119/591], Loss: 383548448.0, KL Divergence: 751.4442749023438, Reconstruction Loss: 383547712.0\n",
      "236it [00:21, 10.84it/s]2023-07-19 13:37:44,586 - INFO - Epoch: [132/600], Step: [237/591], Loss: 275368224.0, KL Divergence: 749.1578369140625, Reconstruction Loss: 275367488.0\n",
      "354it [00:32, 10.62it/s]2023-07-19 13:37:55,443 - INFO - Epoch: [132/600], Step: [355/591], Loss: 340492704.0, KL Divergence: 748.3397216796875, Reconstruction Loss: 340491968.0\n",
      "472it [00:43, 10.92it/s]2023-07-19 13:38:06,231 - INFO - Epoch: [132/600], Step: [473/591], Loss: 296501344.0, KL Divergence: 754.6639404296875, Reconstruction Loss: 296500576.0\n",
      "590it [00:54, 11.03it/s]2023-07-19 13:38:17,021 - INFO - Epoch: [132/600], Step: [591/591], Loss: 231876368.0, KL Divergence: 776.1627197265625, Reconstruction Loss: 231875584.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 13:38:17,022 - INFO - Epoch: [132/600], Total Loss: 19632083024896.0, Total KL Divergence: 57091167.5859375, Total Reconstruction Loss: 19632025893888.0\n",
      "2023-07-19 13:38:17,067 - INFO - Save model at epoch 132\n",
      "0it [00:00, ?it/s]2023-07-19 13:38:17,182 - INFO - Epoch: [133/600], Step: [1/591], Loss: 135910912.0, KL Divergence: 766.0552368164062, Reconstruction Loss: 135910144.0\n",
      "117it [00:10, 10.97it/s]2023-07-19 13:38:27,993 - INFO - Epoch: [133/600], Step: [119/591], Loss: 381845792.0, KL Divergence: 766.4317626953125, Reconstruction Loss: 381845024.0\n",
      "235it [00:21, 11.04it/s]2023-07-19 13:38:38,771 - INFO - Epoch: [133/600], Step: [237/591], Loss: 280039168.0, KL Divergence: 754.35302734375, Reconstruction Loss: 280038400.0\n",
      "353it [00:32, 11.02it/s]2023-07-19 13:38:49,597 - INFO - Epoch: [133/600], Step: [355/591], Loss: 329109504.0, KL Divergence: 750.636962890625, Reconstruction Loss: 329108768.0\n",
      "471it [00:43, 11.00it/s]2023-07-19 13:39:00,386 - INFO - Epoch: [133/600], Step: [473/591], Loss: 295943680.0, KL Divergence: 755.50341796875, Reconstruction Loss: 295942912.0\n",
      "589it [00:53, 11.01it/s]2023-07-19 13:39:11,125 - INFO - Epoch: [133/600], Step: [591/591], Loss: 233547984.0, KL Divergence: 785.6956787109375, Reconstruction Loss: 233547200.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 13:39:11,126 - INFO - Epoch: [133/600], Total Loss: 19535106625536.0, Total KL Divergence: 57544015.359375, Total Reconstruction Loss: 19535048940544.0\n",
      "2023-07-19 13:39:11,170 - INFO - Save model at epoch 133\n",
      "0it [00:00, ?it/s]2023-07-19 13:39:11,276 - INFO - Epoch: [134/600], Step: [1/591], Loss: 142851904.0, KL Divergence: 774.1174926757812, Reconstruction Loss: 142851136.0\n",
      "117it [00:10, 10.58it/s]2023-07-19 13:39:22,310 - INFO - Epoch: [134/600], Step: [119/591], Loss: 379378656.0, KL Divergence: 765.004638671875, Reconstruction Loss: 379377888.0\n",
      "235it [00:21, 10.49it/s]2023-07-19 13:39:33,325 - INFO - Epoch: [134/600], Step: [237/591], Loss: 300211616.0, KL Divergence: 757.36865234375, Reconstruction Loss: 300210848.0\n",
      "353it [00:32, 10.73it/s]2023-07-19 13:39:44,343 - INFO - Epoch: [134/600], Step: [355/591], Loss: 338763776.0, KL Divergence: 757.9826049804688, Reconstruction Loss: 338763008.0\n",
      "471it [00:43, 10.68it/s]2023-07-19 13:39:55,356 - INFO - Epoch: [134/600], Step: [473/591], Loss: 299213344.0, KL Divergence: 763.3358154296875, Reconstruction Loss: 299212576.0\n",
      "589it [00:55, 10.78it/s]2023-07-19 13:40:06,407 - INFO - Epoch: [134/600], Step: [591/591], Loss: 240529040.0, KL Divergence: 791.73876953125, Reconstruction Loss: 240528256.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 13:40:06,409 - INFO - Epoch: [134/600], Total Loss: 19390762962944.0, Total KL Divergence: 57948465.7265625, Total Reconstruction Loss: 19390704905216.0\n",
      "2023-07-19 13:40:06,450 - INFO - Save model at epoch 134\n",
      "0it [00:00, ?it/s]2023-07-19 13:40:06,571 - INFO - Epoch: [135/600], Step: [1/591], Loss: 145623760.0, KL Divergence: 779.7019653320312, Reconstruction Loss: 145622976.0\n",
      "117it [00:10, 10.95it/s]2023-07-19 13:40:17,327 - INFO - Epoch: [135/600], Step: [119/591], Loss: 387709440.0, KL Divergence: 774.0264282226562, Reconstruction Loss: 387708672.0\n",
      "235it [00:21, 10.77it/s]2023-07-19 13:40:28,085 - INFO - Epoch: [135/600], Step: [237/591], Loss: 287309312.0, KL Divergence: 769.6754150390625, Reconstruction Loss: 287308544.0\n",
      "353it [00:32, 11.11it/s]2023-07-19 13:40:38,887 - INFO - Epoch: [135/600], Step: [355/591], Loss: 344732736.0, KL Divergence: 763.8779296875, Reconstruction Loss: 344731968.0\n",
      "471it [00:43, 10.99it/s]2023-07-19 13:40:49,707 - INFO - Epoch: [135/600], Step: [473/591], Loss: 297249152.0, KL Divergence: 765.154296875, Reconstruction Loss: 297248384.0\n",
      "589it [00:53, 10.92it/s]2023-07-19 13:41:00,426 - INFO - Epoch: [135/600], Step: [591/591], Loss: 224159184.0, KL Divergence: 794.4950561523438, Reconstruction Loss: 224158384.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 13:41:00,428 - INFO - Epoch: [135/600], Total Loss: 19333885157376.0, Total KL Divergence: 58346263.0390625, Total Reconstruction Loss: 19333826849792.0\n",
      "2023-07-19 13:41:00,470 - INFO - Save model at epoch 135\n",
      "0it [00:00, ?it/s]2023-07-19 13:41:00,592 - INFO - Epoch: [136/600], Step: [1/591], Loss: 137528880.0, KL Divergence: 782.3841552734375, Reconstruction Loss: 137528096.0\n",
      "117it [00:10, 10.91it/s]2023-07-19 13:41:11,381 - INFO - Epoch: [136/600], Step: [119/591], Loss: 378775424.0, KL Divergence: 771.534912109375, Reconstruction Loss: 378774656.0\n",
      "235it [00:21, 10.66it/s]2023-07-19 13:41:22,149 - INFO - Epoch: [136/600], Step: [237/591], Loss: 278892800.0, KL Divergence: 763.6054077148438, Reconstruction Loss: 278892032.0\n",
      "353it [00:32, 10.75it/s]2023-07-19 13:41:32,976 - INFO - Epoch: [136/600], Step: [355/591], Loss: 337623296.0, KL Divergence: 762.1060180664062, Reconstruction Loss: 337622528.0\n",
      "471it [00:43, 11.06it/s]2023-07-19 13:41:43,771 - INFO - Epoch: [136/600], Step: [473/591], Loss: 288951616.0, KL Divergence: 763.015380859375, Reconstruction Loss: 288950848.0\n",
      "589it [00:53, 11.06it/s]2023-07-19 13:41:54,479 - INFO - Epoch: [136/600], Step: [591/591], Loss: 227260144.0, KL Divergence: 789.0106811523438, Reconstruction Loss: 227259360.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 13:41:54,481 - INFO - Epoch: [136/600], Total Loss: 19096570386432.0, Total KL Divergence: 58175149.4296875, Total Reconstruction Loss: 19096512179200.0\n",
      "2023-07-19 13:41:54,520 - INFO - Save model at epoch 136\n",
      "0it [00:00, ?it/s]2023-07-19 13:41:54,643 - INFO - Epoch: [137/600], Step: [1/591], Loss: 135168384.0, KL Divergence: 778.127685546875, Reconstruction Loss: 135167600.0\n",
      "117it [00:10, 11.09it/s]2023-07-19 13:42:05,366 - INFO - Epoch: [137/600], Step: [119/591], Loss: 370876064.0, KL Divergence: 767.4860229492188, Reconstruction Loss: 370875296.0\n",
      "235it [00:21, 11.03it/s]2023-07-19 13:42:16,110 - INFO - Epoch: [137/600], Step: [237/591], Loss: 276303360.0, KL Divergence: 759.43701171875, Reconstruction Loss: 276302592.0\n",
      "353it [00:32, 10.80it/s]2023-07-19 13:42:26,952 - INFO - Epoch: [137/600], Step: [355/591], Loss: 323131072.0, KL Divergence: 761.2842407226562, Reconstruction Loss: 323130304.0\n",
      "471it [00:43, 11.10it/s]2023-07-19 13:42:37,788 - INFO - Epoch: [137/600], Step: [473/591], Loss: 284330944.0, KL Divergence: 759.4479370117188, Reconstruction Loss: 284330176.0\n",
      "589it [00:53, 11.01it/s]2023-07-19 13:42:48,566 - INFO - Epoch: [137/600], Step: [591/591], Loss: 225907856.0, KL Divergence: 787.3312377929688, Reconstruction Loss: 225907072.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 13:42:48,568 - INFO - Epoch: [137/600], Total Loss: 19118319477760.0, Total KL Divergence: 57945084.015625, Total Reconstruction Loss: 19118261404672.0\n",
      "2023-07-19 13:42:48,621 - INFO - Save model at epoch 137\n",
      "0it [00:00, ?it/s]2023-07-19 13:42:48,731 - INFO - Epoch: [138/600], Step: [1/591], Loss: 135219920.0, KL Divergence: 776.0462646484375, Reconstruction Loss: 135219136.0\n",
      "117it [00:10, 11.16it/s]2023-07-19 13:42:59,469 - INFO - Epoch: [138/600], Step: [119/591], Loss: 374765056.0, KL Divergence: 765.6478271484375, Reconstruction Loss: 374764288.0\n",
      "235it [00:21, 11.06it/s]2023-07-19 13:43:10,213 - INFO - Epoch: [138/600], Step: [237/591], Loss: 271406496.0, KL Divergence: 753.940673828125, Reconstruction Loss: 271405728.0\n",
      "353it [00:32, 10.97it/s]2023-07-19 13:43:21,034 - INFO - Epoch: [138/600], Step: [355/591], Loss: 324514944.0, KL Divergence: 755.103515625, Reconstruction Loss: 324514176.0\n",
      "471it [00:42, 11.05it/s]2023-07-19 13:43:31,761 - INFO - Epoch: [138/600], Step: [473/591], Loss: 286220928.0, KL Divergence: 758.4005737304688, Reconstruction Loss: 286220160.0\n",
      "589it [00:53, 11.02it/s]2023-07-19 13:43:42,488 - INFO - Epoch: [138/600], Step: [591/591], Loss: 229796864.0, KL Divergence: 789.0521240234375, Reconstruction Loss: 229796080.0\n",
      "591it [00:53, 10.97it/s]\n",
      "2023-07-19 13:43:42,490 - INFO - Epoch: [138/600], Total Loss: 19142632051712.0, Total KL Divergence: 57691956.078125, Total Reconstruction Loss: 19142574206976.0\n",
      "2023-07-19 13:43:42,529 - INFO - Save model at epoch 138\n",
      "0it [00:00, ?it/s]2023-07-19 13:43:42,648 - INFO - Epoch: [139/600], Step: [1/591], Loss: 132369288.0, KL Divergence: 777.1014404296875, Reconstruction Loss: 132368512.0\n",
      "117it [00:10, 11.00it/s]2023-07-19 13:43:53,354 - INFO - Epoch: [139/600], Step: [119/591], Loss: 386657376.0, KL Divergence: 768.299560546875, Reconstruction Loss: 386656608.0\n",
      "235it [00:21, 10.80it/s]2023-07-19 13:44:04,200 - INFO - Epoch: [139/600], Step: [237/591], Loss: 276655808.0, KL Divergence: 759.5211791992188, Reconstruction Loss: 276655040.0\n",
      "353it [00:32, 10.79it/s]2023-07-19 13:44:15,072 - INFO - Epoch: [139/600], Step: [355/591], Loss: 332716096.0, KL Divergence: 758.536376953125, Reconstruction Loss: 332715328.0\n",
      "471it [00:43, 10.78it/s]2023-07-19 13:44:25,879 - INFO - Epoch: [139/600], Step: [473/591], Loss: 292840000.0, KL Divergence: 756.8045654296875, Reconstruction Loss: 292839232.0\n",
      "589it [00:53, 10.88it/s]2023-07-19 13:44:36,647 - INFO - Epoch: [139/600], Step: [591/591], Loss: 223711504.0, KL Divergence: 783.4056396484375, Reconstruction Loss: 223710720.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 13:44:36,649 - INFO - Epoch: [139/600], Total Loss: 18937737096192.0, Total KL Divergence: 57841206.1640625, Total Reconstruction Loss: 18937679082496.0\n",
      "2023-07-19 13:44:36,692 - INFO - Save model at epoch 139\n",
      "0it [00:00, ?it/s]2023-07-19 13:44:36,804 - INFO - Epoch: [140/600], Step: [1/591], Loss: 137164960.0, KL Divergence: 772.143310546875, Reconstruction Loss: 137164192.0\n",
      "117it [00:10, 10.95it/s]2023-07-19 13:44:47,648 - INFO - Epoch: [140/600], Step: [119/591], Loss: 379054208.0, KL Divergence: 761.8026123046875, Reconstruction Loss: 379053440.0\n",
      "235it [00:21, 11.11it/s]2023-07-19 13:44:58,392 - INFO - Epoch: [140/600], Step: [237/591], Loss: 275785408.0, KL Divergence: 755.6460571289062, Reconstruction Loss: 275784640.0\n",
      "353it [00:32, 10.91it/s]2023-07-19 13:45:09,199 - INFO - Epoch: [140/600], Step: [355/591], Loss: 316845664.0, KL Divergence: 751.2176513671875, Reconstruction Loss: 316844928.0\n",
      "471it [00:43, 11.03it/s]2023-07-19 13:45:19,954 - INFO - Epoch: [140/600], Step: [473/591], Loss: 303603712.0, KL Divergence: 752.355712890625, Reconstruction Loss: 303602944.0\n",
      "589it [00:53, 11.01it/s]2023-07-19 13:45:30,680 - INFO - Epoch: [140/600], Step: [591/591], Loss: 217822720.0, KL Divergence: 781.5413818359375, Reconstruction Loss: 217821936.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 13:45:30,682 - INFO - Epoch: [140/600], Total Loss: 18910456853504.0, Total KL Divergence: 57527145.1015625, Total Reconstruction Loss: 18910399229952.0\n",
      "2023-07-19 13:45:30,722 - INFO - Save model at epoch 140\n",
      "0it [00:00, ?it/s]2023-07-19 13:45:30,841 - INFO - Epoch: [141/600], Step: [1/591], Loss: 141989888.0, KL Divergence: 771.4874267578125, Reconstruction Loss: 141989120.0\n",
      "117it [00:10, 10.99it/s]2023-07-19 13:45:41,647 - INFO - Epoch: [141/600], Step: [119/591], Loss: 374706080.0, KL Divergence: 763.4561157226562, Reconstruction Loss: 374705312.0\n",
      "235it [00:21, 10.77it/s]2023-07-19 13:45:52,502 - INFO - Epoch: [141/600], Step: [237/591], Loss: 276985408.0, KL Divergence: 757.0808715820312, Reconstruction Loss: 276984640.0\n",
      "353it [00:32, 10.04it/s]2023-07-19 13:46:03,941 - INFO - Epoch: [141/600], Step: [355/591], Loss: 322016864.0, KL Divergence: 759.3761596679688, Reconstruction Loss: 322016096.0\n",
      "471it [00:44, 10.89it/s]2023-07-19 13:46:15,482 - INFO - Epoch: [141/600], Step: [473/591], Loss: 294391168.0, KL Divergence: 757.8319091796875, Reconstruction Loss: 294390400.0\n",
      "589it [00:55, 10.70it/s]2023-07-19 13:46:26,755 - INFO - Epoch: [141/600], Step: [591/591], Loss: 213808896.0, KL Divergence: 786.2535400390625, Reconstruction Loss: 213808112.0\n",
      "591it [00:56, 10.55it/s]\n",
      "2023-07-19 13:46:26,757 - INFO - Epoch: [141/600], Total Loss: 18813950030848.0, Total KL Divergence: 57792313.3203125, Total Reconstruction Loss: 18813892085760.0\n",
      "2023-07-19 13:46:26,800 - INFO - Save model at epoch 141\n",
      "0it [00:00, ?it/s]2023-07-19 13:46:26,922 - INFO - Epoch: [142/600], Step: [1/591], Loss: 138198960.0, KL Divergence: 775.6029052734375, Reconstruction Loss: 138198192.0\n",
      "117it [00:11, 10.43it/s]2023-07-19 13:46:38,143 - INFO - Epoch: [142/600], Step: [119/591], Loss: 371974624.0, KL Divergence: 766.7918090820312, Reconstruction Loss: 371973856.0\n",
      "235it [00:22, 10.34it/s]2023-07-19 13:46:49,779 - INFO - Epoch: [142/600], Step: [237/591], Loss: 293577280.0, KL Divergence: 763.7196044921875, Reconstruction Loss: 293576512.0\n",
      "353it [00:33, 10.42it/s]2023-07-19 13:47:00,871 - INFO - Epoch: [142/600], Step: [355/591], Loss: 318316032.0, KL Divergence: 754.3045654296875, Reconstruction Loss: 318315264.0\n",
      "471it [00:45, 10.62it/s]2023-07-19 13:47:12,182 - INFO - Epoch: [142/600], Step: [473/591], Loss: 302644608.0, KL Divergence: 755.64501953125, Reconstruction Loss: 302643840.0\n",
      "590it [00:56, 10.54it/s]2023-07-19 13:47:23,488 - INFO - Epoch: [142/600], Step: [591/591], Loss: 225222480.0, KL Divergence: 778.2410888671875, Reconstruction Loss: 225221696.0\n",
      "591it [00:56, 10.43it/s]\n",
      "2023-07-19 13:47:23,490 - INFO - Epoch: [142/600], Total Loss: 18763913355264.0, Total KL Divergence: 57709741.3046875, Total Reconstruction Loss: 18763855518720.0\n",
      "2023-07-19 13:47:23,534 - INFO - Save model at epoch 142\n",
      "0it [00:00, ?it/s]2023-07-19 13:47:23,657 - INFO - Epoch: [143/600], Step: [1/591], Loss: 134491232.0, KL Divergence: 768.8587646484375, Reconstruction Loss: 134490464.0\n",
      "118it [00:11, 10.43it/s]2023-07-19 13:47:34,884 - INFO - Epoch: [143/600], Step: [119/591], Loss: 369609408.0, KL Divergence: 759.9967651367188, Reconstruction Loss: 369608640.0\n",
      "236it [00:22, 10.42it/s]2023-07-19 13:47:45,961 - INFO - Epoch: [143/600], Step: [237/591], Loss: 272183584.0, KL Divergence: 746.9020385742188, Reconstruction Loss: 272182848.0\n",
      "354it [00:33, 11.00it/s]2023-07-19 13:47:56,867 - INFO - Epoch: [143/600], Step: [355/591], Loss: 319690144.0, KL Divergence: 744.605712890625, Reconstruction Loss: 319689408.0\n",
      "472it [00:44, 10.82it/s]2023-07-19 13:48:07,717 - INFO - Epoch: [143/600], Step: [473/591], Loss: 307117792.0, KL Divergence: 749.17333984375, Reconstruction Loss: 307117056.0\n",
      "590it [00:54, 10.97it/s]2023-07-19 13:48:18,461 - INFO - Epoch: [143/600], Step: [591/591], Loss: 225961824.0, KL Divergence: 773.052490234375, Reconstruction Loss: 225961056.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 13:48:18,463 - INFO - Epoch: [143/600], Total Loss: 18796037307392.0, Total KL Divergence: 57088030.2109375, Total Reconstruction Loss: 18795980242944.0\n",
      "2023-07-19 13:48:18,502 - INFO - Save model at epoch 143\n",
      "0it [00:00, ?it/s]2023-07-19 13:48:18,619 - INFO - Epoch: [144/600], Step: [1/591], Loss: 131920968.0, KL Divergence: 762.61279296875, Reconstruction Loss: 131920208.0\n",
      "117it [00:10, 10.89it/s]2023-07-19 13:48:29,482 - INFO - Epoch: [144/600], Step: [119/591], Loss: 373675456.0, KL Divergence: 762.301025390625, Reconstruction Loss: 373674688.0\n",
      "235it [00:21, 11.05it/s]2023-07-19 13:48:40,320 - INFO - Epoch: [144/600], Step: [237/591], Loss: 286995360.0, KL Divergence: 747.2056884765625, Reconstruction Loss: 286994624.0\n",
      "353it [00:32, 10.94it/s]2023-07-19 13:48:51,182 - INFO - Epoch: [144/600], Step: [355/591], Loss: 326662784.0, KL Divergence: 744.63427734375, Reconstruction Loss: 326662048.0\n",
      "471it [00:43, 10.68it/s]2023-07-19 13:49:02,061 - INFO - Epoch: [144/600], Step: [473/591], Loss: 286959264.0, KL Divergence: 745.0189208984375, Reconstruction Loss: 286958528.0\n",
      "589it [00:54, 10.81it/s]2023-07-19 13:49:12,812 - INFO - Epoch: [144/600], Step: [591/591], Loss: 225628896.0, KL Divergence: 769.5104370117188, Reconstruction Loss: 225628128.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 13:49:12,813 - INFO - Epoch: [144/600], Total Loss: 18986879780864.0, Total KL Divergence: 56937326.09375, Total Reconstruction Loss: 18986822915072.0\n",
      "2023-07-19 13:49:12,853 - INFO - Save model at epoch 144\n",
      "0it [00:00, ?it/s]2023-07-19 13:49:12,963 - INFO - Epoch: [145/600], Step: [1/591], Loss: 137168624.0, KL Divergence: 759.19775390625, Reconstruction Loss: 137167872.0\n",
      "117it [00:10, 10.92it/s]2023-07-19 13:49:23,941 - INFO - Epoch: [145/600], Step: [119/591], Loss: 375449824.0, KL Divergence: 753.7258911132812, Reconstruction Loss: 375449056.0\n",
      "235it [00:21, 10.82it/s]2023-07-19 13:49:34,832 - INFO - Epoch: [145/600], Step: [237/591], Loss: 267888496.0, KL Divergence: 747.0025634765625, Reconstruction Loss: 267887744.0\n",
      "353it [00:32, 11.14it/s]2023-07-19 13:49:45,678 - INFO - Epoch: [145/600], Step: [355/591], Loss: 328018816.0, KL Divergence: 742.5618896484375, Reconstruction Loss: 328018080.0\n",
      "471it [00:43, 10.79it/s]2023-07-19 13:49:56,489 - INFO - Epoch: [145/600], Step: [473/591], Loss: 283248448.0, KL Divergence: 744.5516967773438, Reconstruction Loss: 283247712.0\n",
      "589it [00:54, 10.84it/s]2023-07-19 13:50:07,460 - INFO - Epoch: [145/600], Step: [591/591], Loss: 216240512.0, KL Divergence: 773.2001953125, Reconstruction Loss: 216239744.0\n",
      "591it [00:54, 10.82it/s]\n",
      "2023-07-19 13:50:07,463 - INFO - Epoch: [145/600], Total Loss: 18820109882368.0, Total KL Divergence: 56761488.453125, Total Reconstruction Loss: 18820053187584.0\n",
      "2023-07-19 13:50:07,509 - INFO - Save model at epoch 145\n",
      "0it [00:00, ?it/s]2023-07-19 13:50:07,630 - INFO - Epoch: [146/600], Step: [1/591], Loss: 146090320.0, KL Divergence: 762.6866455078125, Reconstruction Loss: 146089552.0\n",
      "117it [00:11, 10.70it/s]2023-07-19 13:50:18,759 - INFO - Epoch: [146/600], Step: [119/591], Loss: 398852864.0, KL Divergence: 756.0372314453125, Reconstruction Loss: 398852096.0\n",
      "235it [00:21, 10.91it/s]2023-07-19 13:50:29,568 - INFO - Epoch: [146/600], Step: [237/591], Loss: 277176384.0, KL Divergence: 746.2918090820312, Reconstruction Loss: 277175648.0\n",
      "353it [00:32, 10.92it/s]2023-07-19 13:50:40,459 - INFO - Epoch: [146/600], Step: [355/591], Loss: 313195552.0, KL Divergence: 739.5755004882812, Reconstruction Loss: 313194816.0\n",
      "471it [00:43, 11.00it/s]2023-07-19 13:50:51,285 - INFO - Epoch: [146/600], Step: [473/591], Loss: 285922272.0, KL Divergence: 740.2343139648438, Reconstruction Loss: 285921536.0\n",
      "589it [00:54, 10.76it/s]2023-07-19 13:51:02,069 - INFO - Epoch: [146/600], Step: [591/591], Loss: 220831664.0, KL Divergence: 769.1939697265625, Reconstruction Loss: 220830896.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 13:51:02,071 - INFO - Epoch: [146/600], Total Loss: 18666387906560.0, Total KL Divergence: 56714373.359375, Total Reconstruction Loss: 18666331262976.0\n",
      "2023-07-19 13:51:02,111 - INFO - Save model at epoch 146\n",
      "0it [00:00, ?it/s]2023-07-19 13:51:02,226 - INFO - Epoch: [147/600], Step: [1/591], Loss: 148738992.0, KL Divergence: 759.0552368164062, Reconstruction Loss: 148738240.0\n",
      "117it [00:10, 10.87it/s]2023-07-19 13:51:13,029 - INFO - Epoch: [147/600], Step: [119/591], Loss: 375720320.0, KL Divergence: 748.8160400390625, Reconstruction Loss: 375719584.0\n",
      "235it [00:21, 11.07it/s]2023-07-19 13:51:23,808 - INFO - Epoch: [147/600], Step: [237/591], Loss: 268180512.0, KL Divergence: 741.860107421875, Reconstruction Loss: 268179776.0\n",
      "353it [00:32, 10.87it/s]2023-07-19 13:51:34,665 - INFO - Epoch: [147/600], Step: [355/591], Loss: 319308832.0, KL Divergence: 739.8734130859375, Reconstruction Loss: 319308096.0\n",
      "471it [00:43, 10.91it/s]2023-07-19 13:51:45,474 - INFO - Epoch: [147/600], Step: [473/591], Loss: 288759200.0, KL Divergence: 742.3760375976562, Reconstruction Loss: 288758464.0\n",
      "589it [00:53, 11.09it/s]2023-07-19 13:51:56,195 - INFO - Epoch: [147/600], Step: [591/591], Loss: 214350512.0, KL Divergence: 772.8740234375, Reconstruction Loss: 214349744.0\n",
      "591it [00:54, 10.93it/s]\n",
      "2023-07-19 13:51:56,197 - INFO - Epoch: [147/600], Total Loss: 18770436251648.0, Total KL Divergence: 56588244.375, Total Reconstruction Loss: 18770379729920.0\n",
      "2023-07-19 13:51:56,238 - INFO - Save model at epoch 147\n",
      "0it [00:00, ?it/s]2023-07-19 13:51:56,357 - INFO - Epoch: [148/600], Step: [1/591], Loss: 131601568.0, KL Divergence: 763.70361328125, Reconstruction Loss: 131600808.0\n",
      "117it [00:10, 10.85it/s]2023-07-19 13:52:07,157 - INFO - Epoch: [148/600], Step: [119/591], Loss: 374306240.0, KL Divergence: 754.3972778320312, Reconstruction Loss: 374305472.0\n",
      "235it [00:21, 10.93it/s]2023-07-19 13:52:17,998 - INFO - Epoch: [148/600], Step: [237/591], Loss: 272282048.0, KL Divergence: 744.72607421875, Reconstruction Loss: 272281312.0\n",
      "353it [00:32, 11.12it/s]2023-07-19 13:52:28,849 - INFO - Epoch: [148/600], Step: [355/591], Loss: 317610016.0, KL Divergence: 742.5200805664062, Reconstruction Loss: 317609280.0\n",
      "471it [00:43, 10.64it/s]2023-07-19 13:52:39,696 - INFO - Epoch: [148/600], Step: [473/591], Loss: 278198688.0, KL Divergence: 745.301025390625, Reconstruction Loss: 278197952.0\n",
      "589it [00:54, 11.03it/s]2023-07-19 13:52:50,468 - INFO - Epoch: [148/600], Step: [591/591], Loss: 209205824.0, KL Divergence: 771.5560913085938, Reconstruction Loss: 209205056.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 13:52:50,470 - INFO - Epoch: [148/600], Total Loss: 18661091047424.0, Total KL Divergence: 56739517.25, Total Reconstruction Loss: 18661034371072.0\n",
      "2023-07-19 13:52:50,523 - INFO - Save model at epoch 148\n",
      "0it [00:00, ?it/s]2023-07-19 13:52:50,632 - INFO - Epoch: [149/600], Step: [1/591], Loss: 149860224.0, KL Divergence: 763.660400390625, Reconstruction Loss: 149859456.0\n",
      "117it [00:10, 11.03it/s]2023-07-19 13:53:01,440 - INFO - Epoch: [149/600], Step: [119/591], Loss: 369426080.0, KL Divergence: 751.5241088867188, Reconstruction Loss: 369425344.0\n",
      "235it [00:21, 10.84it/s]2023-07-19 13:53:12,213 - INFO - Epoch: [149/600], Step: [237/591], Loss: 285866176.0, KL Divergence: 744.708740234375, Reconstruction Loss: 285865440.0\n",
      "353it [00:32, 10.93it/s]2023-07-19 13:53:23,024 - INFO - Epoch: [149/600], Step: [355/591], Loss: 313434720.0, KL Divergence: 741.7203979492188, Reconstruction Loss: 313433984.0\n",
      "471it [00:43, 10.87it/s]2023-07-19 13:53:33,816 - INFO - Epoch: [149/600], Step: [473/591], Loss: 288184608.0, KL Divergence: 744.76171875, Reconstruction Loss: 288183872.0\n",
      "589it [00:53, 11.03it/s]2023-07-19 13:53:44,636 - INFO - Epoch: [149/600], Step: [591/591], Loss: 207350880.0, KL Divergence: 774.59423828125, Reconstruction Loss: 207350112.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 13:53:44,637 - INFO - Epoch: [149/600], Total Loss: 18594104962048.0, Total KL Divergence: 56698424.0859375, Total Reconstruction Loss: 18594048350208.0\n",
      "2023-07-19 13:53:44,680 - INFO - Save model at epoch 149\n",
      "0it [00:00, ?it/s]2023-07-19 13:53:44,793 - INFO - Epoch: [150/600], Step: [1/591], Loss: 154431968.0, KL Divergence: 766.18994140625, Reconstruction Loss: 154431200.0\n",
      "118it [00:10, 11.27it/s]2023-07-19 13:53:55,594 - INFO - Epoch: [150/600], Step: [119/591], Loss: 360797792.0, KL Divergence: 756.657958984375, Reconstruction Loss: 360797024.0\n",
      "236it [00:21, 10.81it/s]2023-07-19 13:54:06,313 - INFO - Epoch: [150/600], Step: [237/591], Loss: 276843008.0, KL Divergence: 747.8226318359375, Reconstruction Loss: 276842272.0\n",
      "354it [00:32, 10.94it/s]2023-07-19 13:54:17,169 - INFO - Epoch: [150/600], Step: [355/591], Loss: 331371040.0, KL Divergence: 746.803466796875, Reconstruction Loss: 331370304.0\n",
      "472it [00:43, 11.02it/s]2023-07-19 13:54:27,963 - INFO - Epoch: [150/600], Step: [473/591], Loss: 283311392.0, KL Divergence: 748.12255859375, Reconstruction Loss: 283310656.0\n",
      "590it [00:53, 11.02it/s]2023-07-19 13:54:38,726 - INFO - Epoch: [150/600], Step: [591/591], Loss: 214278160.0, KL Divergence: 779.3143310546875, Reconstruction Loss: 214277376.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 13:54:38,727 - INFO - Epoch: [150/600], Total Loss: 18439304399872.0, Total KL Divergence: 56947524.8671875, Total Reconstruction Loss: 18439247564800.0\n",
      "2023-07-19 13:54:38,766 - INFO - Save model at epoch 150\n",
      "0it [00:00, ?it/s]2023-07-19 13:54:38,884 - INFO - Epoch: [151/600], Step: [1/591], Loss: 144404864.0, KL Divergence: 771.1327514648438, Reconstruction Loss: 144404096.0\n",
      "118it [00:10, 10.90it/s]2023-07-19 13:54:49,671 - INFO - Epoch: [151/600], Step: [119/591], Loss: 363988064.0, KL Divergence: 761.74072265625, Reconstruction Loss: 363987296.0\n",
      "236it [00:21, 10.79it/s]2023-07-19 13:55:00,456 - INFO - Epoch: [151/600], Step: [237/591], Loss: 272465024.0, KL Divergence: 753.4388427734375, Reconstruction Loss: 272464256.0\n",
      "354it [00:32, 10.96it/s]2023-07-19 13:55:11,251 - INFO - Epoch: [151/600], Step: [355/591], Loss: 306265792.0, KL Divergence: 749.4810180664062, Reconstruction Loss: 306265056.0\n",
      "472it [00:43, 10.98it/s]2023-07-19 13:55:22,018 - INFO - Epoch: [151/600], Step: [473/591], Loss: 278878624.0, KL Divergence: 747.8026123046875, Reconstruction Loss: 278877888.0\n",
      "590it [00:53, 10.87it/s]2023-07-19 13:55:32,759 - INFO - Epoch: [151/600], Step: [591/591], Loss: 214487744.0, KL Divergence: 782.95703125, Reconstruction Loss: 214486960.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 13:55:32,760 - INFO - Epoch: [151/600], Total Loss: 18225217248256.0, Total KL Divergence: 57277780.109375, Total Reconstruction Loss: 18225159956480.0\n",
      "2023-07-19 13:55:32,806 - INFO - Save model at epoch 151\n",
      "0it [00:00, ?it/s]2023-07-19 13:55:32,916 - INFO - Epoch: [152/600], Step: [1/591], Loss: 141950080.0, KL Divergence: 773.375732421875, Reconstruction Loss: 141949312.0\n",
      "118it [00:10, 10.70it/s]2023-07-19 13:55:43,735 - INFO - Epoch: [152/600], Step: [119/591], Loss: 362587936.0, KL Divergence: 763.084228515625, Reconstruction Loss: 362587168.0\n",
      "236it [00:21, 11.16it/s]2023-07-19 13:55:54,473 - INFO - Epoch: [152/600], Step: [237/591], Loss: 266887168.0, KL Divergence: 752.238037109375, Reconstruction Loss: 266886416.0\n",
      "354it [00:32, 11.05it/s]2023-07-19 13:56:05,312 - INFO - Epoch: [152/600], Step: [355/591], Loss: 310915392.0, KL Divergence: 748.8649291992188, Reconstruction Loss: 310914656.0\n",
      "472it [00:43, 10.95it/s]2023-07-19 13:56:16,074 - INFO - Epoch: [152/600], Step: [473/591], Loss: 275117504.0, KL Divergence: 744.1378173828125, Reconstruction Loss: 275116768.0\n",
      "590it [00:53, 10.74it/s]2023-07-19 13:56:26,839 - INFO - Epoch: [152/600], Step: [591/591], Loss: 214352880.0, KL Divergence: 774.658935546875, Reconstruction Loss: 214352112.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 13:56:26,840 - INFO - Epoch: [152/600], Total Loss: 18147170186240.0, Total KL Divergence: 57173158.1640625, Total Reconstruction Loss: 18147113043968.0\n",
      "2023-07-19 13:56:26,880 - INFO - Save model at epoch 152\n",
      "0it [00:00, ?it/s]2023-07-19 13:56:26,997 - INFO - Epoch: [153/600], Step: [1/591], Loss: 134186080.0, KL Divergence: 766.608154296875, Reconstruction Loss: 134185312.0\n",
      "117it [00:10, 10.98it/s]2023-07-19 13:56:37,820 - INFO - Epoch: [153/600], Step: [119/591], Loss: 372378560.0, KL Divergence: 754.9465942382812, Reconstruction Loss: 372377792.0\n",
      "236it [00:21, 10.89it/s]2023-07-19 13:56:48,872 - INFO - Epoch: [153/600], Step: [237/591], Loss: 264456816.0, KL Divergence: 745.562744140625, Reconstruction Loss: 264456064.0\n",
      "354it [00:32, 11.20it/s]2023-07-19 13:56:59,679 - INFO - Epoch: [153/600], Step: [355/591], Loss: 308134880.0, KL Divergence: 741.325439453125, Reconstruction Loss: 308134144.0\n",
      "472it [00:45, 10.90it/s]2023-07-19 13:57:12,960 - INFO - Epoch: [153/600], Step: [473/591], Loss: 275232256.0, KL Divergence: 743.2588500976562, Reconstruction Loss: 275231520.0\n",
      "590it [00:56, 10.28it/s]2023-07-19 13:57:23,876 - INFO - Epoch: [153/600], Step: [591/591], Loss: 218180224.0, KL Divergence: 771.3375854492188, Reconstruction Loss: 218179456.0\n",
      "591it [00:56, 10.37it/s]\n",
      "2023-07-19 13:57:23,878 - INFO - Epoch: [153/600], Total Loss: 18084479726592.0, Total KL Divergence: 56735406.0390625, Total Reconstruction Loss: 18084423049216.0\n",
      "2023-07-19 13:57:23,918 - INFO - Save model at epoch 153\n",
      "0it [00:00, ?it/s]2023-07-19 13:57:24,023 - INFO - Epoch: [154/600], Step: [1/591], Loss: 149996608.0, KL Divergence: 763.32763671875, Reconstruction Loss: 149995840.0\n",
      "118it [00:10, 10.75it/s]2023-07-19 13:57:34,913 - INFO - Epoch: [154/600], Step: [119/591], Loss: 374326688.0, KL Divergence: 752.8746337890625, Reconstruction Loss: 374325920.0\n",
      "236it [00:22, 10.62it/s]2023-07-19 13:57:46,042 - INFO - Epoch: [154/600], Step: [237/591], Loss: 261622672.0, KL Divergence: 749.8195190429688, Reconstruction Loss: 261621920.0\n",
      "354it [00:32, 11.03it/s]2023-07-19 13:57:57,008 - INFO - Epoch: [154/600], Step: [355/591], Loss: 310427104.0, KL Divergence: 748.4442138671875, Reconstruction Loss: 310426368.0\n",
      "472it [00:43, 10.96it/s]2023-07-19 13:58:07,795 - INFO - Epoch: [154/600], Step: [473/591], Loss: 279505120.0, KL Divergence: 752.453857421875, Reconstruction Loss: 279504352.0\n",
      "590it [00:54, 10.66it/s]2023-07-19 13:58:18,531 - INFO - Epoch: [154/600], Step: [591/591], Loss: 209065104.0, KL Divergence: 779.978515625, Reconstruction Loss: 209064320.0\n",
      "591it [00:54, 10.82it/s]\n",
      "2023-07-19 13:58:18,532 - INFO - Epoch: [154/600], Total Loss: 18249074935808.0, Total KL Divergence: 57033353.875, Total Reconstruction Loss: 18249017955328.0\n",
      "2023-07-19 13:58:18,573 - INFO - Save model at epoch 154\n",
      "0it [00:00, ?it/s]2023-07-19 13:58:18,695 - INFO - Epoch: [155/600], Step: [1/591], Loss: 152237440.0, KL Divergence: 772.4197998046875, Reconstruction Loss: 152236672.0\n",
      "117it [00:10, 10.44it/s]2023-07-19 13:58:29,458 - INFO - Epoch: [155/600], Step: [119/591], Loss: 394897600.0, KL Divergence: 765.5772705078125, Reconstruction Loss: 394896832.0\n",
      "235it [00:21, 10.95it/s]2023-07-19 13:58:40,251 - INFO - Epoch: [155/600], Step: [237/591], Loss: 266281344.0, KL Divergence: 755.314697265625, Reconstruction Loss: 266280592.0\n",
      "353it [00:32, 10.85it/s]2023-07-19 13:58:51,156 - INFO - Epoch: [155/600], Step: [355/591], Loss: 308664704.0, KL Divergence: 756.7147827148438, Reconstruction Loss: 308663936.0\n",
      "471it [00:43, 10.73it/s]2023-07-19 13:59:02,015 - INFO - Epoch: [155/600], Step: [473/591], Loss: 278080608.0, KL Divergence: 754.8763427734375, Reconstruction Loss: 278079840.0\n",
      "589it [00:54, 10.64it/s]2023-07-19 13:59:12,874 - INFO - Epoch: [155/600], Step: [591/591], Loss: 204254576.0, KL Divergence: 782.6286010742188, Reconstruction Loss: 204253792.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 13:59:12,876 - INFO - Epoch: [155/600], Total Loss: 18202401889280.0, Total KL Divergence: 57511837.453125, Total Reconstruction Loss: 18202344216576.0\n",
      "2023-07-19 13:59:12,918 - INFO - Save model at epoch 155\n",
      "0it [00:00, ?it/s]2023-07-19 13:59:13,036 - INFO - Epoch: [156/600], Step: [1/591], Loss: 137642752.0, KL Divergence: 773.10888671875, Reconstruction Loss: 137641984.0\n",
      "117it [00:10, 10.84it/s]2023-07-19 13:59:23,886 - INFO - Epoch: [156/600], Step: [119/591], Loss: 367341952.0, KL Divergence: 762.248046875, Reconstruction Loss: 367341184.0\n",
      "235it [00:21, 10.78it/s]2023-07-19 13:59:34,677 - INFO - Epoch: [156/600], Step: [237/591], Loss: 259892832.0, KL Divergence: 751.6807861328125, Reconstruction Loss: 259892080.0\n",
      "353it [00:32, 10.79it/s]2023-07-19 13:59:45,588 - INFO - Epoch: [156/600], Step: [355/591], Loss: 306256352.0, KL Divergence: 749.5082397460938, Reconstruction Loss: 306255616.0\n",
      "471it [00:43, 10.73it/s]2023-07-19 13:59:56,492 - INFO - Epoch: [156/600], Step: [473/591], Loss: 311141984.0, KL Divergence: 743.21044921875, Reconstruction Loss: 311141248.0\n",
      "589it [00:54, 10.84it/s]2023-07-19 14:00:07,266 - INFO - Epoch: [156/600], Step: [591/591], Loss: 219999024.0, KL Divergence: 772.2373046875, Reconstruction Loss: 219998256.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 14:00:07,268 - INFO - Epoch: [156/600], Total Loss: 18102252821504.0, Total KL Divergence: 57179019.859375, Total Reconstruction Loss: 18102195668992.0\n",
      "2023-07-19 14:00:07,312 - INFO - Save model at epoch 156\n",
      "0it [00:00, ?it/s]2023-07-19 14:00:07,440 - INFO - Epoch: [157/600], Step: [1/591], Loss: 137069808.0, KL Divergence: 764.3875732421875, Reconstruction Loss: 137069040.0\n",
      "117it [00:10, 11.06it/s]2023-07-19 14:00:18,163 - INFO - Epoch: [157/600], Step: [119/591], Loss: 363620864.0, KL Divergence: 756.2520751953125, Reconstruction Loss: 363620096.0\n",
      "235it [00:21, 10.98it/s]2023-07-19 14:00:29,046 - INFO - Epoch: [157/600], Step: [237/591], Loss: 275372096.0, KL Divergence: 751.454345703125, Reconstruction Loss: 275371360.0\n",
      "353it [00:32, 10.92it/s]2023-07-19 14:00:39,901 - INFO - Epoch: [157/600], Step: [355/591], Loss: 307141152.0, KL Divergence: 745.296142578125, Reconstruction Loss: 307140416.0\n",
      "471it [00:43, 10.84it/s]2023-07-19 14:00:50,714 - INFO - Epoch: [157/600], Step: [473/591], Loss: 303257856.0, KL Divergence: 749.2389526367188, Reconstruction Loss: 303257120.0\n",
      "589it [00:54, 10.38it/s]2023-07-19 14:01:01,536 - INFO - Epoch: [157/600], Step: [591/591], Loss: 237710080.0, KL Divergence: 775.242919921875, Reconstruction Loss: 237709312.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 14:01:01,538 - INFO - Epoch: [157/600], Total Loss: 18175180131328.0, Total KL Divergence: 56938113.375, Total Reconstruction Loss: 18175123253248.0\n",
      "2023-07-19 14:01:01,578 - INFO - Save model at epoch 157\n",
      "0it [00:00, ?it/s]2023-07-19 14:01:01,699 - INFO - Epoch: [158/600], Step: [1/591], Loss: 135267488.0, KL Divergence: 768.24072265625, Reconstruction Loss: 135266720.0\n",
      "117it [00:10, 10.79it/s]2023-07-19 14:01:12,512 - INFO - Epoch: [158/600], Step: [119/591], Loss: 363847200.0, KL Divergence: 757.153564453125, Reconstruction Loss: 363846432.0\n",
      "235it [00:21, 11.10it/s]2023-07-19 14:01:23,298 - INFO - Epoch: [158/600], Step: [237/591], Loss: 282570336.0, KL Divergence: 755.7417602539062, Reconstruction Loss: 282569568.0\n",
      "353it [00:32, 10.99it/s]2023-07-19 14:01:34,112 - INFO - Epoch: [158/600], Step: [355/591], Loss: 325388960.0, KL Divergence: 748.5398559570312, Reconstruction Loss: 325388224.0\n",
      "471it [00:43, 11.00it/s]2023-07-19 14:01:44,851 - INFO - Epoch: [158/600], Step: [473/591], Loss: 295909600.0, KL Divergence: 748.990478515625, Reconstruction Loss: 295908864.0\n",
      "589it [00:53, 10.23it/s]2023-07-19 14:01:55,673 - INFO - Epoch: [158/600], Step: [591/591], Loss: 218145264.0, KL Divergence: 770.2496948242188, Reconstruction Loss: 218144496.0\n",
      "591it [00:54, 10.93it/s]\n",
      "2023-07-19 14:01:55,675 - INFO - Epoch: [158/600], Total Loss: 18135414113280.0, Total KL Divergence: 57088208.09375, Total Reconstruction Loss: 18135357022208.0\n",
      "2023-07-19 14:01:55,715 - INFO - Save model at epoch 158\n",
      "0it [00:00, ?it/s]2023-07-19 14:01:55,826 - INFO - Epoch: [159/600], Step: [1/591], Loss: 142279648.0, KL Divergence: 762.4921875, Reconstruction Loss: 142278880.0\n",
      "117it [00:10, 10.74it/s]2023-07-19 14:02:06,623 - INFO - Epoch: [159/600], Step: [119/591], Loss: 370586848.0, KL Divergence: 750.894287109375, Reconstruction Loss: 370586112.0\n",
      "235it [00:21, 10.95it/s]2023-07-19 14:02:17,391 - INFO - Epoch: [159/600], Step: [237/591], Loss: 262457008.0, KL Divergence: 745.35986328125, Reconstruction Loss: 262456256.0\n",
      "353it [00:32, 11.01it/s]2023-07-19 14:02:28,216 - INFO - Epoch: [159/600], Step: [355/591], Loss: 309882080.0, KL Divergence: 749.9465942382812, Reconstruction Loss: 309881344.0\n",
      "471it [00:43, 10.92it/s]2023-07-19 14:02:38,964 - INFO - Epoch: [159/600], Step: [473/591], Loss: 283651520.0, KL Divergence: 745.8502197265625, Reconstruction Loss: 283650784.0\n",
      "589it [00:53, 10.87it/s]2023-07-19 14:02:49,766 - INFO - Epoch: [159/600], Step: [591/591], Loss: 210179504.0, KL Divergence: 768.4555053710938, Reconstruction Loss: 210178736.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 14:02:49,768 - INFO - Epoch: [159/600], Total Loss: 18078067240960.0, Total KL Divergence: 56683360.1328125, Total Reconstruction Loss: 18078010629120.0\n",
      "2023-07-19 14:02:49,812 - INFO - Save model at epoch 159\n",
      "0it [00:00, ?it/s]2023-07-19 14:02:49,982 - INFO - Epoch: [160/600], Step: [1/591], Loss: 135274896.0, KL Divergence: 759.6402587890625, Reconstruction Loss: 135274144.0\n",
      "117it [00:10, 10.91it/s]2023-07-19 14:03:00,765 - INFO - Epoch: [160/600], Step: [119/591], Loss: 351739776.0, KL Divergence: 753.5668334960938, Reconstruction Loss: 351739008.0\n",
      "235it [00:21, 11.08it/s]2023-07-19 14:03:11,548 - INFO - Epoch: [160/600], Step: [237/591], Loss: 269339936.0, KL Divergence: 745.952880859375, Reconstruction Loss: 269339200.0\n",
      "353it [00:32, 10.87it/s]2023-07-19 14:03:22,365 - INFO - Epoch: [160/600], Step: [355/591], Loss: 298245440.0, KL Divergence: 746.076171875, Reconstruction Loss: 298244704.0\n",
      "471it [00:43, 11.19it/s]2023-07-19 14:03:33,109 - INFO - Epoch: [160/600], Step: [473/591], Loss: 298848160.0, KL Divergence: 748.06103515625, Reconstruction Loss: 298847424.0\n",
      "589it [00:53, 10.97it/s]2023-07-19 14:03:43,856 - INFO - Epoch: [160/600], Step: [591/591], Loss: 209629600.0, KL Divergence: 775.8151245117188, Reconstruction Loss: 209628832.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 14:03:43,857 - INFO - Epoch: [160/600], Total Loss: 17947049615360.0, Total KL Divergence: 56776507.3515625, Total Reconstruction Loss: 17946992868352.0\n",
      "2023-07-19 14:03:43,897 - INFO - Save model at epoch 160\n",
      "0it [00:00, ?it/s]2023-07-19 14:03:44,016 - INFO - Epoch: [161/600], Step: [1/591], Loss: 131046088.0, KL Divergence: 767.7613525390625, Reconstruction Loss: 131045320.0\n",
      "118it [00:10, 10.95it/s]2023-07-19 14:03:54,906 - INFO - Epoch: [161/600], Step: [119/591], Loss: 346506976.0, KL Divergence: 758.8719482421875, Reconstruction Loss: 346506208.0\n",
      "236it [00:21, 10.96it/s]2023-07-19 14:04:05,644 - INFO - Epoch: [161/600], Step: [237/591], Loss: 272835328.0, KL Divergence: 754.0072021484375, Reconstruction Loss: 272834560.0\n",
      "354it [00:32, 10.86it/s]2023-07-19 14:04:16,538 - INFO - Epoch: [161/600], Step: [355/591], Loss: 306844672.0, KL Divergence: 755.1378173828125, Reconstruction Loss: 306843904.0\n",
      "472it [00:43, 10.90it/s]2023-07-19 14:04:27,328 - INFO - Epoch: [161/600], Step: [473/591], Loss: 294378432.0, KL Divergence: 753.2061767578125, Reconstruction Loss: 294377664.0\n",
      "590it [00:54, 10.99it/s]2023-07-19 14:04:38,098 - INFO - Epoch: [161/600], Step: [591/591], Loss: 235865712.0, KL Divergence: 776.545166015625, Reconstruction Loss: 235864928.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 14:04:38,100 - INFO - Epoch: [161/600], Total Loss: 17929355659264.0, Total KL Divergence: 57321464.2265625, Total Reconstruction Loss: 17929298281472.0\n",
      "2023-07-19 14:04:38,192 - INFO - Save model at epoch 161\n",
      "0it [00:00, ?it/s]2023-07-19 14:04:38,311 - INFO - Epoch: [162/600], Step: [1/591], Loss: 131509824.0, KL Divergence: 767.9918823242188, Reconstruction Loss: 131509056.0\n",
      "117it [00:10, 10.65it/s]2023-07-19 14:04:49,172 - INFO - Epoch: [162/600], Step: [119/591], Loss: 347948960.0, KL Divergence: 759.687744140625, Reconstruction Loss: 347948192.0\n",
      "235it [00:21, 11.12it/s]2023-07-19 14:04:59,972 - INFO - Epoch: [162/600], Step: [237/591], Loss: 273598176.0, KL Divergence: 760.24365234375, Reconstruction Loss: 273597408.0\n",
      "353it [00:32, 11.10it/s]2023-07-19 14:05:10,737 - INFO - Epoch: [162/600], Step: [355/591], Loss: 319611904.0, KL Divergence: 753.666259765625, Reconstruction Loss: 319611136.0\n",
      "471it [00:43, 11.08it/s]2023-07-19 14:05:21,485 - INFO - Epoch: [162/600], Step: [473/591], Loss: 295819616.0, KL Divergence: 749.2762451171875, Reconstruction Loss: 295818880.0\n",
      "589it [00:53, 11.08it/s]2023-07-19 14:05:32,181 - INFO - Epoch: [162/600], Step: [591/591], Loss: 226450816.0, KL Divergence: 775.2601928710938, Reconstruction Loss: 226450048.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 14:05:32,183 - INFO - Epoch: [162/600], Total Loss: 18178086368256.0, Total KL Divergence: 57381294.1953125, Total Reconstruction Loss: 18178028899328.0\n",
      "2023-07-19 14:05:32,230 - INFO - Save model at epoch 162\n",
      "0it [00:00, ?it/s]2023-07-19 14:05:32,349 - INFO - Epoch: [163/600], Step: [1/591], Loss: 130285200.0, KL Divergence: 768.031494140625, Reconstruction Loss: 130284432.0\n",
      "118it [00:10, 10.84it/s]2023-07-19 14:05:43,308 - INFO - Epoch: [163/600], Step: [119/591], Loss: 360151008.0, KL Divergence: 757.61083984375, Reconstruction Loss: 360150240.0\n",
      "236it [00:21, 10.80it/s]2023-07-19 14:05:54,323 - INFO - Epoch: [163/600], Step: [237/591], Loss: 265966288.0, KL Divergence: 757.5816650390625, Reconstruction Loss: 265965536.0\n",
      "354it [00:32, 10.88it/s]2023-07-19 14:06:05,231 - INFO - Epoch: [163/600], Step: [355/591], Loss: 305375552.0, KL Divergence: 757.2326049804688, Reconstruction Loss: 305374784.0\n",
      "472it [00:43, 10.79it/s]2023-07-19 14:06:16,087 - INFO - Epoch: [163/600], Step: [473/591], Loss: 288097984.0, KL Divergence: 759.2127075195312, Reconstruction Loss: 288097216.0\n",
      "590it [00:54, 10.90it/s]2023-07-19 14:06:27,040 - INFO - Epoch: [163/600], Step: [591/591], Loss: 219329168.0, KL Divergence: 784.2946166992188, Reconstruction Loss: 219328384.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 14:06:27,041 - INFO - Epoch: [163/600], Total Loss: 18038850772992.0, Total KL Divergence: 57625363.390625, Total Reconstruction Loss: 18038793021440.0\n",
      "2023-07-19 14:06:27,081 - INFO - Save model at epoch 163\n",
      "0it [00:00, ?it/s]2023-07-19 14:06:27,196 - INFO - Epoch: [164/600], Step: [1/591], Loss: 132340928.0, KL Divergence: 776.9508056640625, Reconstruction Loss: 132340152.0\n",
      "117it [00:10, 11.03it/s]2023-07-19 14:06:38,111 - INFO - Epoch: [164/600], Step: [119/591], Loss: 353587264.0, KL Divergence: 766.6625366210938, Reconstruction Loss: 353586496.0\n",
      "235it [00:21, 10.92it/s]2023-07-19 14:06:48,945 - INFO - Epoch: [164/600], Step: [237/591], Loss: 273379232.0, KL Divergence: 762.1805419921875, Reconstruction Loss: 273378464.0\n",
      "353it [00:32, 10.74it/s]2023-07-19 14:06:59,917 - INFO - Epoch: [164/600], Step: [355/591], Loss: 315214432.0, KL Divergence: 751.8487548828125, Reconstruction Loss: 315213696.0\n",
      "471it [00:43, 10.89it/s]2023-07-19 14:07:10,764 - INFO - Epoch: [164/600], Step: [473/591], Loss: 296159104.0, KL Divergence: 757.6751708984375, Reconstruction Loss: 296158336.0\n",
      "589it [00:54, 10.74it/s]2023-07-19 14:07:21,598 - INFO - Epoch: [164/600], Step: [591/591], Loss: 209197824.0, KL Divergence: 775.1696166992188, Reconstruction Loss: 209197056.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 14:07:21,600 - INFO - Epoch: [164/600], Total Loss: 17964942343168.0, Total KL Divergence: 57638466.921875, Total Reconstruction Loss: 17964884648960.0\n",
      "2023-07-19 14:07:21,640 - INFO - Save model at epoch 164\n",
      "0it [00:00, ?it/s]2023-07-19 14:07:21,757 - INFO - Epoch: [165/600], Step: [1/591], Loss: 135086448.0, KL Divergence: 766.9046630859375, Reconstruction Loss: 135085680.0\n",
      "117it [00:10, 10.91it/s]2023-07-19 14:07:32,672 - INFO - Epoch: [165/600], Step: [119/591], Loss: 360375712.0, KL Divergence: 763.5528564453125, Reconstruction Loss: 360374944.0\n",
      "235it [00:21, 10.92it/s]2023-07-19 14:07:43,562 - INFO - Epoch: [165/600], Step: [237/591], Loss: 264822848.0, KL Divergence: 761.0706787109375, Reconstruction Loss: 264822080.0\n",
      "353it [00:32, 10.80it/s]2023-07-19 14:07:54,558 - INFO - Epoch: [165/600], Step: [355/591], Loss: 305892800.0, KL Divergence: 761.1854248046875, Reconstruction Loss: 305892032.0\n",
      "471it [00:43, 11.04it/s]2023-07-19 14:08:05,375 - INFO - Epoch: [165/600], Step: [473/591], Loss: 291855424.0, KL Divergence: 754.2877197265625, Reconstruction Loss: 291854656.0\n",
      "589it [00:54, 10.78it/s]2023-07-19 14:08:16,236 - INFO - Epoch: [165/600], Step: [591/591], Loss: 213362112.0, KL Divergence: 782.8880615234375, Reconstruction Loss: 213361328.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 14:08:16,238 - INFO - Epoch: [165/600], Total Loss: 18018092731392.0, Total KL Divergence: 57683550.421875, Total Reconstruction Loss: 18018034880512.0\n",
      "2023-07-19 14:08:16,279 - INFO - Save model at epoch 165\n",
      "0it [00:00, ?it/s]2023-07-19 14:08:16,393 - INFO - Epoch: [166/600], Step: [1/591], Loss: 135333712.0, KL Divergence: 776.4694213867188, Reconstruction Loss: 135332928.0\n",
      "118it [00:10, 10.86it/s]2023-07-19 14:08:27,301 - INFO - Epoch: [166/600], Step: [119/591], Loss: 357791328.0, KL Divergence: 765.52734375, Reconstruction Loss: 357790560.0\n",
      "236it [00:21, 10.93it/s]2023-07-19 14:08:38,169 - INFO - Epoch: [166/600], Step: [237/591], Loss: 263803200.0, KL Divergence: 757.5928955078125, Reconstruction Loss: 263802448.0\n",
      "354it [00:32, 10.97it/s]2023-07-19 14:08:49,094 - INFO - Epoch: [166/600], Step: [355/591], Loss: 300632832.0, KL Divergence: 758.4378662109375, Reconstruction Loss: 300632064.0\n",
      "472it [00:43, 10.80it/s]2023-07-19 14:08:59,971 - INFO - Epoch: [166/600], Step: [473/591], Loss: 289089920.0, KL Divergence: 759.532470703125, Reconstruction Loss: 289089152.0\n",
      "590it [00:54, 10.66it/s]2023-07-19 14:09:10,830 - INFO - Epoch: [166/600], Step: [591/591], Loss: 209561408.0, KL Divergence: 781.3173828125, Reconstruction Loss: 209560624.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 14:09:10,832 - INFO - Epoch: [166/600], Total Loss: 17870287519744.0, Total KL Divergence: 57758320.484375, Total Reconstruction Loss: 17870229643264.0\n",
      "2023-07-19 14:09:10,876 - INFO - Save model at epoch 166\n",
      "0it [00:00, ?it/s]2023-07-19 14:09:11,014 - INFO - Epoch: [167/600], Step: [1/591], Loss: 137822864.0, KL Divergence: 773.7039184570312, Reconstruction Loss: 137822096.0\n",
      "117it [00:10, 10.86it/s]2023-07-19 14:09:21,894 - INFO - Epoch: [167/600], Step: [119/591], Loss: 363734848.0, KL Divergence: 767.1837158203125, Reconstruction Loss: 363734080.0\n",
      "235it [00:21, 10.60it/s]2023-07-19 14:09:32,796 - INFO - Epoch: [167/600], Step: [237/591], Loss: 253830160.0, KL Divergence: 767.6080322265625, Reconstruction Loss: 253829392.0\n",
      "353it [00:32, 10.71it/s]2023-07-19 14:09:43,764 - INFO - Epoch: [167/600], Step: [355/591], Loss: 294908800.0, KL Divergence: 762.3597412109375, Reconstruction Loss: 294908032.0\n",
      "471it [00:43, 10.98it/s]2023-07-19 14:09:54,648 - INFO - Epoch: [167/600], Step: [473/591], Loss: 309227648.0, KL Divergence: 758.610595703125, Reconstruction Loss: 309226880.0\n",
      "589it [00:54, 11.00it/s]2023-07-19 14:10:05,397 - INFO - Epoch: [167/600], Step: [591/591], Loss: 208180416.0, KL Divergence: 784.930908203125, Reconstruction Loss: 208179632.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 14:10:05,399 - INFO - Epoch: [167/600], Total Loss: 17809924513792.0, Total KL Divergence: 57928602.6328125, Total Reconstruction Loss: 17809866451968.0\n",
      "2023-07-19 14:10:05,442 - INFO - Save model at epoch 167\n",
      "0it [00:00, ?it/s]2023-07-19 14:10:05,548 - INFO - Epoch: [168/600], Step: [1/591], Loss: 129582216.0, KL Divergence: 777.629150390625, Reconstruction Loss: 129581440.0\n",
      "118it [00:10, 10.90it/s]2023-07-19 14:10:16,431 - INFO - Epoch: [168/600], Step: [119/591], Loss: 358706848.0, KL Divergence: 764.9169921875, Reconstruction Loss: 358706080.0\n",
      "236it [00:21, 10.62it/s]2023-07-19 14:10:27,383 - INFO - Epoch: [168/600], Step: [237/591], Loss: 258536880.0, KL Divergence: 764.7750244140625, Reconstruction Loss: 258536112.0\n",
      "354it [00:32, 10.85it/s]2023-07-19 14:10:38,326 - INFO - Epoch: [168/600], Step: [355/591], Loss: 296798656.0, KL Divergence: 762.20751953125, Reconstruction Loss: 296797888.0\n",
      "472it [00:43, 10.95it/s]2023-07-19 14:10:49,202 - INFO - Epoch: [168/600], Step: [473/591], Loss: 304065632.0, KL Divergence: 759.5621337890625, Reconstruction Loss: 304064864.0\n",
      "590it [00:54, 11.04it/s]2023-07-19 14:10:59,963 - INFO - Epoch: [168/600], Step: [591/591], Loss: 213619008.0, KL Divergence: 785.5538940429688, Reconstruction Loss: 213618224.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 14:10:59,965 - INFO - Epoch: [168/600], Total Loss: 17891075309568.0, Total KL Divergence: 57973807.0859375, Total Reconstruction Loss: 17891017228288.0\n",
      "2023-07-19 14:11:00,006 - INFO - Save model at epoch 168\n",
      "0it [00:00, ?it/s]2023-07-19 14:11:00,124 - INFO - Epoch: [169/600], Step: [1/591], Loss: 131897640.0, KL Divergence: 777.247802734375, Reconstruction Loss: 131896864.0\n",
      "118it [00:10, 10.93it/s]2023-07-19 14:11:11,045 - INFO - Epoch: [169/600], Step: [119/591], Loss: 346009056.0, KL Divergence: 769.6875, Reconstruction Loss: 346008288.0\n",
      "236it [00:21, 10.21it/s]2023-07-19 14:11:22,067 - INFO - Epoch: [169/600], Step: [237/591], Loss: 253574384.0, KL Divergence: 768.8942260742188, Reconstruction Loss: 253573616.0\n",
      "354it [00:33, 10.94it/s]2023-07-19 14:11:33,131 - INFO - Epoch: [169/600], Step: [355/591], Loss: 303840448.0, KL Divergence: 769.4912719726562, Reconstruction Loss: 303839680.0\n",
      "472it [00:43, 10.58it/s]2023-07-19 14:11:44,106 - INFO - Epoch: [169/600], Step: [473/591], Loss: 327324544.0, KL Divergence: 765.7174072265625, Reconstruction Loss: 327323776.0\n",
      "590it [00:54, 10.81it/s]2023-07-19 14:11:54,950 - INFO - Epoch: [169/600], Step: [591/591], Loss: 219722160.0, KL Divergence: 790.3307495117188, Reconstruction Loss: 219721376.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 14:11:54,952 - INFO - Epoch: [169/600], Total Loss: 17908103716864.0, Total KL Divergence: 58326377.3828125, Total Reconstruction Loss: 17908045446144.0\n",
      "2023-07-19 14:11:54,991 - INFO - Save model at epoch 169\n",
      "0it [00:00, ?it/s]2023-07-19 14:11:55,100 - INFO - Epoch: [170/600], Step: [1/591], Loss: 125801728.0, KL Divergence: 782.9683227539062, Reconstruction Loss: 125800944.0\n",
      "117it [00:10, 10.89it/s]2023-07-19 14:12:05,997 - INFO - Epoch: [170/600], Step: [119/591], Loss: 344941216.0, KL Divergence: 777.643310546875, Reconstruction Loss: 344940448.0\n",
      "235it [00:21, 10.81it/s]2023-07-19 14:12:16,837 - INFO - Epoch: [170/600], Step: [237/591], Loss: 261109952.0, KL Divergence: 770.8931884765625, Reconstruction Loss: 261109184.0\n",
      "353it [00:32, 10.95it/s]2023-07-19 14:12:27,709 - INFO - Epoch: [170/600], Step: [355/591], Loss: 295369536.0, KL Divergence: 767.5794677734375, Reconstruction Loss: 295368768.0\n",
      "471it [00:43, 10.84it/s]2023-07-19 14:12:38,535 - INFO - Epoch: [170/600], Step: [473/591], Loss: 312450816.0, KL Divergence: 768.9661254882812, Reconstruction Loss: 312450048.0\n",
      "589it [00:54, 10.62it/s]2023-07-19 14:12:49,326 - INFO - Epoch: [170/600], Step: [591/591], Loss: 210742224.0, KL Divergence: 793.1251831054688, Reconstruction Loss: 210741424.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 14:12:49,328 - INFO - Epoch: [170/600], Total Loss: 17839523899392.0, Total KL Divergence: 58532913.84375, Total Reconstruction Loss: 17839465425920.0\n",
      "2023-07-19 14:12:49,368 - INFO - Save model at epoch 170\n",
      "0it [00:00, ?it/s]2023-07-19 14:12:49,482 - INFO - Epoch: [171/600], Step: [1/591], Loss: 123974240.0, KL Divergence: 786.645751953125, Reconstruction Loss: 123973456.0\n",
      "117it [00:10, 10.82it/s]2023-07-19 14:13:00,443 - INFO - Epoch: [171/600], Step: [119/591], Loss: 346255232.0, KL Divergence: 775.4285278320312, Reconstruction Loss: 346254464.0\n",
      "235it [00:21, 10.86it/s]2023-07-19 14:13:11,231 - INFO - Epoch: [171/600], Step: [237/591], Loss: 249272064.0, KL Divergence: 774.0083618164062, Reconstruction Loss: 249271296.0\n",
      "353it [00:32, 11.01it/s]2023-07-19 14:13:22,086 - INFO - Epoch: [171/600], Step: [355/591], Loss: 292801216.0, KL Divergence: 768.068603515625, Reconstruction Loss: 292800448.0\n",
      "471it [00:43, 11.00it/s]2023-07-19 14:13:32,867 - INFO - Epoch: [171/600], Step: [473/591], Loss: 288823712.0, KL Divergence: 766.44091796875, Reconstruction Loss: 288822944.0\n",
      "589it [00:54, 10.76it/s]2023-07-19 14:13:43,659 - INFO - Epoch: [171/600], Step: [591/591], Loss: 204519632.0, KL Divergence: 793.04833984375, Reconstruction Loss: 204518832.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 14:13:43,660 - INFO - Epoch: [171/600], Total Loss: 17458733420544.0, Total KL Divergence: 58536949.859375, Total Reconstruction Loss: 17458674948096.0\n",
      "2023-07-19 14:13:43,701 - INFO - Save model at epoch 171\n",
      "0it [00:00, ?it/s]2023-07-19 14:13:43,811 - INFO - Epoch: [172/600], Step: [1/591], Loss: 129515048.0, KL Divergence: 785.9444580078125, Reconstruction Loss: 129514264.0\n",
      "117it [00:10, 10.89it/s]2023-07-19 14:13:54,686 - INFO - Epoch: [172/600], Step: [119/591], Loss: 350897024.0, KL Divergence: 775.0013427734375, Reconstruction Loss: 350896256.0\n",
      "235it [00:21, 10.78it/s]2023-07-19 14:14:05,581 - INFO - Epoch: [172/600], Step: [237/591], Loss: 251851968.0, KL Divergence: 772.7474365234375, Reconstruction Loss: 251851200.0\n",
      "353it [00:32, 10.58it/s]2023-07-19 14:14:16,498 - INFO - Epoch: [172/600], Step: [355/591], Loss: 295354720.0, KL Divergence: 766.813720703125, Reconstruction Loss: 295353952.0\n",
      "471it [00:43, 11.10it/s]2023-07-19 14:14:27,326 - INFO - Epoch: [172/600], Step: [473/591], Loss: 308035584.0, KL Divergence: 759.0657958984375, Reconstruction Loss: 308034816.0\n",
      "589it [00:54, 11.06it/s]2023-07-19 14:14:38,037 - INFO - Epoch: [172/600], Step: [591/591], Loss: 205792304.0, KL Divergence: 783.8450927734375, Reconstruction Loss: 205791520.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 14:14:38,040 - INFO - Epoch: [172/600], Total Loss: 17525169069056.0, Total KL Divergence: 58266750.640625, Total Reconstruction Loss: 17525110787072.0\n",
      "2023-07-19 14:14:38,094 - INFO - Save model at epoch 172\n",
      "0it [00:00, ?it/s]2023-07-19 14:14:38,214 - INFO - Epoch: [173/600], Step: [1/591], Loss: 125019480.0, KL Divergence: 775.761962890625, Reconstruction Loss: 125018704.0\n",
      "117it [00:10, 10.89it/s]2023-07-19 14:14:49,141 - INFO - Epoch: [173/600], Step: [119/591], Loss: 341331936.0, KL Divergence: 768.1972045898438, Reconstruction Loss: 341331168.0\n",
      "235it [00:21, 10.61it/s]2023-07-19 14:15:00,037 - INFO - Epoch: [173/600], Step: [237/591], Loss: 249601264.0, KL Divergence: 766.2283935546875, Reconstruction Loss: 249600496.0\n",
      "353it [00:32, 10.76it/s]2023-07-19 14:15:11,199 - INFO - Epoch: [173/600], Step: [355/591], Loss: 312349056.0, KL Divergence: 765.71142578125, Reconstruction Loss: 312348288.0\n",
      "471it [00:43, 10.73it/s]2023-07-19 14:15:22,291 - INFO - Epoch: [173/600], Step: [473/591], Loss: 280482912.0, KL Divergence: 763.19775390625, Reconstruction Loss: 280482144.0\n",
      "589it [00:54, 10.92it/s]2023-07-19 14:15:33,194 - INFO - Epoch: [173/600], Step: [591/591], Loss: 218232000.0, KL Divergence: 787.64306640625, Reconstruction Loss: 218231216.0\n",
      "591it [00:55, 10.73it/s]\n",
      "2023-07-19 14:15:33,196 - INFO - Epoch: [173/600], Total Loss: 17544613124096.0, Total KL Divergence: 58081270.9609375, Total Reconstruction Loss: 17544554987520.0\n",
      "2023-07-19 14:15:33,247 - INFO - Save model at epoch 173\n",
      "0it [00:00, ?it/s]2023-07-19 14:15:33,378 - INFO - Epoch: [174/600], Step: [1/591], Loss: 139593808.0, KL Divergence: 780.937255859375, Reconstruction Loss: 139593024.0\n",
      "117it [00:11, 10.68it/s]2023-07-19 14:15:44,468 - INFO - Epoch: [174/600], Step: [119/591], Loss: 346232256.0, KL Divergence: 776.6485595703125, Reconstruction Loss: 346231488.0\n",
      "235it [00:22, 10.69it/s]2023-07-19 14:15:55,586 - INFO - Epoch: [174/600], Step: [237/591], Loss: 253258752.0, KL Divergence: 771.6424560546875, Reconstruction Loss: 253257984.0\n",
      "353it [00:33, 10.79it/s]2023-07-19 14:16:06,746 - INFO - Epoch: [174/600], Step: [355/591], Loss: 300868544.0, KL Divergence: 768.3394775390625, Reconstruction Loss: 300867776.0\n",
      "471it [00:44, 10.78it/s]2023-07-19 14:16:17,748 - INFO - Epoch: [174/600], Step: [473/591], Loss: 281951680.0, KL Divergence: 763.3756713867188, Reconstruction Loss: 281950912.0\n",
      "589it [00:55, 10.79it/s]2023-07-19 14:16:28,707 - INFO - Epoch: [174/600], Step: [591/591], Loss: 215120064.0, KL Divergence: 785.085205078125, Reconstruction Loss: 215119280.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 14:16:28,709 - INFO - Epoch: [174/600], Total Loss: 17654449166336.0, Total KL Divergence: 58367668.3671875, Total Reconstruction Loss: 17654390880256.0\n",
      "2023-07-19 14:16:28,775 - INFO - Save model at epoch 174\n",
      "0it [00:00, ?it/s]2023-07-19 14:16:28,897 - INFO - Epoch: [175/600], Step: [1/591], Loss: 125979944.0, KL Divergence: 777.2218017578125, Reconstruction Loss: 125979168.0\n",
      "117it [00:11, 10.82it/s]2023-07-19 14:16:40,030 - INFO - Epoch: [175/600], Step: [119/591], Loss: 344553984.0, KL Divergence: 775.5579833984375, Reconstruction Loss: 344553216.0\n",
      "235it [00:22, 10.72it/s]2023-07-19 14:16:51,080 - INFO - Epoch: [175/600], Step: [237/591], Loss: 254291040.0, KL Divergence: 773.5018310546875, Reconstruction Loss: 254290272.0\n",
      "353it [00:33, 10.89it/s]2023-07-19 14:17:02,124 - INFO - Epoch: [175/600], Step: [355/591], Loss: 291925280.0, KL Divergence: 772.1868896484375, Reconstruction Loss: 291924512.0\n",
      "471it [00:44, 10.66it/s]2023-07-19 14:17:13,132 - INFO - Epoch: [175/600], Step: [473/591], Loss: 280706848.0, KL Divergence: 769.7054443359375, Reconstruction Loss: 280706080.0\n",
      "589it [00:55, 10.64it/s]2023-07-19 14:17:24,287 - INFO - Epoch: [175/600], Step: [591/591], Loss: 220187024.0, KL Divergence: 791.2490234375, Reconstruction Loss: 220186240.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 14:17:24,289 - INFO - Epoch: [175/600], Total Loss: 17650598448128.0, Total KL Divergence: 58532577.5625, Total Reconstruction Loss: 17650540037120.0\n",
      "2023-07-19 14:17:24,330 - INFO - Save model at epoch 175\n",
      "0it [00:00, ?it/s]2023-07-19 14:17:24,456 - INFO - Epoch: [176/600], Step: [1/591], Loss: 131521760.0, KL Divergence: 782.4212646484375, Reconstruction Loss: 131520976.0\n",
      "118it [00:11, 10.61it/s]2023-07-19 14:17:35,636 - INFO - Epoch: [176/600], Step: [119/591], Loss: 337262720.0, KL Divergence: 776.4075927734375, Reconstruction Loss: 337261952.0\n",
      "236it [00:22, 10.79it/s]2023-07-19 14:17:46,642 - INFO - Epoch: [176/600], Step: [237/591], Loss: 249893392.0, KL Divergence: 767.1721801757812, Reconstruction Loss: 249892624.0\n",
      "354it [00:33, 10.69it/s]2023-07-19 14:17:57,695 - INFO - Epoch: [176/600], Step: [355/591], Loss: 316552640.0, KL Divergence: 756.53759765625, Reconstruction Loss: 316551872.0\n",
      "472it [00:44, 10.77it/s]2023-07-19 14:18:08,706 - INFO - Epoch: [176/600], Step: [473/591], Loss: 283974464.0, KL Divergence: 754.7864379882812, Reconstruction Loss: 283973696.0\n",
      "590it [00:55, 10.78it/s]2023-07-19 14:18:19,643 - INFO - Epoch: [176/600], Step: [591/591], Loss: 225032432.0, KL Divergence: 778.0299682617188, Reconstruction Loss: 225031648.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 14:18:19,645 - INFO - Epoch: [176/600], Total Loss: 17594984599552.0, Total KL Divergence: 57975856.5234375, Total Reconstruction Loss: 17594926555136.0\n",
      "2023-07-19 14:18:19,686 - INFO - Save model at epoch 176\n",
      "0it [00:00, ?it/s]2023-07-19 14:18:19,820 - INFO - Epoch: [177/600], Step: [1/591], Loss: 139884496.0, KL Divergence: 770.1575927734375, Reconstruction Loss: 139883728.0\n",
      "117it [00:11, 10.63it/s]2023-07-19 14:18:30,937 - INFO - Epoch: [177/600], Step: [119/591], Loss: 341487008.0, KL Divergence: 767.9027099609375, Reconstruction Loss: 341486240.0\n",
      "235it [00:22, 10.78it/s]2023-07-19 14:18:41,933 - INFO - Epoch: [177/600], Step: [237/591], Loss: 249335488.0, KL Divergence: 761.1599731445312, Reconstruction Loss: 249334720.0\n",
      "353it [00:33, 10.78it/s]2023-07-19 14:18:53,016 - INFO - Epoch: [177/600], Step: [355/591], Loss: 303835968.0, KL Divergence: 757.336669921875, Reconstruction Loss: 303835200.0\n",
      "471it [00:44, 10.63it/s]2023-07-19 14:19:04,044 - INFO - Epoch: [177/600], Step: [473/591], Loss: 320118432.0, KL Divergence: 757.4957275390625, Reconstruction Loss: 320117664.0\n",
      "589it [00:55, 10.40it/s]2023-07-19 14:19:15,020 - INFO - Epoch: [177/600], Step: [591/591], Loss: 210700736.0, KL Divergence: 781.1749877929688, Reconstruction Loss: 210699952.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 14:19:15,022 - INFO - Epoch: [177/600], Total Loss: 17684541515776.0, Total KL Divergence: 57672243.90625, Total Reconstruction Loss: 17684483709952.0\n",
      "2023-07-19 14:19:15,064 - INFO - Save model at epoch 177\n",
      "0it [00:00, ?it/s]2023-07-19 14:19:15,182 - INFO - Epoch: [178/600], Step: [1/591], Loss: 136767488.0, KL Divergence: 773.9056396484375, Reconstruction Loss: 136766720.0\n",
      "117it [00:11, 10.78it/s]2023-07-19 14:19:26,293 - INFO - Epoch: [178/600], Step: [119/591], Loss: 342005824.0, KL Divergence: 772.9955444335938, Reconstruction Loss: 342005056.0\n",
      "235it [00:22, 10.62it/s]2023-07-19 14:19:37,367 - INFO - Epoch: [178/600], Step: [237/591], Loss: 261867520.0, KL Divergence: 770.392333984375, Reconstruction Loss: 261866752.0\n",
      "353it [00:33, 10.61it/s]2023-07-19 14:19:48,454 - INFO - Epoch: [178/600], Step: [355/591], Loss: 295834752.0, KL Divergence: 764.8095703125, Reconstruction Loss: 295833984.0\n",
      "471it [00:44, 10.84it/s]2023-07-19 14:19:59,420 - INFO - Epoch: [178/600], Step: [473/591], Loss: 297573024.0, KL Divergence: 765.7506103515625, Reconstruction Loss: 297572256.0\n",
      "589it [00:55, 10.92it/s]2023-07-19 14:20:10,322 - INFO - Epoch: [178/600], Step: [591/591], Loss: 205004736.0, KL Divergence: 791.807373046875, Reconstruction Loss: 205003952.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 14:20:10,324 - INFO - Epoch: [178/600], Total Loss: 17429839715328.0, Total KL Divergence: 58262655.0546875, Total Reconstruction Loss: 17429781464064.0\n",
      "2023-07-19 14:20:10,369 - INFO - Save model at epoch 178\n",
      "0it [00:00, ?it/s]2023-07-19 14:20:10,494 - INFO - Epoch: [179/600], Step: [1/591], Loss: 127367088.0, KL Divergence: 783.9263916015625, Reconstruction Loss: 127366304.0\n",
      "117it [00:11, 10.58it/s]2023-07-19 14:20:21,591 - INFO - Epoch: [179/600], Step: [119/591], Loss: 333936064.0, KL Divergence: 770.7415161132812, Reconstruction Loss: 333935296.0\n",
      "235it [00:21, 10.78it/s]2023-07-19 14:20:32,522 - INFO - Epoch: [179/600], Step: [237/591], Loss: 246063808.0, KL Divergence: 766.1323852539062, Reconstruction Loss: 246063040.0\n",
      "353it [00:33, 10.65it/s]2023-07-19 14:20:43,597 - INFO - Epoch: [179/600], Step: [355/591], Loss: 296276416.0, KL Divergence: 756.9085693359375, Reconstruction Loss: 296275648.0\n",
      "471it [00:44, 10.76it/s]2023-07-19 14:20:54,597 - INFO - Epoch: [179/600], Step: [473/591], Loss: 290331008.0, KL Divergence: 760.9671630859375, Reconstruction Loss: 290330240.0\n",
      "589it [00:55, 10.85it/s]2023-07-19 14:21:05,561 - INFO - Epoch: [179/600], Step: [591/591], Loss: 211367184.0, KL Divergence: 786.1198120117188, Reconstruction Loss: 211366400.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 14:21:05,564 - INFO - Epoch: [179/600], Total Loss: 17463082066944.0, Total KL Divergence: 58044319.0078125, Total Reconstruction Loss: 17463023976448.0\n",
      "2023-07-19 14:21:05,605 - INFO - Save model at epoch 179\n",
      "0it [00:00, ?it/s]2023-07-19 14:21:05,724 - INFO - Epoch: [180/600], Step: [1/591], Loss: 129116400.0, KL Divergence: 777.80126953125, Reconstruction Loss: 129115624.0\n",
      "117it [00:10, 10.74it/s]2023-07-19 14:21:16,778 - INFO - Epoch: [180/600], Step: [119/591], Loss: 330841920.0, KL Divergence: 767.9443359375, Reconstruction Loss: 330841152.0\n",
      "235it [00:21, 10.88it/s]2023-07-19 14:21:27,785 - INFO - Epoch: [180/600], Step: [237/591], Loss: 248435680.0, KL Divergence: 764.9019775390625, Reconstruction Loss: 248434912.0\n",
      "353it [00:32, 10.49it/s]2023-07-19 14:21:38,814 - INFO - Epoch: [180/600], Step: [355/591], Loss: 294191872.0, KL Divergence: 758.7926025390625, Reconstruction Loss: 294191104.0\n",
      "471it [00:44, 10.73it/s]2023-07-19 14:21:49,828 - INFO - Epoch: [180/600], Step: [473/591], Loss: 275298272.0, KL Divergence: 753.54296875, Reconstruction Loss: 275297504.0\n",
      "589it [00:55, 10.54it/s]2023-07-19 14:22:00,809 - INFO - Epoch: [180/600], Step: [591/591], Loss: 206987536.0, KL Divergence: 780.0363159179688, Reconstruction Loss: 206986752.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 14:22:00,811 - INFO - Epoch: [180/600], Total Loss: 17285481281536.0, Total KL Divergence: 57775314.6875, Total Reconstruction Loss: 17285423415296.0\n",
      "2023-07-19 14:22:00,854 - INFO - Save model at epoch 180\n",
      "0it [00:00, ?it/s]2023-07-19 14:22:00,983 - INFO - Epoch: [181/600], Step: [1/591], Loss: 123966800.0, KL Divergence: 773.1951293945312, Reconstruction Loss: 123966024.0\n",
      "118it [00:11, 10.84it/s]2023-07-19 14:22:12,341 - INFO - Epoch: [181/600], Step: [119/591], Loss: 329858272.0, KL Divergence: 766.0679931640625, Reconstruction Loss: 329857504.0\n",
      "236it [00:22, 10.87it/s]2023-07-19 14:22:23,455 - INFO - Epoch: [181/600], Step: [237/591], Loss: 244568736.0, KL Divergence: 765.630615234375, Reconstruction Loss: 244567968.0\n",
      "354it [00:33, 10.45it/s]2023-07-19 14:22:34,681 - INFO - Epoch: [181/600], Step: [355/591], Loss: 301285504.0, KL Divergence: 764.3687133789062, Reconstruction Loss: 301284736.0\n",
      "472it [00:44, 10.48it/s]2023-07-19 14:22:45,944 - INFO - Epoch: [181/600], Step: [473/591], Loss: 302380416.0, KL Divergence: 760.7041015625, Reconstruction Loss: 302379648.0\n",
      "589it [00:56, 10.71it/s]2023-07-19 14:22:57,166 - INFO - Epoch: [181/600], Step: [591/591], Loss: 217649232.0, KL Divergence: 789.4429931640625, Reconstruction Loss: 217648448.0\n",
      "591it [00:56, 10.50it/s]\n",
      "2023-07-19 14:22:57,168 - INFO - Epoch: [181/600], Total Loss: 17434685142016.0, Total KL Divergence: 58025272.390625, Total Reconstruction Loss: 17434627057664.0\n",
      "2023-07-19 14:22:57,210 - INFO - Save model at epoch 181\n",
      "0it [00:00, ?it/s]2023-07-19 14:22:57,330 - INFO - Epoch: [182/600], Step: [1/591], Loss: 131429264.0, KL Divergence: 784.1944580078125, Reconstruction Loss: 131428480.0\n",
      "117it [00:11, 10.54it/s]2023-07-19 14:23:08,539 - INFO - Epoch: [182/600], Step: [119/591], Loss: 327460224.0, KL Divergence: 774.709228515625, Reconstruction Loss: 327459456.0\n",
      "235it [00:22, 10.60it/s]2023-07-19 14:23:19,640 - INFO - Epoch: [182/600], Step: [237/591], Loss: 242884368.0, KL Divergence: 772.0172119140625, Reconstruction Loss: 242883600.0\n",
      "353it [00:33, 10.49it/s]2023-07-19 14:23:30,816 - INFO - Epoch: [182/600], Step: [355/591], Loss: 297389312.0, KL Divergence: 764.7406616210938, Reconstruction Loss: 297388544.0\n",
      "471it [00:44, 10.38it/s]2023-07-19 14:23:41,946 - INFO - Epoch: [182/600], Step: [473/591], Loss: 294732352.0, KL Divergence: 763.48779296875, Reconstruction Loss: 294731584.0\n",
      "589it [00:55, 10.54it/s]2023-07-19 14:23:53,166 - INFO - Epoch: [182/600], Step: [591/591], Loss: 205886912.0, KL Divergence: 789.6324462890625, Reconstruction Loss: 205886128.0\n",
      "591it [00:55, 10.56it/s]\n",
      "2023-07-19 14:23:53,169 - INFO - Epoch: [182/600], Total Loss: 17338205832192.0, Total KL Divergence: 58381263.2890625, Total Reconstruction Loss: 17338147515392.0\n",
      "2023-07-19 14:23:53,217 - INFO - Save model at epoch 182\n",
      "0it [00:00, ?it/s]2023-07-19 14:23:53,340 - INFO - Epoch: [183/600], Step: [1/591], Loss: 131540128.0, KL Divergence: 783.6920166015625, Reconstruction Loss: 131539344.0\n",
      "118it [00:11, 10.45it/s]2023-07-19 14:24:04,604 - INFO - Epoch: [183/600], Step: [119/591], Loss: 328213632.0, KL Divergence: 778.9747314453125, Reconstruction Loss: 328212864.0\n",
      "236it [00:22, 10.61it/s]2023-07-19 14:24:15,748 - INFO - Epoch: [183/600], Step: [237/591], Loss: 246887584.0, KL Divergence: 772.5787353515625, Reconstruction Loss: 246886816.0\n",
      "354it [00:33, 10.17it/s]2023-07-19 14:24:26,953 - INFO - Epoch: [183/600], Step: [355/591], Loss: 293717632.0, KL Divergence: 767.952880859375, Reconstruction Loss: 293716864.0\n",
      "472it [00:44, 10.48it/s]2023-07-19 14:24:38,058 - INFO - Epoch: [183/600], Step: [473/591], Loss: 270980640.0, KL Divergence: 769.7254638671875, Reconstruction Loss: 270979872.0\n",
      "590it [00:55, 10.44it/s]2023-07-19 14:24:49,131 - INFO - Epoch: [183/600], Step: [591/591], Loss: 211937840.0, KL Divergence: 789.6705932617188, Reconstruction Loss: 211937056.0\n",
      "591it [00:55, 10.57it/s]\n",
      "2023-07-19 14:24:49,133 - INFO - Epoch: [183/600], Total Loss: 17207760398336.0, Total KL Divergence: 58611037.328125, Total Reconstruction Loss: 17207701843968.0\n",
      "2023-07-19 14:24:49,178 - INFO - Save model at epoch 183\n",
      "0it [00:00, ?it/s]2023-07-19 14:24:49,297 - INFO - Epoch: [184/600], Step: [1/591], Loss: 125838464.0, KL Divergence: 784.0751953125, Reconstruction Loss: 125837680.0\n",
      "117it [00:11, 10.26it/s]2023-07-19 14:25:00,555 - INFO - Epoch: [184/600], Step: [119/591], Loss: 328184000.0, KL Divergence: 777.37158203125, Reconstruction Loss: 328183232.0\n",
      "236it [00:22, 10.65it/s]2023-07-19 14:25:11,678 - INFO - Epoch: [184/600], Step: [237/591], Loss: 242481120.0, KL Divergence: 770.65771484375, Reconstruction Loss: 242480352.0\n",
      "354it [00:33, 10.87it/s]2023-07-19 14:25:22,785 - INFO - Epoch: [184/600], Step: [355/591], Loss: 295247104.0, KL Divergence: 773.6097412109375, Reconstruction Loss: 295246336.0\n",
      "472it [00:44, 10.71it/s]2023-07-19 14:25:33,820 - INFO - Epoch: [184/600], Step: [473/591], Loss: 268414752.0, KL Divergence: 768.974365234375, Reconstruction Loss: 268413984.0\n",
      "590it [00:55, 10.54it/s]2023-07-19 14:25:44,852 - INFO - Epoch: [184/600], Step: [591/591], Loss: 204691520.0, KL Divergence: 793.85205078125, Reconstruction Loss: 204690720.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 14:25:44,854 - INFO - Epoch: [184/600], Total Loss: 17273139994624.0, Total KL Divergence: 58596877.921875, Total Reconstruction Loss: 17273081468928.0\n",
      "2023-07-19 14:25:44,912 - INFO - Save model at epoch 184\n",
      "0it [00:00, ?it/s]2023-07-19 14:25:45,035 - INFO - Epoch: [185/600], Step: [1/591], Loss: 129077952.0, KL Divergence: 787.5888671875, Reconstruction Loss: 129077168.0\n",
      "117it [00:11, 10.10it/s]2023-07-19 14:25:56,258 - INFO - Epoch: [185/600], Step: [119/591], Loss: 324678176.0, KL Divergence: 779.22900390625, Reconstruction Loss: 324677408.0\n",
      "236it [00:22,  9.88it/s]2023-07-19 14:26:07,515 - INFO - Epoch: [185/600], Step: [237/591], Loss: 244858224.0, KL Divergence: 773.479736328125, Reconstruction Loss: 244857456.0\n",
      "354it [00:33, 10.44it/s]2023-07-19 14:26:18,702 - INFO - Epoch: [185/600], Step: [355/591], Loss: 286801664.0, KL Divergence: 767.778564453125, Reconstruction Loss: 286800896.0\n",
      "472it [00:44, 10.57it/s]2023-07-19 14:26:29,839 - INFO - Epoch: [185/600], Step: [473/591], Loss: 280227232.0, KL Divergence: 766.162353515625, Reconstruction Loss: 280226464.0\n",
      "590it [00:56, 10.60it/s]2023-07-19 14:26:41,007 - INFO - Epoch: [185/600], Step: [591/591], Loss: 203274832.0, KL Divergence: 791.872314453125, Reconstruction Loss: 203274048.0\n",
      "591it [00:56, 10.54it/s]\n",
      "2023-07-19 14:26:41,009 - INFO - Epoch: [185/600], Total Loss: 17175299639296.0, Total KL Divergence: 58542644.4140625, Total Reconstruction Loss: 17175241118720.0\n",
      "2023-07-19 14:26:41,052 - INFO - Save model at epoch 185\n",
      "0it [00:00, ?it/s]2023-07-19 14:26:41,180 - INFO - Epoch: [186/600], Step: [1/591], Loss: 134858816.0, KL Divergence: 784.0106201171875, Reconstruction Loss: 134858032.0\n",
      "117it [00:11, 10.19it/s]2023-07-19 14:26:52,715 - INFO - Epoch: [186/600], Step: [119/591], Loss: 329270144.0, KL Divergence: 779.0533447265625, Reconstruction Loss: 329269376.0\n",
      "235it [00:22, 10.39it/s]2023-07-19 14:27:04,044 - INFO - Epoch: [186/600], Step: [237/591], Loss: 239937088.0, KL Divergence: 775.60791015625, Reconstruction Loss: 239936320.0\n",
      "353it [00:34, 10.69it/s]2023-07-19 14:27:15,376 - INFO - Epoch: [186/600], Step: [355/591], Loss: 307765056.0, KL Divergence: 769.630859375, Reconstruction Loss: 307764288.0\n",
      "471it [00:45, 10.52it/s]2023-07-19 14:27:26,488 - INFO - Epoch: [186/600], Step: [473/591], Loss: 299668544.0, KL Divergence: 765.1060791015625, Reconstruction Loss: 299667776.0\n",
      "589it [00:56, 10.45it/s]2023-07-19 14:27:37,488 - INFO - Epoch: [186/600], Step: [591/591], Loss: 203304976.0, KL Divergence: 787.9365234375, Reconstruction Loss: 203304192.0\n",
      "591it [00:56, 10.47it/s]\n",
      "2023-07-19 14:27:37,490 - INFO - Epoch: [186/600], Total Loss: 17339333025792.0, Total KL Divergence: 58447013.2265625, Total Reconstruction Loss: 17339274648576.0\n",
      "2023-07-19 14:27:37,536 - INFO - Save model at epoch 186\n",
      "0it [00:00, ?it/s]2023-07-19 14:27:37,658 - INFO - Epoch: [187/600], Step: [1/591], Loss: 130448296.0, KL Divergence: 779.9735107421875, Reconstruction Loss: 130447520.0\n",
      "117it [00:11, 10.77it/s]2023-07-19 14:27:48,856 - INFO - Epoch: [187/600], Step: [119/591], Loss: 331275488.0, KL Divergence: 772.77685546875, Reconstruction Loss: 331274720.0\n",
      "235it [00:22, 10.95it/s]2023-07-19 14:27:59,897 - INFO - Epoch: [187/600], Step: [237/591], Loss: 241501568.0, KL Divergence: 770.94287109375, Reconstruction Loss: 241500800.0\n",
      "354it [00:33, 10.86it/s]2023-07-19 14:28:11,049 - INFO - Epoch: [187/600], Step: [355/591], Loss: 285113216.0, KL Divergence: 770.1617431640625, Reconstruction Loss: 285112448.0\n",
      "472it [00:44, 10.59it/s]2023-07-19 14:28:22,226 - INFO - Epoch: [187/600], Step: [473/591], Loss: 278796736.0, KL Divergence: 765.3335571289062, Reconstruction Loss: 278795968.0\n",
      "590it [00:55, 10.69it/s]2023-07-19 14:28:33,203 - INFO - Epoch: [187/600], Step: [591/591], Loss: 206113088.0, KL Divergence: 781.4523315429688, Reconstruction Loss: 206112304.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 14:28:33,205 - INFO - Epoch: [187/600], Total Loss: 17174966385664.0, Total KL Divergence: 58268366.3984375, Total Reconstruction Loss: 17174908176384.0\n",
      "2023-07-19 14:28:33,259 - INFO - Save model at epoch 187\n",
      "0it [00:00, ?it/s]2023-07-19 14:28:33,373 - INFO - Epoch: [188/600], Step: [1/591], Loss: 137811120.0, KL Divergence: 774.2930908203125, Reconstruction Loss: 137810352.0\n",
      "118it [00:11, 10.41it/s]2023-07-19 14:28:44,572 - INFO - Epoch: [188/600], Step: [119/591], Loss: 324655136.0, KL Divergence: 772.3177490234375, Reconstruction Loss: 324654368.0\n",
      "236it [00:22, 10.48it/s]2023-07-19 14:28:55,764 - INFO - Epoch: [188/600], Step: [237/591], Loss: 240309952.0, KL Divergence: 773.75732421875, Reconstruction Loss: 240309184.0\n",
      "354it [00:33, 10.68it/s]2023-07-19 14:29:06,930 - INFO - Epoch: [188/600], Step: [355/591], Loss: 291369600.0, KL Divergence: 770.0308837890625, Reconstruction Loss: 291368832.0\n",
      "472it [00:44, 10.60it/s]2023-07-19 14:29:18,121 - INFO - Epoch: [188/600], Step: [473/591], Loss: 277751488.0, KL Divergence: 771.5767211914062, Reconstruction Loss: 277750720.0\n",
      "590it [00:55, 10.61it/s]2023-07-19 14:29:29,288 - INFO - Epoch: [188/600], Step: [591/591], Loss: 207447440.0, KL Divergence: 791.9178466796875, Reconstruction Loss: 207446656.0\n",
      "591it [00:56, 10.55it/s]\n",
      "2023-07-19 14:29:29,290 - INFO - Epoch: [188/600], Total Loss: 17196098973696.0, Total KL Divergence: 58476977.640625, Total Reconstruction Loss: 17196040597504.0\n",
      "2023-07-19 14:29:29,331 - INFO - Save model at epoch 188\n",
      "0it [00:00, ?it/s]2023-07-19 14:29:29,453 - INFO - Epoch: [189/600], Step: [1/591], Loss: 123631368.0, KL Divergence: 786.4994506835938, Reconstruction Loss: 123630584.0\n",
      "118it [00:11, 10.73it/s]2023-07-19 14:29:40,780 - INFO - Epoch: [189/600], Step: [119/591], Loss: 327698720.0, KL Divergence: 783.319580078125, Reconstruction Loss: 327697952.0\n",
      "236it [00:22, 10.77it/s]2023-07-19 14:29:51,933 - INFO - Epoch: [189/600], Step: [237/591], Loss: 246116240.0, KL Divergence: 778.8037719726562, Reconstruction Loss: 246115456.0\n",
      "354it [00:33, 10.35it/s]2023-07-19 14:30:03,119 - INFO - Epoch: [189/600], Step: [355/591], Loss: 294575872.0, KL Divergence: 771.0740356445312, Reconstruction Loss: 294575104.0\n",
      "472it [00:44, 10.56it/s]2023-07-19 14:30:14,291 - INFO - Epoch: [189/600], Step: [473/591], Loss: 277631584.0, KL Divergence: 771.67578125, Reconstruction Loss: 277630816.0\n",
      "590it [00:55, 10.62it/s]2023-07-19 14:30:25,329 - INFO - Epoch: [189/600], Step: [591/591], Loss: 201337840.0, KL Divergence: 787.671875, Reconstruction Loss: 201337056.0\n",
      "591it [00:55, 10.56it/s]\n",
      "2023-07-19 14:30:25,330 - INFO - Epoch: [189/600], Total Loss: 17288256523264.0, Total KL Divergence: 58762123.328125, Total Reconstruction Loss: 17288197836800.0\n",
      "2023-07-19 14:30:25,378 - INFO - Save model at epoch 189\n",
      "0it [00:00, ?it/s]2023-07-19 14:30:25,500 - INFO - Epoch: [190/600], Step: [1/591], Loss: 122830000.0, KL Divergence: 781.155517578125, Reconstruction Loss: 122829216.0\n",
      "118it [00:11, 10.40it/s]2023-07-19 14:30:36,768 - INFO - Epoch: [190/600], Step: [119/591], Loss: 334553024.0, KL Divergence: 774.1384887695312, Reconstruction Loss: 334552256.0\n",
      "236it [00:22, 10.65it/s]2023-07-19 14:30:47,934 - INFO - Epoch: [190/600], Step: [237/591], Loss: 240298864.0, KL Divergence: 773.9818115234375, Reconstruction Loss: 240298096.0\n",
      "354it [00:33, 10.75it/s]2023-07-19 14:30:59,135 - INFO - Epoch: [190/600], Step: [355/591], Loss: 287515872.0, KL Divergence: 765.9390869140625, Reconstruction Loss: 287515104.0\n",
      "472it [00:44, 10.56it/s]2023-07-19 14:31:10,281 - INFO - Epoch: [190/600], Step: [473/591], Loss: 264540096.0, KL Divergence: 771.3701171875, Reconstruction Loss: 264539328.0\n",
      "590it [00:55, 10.53it/s]2023-07-19 14:31:21,401 - INFO - Epoch: [190/600], Step: [591/591], Loss: 197625456.0, KL Divergence: 788.0263671875, Reconstruction Loss: 197624672.0\n",
      "591it [00:56, 10.55it/s]\n",
      "2023-07-19 14:31:21,403 - INFO - Epoch: [190/600], Total Loss: 17127528207360.0, Total KL Divergence: 58480422.8203125, Total Reconstruction Loss: 17127469787136.0\n",
      "2023-07-19 14:31:21,443 - INFO - Save model at epoch 190\n",
      "0it [00:00, ?it/s]2023-07-19 14:31:21,571 - INFO - Epoch: [191/600], Step: [1/591], Loss: 125407520.0, KL Divergence: 782.6036376953125, Reconstruction Loss: 125406736.0\n",
      "117it [00:11, 10.66it/s]2023-07-19 14:31:32,700 - INFO - Epoch: [191/600], Step: [119/591], Loss: 327723392.0, KL Divergence: 780.7714233398438, Reconstruction Loss: 327722624.0\n",
      "235it [00:22, 10.65it/s]2023-07-19 14:31:43,879 - INFO - Epoch: [191/600], Step: [237/591], Loss: 246801248.0, KL Divergence: 776.037841796875, Reconstruction Loss: 246800464.0\n",
      "354it [00:33, 10.61it/s]2023-07-19 14:31:55,124 - INFO - Epoch: [191/600], Step: [355/591], Loss: 290430528.0, KL Divergence: 765.00439453125, Reconstruction Loss: 290429760.0\n",
      "472it [00:44, 10.92it/s]2023-07-19 14:32:06,181 - INFO - Epoch: [191/600], Step: [473/591], Loss: 278848704.0, KL Divergence: 764.6276245117188, Reconstruction Loss: 278847936.0\n",
      "590it [00:55, 10.63it/s]2023-07-19 14:32:17,285 - INFO - Epoch: [191/600], Step: [591/591], Loss: 206471728.0, KL Divergence: 778.4769287109375, Reconstruction Loss: 206470944.0\n",
      "591it [00:55, 10.59it/s]\n",
      "2023-07-19 14:32:17,287 - INFO - Epoch: [191/600], Total Loss: 17105447065600.0, Total KL Divergence: 58330758.75, Total Reconstruction Loss: 17105388693504.0\n",
      "2023-07-19 14:32:17,332 - INFO - Save model at epoch 191\n",
      "0it [00:00, ?it/s]2023-07-19 14:32:17,461 - INFO - Epoch: [192/600], Step: [1/591], Loss: 132694960.0, KL Divergence: 773.3094482421875, Reconstruction Loss: 132694184.0\n",
      "118it [00:11, 10.61it/s]2023-07-19 14:32:28,650 - INFO - Epoch: [192/600], Step: [119/591], Loss: 338326976.0, KL Divergence: 767.360595703125, Reconstruction Loss: 338326208.0\n",
      "236it [00:22, 10.78it/s]2023-07-19 14:32:39,777 - INFO - Epoch: [192/600], Step: [237/591], Loss: 245114224.0, KL Divergence: 768.0189819335938, Reconstruction Loss: 245113456.0\n",
      "354it [00:33, 10.21it/s]2023-07-19 14:32:51,011 - INFO - Epoch: [192/600], Step: [355/591], Loss: 284367616.0, KL Divergence: 760.2794799804688, Reconstruction Loss: 284366848.0\n",
      "471it [00:44, 10.55it/s]2023-07-19 14:33:02,159 - INFO - Epoch: [192/600], Step: [473/591], Loss: 283344768.0, KL Divergence: 758.3335571289062, Reconstruction Loss: 283344000.0\n",
      "589it [00:55, 10.08it/s]2023-07-19 14:33:13,299 - INFO - Epoch: [192/600], Step: [591/591], Loss: 199463744.0, KL Divergence: 780.530517578125, Reconstruction Loss: 199462960.0\n",
      "591it [00:55, 10.56it/s]\n",
      "2023-07-19 14:33:13,300 - INFO - Epoch: [192/600], Total Loss: 17119056596992.0, Total KL Divergence: 57819967.3984375, Total Reconstruction Loss: 17118998691840.0\n",
      "2023-07-19 14:33:13,345 - INFO - Save model at epoch 192\n",
      "0it [00:00, ?it/s]2023-07-19 14:33:13,472 - INFO - Epoch: [193/600], Step: [1/591], Loss: 125591304.0, KL Divergence: 774.550048828125, Reconstruction Loss: 125590528.0\n",
      "117it [00:11, 10.66it/s]2023-07-19 14:33:24,683 - INFO - Epoch: [193/600], Step: [119/591], Loss: 330383040.0, KL Divergence: 769.1611938476562, Reconstruction Loss: 330382272.0\n",
      "235it [00:22, 10.43it/s]2023-07-19 14:33:35,807 - INFO - Epoch: [193/600], Step: [237/591], Loss: 259868384.0, KL Divergence: 768.8375244140625, Reconstruction Loss: 259867616.0\n",
      "354it [00:33, 10.63it/s]2023-07-19 14:33:46,978 - INFO - Epoch: [193/600], Step: [355/591], Loss: 295712736.0, KL Divergence: 761.9705810546875, Reconstruction Loss: 295711968.0\n",
      "472it [00:44, 10.53it/s]2023-07-19 14:33:58,311 - INFO - Epoch: [193/600], Step: [473/591], Loss: 274813600.0, KL Divergence: 762.7537841796875, Reconstruction Loss: 274812832.0\n",
      "590it [00:55, 10.74it/s]2023-07-19 14:34:09,374 - INFO - Epoch: [193/600], Step: [591/591], Loss: 205803472.0, KL Divergence: 778.602294921875, Reconstruction Loss: 205802688.0\n",
      "591it [00:56, 10.55it/s]\n",
      "2023-07-19 14:34:09,376 - INFO - Epoch: [193/600], Total Loss: 17205645396992.0, Total KL Divergence: 57917822.921875, Total Reconstruction Loss: 17205587368960.0\n",
      "2023-07-19 14:34:09,416 - INFO - Save model at epoch 193\n",
      "0it [00:00, ?it/s]2023-07-19 14:34:09,534 - INFO - Epoch: [194/600], Step: [1/591], Loss: 123598616.0, KL Divergence: 772.6583251953125, Reconstruction Loss: 123597840.0\n",
      "117it [00:11, 10.76it/s]2023-07-19 14:34:20,717 - INFO - Epoch: [194/600], Step: [119/591], Loss: 323084576.0, KL Divergence: 770.2080078125, Reconstruction Loss: 323083808.0\n",
      "235it [00:22, 10.78it/s]2023-07-19 14:34:31,817 - INFO - Epoch: [194/600], Step: [237/591], Loss: 244123728.0, KL Divergence: 767.5490112304688, Reconstruction Loss: 244122960.0\n",
      "353it [00:33, 10.54it/s]2023-07-19 14:34:43,354 - INFO - Epoch: [194/600], Step: [355/591], Loss: 290599200.0, KL Divergence: 761.0910034179688, Reconstruction Loss: 290598432.0\n",
      "471it [00:45, 10.61it/s]2023-07-19 14:34:54,707 - INFO - Epoch: [194/600], Step: [473/591], Loss: 290592896.0, KL Divergence: 758.3543090820312, Reconstruction Loss: 290592128.0\n",
      "589it [00:56, 10.43it/s]2023-07-19 14:35:05,918 - INFO - Epoch: [194/600], Step: [591/591], Loss: 199301184.0, KL Divergence: 776.5494995117188, Reconstruction Loss: 199300400.0\n",
      "591it [00:56, 10.46it/s]\n",
      "2023-07-19 14:35:05,921 - INFO - Epoch: [194/600], Total Loss: 17027475813376.0, Total KL Divergence: 57780732.1328125, Total Reconstruction Loss: 17027417944064.0\n",
      "2023-07-19 14:35:05,970 - INFO - Save model at epoch 194\n",
      "0it [00:00, ?it/s]2023-07-19 14:35:06,098 - INFO - Epoch: [195/600], Step: [1/591], Loss: 128654896.0, KL Divergence: 770.365478515625, Reconstruction Loss: 128654128.0\n",
      "118it [00:11, 10.61it/s]2023-07-19 14:35:17,382 - INFO - Epoch: [195/600], Step: [119/591], Loss: 326327488.0, KL Divergence: 761.9326171875, Reconstruction Loss: 326326720.0\n",
      "236it [00:22, 10.43it/s]2023-07-19 14:35:28,452 - INFO - Epoch: [195/600], Step: [237/591], Loss: 238846592.0, KL Divergence: 761.8101196289062, Reconstruction Loss: 238845824.0\n",
      "354it [00:33, 10.57it/s]2023-07-19 14:35:39,522 - INFO - Epoch: [195/600], Step: [355/591], Loss: 290467072.0, KL Divergence: 755.0638427734375, Reconstruction Loss: 290466304.0\n",
      "472it [00:44, 10.67it/s]2023-07-19 14:35:50,709 - INFO - Epoch: [195/600], Step: [473/591], Loss: 274992896.0, KL Divergence: 754.745849609375, Reconstruction Loss: 274992128.0\n",
      "589it [00:56, 10.62it/s]2023-07-19 14:36:02,221 - INFO - Epoch: [195/600], Step: [591/591], Loss: 205853744.0, KL Divergence: 772.8399658203125, Reconstruction Loss: 205852976.0\n",
      "591it [00:56, 10.51it/s]\n",
      "2023-07-19 14:36:02,223 - INFO - Epoch: [195/600], Total Loss: 17056538645504.0, Total KL Divergence: 57376412.96875, Total Reconstruction Loss: 17056481210368.0\n",
      "2023-07-19 14:36:02,268 - INFO - Save model at epoch 195\n",
      "0it [00:00, ?it/s]2023-07-19 14:36:02,378 - INFO - Epoch: [196/600], Step: [1/591], Loss: 122801056.0, KL Divergence: 767.5946044921875, Reconstruction Loss: 122800288.0\n",
      "118it [00:11, 10.73it/s]2023-07-19 14:36:13,427 - INFO - Epoch: [196/600], Step: [119/591], Loss: 335187456.0, KL Divergence: 762.7611694335938, Reconstruction Loss: 335186688.0\n",
      "236it [00:22, 10.68it/s]2023-07-19 14:36:24,695 - INFO - Epoch: [196/600], Step: [237/591], Loss: 238531600.0, KL Divergence: 764.5760498046875, Reconstruction Loss: 238530832.0\n",
      "354it [00:33, 10.01it/s]2023-07-19 14:36:36,130 - INFO - Epoch: [196/600], Step: [355/591], Loss: 291732480.0, KL Divergence: 766.6043701171875, Reconstruction Loss: 291731712.0\n",
      "472it [00:44, 10.82it/s]2023-07-19 14:36:47,291 - INFO - Epoch: [196/600], Step: [473/591], Loss: 302182880.0, KL Divergence: 765.531494140625, Reconstruction Loss: 302182112.0\n",
      "590it [00:56, 10.54it/s]2023-07-19 14:36:58,437 - INFO - Epoch: [196/600], Step: [591/591], Loss: 207775168.0, KL Divergence: 781.86376953125, Reconstruction Loss: 207774384.0\n",
      "591it [00:56, 10.52it/s]\n",
      "2023-07-19 14:36:58,438 - INFO - Epoch: [196/600], Total Loss: 17219857096704.0, Total KL Divergence: 57839640.5390625, Total Reconstruction Loss: 17219799201792.0\n",
      "2023-07-19 14:36:58,480 - INFO - Save model at epoch 196\n",
      "0it [00:00, ?it/s]2023-07-19 14:36:58,597 - INFO - Epoch: [197/600], Step: [1/591], Loss: 129155048.0, KL Divergence: 774.80419921875, Reconstruction Loss: 129154272.0\n",
      "118it [00:11, 10.10it/s]2023-07-19 14:37:10,122 - INFO - Epoch: [197/600], Step: [119/591], Loss: 330384064.0, KL Divergence: 771.7281494140625, Reconstruction Loss: 330383296.0\n",
      "236it [00:22, 10.68it/s]2023-07-19 14:37:21,318 - INFO - Epoch: [197/600], Step: [237/591], Loss: 244746928.0, KL Divergence: 772.1395874023438, Reconstruction Loss: 244746160.0\n",
      "353it [00:33, 10.32it/s]2023-07-19 14:37:32,577 - INFO - Epoch: [197/600], Step: [355/591], Loss: 289442816.0, KL Divergence: 772.0589599609375, Reconstruction Loss: 289442048.0\n",
      "471it [00:44, 10.66it/s]2023-07-19 14:37:43,676 - INFO - Epoch: [197/600], Step: [473/591], Loss: 259814336.0, KL Divergence: 773.4837036132812, Reconstruction Loss: 259813568.0\n",
      "589it [00:56, 10.87it/s]2023-07-19 14:37:54,656 - INFO - Epoch: [197/600], Step: [591/591], Loss: 208613792.0, KL Divergence: 792.9323120117188, Reconstruction Loss: 208612992.0\n",
      "591it [00:56, 10.52it/s]\n",
      "2023-07-19 14:37:54,658 - INFO - Epoch: [197/600], Total Loss: 17210708718592.0, Total KL Divergence: 58421018.8515625, Total Reconstruction Loss: 17210650385408.0\n",
      "2023-07-19 14:37:54,699 - INFO - Save model at epoch 197\n",
      "0it [00:00, ?it/s]2023-07-19 14:37:54,818 - INFO - Epoch: [198/600], Step: [1/591], Loss: 127192880.0, KL Divergence: 785.5695190429688, Reconstruction Loss: 127192096.0\n",
      "117it [00:10, 10.85it/s]2023-07-19 14:38:05,826 - INFO - Epoch: [198/600], Step: [119/591], Loss: 338523840.0, KL Divergence: 776.7910766601562, Reconstruction Loss: 338523072.0\n",
      "235it [00:21, 10.44it/s]2023-07-19 14:38:16,864 - INFO - Epoch: [198/600], Step: [237/591], Loss: 251401008.0, KL Divergence: 777.9150390625, Reconstruction Loss: 251400224.0\n",
      "353it [00:32, 10.88it/s]2023-07-19 14:38:27,820 - INFO - Epoch: [198/600], Step: [355/591], Loss: 305715712.0, KL Divergence: 769.9119873046875, Reconstruction Loss: 305714944.0\n",
      "471it [00:43, 10.83it/s]2023-07-19 14:38:38,670 - INFO - Epoch: [198/600], Step: [473/591], Loss: 272087872.0, KL Divergence: 773.12646484375, Reconstruction Loss: 272087104.0\n",
      "589it [00:54, 10.80it/s]2023-07-19 14:38:49,549 - INFO - Epoch: [198/600], Step: [591/591], Loss: 208702624.0, KL Divergence: 792.59130859375, Reconstruction Loss: 208701824.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 14:38:49,551 - INFO - Epoch: [198/600], Total Loss: 17155010308096.0, Total KL Divergence: 58710220.1875, Total Reconstruction Loss: 17154951670784.0\n",
      "2023-07-19 14:38:49,594 - INFO - Save model at epoch 198\n",
      "0it [00:00, ?it/s]2023-07-19 14:38:49,714 - INFO - Epoch: [199/600], Step: [1/591], Loss: 125257520.0, KL Divergence: 787.20361328125, Reconstruction Loss: 125256736.0\n",
      "117it [00:10, 10.99it/s]2023-07-19 14:39:00,774 - INFO - Epoch: [199/600], Step: [119/591], Loss: 325845856.0, KL Divergence: 781.2537841796875, Reconstruction Loss: 325845088.0\n",
      "235it [00:21, 10.81it/s]2023-07-19 14:39:11,732 - INFO - Epoch: [199/600], Step: [237/591], Loss: 265941616.0, KL Divergence: 785.4322509765625, Reconstruction Loss: 265940832.0\n",
      "353it [00:32, 10.82it/s]2023-07-19 14:39:22,749 - INFO - Epoch: [199/600], Step: [355/591], Loss: 295944288.0, KL Divergence: 782.1459350585938, Reconstruction Loss: 295943520.0\n",
      "471it [00:43, 10.93it/s]2023-07-19 14:39:33,658 - INFO - Epoch: [199/600], Step: [473/591], Loss: 265383152.0, KL Divergence: 781.2479248046875, Reconstruction Loss: 265382368.0\n",
      "589it [00:54, 10.82it/s]2023-07-19 14:39:44,601 - INFO - Epoch: [199/600], Step: [591/591], Loss: 208155856.0, KL Divergence: 801.080078125, Reconstruction Loss: 208155056.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 14:39:44,603 - INFO - Epoch: [199/600], Total Loss: 17230256843776.0, Total KL Divergence: 59189252.3984375, Total Reconstruction Loss: 17230197672960.0\n",
      "2023-07-19 14:39:44,644 - INFO - Save model at epoch 199\n",
      "0it [00:00, ?it/s]2023-07-19 14:39:44,759 - INFO - Epoch: [200/600], Step: [1/591], Loss: 128617608.0, KL Divergence: 794.1787109375, Reconstruction Loss: 128616816.0\n",
      "117it [00:10, 10.82it/s]2023-07-19 14:39:55,735 - INFO - Epoch: [200/600], Step: [119/591], Loss: 330713184.0, KL Divergence: 787.6021728515625, Reconstruction Loss: 330712384.0\n",
      "235it [00:21, 11.02it/s]2023-07-19 14:40:06,642 - INFO - Epoch: [200/600], Step: [237/591], Loss: 250299984.0, KL Divergence: 782.3424072265625, Reconstruction Loss: 250299200.0\n",
      "353it [00:32, 10.54it/s]2023-07-19 14:40:17,621 - INFO - Epoch: [200/600], Step: [355/591], Loss: 292335104.0, KL Divergence: 778.1451416015625, Reconstruction Loss: 292334336.0\n",
      "471it [00:43, 10.56it/s]2023-07-19 14:40:28,571 - INFO - Epoch: [200/600], Step: [473/591], Loss: 269796224.0, KL Divergence: 780.0719604492188, Reconstruction Loss: 269795456.0\n",
      "589it [00:54, 10.79it/s]2023-07-19 14:40:39,398 - INFO - Epoch: [200/600], Step: [591/591], Loss: 200999248.0, KL Divergence: 797.1580810546875, Reconstruction Loss: 200998448.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 14:40:39,400 - INFO - Epoch: [200/600], Total Loss: 17273032694784.0, Total KL Divergence: 59190305.5390625, Total Reconstruction Loss: 17272973542400.0\n",
      "2023-07-19 14:40:39,440 - INFO - Save model at epoch 200\n",
      "0it [00:00, ?it/s]2023-07-19 14:40:39,569 - INFO - Epoch: [201/600], Step: [1/591], Loss: 131298152.0, KL Divergence: 791.421875, Reconstruction Loss: 131297360.0\n",
      "117it [00:10, 10.89it/s]2023-07-19 14:40:50,525 - INFO - Epoch: [201/600], Step: [119/591], Loss: 345773824.0, KL Divergence: 784.3590087890625, Reconstruction Loss: 345773024.0\n",
      "235it [00:21, 10.75it/s]2023-07-19 14:41:01,472 - INFO - Epoch: [201/600], Step: [237/591], Loss: 254932784.0, KL Divergence: 782.1364135742188, Reconstruction Loss: 254932000.0\n",
      "353it [00:32, 10.17it/s]2023-07-19 14:41:12,569 - INFO - Epoch: [201/600], Step: [355/591], Loss: 286597504.0, KL Divergence: 772.3389892578125, Reconstruction Loss: 286596736.0\n",
      "471it [00:43, 10.85it/s]2023-07-19 14:41:23,494 - INFO - Epoch: [201/600], Step: [473/591], Loss: 258059072.0, KL Divergence: 764.603271484375, Reconstruction Loss: 258058304.0\n",
      "589it [00:54, 10.90it/s]2023-07-19 14:41:34,359 - INFO - Epoch: [201/600], Step: [591/591], Loss: 201788784.0, KL Divergence: 785.5953979492188, Reconstruction Loss: 201788000.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 14:41:34,361 - INFO - Epoch: [201/600], Total Loss: 17215104327680.0, Total KL Divergence: 58722641.1640625, Total Reconstruction Loss: 17215045652480.0\n",
      "2023-07-19 14:41:34,404 - INFO - Save model at epoch 201\n",
      "0it [00:00, ?it/s]2023-07-19 14:41:34,511 - INFO - Epoch: [202/600], Step: [1/591], Loss: 126667480.0, KL Divergence: 779.9529418945312, Reconstruction Loss: 126666704.0\n",
      "117it [00:10, 10.82it/s]2023-07-19 14:41:45,441 - INFO - Epoch: [202/600], Step: [119/591], Loss: 320643232.0, KL Divergence: 778.8750610351562, Reconstruction Loss: 320642464.0\n",
      "235it [00:21, 10.94it/s]2023-07-19 14:41:56,351 - INFO - Epoch: [202/600], Step: [237/591], Loss: 241436320.0, KL Divergence: 778.862548828125, Reconstruction Loss: 241435536.0\n",
      "353it [00:32, 10.02it/s]2023-07-19 14:42:07,434 - INFO - Epoch: [202/600], Step: [355/591], Loss: 285380224.0, KL Divergence: 778.6957397460938, Reconstruction Loss: 285379456.0\n",
      "471it [00:43, 10.80it/s]2023-07-19 14:42:18,314 - INFO - Epoch: [202/600], Step: [473/591], Loss: 257987792.0, KL Divergence: 779.5839233398438, Reconstruction Loss: 257987008.0\n",
      "589it [00:54, 10.65it/s]2023-07-19 14:42:29,164 - INFO - Epoch: [202/600], Step: [591/591], Loss: 206222928.0, KL Divergence: 799.97509765625, Reconstruction Loss: 206222128.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 14:42:29,166 - INFO - Epoch: [202/600], Total Loss: 17087250172928.0, Total KL Divergence: 58893676.1796875, Total Reconstruction Loss: 17087191356416.0\n",
      "2023-07-19 14:42:29,229 - INFO - Save model at epoch 202\n",
      "0it [00:00, ?it/s]2023-07-19 14:42:29,346 - INFO - Epoch: [203/600], Step: [1/591], Loss: 137964256.0, KL Divergence: 793.1648559570312, Reconstruction Loss: 137963456.0\n",
      "117it [00:10, 10.82it/s]2023-07-19 14:42:40,312 - INFO - Epoch: [203/600], Step: [119/591], Loss: 329706080.0, KL Divergence: 784.092041015625, Reconstruction Loss: 329705280.0\n",
      "235it [00:21, 10.84it/s]2023-07-19 14:42:51,291 - INFO - Epoch: [203/600], Step: [237/591], Loss: 241409360.0, KL Divergence: 787.0173950195312, Reconstruction Loss: 241408576.0\n",
      "353it [00:32, 10.84it/s]2023-07-19 14:43:02,171 - INFO - Epoch: [203/600], Step: [355/591], Loss: 288505728.0, KL Divergence: 780.114990234375, Reconstruction Loss: 288504960.0\n",
      "471it [00:43, 10.97it/s]2023-07-19 14:43:13,123 - INFO - Epoch: [203/600], Step: [473/591], Loss: 262091120.0, KL Divergence: 777.4376831054688, Reconstruction Loss: 262090336.0\n",
      "589it [00:54, 10.87it/s]2023-07-19 14:43:23,994 - INFO - Epoch: [203/600], Step: [591/591], Loss: 206276400.0, KL Divergence: 790.8363037109375, Reconstruction Loss: 206275616.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 14:43:23,996 - INFO - Epoch: [203/600], Total Loss: 17092179469312.0, Total KL Divergence: 59149768.375, Total Reconstruction Loss: 17092120334336.0\n",
      "2023-07-19 14:43:24,042 - INFO - Save model at epoch 203\n",
      "0it [00:00, ?it/s]2023-07-19 14:43:24,164 - INFO - Epoch: [204/600], Step: [1/591], Loss: 124309536.0, KL Divergence: 785.6008911132812, Reconstruction Loss: 124308752.0\n",
      "117it [00:10, 11.01it/s]2023-07-19 14:43:35,036 - INFO - Epoch: [204/600], Step: [119/591], Loss: 332072448.0, KL Divergence: 775.9239501953125, Reconstruction Loss: 332071680.0\n",
      "235it [00:21, 10.88it/s]2023-07-19 14:43:45,998 - INFO - Epoch: [204/600], Step: [237/591], Loss: 236822880.0, KL Divergence: 775.332275390625, Reconstruction Loss: 236822112.0\n",
      "353it [00:32,  9.88it/s]2023-07-19 14:43:56,984 - INFO - Epoch: [204/600], Step: [355/591], Loss: 288500896.0, KL Divergence: 771.6722412109375, Reconstruction Loss: 288500128.0\n",
      "471it [00:43, 10.64it/s]2023-07-19 14:44:08,118 - INFO - Epoch: [204/600], Step: [473/591], Loss: 255306240.0, KL Divergence: 773.9324340820312, Reconstruction Loss: 255305472.0\n",
      "589it [00:54, 10.75it/s]2023-07-19 14:44:18,978 - INFO - Epoch: [204/600], Step: [591/591], Loss: 214751168.0, KL Divergence: 785.6093139648438, Reconstruction Loss: 214750384.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 14:44:18,980 - INFO - Epoch: [204/600], Total Loss: 17106234425344.0, Total KL Divergence: 58611217.015625, Total Reconstruction Loss: 17106175935488.0\n",
      "2023-07-19 14:44:19,020 - INFO - Save model at epoch 204\n",
      "0it [00:00, ?it/s]2023-07-19 14:44:19,150 - INFO - Epoch: [205/600], Step: [1/591], Loss: 127698560.0, KL Divergence: 780.4603271484375, Reconstruction Loss: 127697776.0\n",
      "117it [00:10, 10.70it/s]2023-07-19 14:44:30,133 - INFO - Epoch: [205/600], Step: [119/591], Loss: 330778304.0, KL Divergence: 778.5219116210938, Reconstruction Loss: 330777536.0\n",
      "235it [00:21, 10.88it/s]2023-07-19 14:44:41,016 - INFO - Epoch: [205/600], Step: [237/591], Loss: 232958544.0, KL Divergence: 783.8212890625, Reconstruction Loss: 232957760.0\n",
      "353it [00:32, 10.02it/s]2023-07-19 14:44:51,997 - INFO - Epoch: [205/600], Step: [355/591], Loss: 299770336.0, KL Divergence: 777.6500244140625, Reconstruction Loss: 299769568.0\n",
      "471it [00:43, 10.95it/s]2023-07-19 14:45:02,828 - INFO - Epoch: [205/600], Step: [473/591], Loss: 260603248.0, KL Divergence: 783.2288818359375, Reconstruction Loss: 260602464.0\n",
      "589it [00:54, 10.96it/s]2023-07-19 14:45:13,629 - INFO - Epoch: [205/600], Step: [591/591], Loss: 202396544.0, KL Divergence: 800.347412109375, Reconstruction Loss: 202395744.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 14:45:13,631 - INFO - Epoch: [205/600], Total Loss: 17103861988352.0, Total KL Divergence: 58961303.578125, Total Reconstruction Loss: 17103803096064.0\n",
      "2023-07-19 14:45:13,672 - INFO - Save model at epoch 205\n",
      "0it [00:00, ?it/s]2023-07-19 14:45:13,785 - INFO - Epoch: [206/600], Step: [1/591], Loss: 132825368.0, KL Divergence: 795.8577270507812, Reconstruction Loss: 132824576.0\n",
      "117it [00:10, 10.89it/s]2023-07-19 14:45:24,864 - INFO - Epoch: [206/600], Step: [119/591], Loss: 331735072.0, KL Divergence: 785.4230346679688, Reconstruction Loss: 331734272.0\n",
      "235it [00:21, 10.81it/s]2023-07-19 14:45:35,780 - INFO - Epoch: [206/600], Step: [237/591], Loss: 239117120.0, KL Divergence: 786.4713134765625, Reconstruction Loss: 239116336.0\n",
      "353it [00:32, 10.86it/s]2023-07-19 14:45:46,661 - INFO - Epoch: [206/600], Step: [355/591], Loss: 306949728.0, KL Divergence: 780.3999633789062, Reconstruction Loss: 306948960.0\n",
      "471it [00:43, 10.84it/s]2023-07-19 14:45:57,666 - INFO - Epoch: [206/600], Step: [473/591], Loss: 256190160.0, KL Divergence: 785.917724609375, Reconstruction Loss: 256189376.0\n",
      "589it [00:54, 10.96it/s]2023-07-19 14:46:08,490 - INFO - Epoch: [206/600], Step: [591/591], Loss: 203526016.0, KL Divergence: 798.3742065429688, Reconstruction Loss: 203525216.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 14:46:08,492 - INFO - Epoch: [206/600], Total Loss: 17189815570432.0, Total KL Divergence: 59335536.265625, Total Reconstruction Loss: 17189756256256.0\n",
      "2023-07-19 14:46:08,540 - INFO - Save model at epoch 206\n",
      "0it [00:00, ?it/s]2023-07-19 14:46:08,664 - INFO - Epoch: [207/600], Step: [1/591], Loss: 128677208.0, KL Divergence: 793.0533447265625, Reconstruction Loss: 128676416.0\n",
      "117it [00:10, 10.77it/s]2023-07-19 14:46:19,581 - INFO - Epoch: [207/600], Step: [119/591], Loss: 339636928.0, KL Divergence: 782.3314208984375, Reconstruction Loss: 339636160.0\n",
      "235it [00:21, 10.70it/s]2023-07-19 14:46:30,622 - INFO - Epoch: [207/600], Step: [237/591], Loss: 234308656.0, KL Divergence: 787.284912109375, Reconstruction Loss: 234307872.0\n",
      "353it [00:32, 10.93it/s]2023-07-19 14:46:41,388 - INFO - Epoch: [207/600], Step: [355/591], Loss: 304082176.0, KL Divergence: 775.647705078125, Reconstruction Loss: 304081408.0\n",
      "471it [00:43, 10.71it/s]2023-07-19 14:46:52,257 - INFO - Epoch: [207/600], Step: [473/591], Loss: 273347360.0, KL Divergence: 779.5298461914062, Reconstruction Loss: 273346592.0\n",
      "589it [00:54, 10.95it/s]2023-07-19 14:47:03,022 - INFO - Epoch: [207/600], Step: [591/591], Loss: 195405008.0, KL Divergence: 794.7437744140625, Reconstruction Loss: 195404208.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 14:47:03,024 - INFO - Epoch: [207/600], Total Loss: 17022875288576.0, Total KL Divergence: 59136542.484375, Total Reconstruction Loss: 17022816209920.0\n",
      "2023-07-19 14:47:03,064 - INFO - Save model at epoch 207\n",
      "0it [00:00, ?it/s]2023-07-19 14:47:03,185 - INFO - Epoch: [208/600], Step: [1/591], Loss: 129675176.0, KL Divergence: 789.3640747070312, Reconstruction Loss: 129674384.0\n",
      "117it [00:10, 11.03it/s]2023-07-19 14:47:13,994 - INFO - Epoch: [208/600], Step: [119/591], Loss: 344248352.0, KL Divergence: 780.086669921875, Reconstruction Loss: 344247584.0\n",
      "235it [00:21, 11.04it/s]2023-07-19 14:47:24,827 - INFO - Epoch: [208/600], Step: [237/591], Loss: 238561712.0, KL Divergence: 777.6392211914062, Reconstruction Loss: 238560928.0\n",
      "353it [00:32, 11.01it/s]2023-07-19 14:47:35,628 - INFO - Epoch: [208/600], Step: [355/591], Loss: 306464832.0, KL Divergence: 773.8234252929688, Reconstruction Loss: 306464064.0\n",
      "471it [00:43, 10.98it/s]2023-07-19 14:47:46,451 - INFO - Epoch: [208/600], Step: [473/591], Loss: 264469472.0, KL Divergence: 775.4942626953125, Reconstruction Loss: 264468704.0\n",
      "589it [00:54, 10.88it/s]2023-07-19 14:47:57,294 - INFO - Epoch: [208/600], Step: [591/591], Loss: 189849152.0, KL Divergence: 797.29833984375, Reconstruction Loss: 189848352.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 14:47:57,296 - INFO - Epoch: [208/600], Total Loss: 17024475728896.0, Total KL Divergence: 58824187.734375, Total Reconstruction Loss: 17024416992256.0\n",
      "2023-07-19 14:47:57,337 - INFO - Save model at epoch 208\n",
      "0it [00:00, ?it/s]2023-07-19 14:47:57,444 - INFO - Epoch: [209/600], Step: [1/591], Loss: 138577328.0, KL Divergence: 791.712890625, Reconstruction Loss: 138576544.0\n",
      "117it [00:10, 10.94it/s]2023-07-19 14:48:08,397 - INFO - Epoch: [209/600], Step: [119/591], Loss: 328121472.0, KL Divergence: 778.1002197265625, Reconstruction Loss: 328120704.0\n",
      "235it [00:21, 10.94it/s]2023-07-19 14:48:19,196 - INFO - Epoch: [209/600], Step: [237/591], Loss: 231985168.0, KL Divergence: 777.2738037109375, Reconstruction Loss: 231984384.0\n",
      "353it [00:32, 11.02it/s]2023-07-19 14:48:30,016 - INFO - Epoch: [209/600], Step: [355/591], Loss: 289032896.0, KL Divergence: 773.7841186523438, Reconstruction Loss: 289032128.0\n",
      "471it [00:43, 11.06it/s]2023-07-19 14:48:40,832 - INFO - Epoch: [209/600], Step: [473/591], Loss: 273073152.0, KL Divergence: 773.030517578125, Reconstruction Loss: 273072384.0\n",
      "589it [00:54, 11.01it/s]2023-07-19 14:48:51,607 - INFO - Epoch: [209/600], Step: [591/591], Loss: 194996768.0, KL Divergence: 793.58642578125, Reconstruction Loss: 194995968.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 14:48:51,609 - INFO - Epoch: [209/600], Total Loss: 16927121634304.0, Total KL Divergence: 58706325.640625, Total Reconstruction Loss: 16927063045120.0\n",
      "2023-07-19 14:48:51,650 - INFO - Save model at epoch 209\n",
      "0it [00:00, ?it/s]2023-07-19 14:48:51,768 - INFO - Epoch: [210/600], Step: [1/591], Loss: 123405048.0, KL Divergence: 789.677490234375, Reconstruction Loss: 123404256.0\n",
      "117it [00:10, 10.97it/s]2023-07-19 14:49:02,648 - INFO - Epoch: [210/600], Step: [119/591], Loss: 354072800.0, KL Divergence: 784.357666015625, Reconstruction Loss: 354072000.0\n",
      "235it [00:21, 10.89it/s]2023-07-19 14:49:13,492 - INFO - Epoch: [210/600], Step: [237/591], Loss: 240311728.0, KL Divergence: 788.4190673828125, Reconstruction Loss: 240310944.0\n",
      "353it [00:32, 10.99it/s]2023-07-19 14:49:24,338 - INFO - Epoch: [210/600], Step: [355/591], Loss: 282512192.0, KL Divergence: 781.8609008789062, Reconstruction Loss: 282511424.0\n",
      "471it [00:43, 10.90it/s]2023-07-19 14:49:35,404 - INFO - Epoch: [210/600], Step: [473/591], Loss: 260854192.0, KL Divergence: 782.6939086914062, Reconstruction Loss: 260853408.0\n",
      "589it [00:54, 10.96it/s]2023-07-19 14:49:46,202 - INFO - Epoch: [210/600], Step: [591/591], Loss: 198779472.0, KL Divergence: 801.577392578125, Reconstruction Loss: 198778672.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 14:49:46,204 - INFO - Epoch: [210/600], Total Loss: 16807260232704.0, Total KL Divergence: 59272596.96875, Total Reconstruction Loss: 16807200957440.0\n",
      "2023-07-19 14:49:46,252 - INFO - Save model at epoch 210\n",
      "0it [00:00, ?it/s]2023-07-19 14:49:46,363 - INFO - Epoch: [211/600], Step: [1/591], Loss: 134857472.0, KL Divergence: 796.7301635742188, Reconstruction Loss: 134856672.0\n",
      "118it [00:10, 11.00it/s]2023-07-19 14:49:57,269 - INFO - Epoch: [211/600], Step: [119/591], Loss: 326744864.0, KL Divergence: 787.0350341796875, Reconstruction Loss: 326744064.0\n",
      "236it [00:21, 11.14it/s]2023-07-19 14:50:08,112 - INFO - Epoch: [211/600], Step: [237/591], Loss: 259328448.0, KL Divergence: 787.7689208984375, Reconstruction Loss: 259327664.0\n",
      "354it [00:32, 10.97it/s]2023-07-19 14:50:18,935 - INFO - Epoch: [211/600], Step: [355/591], Loss: 282910016.0, KL Divergence: 788.8221435546875, Reconstruction Loss: 282909216.0\n",
      "472it [00:43, 11.04it/s]2023-07-19 14:50:29,853 - INFO - Epoch: [211/600], Step: [473/591], Loss: 258988800.0, KL Divergence: 792.6001586914062, Reconstruction Loss: 258988000.0\n",
      "590it [00:54, 11.01it/s]2023-07-19 14:50:40,635 - INFO - Epoch: [211/600], Step: [591/591], Loss: 201328992.0, KL Divergence: 804.2943115234375, Reconstruction Loss: 201328192.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 14:50:40,637 - INFO - Epoch: [211/600], Total Loss: 16856957704192.0, Total KL Divergence: 59676938.8515625, Total Reconstruction Loss: 16856897981440.0\n",
      "2023-07-19 14:50:40,677 - INFO - Save model at epoch 211\n",
      "0it [00:00, ?it/s]2023-07-19 14:50:40,800 - INFO - Epoch: [212/600], Step: [1/591], Loss: 127569696.0, KL Divergence: 799.8269653320312, Reconstruction Loss: 127568896.0\n",
      "117it [00:10, 11.08it/s]2023-07-19 14:50:51,655 - INFO - Epoch: [212/600], Step: [119/591], Loss: 323129664.0, KL Divergence: 791.0682373046875, Reconstruction Loss: 323128864.0\n",
      "235it [00:21, 10.62it/s]2023-07-19 14:51:02,491 - INFO - Epoch: [212/600], Step: [237/591], Loss: 228921248.0, KL Divergence: 795.8526611328125, Reconstruction Loss: 228920448.0\n",
      "353it [00:32, 10.70it/s]2023-07-19 14:51:13,298 - INFO - Epoch: [212/600], Step: [355/591], Loss: 282159808.0, KL Divergence: 789.990234375, Reconstruction Loss: 282159008.0\n",
      "471it [00:43, 10.68it/s]2023-07-19 14:51:24,142 - INFO - Epoch: [212/600], Step: [473/591], Loss: 263498912.0, KL Divergence: 794.30224609375, Reconstruction Loss: 263498112.0\n",
      "589it [00:54, 10.61it/s]2023-07-19 14:51:34,967 - INFO - Epoch: [212/600], Step: [591/591], Loss: 215810272.0, KL Divergence: 813.5526123046875, Reconstruction Loss: 215809456.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 14:51:34,969 - INFO - Epoch: [212/600], Total Loss: 16910293109760.0, Total KL Divergence: 59998109.1171875, Total Reconstruction Loss: 16910233061376.0\n",
      "2023-07-19 14:51:35,010 - INFO - Save model at epoch 212\n",
      "0it [00:00, ?it/s]2023-07-19 14:51:35,133 - INFO - Epoch: [213/600], Step: [1/591], Loss: 129308960.0, KL Divergence: 809.7610473632812, Reconstruction Loss: 129308152.0\n",
      "117it [00:10, 10.89it/s]2023-07-19 14:51:46,005 - INFO - Epoch: [213/600], Step: [119/591], Loss: 320431392.0, KL Divergence: 801.9935302734375, Reconstruction Loss: 320430592.0\n",
      "235it [00:21, 10.95it/s]2023-07-19 14:51:56,851 - INFO - Epoch: [213/600], Step: [237/591], Loss: 230372768.0, KL Divergence: 799.5657958984375, Reconstruction Loss: 230371968.0\n",
      "353it [00:32, 10.88it/s]2023-07-19 14:52:07,680 - INFO - Epoch: [213/600], Step: [355/591], Loss: 285479232.0, KL Divergence: 788.42431640625, Reconstruction Loss: 285478432.0\n",
      "471it [00:43, 10.76it/s]2023-07-19 14:52:18,544 - INFO - Epoch: [213/600], Step: [473/591], Loss: 295908704.0, KL Divergence: 793.46923828125, Reconstruction Loss: 295907904.0\n",
      "589it [00:54, 10.77it/s]2023-07-19 14:52:29,336 - INFO - Epoch: [213/600], Step: [591/591], Loss: 194679776.0, KL Divergence: 813.691650390625, Reconstruction Loss: 194678960.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 14:52:29,338 - INFO - Epoch: [213/600], Total Loss: 16823116673024.0, Total KL Divergence: 60235497.09375, Total Reconstruction Loss: 16823056375808.0\n",
      "2023-07-19 14:52:29,380 - INFO - Save model at epoch 213\n",
      "0it [00:00, ?it/s]2023-07-19 14:52:29,501 - INFO - Epoch: [214/600], Step: [1/591], Loss: 124716712.0, KL Divergence: 807.7140502929688, Reconstruction Loss: 124715904.0\n",
      "118it [00:11, 10.60it/s]2023-07-19 14:52:40,880 - INFO - Epoch: [214/600], Step: [119/591], Loss: 325825696.0, KL Divergence: 800.6552124023438, Reconstruction Loss: 325824896.0\n",
      "236it [00:22, 11.00it/s]2023-07-19 14:52:51,757 - INFO - Epoch: [214/600], Step: [237/591], Loss: 235910848.0, KL Divergence: 799.738525390625, Reconstruction Loss: 235910048.0\n",
      "354it [00:33, 10.98it/s]2023-07-19 14:53:02,594 - INFO - Epoch: [214/600], Step: [355/591], Loss: 296157760.0, KL Divergence: 793.65283203125, Reconstruction Loss: 296156960.0\n",
      "472it [00:43, 11.00it/s]2023-07-19 14:53:13,439 - INFO - Epoch: [214/600], Step: [473/591], Loss: 261127584.0, KL Divergence: 797.2965087890625, Reconstruction Loss: 261126784.0\n",
      "589it [00:54, 10.13it/s]2023-07-19 14:53:24,438 - INFO - Epoch: [214/600], Step: [591/591], Loss: 208305120.0, KL Divergence: 815.8703002929688, Reconstruction Loss: 208304304.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 14:53:24,440 - INFO - Epoch: [214/600], Total Loss: 16855069607936.0, Total KL Divergence: 60297621.234375, Total Reconstruction Loss: 16855009231872.0\n",
      "2023-07-19 14:53:24,480 - INFO - Save model at epoch 214\n",
      "0it [00:00, ?it/s]2023-07-19 14:53:24,595 - INFO - Epoch: [215/600], Step: [1/591], Loss: 126505840.0, KL Divergence: 808.335205078125, Reconstruction Loss: 126505032.0\n",
      "117it [00:10, 10.93it/s]2023-07-19 14:53:35,609 - INFO - Epoch: [215/600], Step: [119/591], Loss: 317278752.0, KL Divergence: 798.5867919921875, Reconstruction Loss: 317277952.0\n",
      "235it [00:21, 10.80it/s]2023-07-19 14:53:46,437 - INFO - Epoch: [215/600], Step: [237/591], Loss: 251364256.0, KL Divergence: 804.537841796875, Reconstruction Loss: 251363456.0\n",
      "353it [00:32, 10.82it/s]2023-07-19 14:53:57,258 - INFO - Epoch: [215/600], Step: [355/591], Loss: 282906144.0, KL Divergence: 804.6995849609375, Reconstruction Loss: 282905344.0\n",
      "471it [00:43, 11.01it/s]2023-07-19 14:54:08,112 - INFO - Epoch: [215/600], Step: [473/591], Loss: 268062880.0, KL Divergence: 800.3299560546875, Reconstruction Loss: 268062080.0\n",
      "589it [00:54, 11.13it/s]2023-07-19 14:54:18,816 - INFO - Epoch: [215/600], Step: [591/591], Loss: 201184496.0, KL Divergence: 819.217041015625, Reconstruction Loss: 201183680.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 14:54:18,818 - INFO - Epoch: [215/600], Total Loss: 16778803503104.0, Total KL Divergence: 60658671.6171875, Total Reconstruction Loss: 16778742885376.0\n",
      "2023-07-19 14:54:18,875 - INFO - Save model at epoch 215\n",
      "0it [00:00, ?it/s]2023-07-19 14:54:18,994 - INFO - Epoch: [216/600], Step: [1/591], Loss: 125606672.0, KL Divergence: 813.2491455078125, Reconstruction Loss: 125605856.0\n",
      "117it [00:10, 10.90it/s]2023-07-19 14:54:29,884 - INFO - Epoch: [216/600], Step: [119/591], Loss: 311927840.0, KL Divergence: 804.7618408203125, Reconstruction Loss: 311927040.0\n",
      "235it [00:21, 10.71it/s]2023-07-19 14:54:40,804 - INFO - Epoch: [216/600], Step: [237/591], Loss: 236464576.0, KL Divergence: 805.1937255859375, Reconstruction Loss: 236463776.0\n",
      "353it [00:32, 10.96it/s]2023-07-19 14:54:51,717 - INFO - Epoch: [216/600], Step: [355/591], Loss: 285306624.0, KL Divergence: 803.1412353515625, Reconstruction Loss: 285305824.0\n",
      "471it [00:43, 10.65it/s]2023-07-19 14:55:02,663 - INFO - Epoch: [216/600], Step: [473/591], Loss: 267041840.0, KL Divergence: 804.6917724609375, Reconstruction Loss: 267041040.0\n",
      "589it [00:54, 10.78it/s]2023-07-19 14:55:13,473 - INFO - Epoch: [216/600], Step: [591/591], Loss: 211478304.0, KL Divergence: 828.3414916992188, Reconstruction Loss: 211477472.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 14:55:13,475 - INFO - Epoch: [216/600], Total Loss: 16704745445376.0, Total KL Divergence: 60881673.625, Total Reconstruction Loss: 16704684637184.0\n",
      "2023-07-19 14:55:13,520 - INFO - Save model at epoch 216\n",
      "0it [00:00, ?it/s]2023-07-19 14:55:13,627 - INFO - Epoch: [217/600], Step: [1/591], Loss: 126618128.0, KL Divergence: 821.5712890625, Reconstruction Loss: 126617304.0\n",
      "118it [00:11, 10.77it/s]2023-07-19 14:55:24,730 - INFO - Epoch: [217/600], Step: [119/591], Loss: 320202912.0, KL Divergence: 807.4640502929688, Reconstruction Loss: 320202112.0\n",
      "236it [00:22, 10.96it/s]2023-07-19 14:55:35,666 - INFO - Epoch: [217/600], Step: [237/591], Loss: 256125376.0, KL Divergence: 810.419677734375, Reconstruction Loss: 256124560.0\n",
      "354it [00:32, 10.66it/s]2023-07-19 14:55:46,608 - INFO - Epoch: [217/600], Step: [355/591], Loss: 306484128.0, KL Divergence: 806.5216674804688, Reconstruction Loss: 306483328.0\n",
      "472it [00:44, 11.03it/s]2023-07-19 14:55:57,630 - INFO - Epoch: [217/600], Step: [473/591], Loss: 260705984.0, KL Divergence: 801.2991333007812, Reconstruction Loss: 260705184.0\n",
      "590it [00:54, 10.78it/s]2023-07-19 14:56:08,419 - INFO - Epoch: [217/600], Step: [591/591], Loss: 202359760.0, KL Divergence: 813.32373046875, Reconstruction Loss: 202358944.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 14:56:08,421 - INFO - Epoch: [217/600], Total Loss: 16759577706496.0, Total KL Divergence: 61057435.96875, Total Reconstruction Loss: 16759516748800.0\n",
      "2023-07-19 14:56:08,459 - INFO - Save model at epoch 217\n",
      "0it [00:00, ?it/s]2023-07-19 14:56:08,575 - INFO - Epoch: [218/600], Step: [1/591], Loss: 125125640.0, KL Divergence: 807.9885864257812, Reconstruction Loss: 125124832.0\n",
      "117it [00:10, 10.88it/s]2023-07-19 14:56:19,478 - INFO - Epoch: [218/600], Step: [119/591], Loss: 320060896.0, KL Divergence: 802.930419921875, Reconstruction Loss: 320060096.0\n",
      "235it [00:21, 10.84it/s]2023-07-19 14:56:30,324 - INFO - Epoch: [218/600], Step: [237/591], Loss: 241131072.0, KL Divergence: 803.2344970703125, Reconstruction Loss: 241130272.0\n",
      "353it [00:32, 11.10it/s]2023-07-19 14:56:41,085 - INFO - Epoch: [218/600], Step: [355/591], Loss: 296715872.0, KL Divergence: 804.3162841796875, Reconstruction Loss: 296715072.0\n",
      "471it [00:43, 10.62it/s]2023-07-19 14:56:52,222 - INFO - Epoch: [218/600], Step: [473/591], Loss: 258624256.0, KL Divergence: 806.7718505859375, Reconstruction Loss: 258623456.0\n",
      "589it [00:54, 10.60it/s]2023-07-19 14:57:03,240 - INFO - Epoch: [218/600], Step: [591/591], Loss: 203175856.0, KL Divergence: 825.4371948242188, Reconstruction Loss: 203175024.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 14:57:03,242 - INFO - Epoch: [218/600], Total Loss: 16765658090496.0, Total KL Divergence: 60770647.796875, Total Reconstruction Loss: 16765597360128.0\n",
      "2023-07-19 14:57:03,290 - INFO - Save model at epoch 218\n",
      "0it [00:00, ?it/s]2023-07-19 14:57:03,412 - INFO - Epoch: [219/600], Step: [1/591], Loss: 124815256.0, KL Divergence: 818.1017456054688, Reconstruction Loss: 124814440.0\n",
      "117it [00:11, 10.91it/s]2023-07-19 14:57:14,538 - INFO - Epoch: [219/600], Step: [119/591], Loss: 323355104.0, KL Divergence: 806.9822387695312, Reconstruction Loss: 323354304.0\n",
      "235it [00:22, 10.61it/s]2023-07-19 14:57:25,623 - INFO - Epoch: [219/600], Step: [237/591], Loss: 235508144.0, KL Divergence: 808.59619140625, Reconstruction Loss: 235507328.0\n",
      "353it [00:33, 10.47it/s]2023-07-19 14:57:36,753 - INFO - Epoch: [219/600], Step: [355/591], Loss: 287958176.0, KL Divergence: 806.574462890625, Reconstruction Loss: 287957376.0\n",
      "471it [00:44, 11.14it/s]2023-07-19 14:57:47,642 - INFO - Epoch: [219/600], Step: [473/591], Loss: 249975056.0, KL Divergence: 812.52490234375, Reconstruction Loss: 249974240.0\n",
      "589it [00:55, 10.83it/s]2023-07-19 14:57:58,475 - INFO - Epoch: [219/600], Step: [591/591], Loss: 214405104.0, KL Divergence: 831.0563354492188, Reconstruction Loss: 214404272.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 14:57:58,477 - INFO - Epoch: [219/600], Total Loss: 16559783424000.0, Total KL Divergence: 61269058.375, Total Reconstruction Loss: 16559722235904.0\n",
      "2023-07-19 14:57:58,519 - INFO - Save model at epoch 219\n",
      "0it [00:00, ?it/s]2023-07-19 14:57:58,633 - INFO - Epoch: [220/600], Step: [1/591], Loss: 137388832.0, KL Divergence: 825.99560546875, Reconstruction Loss: 137388000.0\n",
      "117it [00:10, 11.27it/s]2023-07-19 14:58:09,481 - INFO - Epoch: [220/600], Step: [119/591], Loss: 326699296.0, KL Divergence: 810.7385864257812, Reconstruction Loss: 326698496.0\n",
      "235it [00:21, 10.91it/s]2023-07-19 14:58:20,286 - INFO - Epoch: [220/600], Step: [237/591], Loss: 230853216.0, KL Divergence: 806.0279541015625, Reconstruction Loss: 230852416.0\n",
      "353it [00:32, 10.93it/s]2023-07-19 14:58:31,127 - INFO - Epoch: [220/600], Step: [355/591], Loss: 283379904.0, KL Divergence: 808.6024780273438, Reconstruction Loss: 283379104.0\n",
      "471it [00:43, 10.79it/s]2023-07-19 14:58:42,124 - INFO - Epoch: [220/600], Step: [473/591], Loss: 263561504.0, KL Divergence: 806.9891357421875, Reconstruction Loss: 263560704.0\n",
      "589it [00:54, 11.01it/s]2023-07-19 14:58:52,946 - INFO - Epoch: [220/600], Step: [591/591], Loss: 204301616.0, KL Divergence: 818.7198486328125, Reconstruction Loss: 204300800.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 14:58:52,948 - INFO - Epoch: [220/600], Total Loss: 16670665324544.0, Total KL Divergence: 61078827.390625, Total Reconstruction Loss: 16670604311552.0\n",
      "2023-07-19 14:58:52,992 - INFO - Save model at epoch 220\n",
      "0it [00:00, ?it/s]2023-07-19 14:58:53,105 - INFO - Epoch: [221/600], Step: [1/591], Loss: 127729456.0, KL Divergence: 813.68359375, Reconstruction Loss: 127728640.0\n",
      "118it [00:10, 10.80it/s]2023-07-19 14:59:04,085 - INFO - Epoch: [221/600], Step: [119/591], Loss: 333290336.0, KL Divergence: 809.8786010742188, Reconstruction Loss: 333289536.0\n",
      "236it [00:21, 10.94it/s]2023-07-19 14:59:14,868 - INFO - Epoch: [221/600], Step: [237/591], Loss: 246067856.0, KL Divergence: 808.1425170898438, Reconstruction Loss: 246067040.0\n",
      "354it [00:32, 10.81it/s]2023-07-19 14:59:25,768 - INFO - Epoch: [221/600], Step: [355/591], Loss: 277065952.0, KL Divergence: 797.9843139648438, Reconstruction Loss: 277065152.0\n",
      "472it [00:43, 10.92it/s]2023-07-19 14:59:36,710 - INFO - Epoch: [221/600], Step: [473/591], Loss: 255717920.0, KL Divergence: 801.5006713867188, Reconstruction Loss: 255717120.0\n",
      "590it [00:54, 10.85it/s]2023-07-19 14:59:47,529 - INFO - Epoch: [221/600], Step: [591/591], Loss: 199626768.0, KL Divergence: 822.0567626953125, Reconstruction Loss: 199625952.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 14:59:47,531 - INFO - Epoch: [221/600], Total Loss: 16388745780224.0, Total KL Divergence: 60891221.9609375, Total Reconstruction Loss: 16388684939264.0\n",
      "2023-07-19 14:59:47,571 - INFO - Save model at epoch 221\n",
      "0it [00:00, ?it/s]2023-07-19 14:59:47,677 - INFO - Epoch: [222/600], Step: [1/591], Loss: 122992176.0, KL Divergence: 817.5154418945312, Reconstruction Loss: 122991360.0\n",
      "117it [00:10, 11.03it/s]2023-07-19 14:59:58,588 - INFO - Epoch: [222/600], Step: [119/591], Loss: 324973184.0, KL Divergence: 807.6709594726562, Reconstruction Loss: 324972384.0\n",
      "235it [00:21, 10.92it/s]2023-07-19 15:00:09,458 - INFO - Epoch: [222/600], Step: [237/591], Loss: 233357600.0, KL Divergence: 810.5703735351562, Reconstruction Loss: 233356784.0\n",
      "353it [00:32, 10.68it/s]2023-07-19 15:00:20,281 - INFO - Epoch: [222/600], Step: [355/591], Loss: 289951648.0, KL Divergence: 802.7470092773438, Reconstruction Loss: 289950848.0\n",
      "471it [00:43, 10.63it/s]2023-07-19 15:00:31,283 - INFO - Epoch: [222/600], Step: [473/591], Loss: 267304208.0, KL Divergence: 806.6309814453125, Reconstruction Loss: 267303408.0\n",
      "589it [00:54, 10.84it/s]2023-07-19 15:00:42,343 - INFO - Epoch: [222/600], Step: [591/591], Loss: 205834560.0, KL Divergence: 824.3214111328125, Reconstruction Loss: 205833728.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 15:00:42,344 - INFO - Epoch: [222/600], Total Loss: 16394108429312.0, Total KL Divergence: 61007027.5, Total Reconstruction Loss: 16394047498240.0\n",
      "2023-07-19 15:00:42,394 - INFO - Save model at epoch 222\n",
      "0it [00:00, ?it/s]2023-07-19 15:00:42,510 - INFO - Epoch: [223/600], Step: [1/591], Loss: 121236048.0, KL Divergence: 818.1007080078125, Reconstruction Loss: 121235232.0\n",
      "117it [00:10, 10.62it/s]2023-07-19 15:00:53,580 - INFO - Epoch: [223/600], Step: [119/591], Loss: 311091232.0, KL Divergence: 810.6546630859375, Reconstruction Loss: 311090432.0\n",
      "235it [00:21, 10.80it/s]2023-07-19 15:01:04,527 - INFO - Epoch: [223/600], Step: [237/591], Loss: 231605440.0, KL Divergence: 804.6019287109375, Reconstruction Loss: 231604640.0\n",
      "353it [00:32, 10.55it/s]2023-07-19 15:01:15,550 - INFO - Epoch: [223/600], Step: [355/591], Loss: 289467168.0, KL Divergence: 807.2189331054688, Reconstruction Loss: 289466368.0\n",
      "471it [00:43, 10.54it/s]2023-07-19 15:01:26,593 - INFO - Epoch: [223/600], Step: [473/591], Loss: 252529344.0, KL Divergence: 806.2100830078125, Reconstruction Loss: 252528544.0\n",
      "589it [00:54, 10.76it/s]2023-07-19 15:01:37,446 - INFO - Epoch: [223/600], Step: [591/591], Loss: 218701200.0, KL Divergence: 819.84716796875, Reconstruction Loss: 218700384.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 15:01:37,448 - INFO - Epoch: [223/600], Total Loss: 16383223267328.0, Total KL Divergence: 61025543.5703125, Total Reconstruction Loss: 16383162319872.0\n",
      "2023-07-19 15:01:37,488 - INFO - Save model at epoch 223\n",
      "0it [00:00, ?it/s]2023-07-19 15:01:37,609 - INFO - Epoch: [224/600], Step: [1/591], Loss: 137822608.0, KL Divergence: 814.7039794921875, Reconstruction Loss: 137821792.0\n",
      "117it [00:10, 10.95it/s]2023-07-19 15:01:48,569 - INFO - Epoch: [224/600], Step: [119/591], Loss: 311471424.0, KL Divergence: 808.7276000976562, Reconstruction Loss: 311470624.0\n",
      "235it [00:21, 10.89it/s]2023-07-19 15:01:59,654 - INFO - Epoch: [224/600], Step: [237/591], Loss: 233839840.0, KL Divergence: 805.4474487304688, Reconstruction Loss: 233839040.0\n",
      "353it [00:32, 10.92it/s]2023-07-19 15:02:10,570 - INFO - Epoch: [224/600], Step: [355/591], Loss: 279303904.0, KL Divergence: 797.7232055664062, Reconstruction Loss: 279303104.0\n",
      "471it [00:43, 10.77it/s]2023-07-19 15:02:21,565 - INFO - Epoch: [224/600], Step: [473/591], Loss: 253826048.0, KL Divergence: 806.7449951171875, Reconstruction Loss: 253825248.0\n",
      "589it [00:54, 10.80it/s]2023-07-19 15:02:32,344 - INFO - Epoch: [224/600], Step: [591/591], Loss: 223733520.0, KL Divergence: 823.5135498046875, Reconstruction Loss: 223732704.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 15:02:32,346 - INFO - Epoch: [224/600], Total Loss: 16465737755648.0, Total KL Divergence: 60850344.5390625, Total Reconstruction Loss: 16465676951552.0\n",
      "2023-07-19 15:02:32,386 - INFO - Save model at epoch 224\n",
      "0it [00:00, ?it/s]2023-07-19 15:02:32,529 - INFO - Epoch: [225/600], Step: [1/591], Loss: 134804304.0, KL Divergence: 817.0216064453125, Reconstruction Loss: 134803488.0\n",
      "118it [00:11, 11.00it/s]2023-07-19 15:02:43,551 - INFO - Epoch: [225/600], Step: [119/591], Loss: 311155520.0, KL Divergence: 810.5472412109375, Reconstruction Loss: 311154720.0\n",
      "236it [00:21, 10.49it/s]2023-07-19 15:02:54,448 - INFO - Epoch: [225/600], Step: [237/591], Loss: 235419664.0, KL Divergence: 811.0771484375, Reconstruction Loss: 235418848.0\n",
      "354it [00:32, 10.76it/s]2023-07-19 15:03:05,303 - INFO - Epoch: [225/600], Step: [355/591], Loss: 284830752.0, KL Divergence: 804.9381713867188, Reconstruction Loss: 284829952.0\n",
      "472it [00:43, 11.14it/s]2023-07-19 15:03:16,143 - INFO - Epoch: [225/600], Step: [473/591], Loss: 261245120.0, KL Divergence: 809.234375, Reconstruction Loss: 261244304.0\n",
      "590it [00:54, 11.06it/s]2023-07-19 15:03:26,901 - INFO - Epoch: [225/600], Step: [591/591], Loss: 203144032.0, KL Divergence: 822.9376831054688, Reconstruction Loss: 203143216.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 15:03:26,902 - INFO - Epoch: [225/600], Total Loss: 16247495258112.0, Total KL Divergence: 61138908.6015625, Total Reconstruction Loss: 16247434188800.0\n",
      "2023-07-19 15:03:26,961 - INFO - Save model at epoch 225\n",
      "0it [00:00, ?it/s]2023-07-19 15:03:27,069 - INFO - Epoch: [226/600], Step: [1/591], Loss: 125183080.0, KL Divergence: 817.6865234375, Reconstruction Loss: 125182264.0\n",
      "118it [00:10, 10.94it/s]2023-07-19 15:03:37,973 - INFO - Epoch: [226/600], Step: [119/591], Loss: 308093344.0, KL Divergence: 804.1937255859375, Reconstruction Loss: 308092544.0\n",
      "236it [00:21, 10.82it/s]2023-07-19 15:03:48,819 - INFO - Epoch: [226/600], Step: [237/591], Loss: 247047872.0, KL Divergence: 800.3251342773438, Reconstruction Loss: 247047072.0\n",
      "354it [00:32, 10.96it/s]2023-07-19 15:03:59,733 - INFO - Epoch: [226/600], Step: [355/591], Loss: 296415776.0, KL Divergence: 803.36865234375, Reconstruction Loss: 296414976.0\n",
      "472it [00:43, 10.93it/s]2023-07-19 15:04:10,598 - INFO - Epoch: [226/600], Step: [473/591], Loss: 255223856.0, KL Divergence: 806.3261108398438, Reconstruction Loss: 255223056.0\n",
      "590it [00:54, 11.04it/s]2023-07-19 15:04:21,272 - INFO - Epoch: [226/600], Step: [591/591], Loss: 208165488.0, KL Divergence: 816.9969482421875, Reconstruction Loss: 208164672.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 15:04:21,274 - INFO - Epoch: [226/600], Total Loss: 16406137019392.0, Total KL Divergence: 60819603.640625, Total Reconstruction Loss: 16406076230656.0\n",
      "2023-07-19 15:04:21,319 - INFO - Save model at epoch 226\n",
      "0it [00:00, ?it/s]2023-07-19 15:04:21,437 - INFO - Epoch: [227/600], Step: [1/591], Loss: 124866184.0, KL Divergence: 814.5238647460938, Reconstruction Loss: 124865368.0\n",
      "118it [00:10, 10.74it/s]2023-07-19 15:04:32,359 - INFO - Epoch: [227/600], Step: [119/591], Loss: 306610528.0, KL Divergence: 801.66259765625, Reconstruction Loss: 306609728.0\n",
      "236it [00:21, 11.08it/s]2023-07-19 15:04:43,215 - INFO - Epoch: [227/600], Step: [237/591], Loss: 231450112.0, KL Divergence: 804.9345703125, Reconstruction Loss: 231449312.0\n",
      "354it [00:32, 10.92it/s]2023-07-19 15:04:54,095 - INFO - Epoch: [227/600], Step: [355/591], Loss: 309127392.0, KL Divergence: 797.57275390625, Reconstruction Loss: 309126592.0\n",
      "472it [00:43, 10.95it/s]2023-07-19 15:05:05,036 - INFO - Epoch: [227/600], Step: [473/591], Loss: 252501216.0, KL Divergence: 806.8704833984375, Reconstruction Loss: 252500416.0\n",
      "590it [00:54, 10.84it/s]2023-07-19 15:05:15,938 - INFO - Epoch: [227/600], Step: [591/591], Loss: 196453136.0, KL Divergence: 822.4970092773438, Reconstruction Loss: 196452320.0\n",
      "591it [00:54, 10.82it/s]\n",
      "2023-07-19 15:05:15,940 - INFO - Epoch: [227/600], Total Loss: 16519659526144.0, Total KL Divergence: 60770421.796875, Total Reconstruction Loss: 16519598807040.0\n",
      "2023-07-19 15:05:15,990 - INFO - Save model at epoch 227\n",
      "0it [00:00, ?it/s]2023-07-19 15:05:16,096 - INFO - Epoch: [228/600], Step: [1/591], Loss: 129019864.0, KL Divergence: 820.5165405273438, Reconstruction Loss: 129019040.0\n",
      "117it [00:11, 10.74it/s]2023-07-19 15:05:27,191 - INFO - Epoch: [228/600], Step: [119/591], Loss: 316913792.0, KL Divergence: 807.1246337890625, Reconstruction Loss: 316912992.0\n",
      "235it [00:21, 10.76it/s]2023-07-19 15:05:38,055 - INFO - Epoch: [228/600], Step: [237/591], Loss: 226268448.0, KL Divergence: 808.6934204101562, Reconstruction Loss: 226267632.0\n",
      "353it [00:32, 10.65it/s]2023-07-19 15:05:48,963 - INFO - Epoch: [228/600], Step: [355/591], Loss: 299916704.0, KL Divergence: 807.6060791015625, Reconstruction Loss: 299915904.0\n",
      "471it [00:43, 11.04it/s]2023-07-19 15:06:00,015 - INFO - Epoch: [228/600], Step: [473/591], Loss: 247686736.0, KL Divergence: 807.16943359375, Reconstruction Loss: 247685936.0\n",
      "589it [00:54, 10.80it/s]2023-07-19 15:06:10,860 - INFO - Epoch: [228/600], Step: [591/591], Loss: 194717040.0, KL Divergence: 826.6874389648438, Reconstruction Loss: 194716208.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 15:06:10,862 - INFO - Epoch: [228/600], Total Loss: 16376705031168.0, Total KL Divergence: 61090378.484375, Total Reconstruction Loss: 16376644023296.0\n",
      "2023-07-19 15:06:10,901 - INFO - Save model at epoch 228\n",
      "0it [00:00, ?it/s]2023-07-19 15:06:11,019 - INFO - Epoch: [229/600], Step: [1/591], Loss: 123302616.0, KL Divergence: 822.3067626953125, Reconstruction Loss: 123301792.0\n",
      "117it [00:10, 10.72it/s]2023-07-19 15:06:21,946 - INFO - Epoch: [229/600], Step: [119/591], Loss: 312457056.0, KL Divergence: 812.2529296875, Reconstruction Loss: 312456256.0\n",
      "235it [00:21, 10.78it/s]2023-07-19 15:06:32,789 - INFO - Epoch: [229/600], Step: [237/591], Loss: 234759088.0, KL Divergence: 808.419189453125, Reconstruction Loss: 234758272.0\n",
      "353it [00:32, 10.93it/s]2023-07-19 15:06:43,653 - INFO - Epoch: [229/600], Step: [355/591], Loss: 278822336.0, KL Divergence: 803.279296875, Reconstruction Loss: 278821536.0\n",
      "471it [00:43, 10.94it/s]2023-07-19 15:06:54,509 - INFO - Epoch: [229/600], Step: [473/591], Loss: 246978960.0, KL Divergence: 806.8388671875, Reconstruction Loss: 246978160.0\n",
      "589it [00:54, 11.09it/s]2023-07-19 15:07:05,236 - INFO - Epoch: [229/600], Step: [591/591], Loss: 199577184.0, KL Divergence: 822.8831787109375, Reconstruction Loss: 199576368.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 15:07:05,238 - INFO - Epoch: [229/600], Total Loss: 16163439780864.0, Total KL Divergence: 61024266.140625, Total Reconstruction Loss: 16163378801664.0\n",
      "2023-07-19 15:07:05,279 - INFO - Save model at epoch 229\n",
      "0it [00:00, ?it/s]2023-07-19 15:07:05,414 - INFO - Epoch: [230/600], Step: [1/591], Loss: 119155456.0, KL Divergence: 818.8104248046875, Reconstruction Loss: 119154640.0\n",
      "117it [00:10, 11.01it/s]2023-07-19 15:07:16,236 - INFO - Epoch: [230/600], Step: [119/591], Loss: 326642016.0, KL Divergence: 808.3699951171875, Reconstruction Loss: 326641216.0\n",
      "235it [00:21, 10.68it/s]2023-07-19 15:07:27,076 - INFO - Epoch: [230/600], Step: [237/591], Loss: 243359456.0, KL Divergence: 812.0174560546875, Reconstruction Loss: 243358640.0\n",
      "353it [00:32, 10.97it/s]2023-07-19 15:07:37,912 - INFO - Epoch: [230/600], Step: [355/591], Loss: 280575680.0, KL Divergence: 813.581787109375, Reconstruction Loss: 280574880.0\n",
      "471it [00:43, 10.81it/s]2023-07-19 15:07:48,893 - INFO - Epoch: [230/600], Step: [473/591], Loss: 269060640.0, KL Divergence: 816.588134765625, Reconstruction Loss: 269059808.0\n",
      "589it [00:54, 10.81it/s]2023-07-19 15:07:59,860 - INFO - Epoch: [230/600], Step: [591/591], Loss: 200653984.0, KL Divergence: 836.9921875, Reconstruction Loss: 200653152.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 15:07:59,862 - INFO - Epoch: [230/600], Total Loss: 16311965879296.0, Total KL Divergence: 61464209.0859375, Total Reconstruction Loss: 16311904454656.0\n",
      "2023-07-19 15:07:59,905 - INFO - Save model at epoch 230\n",
      "0it [00:00, ?it/s]2023-07-19 15:08:00,024 - INFO - Epoch: [231/600], Step: [1/591], Loss: 120886096.0, KL Divergence: 830.2994995117188, Reconstruction Loss: 120885264.0\n",
      "117it [00:10, 10.88it/s]2023-07-19 15:08:10,939 - INFO - Epoch: [231/600], Step: [119/591], Loss: 329621568.0, KL Divergence: 818.593505859375, Reconstruction Loss: 329620736.0\n",
      "235it [00:21, 10.93it/s]2023-07-19 15:08:21,801 - INFO - Epoch: [231/600], Step: [237/591], Loss: 231179056.0, KL Divergence: 817.8218383789062, Reconstruction Loss: 231178240.0\n",
      "353it [00:32, 10.99it/s]2023-07-19 15:08:32,722 - INFO - Epoch: [231/600], Step: [355/591], Loss: 278997792.0, KL Divergence: 814.509033203125, Reconstruction Loss: 278996992.0\n",
      "471it [00:43, 10.66it/s]2023-07-19 15:08:43,694 - INFO - Epoch: [231/600], Step: [473/591], Loss: 261949632.0, KL Divergence: 813.1593627929688, Reconstruction Loss: 261948816.0\n",
      "589it [00:54, 10.77it/s]2023-07-19 15:08:54,630 - INFO - Epoch: [231/600], Step: [591/591], Loss: 201883040.0, KL Divergence: 832.732666015625, Reconstruction Loss: 201882208.0\n",
      "591it [00:54, 10.80it/s]\n",
      "2023-07-19 15:08:54,632 - INFO - Epoch: [231/600], Total Loss: 16452607234048.0, Total KL Divergence: 61778866.40625, Total Reconstruction Loss: 16452545418240.0\n",
      "2023-07-19 15:08:54,671 - INFO - Save model at epoch 231\n",
      "0it [00:00, ?it/s]2023-07-19 15:08:54,777 - INFO - Epoch: [232/600], Step: [1/591], Loss: 130501824.0, KL Divergence: 825.1100463867188, Reconstruction Loss: 130501000.0\n",
      "118it [00:11, 10.46it/s]2023-07-19 15:09:05,802 - INFO - Epoch: [232/600], Step: [119/591], Loss: 319063872.0, KL Divergence: 813.9300537109375, Reconstruction Loss: 319063072.0\n",
      "236it [00:21, 10.98it/s]2023-07-19 15:09:16,678 - INFO - Epoch: [232/600], Step: [237/591], Loss: 228699760.0, KL Divergence: 813.3165283203125, Reconstruction Loss: 228698944.0\n",
      "354it [00:32, 10.92it/s]2023-07-19 15:09:27,634 - INFO - Epoch: [232/600], Step: [355/591], Loss: 276946720.0, KL Divergence: 807.6133422851562, Reconstruction Loss: 276945920.0\n",
      "472it [00:43, 10.66it/s]2023-07-19 15:09:38,609 - INFO - Epoch: [232/600], Step: [473/591], Loss: 266220128.0, KL Divergence: 803.6676635742188, Reconstruction Loss: 266219328.0\n",
      "590it [00:54, 10.86it/s]2023-07-19 15:09:49,478 - INFO - Epoch: [232/600], Step: [591/591], Loss: 220522992.0, KL Divergence: 817.429931640625, Reconstruction Loss: 220522176.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 15:09:49,480 - INFO - Epoch: [232/600], Total Loss: 16266623258624.0, Total KL Divergence: 61272135.96875, Total Reconstruction Loss: 16266562065408.0\n",
      "2023-07-19 15:09:49,524 - INFO - Save model at epoch 232\n",
      "0it [00:00, ?it/s]2023-07-19 15:09:49,633 - INFO - Epoch: [233/600], Step: [1/591], Loss: 121299896.0, KL Divergence: 812.027587890625, Reconstruction Loss: 121299080.0\n",
      "118it [00:10, 10.15it/s]2023-07-19 15:10:00,593 - INFO - Epoch: [233/600], Step: [119/591], Loss: 314804352.0, KL Divergence: 804.6549072265625, Reconstruction Loss: 314803552.0\n",
      "236it [00:21, 10.52it/s]2023-07-19 15:10:11,599 - INFO - Epoch: [233/600], Step: [237/591], Loss: 228175872.0, KL Divergence: 803.4523315429688, Reconstruction Loss: 228175072.0\n",
      "353it [00:33, 10.89it/s]2023-07-19 15:10:22,877 - INFO - Epoch: [233/600], Step: [355/591], Loss: 278797216.0, KL Divergence: 804.619140625, Reconstruction Loss: 278796416.0\n",
      "471it [00:44, 10.85it/s]2023-07-19 15:10:33,862 - INFO - Epoch: [233/600], Step: [473/591], Loss: 307492448.0, KL Divergence: 803.4196166992188, Reconstruction Loss: 307491648.0\n",
      "589it [00:55, 10.86it/s]2023-07-19 15:10:44,807 - INFO - Epoch: [233/600], Step: [591/591], Loss: 210043360.0, KL Divergence: 819.5955810546875, Reconstruction Loss: 210042544.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 15:10:44,809 - INFO - Epoch: [233/600], Total Loss: 16330312500224.0, Total KL Divergence: 60829650.4921875, Total Reconstruction Loss: 16330251697152.0\n",
      "2023-07-19 15:10:44,850 - INFO - Save model at epoch 233\n",
      "0it [00:00, ?it/s]2023-07-19 15:10:44,972 - INFO - Epoch: [234/600], Step: [1/591], Loss: 125293216.0, KL Divergence: 813.8818359375, Reconstruction Loss: 125292400.0\n",
      "118it [00:11, 10.82it/s]2023-07-19 15:10:56,074 - INFO - Epoch: [234/600], Step: [119/591], Loss: 314637120.0, KL Divergence: 810.0458984375, Reconstruction Loss: 314636320.0\n",
      "236it [00:22, 10.90it/s]2023-07-19 15:11:07,030 - INFO - Epoch: [234/600], Step: [237/591], Loss: 229687888.0, KL Divergence: 807.716796875, Reconstruction Loss: 229687088.0\n",
      "354it [00:33, 10.72it/s]2023-07-19 15:11:18,018 - INFO - Epoch: [234/600], Step: [355/591], Loss: 280309088.0, KL Divergence: 805.0631103515625, Reconstruction Loss: 280308288.0\n",
      "472it [00:44, 10.77it/s]2023-07-19 15:11:29,121 - INFO - Epoch: [234/600], Step: [473/591], Loss: 259706128.0, KL Divergence: 802.8267211914062, Reconstruction Loss: 259705328.0\n",
      "590it [00:55, 10.93it/s]2023-07-19 15:11:40,045 - INFO - Epoch: [234/600], Step: [591/591], Loss: 200489120.0, KL Divergence: 817.7050170898438, Reconstruction Loss: 200488304.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 15:11:40,047 - INFO - Epoch: [234/600], Total Loss: 16235621819392.0, Total KL Divergence: 60962681.0390625, Total Reconstruction Loss: 16235560925184.0\n",
      "2023-07-19 15:11:40,088 - INFO - Save model at epoch 234\n",
      "0it [00:00, ?it/s]2023-07-19 15:11:40,207 - INFO - Epoch: [235/600], Step: [1/591], Loss: 120918368.0, KL Divergence: 812.31298828125, Reconstruction Loss: 120917552.0\n",
      "117it [00:11, 10.38it/s]2023-07-19 15:11:51,372 - INFO - Epoch: [235/600], Step: [119/591], Loss: 308653184.0, KL Divergence: 802.564208984375, Reconstruction Loss: 308652384.0\n",
      "235it [00:22, 10.72it/s]2023-07-19 15:12:02,422 - INFO - Epoch: [235/600], Step: [237/591], Loss: 224256864.0, KL Divergence: 802.7625122070312, Reconstruction Loss: 224256064.0\n",
      "353it [00:33, 10.91it/s]2023-07-19 15:12:13,335 - INFO - Epoch: [235/600], Step: [355/591], Loss: 287093728.0, KL Divergence: 800.1239013671875, Reconstruction Loss: 287092928.0\n",
      "471it [00:44, 10.64it/s]2023-07-19 15:12:24,469 - INFO - Epoch: [235/600], Step: [473/591], Loss: 263988032.0, KL Divergence: 803.7511596679688, Reconstruction Loss: 263987232.0\n",
      "589it [00:55, 10.43it/s]2023-07-19 15:12:35,447 - INFO - Epoch: [235/600], Step: [591/591], Loss: 209369968.0, KL Divergence: 818.6795654296875, Reconstruction Loss: 209369152.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 15:12:35,448 - INFO - Epoch: [235/600], Total Loss: 16182654845952.0, Total KL Divergence: 60722998.6328125, Total Reconstruction Loss: 16182594140160.0\n",
      "2023-07-19 15:12:35,491 - INFO - Save model at epoch 235\n",
      "0it [00:00, ?it/s]2023-07-19 15:12:35,596 - INFO - Epoch: [236/600], Step: [1/591], Loss: 121963888.0, KL Divergence: 814.070556640625, Reconstruction Loss: 121963072.0\n",
      "117it [00:10, 10.40it/s]2023-07-19 15:12:46,668 - INFO - Epoch: [236/600], Step: [119/591], Loss: 316263168.0, KL Divergence: 807.8150634765625, Reconstruction Loss: 316262368.0\n",
      "235it [00:22, 10.80it/s]2023-07-19 15:12:57,731 - INFO - Epoch: [236/600], Step: [237/591], Loss: 228642096.0, KL Divergence: 811.446044921875, Reconstruction Loss: 228641280.0\n",
      "353it [00:33, 10.87it/s]2023-07-19 15:13:08,726 - INFO - Epoch: [236/600], Step: [355/591], Loss: 286986016.0, KL Divergence: 808.8819580078125, Reconstruction Loss: 286985216.0\n",
      "471it [00:44, 10.94it/s]2023-07-19 15:13:19,728 - INFO - Epoch: [236/600], Step: [473/591], Loss: 250050672.0, KL Divergence: 806.7759399414062, Reconstruction Loss: 250049872.0\n",
      "589it [00:55, 10.57it/s]2023-07-19 15:13:30,649 - INFO - Epoch: [236/600], Step: [591/591], Loss: 206795936.0, KL Divergence: 826.3013916015625, Reconstruction Loss: 206795104.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 15:13:30,652 - INFO - Epoch: [236/600], Total Loss: 16288255930368.0, Total KL Divergence: 61197350.4921875, Total Reconstruction Loss: 16288194813952.0\n",
      "2023-07-19 15:13:30,699 - INFO - Save model at epoch 236\n",
      "0it [00:00, ?it/s]2023-07-19 15:13:30,820 - INFO - Epoch: [237/600], Step: [1/591], Loss: 121240312.0, KL Divergence: 820.4903564453125, Reconstruction Loss: 121239488.0\n",
      "117it [00:10, 10.07it/s]2023-07-19 15:13:41,880 - INFO - Epoch: [237/600], Step: [119/591], Loss: 305148448.0, KL Divergence: 810.6842651367188, Reconstruction Loss: 305147648.0\n",
      "235it [00:21, 10.95it/s]2023-07-19 15:13:52,904 - INFO - Epoch: [237/600], Step: [237/591], Loss: 220457200.0, KL Divergence: 813.49658203125, Reconstruction Loss: 220456384.0\n",
      "353it [00:33, 10.78it/s]2023-07-19 15:14:04,069 - INFO - Epoch: [237/600], Step: [355/591], Loss: 320117888.0, KL Divergence: 811.520263671875, Reconstruction Loss: 320117088.0\n",
      "471it [00:43, 10.61it/s]2023-07-19 15:14:14,795 - INFO - Epoch: [237/600], Step: [473/591], Loss: 251354192.0, KL Divergence: 809.3572387695312, Reconstruction Loss: 251353376.0\n",
      "589it [00:54, 11.45it/s]2023-07-19 15:14:25,382 - INFO - Epoch: [237/600], Step: [591/591], Loss: 196134912.0, KL Divergence: 827.4931640625, Reconstruction Loss: 196134080.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 15:14:25,384 - INFO - Epoch: [237/600], Total Loss: 16280181095424.0, Total KL Divergence: 61394098.6015625, Total Reconstruction Loss: 16280119755776.0\n",
      "2023-07-19 15:14:25,429 - INFO - Save model at epoch 237\n",
      "0it [00:00, ?it/s]2023-07-19 15:14:25,529 - INFO - Epoch: [238/600], Step: [1/591], Loss: 118157976.0, KL Divergence: 822.4434814453125, Reconstruction Loss: 118157152.0\n",
      "118it [00:11, 10.47it/s]2023-07-19 15:14:36,541 - INFO - Epoch: [238/600], Step: [119/591], Loss: 307854112.0, KL Divergence: 809.59033203125, Reconstruction Loss: 307853312.0\n",
      "236it [00:22, 10.44it/s]2023-07-19 15:14:47,583 - INFO - Epoch: [238/600], Step: [237/591], Loss: 224914720.0, KL Divergence: 807.7506103515625, Reconstruction Loss: 224913920.0\n",
      "354it [00:33, 10.24it/s]2023-07-19 15:14:58,607 - INFO - Epoch: [238/600], Step: [355/591], Loss: 296672704.0, KL Divergence: 806.799072265625, Reconstruction Loss: 296671904.0\n",
      "471it [00:44, 10.76it/s]2023-07-19 15:15:09,707 - INFO - Epoch: [238/600], Step: [473/591], Loss: 254001520.0, KL Divergence: 808.079833984375, Reconstruction Loss: 254000704.0\n",
      "589it [00:55, 10.52it/s]2023-07-19 15:15:20,582 - INFO - Epoch: [238/600], Step: [591/591], Loss: 195829632.0, KL Divergence: 828.642333984375, Reconstruction Loss: 195828800.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 15:15:20,584 - INFO - Epoch: [238/600], Total Loss: 16127717235712.0, Total KL Divergence: 61255503.5546875, Total Reconstruction Loss: 16127656042496.0\n",
      "2023-07-19 15:15:20,624 - INFO - Save model at epoch 238\n",
      "0it [00:00, ?it/s]2023-07-19 15:15:20,738 - INFO - Epoch: [239/600], Step: [1/591], Loss: 121927816.0, KL Divergence: 822.9151611328125, Reconstruction Loss: 121926992.0\n",
      "117it [00:10, 10.88it/s]2023-07-19 15:15:31,664 - INFO - Epoch: [239/600], Step: [119/591], Loss: 298597344.0, KL Divergence: 810.3630981445312, Reconstruction Loss: 298596544.0\n",
      "235it [00:21, 10.97it/s]2023-07-19 15:15:42,668 - INFO - Epoch: [239/600], Step: [237/591], Loss: 227622512.0, KL Divergence: 812.5567016601562, Reconstruction Loss: 227621696.0\n",
      "353it [00:32, 10.52it/s]2023-07-19 15:15:53,671 - INFO - Epoch: [239/600], Step: [355/591], Loss: 286778336.0, KL Divergence: 806.4190673828125, Reconstruction Loss: 286777536.0\n",
      "471it [00:44, 10.36it/s]2023-07-19 15:16:04,911 - INFO - Epoch: [239/600], Step: [473/591], Loss: 257715616.0, KL Divergence: 808.2344970703125, Reconstruction Loss: 257714800.0\n",
      "589it [00:55, 10.84it/s]2023-07-19 15:16:15,816 - INFO - Epoch: [239/600], Step: [591/591], Loss: 197511600.0, KL Divergence: 820.3658447265625, Reconstruction Loss: 197510784.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 15:16:15,818 - INFO - Epoch: [239/600], Total Loss: 16129188878336.0, Total KL Divergence: 61138429.0390625, Total Reconstruction Loss: 16129127795712.0\n",
      "2023-07-19 15:16:15,864 - INFO - Save model at epoch 239\n",
      "0it [00:00, ?it/s]2023-07-19 15:16:15,981 - INFO - Epoch: [240/600], Step: [1/591], Loss: 122222240.0, KL Divergence: 814.7210083007812, Reconstruction Loss: 122221424.0\n",
      "117it [00:10, 10.69it/s]2023-07-19 15:16:26,965 - INFO - Epoch: [240/600], Step: [119/591], Loss: 316191456.0, KL Divergence: 806.8064575195312, Reconstruction Loss: 316190656.0\n",
      "235it [00:21, 10.74it/s]2023-07-19 15:16:37,907 - INFO - Epoch: [240/600], Step: [237/591], Loss: 232051504.0, KL Divergence: 803.6234741210938, Reconstruction Loss: 232050704.0\n",
      "353it [00:32, 10.84it/s]2023-07-19 15:16:48,960 - INFO - Epoch: [240/600], Step: [355/591], Loss: 293258336.0, KL Divergence: 811.73388671875, Reconstruction Loss: 293257536.0\n",
      "471it [00:43, 10.56it/s]2023-07-19 15:17:00,039 - INFO - Epoch: [240/600], Step: [473/591], Loss: 248356096.0, KL Divergence: 803.98583984375, Reconstruction Loss: 248355296.0\n",
      "589it [00:54, 11.07it/s]2023-07-19 15:17:10,728 - INFO - Epoch: [240/600], Step: [591/591], Loss: 208193840.0, KL Divergence: 815.4163818359375, Reconstruction Loss: 208193024.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 15:17:10,730 - INFO - Epoch: [240/600], Total Loss: 16128023615488.0, Total KL Divergence: 60995627.7734375, Total Reconstruction Loss: 16127962686464.0\n",
      "2023-07-19 15:17:10,773 - INFO - Save model at epoch 240\n",
      "0it [00:00, ?it/s]2023-07-19 15:17:10,896 - INFO - Epoch: [241/600], Step: [1/591], Loss: 121800472.0, KL Divergence: 811.3399658203125, Reconstruction Loss: 121799664.0\n",
      "118it [00:10, 10.85it/s]2023-07-19 15:17:21,918 - INFO - Epoch: [241/600], Step: [119/591], Loss: 315870976.0, KL Divergence: 804.0516967773438, Reconstruction Loss: 315870176.0\n",
      "236it [00:22, 10.72it/s]2023-07-19 15:17:32,974 - INFO - Epoch: [241/600], Step: [237/591], Loss: 227478240.0, KL Divergence: 811.6359252929688, Reconstruction Loss: 227477424.0\n",
      "354it [00:33, 10.81it/s]2023-07-19 15:17:43,920 - INFO - Epoch: [241/600], Step: [355/591], Loss: 299357376.0, KL Divergence: 811.3990478515625, Reconstruction Loss: 299356576.0\n",
      "472it [00:44, 10.83it/s]2023-07-19 15:17:54,967 - INFO - Epoch: [241/600], Step: [473/591], Loss: 278027040.0, KL Divergence: 808.4549560546875, Reconstruction Loss: 278026240.0\n",
      "590it [00:55, 10.90it/s]2023-07-19 15:18:05,973 - INFO - Epoch: [241/600], Step: [591/591], Loss: 204584672.0, KL Divergence: 821.30517578125, Reconstruction Loss: 204583856.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 15:18:05,975 - INFO - Epoch: [241/600], Total Loss: 16267200548864.0, Total KL Divergence: 61160607.625, Total Reconstruction Loss: 16267139476480.0\n",
      "2023-07-19 15:18:06,024 - INFO - Save model at epoch 241\n",
      "0it [00:00, ?it/s]2023-07-19 15:18:06,145 - INFO - Epoch: [242/600], Step: [1/591], Loss: 122543472.0, KL Divergence: 817.3814697265625, Reconstruction Loss: 122542656.0\n",
      "118it [00:10, 10.64it/s]2023-07-19 15:18:17,123 - INFO - Epoch: [242/600], Step: [119/591], Loss: 312667744.0, KL Divergence: 811.9630737304688, Reconstruction Loss: 312666944.0\n",
      "236it [00:22, 10.99it/s]2023-07-19 15:18:28,153 - INFO - Epoch: [242/600], Step: [237/591], Loss: 227362880.0, KL Divergence: 811.11181640625, Reconstruction Loss: 227362064.0\n",
      "354it [00:32, 11.02it/s]2023-07-19 15:18:39,087 - INFO - Epoch: [242/600], Step: [355/591], Loss: 291454784.0, KL Divergence: 816.994140625, Reconstruction Loss: 291453952.0\n",
      "472it [00:44, 10.66it/s]2023-07-19 15:18:50,196 - INFO - Epoch: [242/600], Step: [473/591], Loss: 251461584.0, KL Divergence: 822.2388916015625, Reconstruction Loss: 251460768.0\n",
      "590it [00:55, 10.95it/s]2023-07-19 15:19:01,132 - INFO - Epoch: [242/600], Step: [591/591], Loss: 202736800.0, KL Divergence: 837.1336669921875, Reconstruction Loss: 202735968.0\n",
      "591it [00:55, 10.73it/s]\n",
      "2023-07-19 15:19:01,134 - INFO - Epoch: [242/600], Total Loss: 16188973476864.0, Total KL Divergence: 61702428.015625, Total Reconstruction Loss: 16188911764480.0\n",
      "2023-07-19 15:19:01,176 - INFO - Save model at epoch 242\n",
      "0it [00:00, ?it/s]2023-07-19 15:19:01,309 - INFO - Epoch: [243/600], Step: [1/591], Loss: 121259096.0, KL Divergence: 831.3790893554688, Reconstruction Loss: 121258264.0\n",
      "117it [00:10, 10.15it/s]2023-07-19 15:19:12,297 - INFO - Epoch: [243/600], Step: [119/591], Loss: 300179072.0, KL Divergence: 821.646240234375, Reconstruction Loss: 300178240.0\n",
      "235it [00:22, 10.63it/s]2023-07-19 15:19:23,429 - INFO - Epoch: [243/600], Step: [237/591], Loss: 228533424.0, KL Divergence: 812.918701171875, Reconstruction Loss: 228532608.0\n",
      "353it [00:33, 10.60it/s]2023-07-19 15:19:34,516 - INFO - Epoch: [243/600], Step: [355/591], Loss: 300399744.0, KL Divergence: 818.8585815429688, Reconstruction Loss: 300398912.0\n",
      "471it [00:44, 10.96it/s]2023-07-19 15:19:45,642 - INFO - Epoch: [243/600], Step: [473/591], Loss: 247556224.0, KL Divergence: 816.2698974609375, Reconstruction Loss: 247555408.0\n",
      "589it [00:55, 10.56it/s]2023-07-19 15:19:56,737 - INFO - Epoch: [243/600], Step: [591/591], Loss: 211405312.0, KL Divergence: 834.6513671875, Reconstruction Loss: 211404480.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 15:19:56,739 - INFO - Epoch: [243/600], Total Loss: 16101116044288.0, Total KL Divergence: 61938696.5, Total Reconstruction Loss: 16101054093312.0\n",
      "2023-07-19 15:19:56,780 - INFO - Save model at epoch 243\n",
      "0it [00:00, ?it/s]2023-07-19 15:19:56,897 - INFO - Epoch: [244/600], Step: [1/591], Loss: 123968288.0, KL Divergence: 831.6489868164062, Reconstruction Loss: 123967456.0\n",
      "117it [00:11, 10.71it/s]2023-07-19 15:20:08,070 - INFO - Epoch: [244/600], Step: [119/591], Loss: 302465984.0, KL Divergence: 821.0994873046875, Reconstruction Loss: 302465152.0\n",
      "235it [00:22, 10.91it/s]2023-07-19 15:20:19,184 - INFO - Epoch: [244/600], Step: [237/591], Loss: 226773392.0, KL Divergence: 817.8985595703125, Reconstruction Loss: 226772576.0\n",
      "353it [00:33, 10.72it/s]2023-07-19 15:20:30,295 - INFO - Epoch: [244/600], Step: [355/591], Loss: 281866496.0, KL Divergence: 819.5764770507812, Reconstruction Loss: 281865664.0\n",
      "471it [00:44, 10.92it/s]2023-07-19 15:20:41,273 - INFO - Epoch: [244/600], Step: [473/591], Loss: 247259984.0, KL Divergence: 820.366943359375, Reconstruction Loss: 247259168.0\n",
      "589it [00:55, 10.81it/s]2023-07-19 15:20:52,108 - INFO - Epoch: [244/600], Step: [591/591], Loss: 197110720.0, KL Divergence: 836.4764404296875, Reconstruction Loss: 197109888.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 15:20:52,110 - INFO - Epoch: [244/600], Total Loss: 16096837272576.0, Total KL Divergence: 62116555.421875, Total Reconstruction Loss: 16096775118848.0\n",
      "2023-07-19 15:20:52,165 - INFO - Save model at epoch 244\n",
      "0it [00:00, ?it/s]2023-07-19 15:20:52,293 - INFO - Epoch: [245/600], Step: [1/591], Loss: 122843480.0, KL Divergence: 832.6787719726562, Reconstruction Loss: 122842648.0\n",
      "117it [00:11, 10.36it/s]2023-07-19 15:21:03,421 - INFO - Epoch: [245/600], Step: [119/591], Loss: 303741728.0, KL Divergence: 821.1770629882812, Reconstruction Loss: 303740896.0\n",
      "235it [00:22, 10.80it/s]2023-07-19 15:21:14,424 - INFO - Epoch: [245/600], Step: [237/591], Loss: 223520384.0, KL Divergence: 819.7756958007812, Reconstruction Loss: 223519568.0\n",
      "353it [00:33, 10.90it/s]2023-07-19 15:21:25,426 - INFO - Epoch: [245/600], Step: [355/591], Loss: 275174208.0, KL Divergence: 820.0449829101562, Reconstruction Loss: 275173376.0\n",
      "471it [00:44, 10.92it/s]2023-07-19 15:21:36,465 - INFO - Epoch: [245/600], Step: [473/591], Loss: 245713584.0, KL Divergence: 824.3870849609375, Reconstruction Loss: 245712752.0\n",
      "589it [00:55, 10.64it/s]2023-07-19 15:21:47,377 - INFO - Epoch: [245/600], Step: [591/591], Loss: 221112256.0, KL Divergence: 830.3566284179688, Reconstruction Loss: 221111424.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 15:21:47,379 - INFO - Epoch: [245/600], Total Loss: 16111836477440.0, Total KL Divergence: 62194896.8984375, Total Reconstruction Loss: 16111774273536.0\n",
      "2023-07-19 15:21:47,441 - INFO - Save model at epoch 245\n",
      "0it [00:00, ?it/s]2023-07-19 15:21:47,560 - INFO - Epoch: [246/600], Step: [1/591], Loss: 120509848.0, KL Divergence: 826.4293212890625, Reconstruction Loss: 120509024.0\n",
      "117it [00:10, 10.74it/s]2023-07-19 15:21:58,656 - INFO - Epoch: [246/600], Step: [119/591], Loss: 307587136.0, KL Divergence: 825.225830078125, Reconstruction Loss: 307586304.0\n",
      "235it [00:22, 10.91it/s]2023-07-19 15:22:09,770 - INFO - Epoch: [246/600], Step: [237/591], Loss: 235332256.0, KL Divergence: 823.3157348632812, Reconstruction Loss: 235331440.0\n",
      "353it [00:33, 10.88it/s]2023-07-19 15:22:20,799 - INFO - Epoch: [246/600], Step: [355/591], Loss: 276120064.0, KL Divergence: 829.236083984375, Reconstruction Loss: 276119232.0\n",
      "471it [00:44, 10.87it/s]2023-07-19 15:22:31,842 - INFO - Epoch: [246/600], Step: [473/591], Loss: 243525088.0, KL Divergence: 830.791015625, Reconstruction Loss: 243524256.0\n",
      "589it [00:55, 10.67it/s]2023-07-19 15:22:42,812 - INFO - Epoch: [246/600], Step: [591/591], Loss: 201850560.0, KL Divergence: 841.0780639648438, Reconstruction Loss: 201849712.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 15:22:42,814 - INFO - Epoch: [246/600], Total Loss: 16080804928512.0, Total KL Divergence: 62579598.6640625, Total Reconstruction Loss: 16080742288384.0\n",
      "2023-07-19 15:22:42,856 - INFO - Save model at epoch 246\n",
      "0it [00:00, ?it/s]2023-07-19 15:22:42,976 - INFO - Epoch: [247/600], Step: [1/591], Loss: 132836976.0, KL Divergence: 835.200927734375, Reconstruction Loss: 132836144.0\n",
      "117it [00:11, 10.60it/s]2023-07-19 15:22:54,086 - INFO - Epoch: [247/600], Step: [119/591], Loss: 304295584.0, KL Divergence: 830.06640625, Reconstruction Loss: 304294752.0\n",
      "235it [00:22, 10.71it/s]2023-07-19 15:23:05,291 - INFO - Epoch: [247/600], Step: [237/591], Loss: 232010592.0, KL Divergence: 837.479248046875, Reconstruction Loss: 232009760.0\n",
      "353it [00:33, 10.74it/s]2023-07-19 15:23:16,324 - INFO - Epoch: [247/600], Step: [355/591], Loss: 275499552.0, KL Divergence: 839.1434326171875, Reconstruction Loss: 275498720.0\n",
      "471it [00:44, 11.03it/s]2023-07-19 15:23:27,318 - INFO - Epoch: [247/600], Step: [473/591], Loss: 264627520.0, KL Divergence: 834.6663818359375, Reconstruction Loss: 264626688.0\n",
      "589it [00:55, 10.55it/s]2023-07-19 15:23:38,329 - INFO - Epoch: [247/600], Step: [591/591], Loss: 196137216.0, KL Divergence: 855.8180541992188, Reconstruction Loss: 196136368.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 15:23:38,331 - INFO - Epoch: [247/600], Total Loss: 16205668866048.0, Total KL Divergence: 63301370.8828125, Total Reconstruction Loss: 16205605652480.0\n",
      "2023-07-19 15:23:38,376 - INFO - Save model at epoch 247\n",
      "0it [00:00, ?it/s]2023-07-19 15:23:38,499 - INFO - Epoch: [248/600], Step: [1/591], Loss: 126342824.0, KL Divergence: 849.8822021484375, Reconstruction Loss: 126341976.0\n",
      "117it [00:10, 10.48it/s]2023-07-19 15:23:49,565 - INFO - Epoch: [248/600], Step: [119/591], Loss: 304568544.0, KL Divergence: 840.08203125, Reconstruction Loss: 304567712.0\n",
      "235it [00:22, 10.81it/s]2023-07-19 15:24:00,695 - INFO - Epoch: [248/600], Step: [237/591], Loss: 221193488.0, KL Divergence: 837.634765625, Reconstruction Loss: 221192656.0\n",
      "353it [00:33, 10.54it/s]2023-07-19 15:24:11,704 - INFO - Epoch: [248/600], Step: [355/591], Loss: 276484672.0, KL Divergence: 839.7905883789062, Reconstruction Loss: 276483840.0\n",
      "471it [00:44, 10.92it/s]2023-07-19 15:24:22,780 - INFO - Epoch: [248/600], Step: [473/591], Loss: 270061312.0, KL Divergence: 837.3580932617188, Reconstruction Loss: 270060480.0\n",
      "589it [00:55, 10.52it/s]2023-07-19 15:24:33,752 - INFO - Epoch: [248/600], Step: [591/591], Loss: 202807088.0, KL Divergence: 846.7080078125, Reconstruction Loss: 202806240.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 15:24:33,754 - INFO - Epoch: [248/600], Total Loss: 16089401242624.0, Total KL Divergence: 63507785.4921875, Total Reconstruction Loss: 16089337819136.0\n",
      "2023-07-19 15:24:33,796 - INFO - Save model at epoch 248\n",
      "0it [00:00, ?it/s]2023-07-19 15:24:33,926 - INFO - Epoch: [249/600], Step: [1/591], Loss: 148182032.0, KL Divergence: 843.399658203125, Reconstruction Loss: 148181184.0\n",
      "117it [00:10, 10.69it/s]2023-07-19 15:24:44,956 - INFO - Epoch: [249/600], Step: [119/591], Loss: 299864448.0, KL Divergence: 834.735107421875, Reconstruction Loss: 299863616.0\n",
      "235it [00:22, 10.64it/s]2023-07-19 15:24:56,190 - INFO - Epoch: [249/600], Step: [237/591], Loss: 226076352.0, KL Divergence: 837.81982421875, Reconstruction Loss: 226075520.0\n",
      "353it [00:33, 10.88it/s]2023-07-19 15:25:07,175 - INFO - Epoch: [249/600], Step: [355/591], Loss: 278194112.0, KL Divergence: 841.9700927734375, Reconstruction Loss: 278193280.0\n",
      "471it [00:44, 10.76it/s]2023-07-19 15:25:18,231 - INFO - Epoch: [249/600], Step: [473/591], Loss: 247417920.0, KL Divergence: 835.6590576171875, Reconstruction Loss: 247417088.0\n",
      "589it [00:55, 10.67it/s]2023-07-19 15:25:29,279 - INFO - Epoch: [249/600], Step: [591/591], Loss: 203223728.0, KL Divergence: 849.8925170898438, Reconstruction Loss: 203222880.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 15:25:29,281 - INFO - Epoch: [249/600], Total Loss: 15966390274048.0, Total KL Divergence: 63529777.734375, Total Reconstruction Loss: 15966326810624.0\n",
      "2023-07-19 15:25:29,321 - INFO - Save model at epoch 249\n",
      "0it [00:00, ?it/s]2023-07-19 15:25:29,442 - INFO - Epoch: [250/600], Step: [1/591], Loss: 119508456.0, KL Divergence: 843.5969848632812, Reconstruction Loss: 119507616.0\n",
      "117it [00:10, 10.62it/s]2023-07-19 15:25:40,481 - INFO - Epoch: [250/600], Step: [119/591], Loss: 304154944.0, KL Divergence: 841.7033081054688, Reconstruction Loss: 304154112.0\n",
      "235it [00:22, 10.58it/s]2023-07-19 15:25:51,754 - INFO - Epoch: [250/600], Step: [237/591], Loss: 225338912.0, KL Divergence: 832.4380493164062, Reconstruction Loss: 225338080.0\n",
      "353it [00:33, 10.62it/s]2023-07-19 15:26:02,811 - INFO - Epoch: [250/600], Step: [355/591], Loss: 275184160.0, KL Divergence: 833.5379638671875, Reconstruction Loss: 275183328.0\n",
      "471it [00:44, 10.24it/s]2023-07-19 15:26:13,939 - INFO - Epoch: [250/600], Step: [473/591], Loss: 275751872.0, KL Divergence: 838.9638061523438, Reconstruction Loss: 275751040.0\n",
      "589it [00:55, 10.75it/s]2023-07-19 15:26:24,860 - INFO - Epoch: [250/600], Step: [591/591], Loss: 238925616.0, KL Divergence: 847.7702026367188, Reconstruction Loss: 238924768.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 15:26:24,862 - INFO - Epoch: [250/600], Total Loss: 16279591308288.0, Total KL Divergence: 63400157.0390625, Total Reconstruction Loss: 16279527976960.0\n",
      "2023-07-19 15:26:24,906 - INFO - Save model at epoch 250\n",
      "0it [00:00, ?it/s]2023-07-19 15:26:25,019 - INFO - Epoch: [251/600], Step: [1/591], Loss: 128473160.0, KL Divergence: 843.8364868164062, Reconstruction Loss: 128472320.0\n",
      "117it [00:10, 10.42it/s]2023-07-19 15:26:36,070 - INFO - Epoch: [251/600], Step: [119/591], Loss: 298847424.0, KL Divergence: 838.5330200195312, Reconstruction Loss: 298846592.0\n",
      "235it [00:22, 10.77it/s]2023-07-19 15:26:47,157 - INFO - Epoch: [251/600], Step: [237/591], Loss: 243200560.0, KL Divergence: 834.8269653320312, Reconstruction Loss: 243199728.0\n",
      "353it [00:33, 10.59it/s]2023-07-19 15:26:58,348 - INFO - Epoch: [251/600], Step: [355/591], Loss: 275657824.0, KL Divergence: 832.7374877929688, Reconstruction Loss: 275656992.0\n",
      "472it [00:44, 10.64it/s]2023-07-19 15:27:09,436 - INFO - Epoch: [251/600], Step: [473/591], Loss: 240078512.0, KL Divergence: 840.5345458984375, Reconstruction Loss: 240077664.0\n",
      "590it [00:55, 10.91it/s]2023-07-19 15:27:20,327 - INFO - Epoch: [251/600], Step: [591/591], Loss: 193690800.0, KL Divergence: 849.7987060546875, Reconstruction Loss: 193689952.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 15:27:20,328 - INFO - Epoch: [251/600], Total Loss: 15990859420672.0, Total KL Divergence: 63345056.453125, Total Reconstruction Loss: 15990796123136.0\n",
      "2023-07-19 15:27:20,369 - INFO - Save model at epoch 251\n",
      "0it [00:00, ?it/s]2023-07-19 15:27:20,485 - INFO - Epoch: [252/600], Step: [1/591], Loss: 134812976.0, KL Divergence: 843.4507446289062, Reconstruction Loss: 134812128.0\n",
      "118it [00:10, 10.93it/s]2023-07-19 15:27:31,438 - INFO - Epoch: [252/600], Step: [119/591], Loss: 296442240.0, KL Divergence: 839.46533203125, Reconstruction Loss: 296441408.0\n",
      "236it [00:22, 10.88it/s]2023-07-19 15:27:42,608 - INFO - Epoch: [252/600], Step: [237/591], Loss: 245587072.0, KL Divergence: 825.94482421875, Reconstruction Loss: 245586240.0\n",
      "354it [00:33, 10.78it/s]2023-07-19 15:27:53,510 - INFO - Epoch: [252/600], Step: [355/591], Loss: 274223776.0, KL Divergence: 829.4251098632812, Reconstruction Loss: 274222944.0\n",
      "472it [00:44, 10.66it/s]2023-07-19 15:28:04,638 - INFO - Epoch: [252/600], Step: [473/591], Loss: 251298416.0, KL Divergence: 827.0445556640625, Reconstruction Loss: 251297584.0\n",
      "590it [00:55, 10.63it/s]2023-07-19 15:28:15,644 - INFO - Epoch: [252/600], Step: [591/591], Loss: 191498128.0, KL Divergence: 843.5304565429688, Reconstruction Loss: 191497280.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 15:28:15,645 - INFO - Epoch: [252/600], Total Loss: 16015748218880.0, Total KL Divergence: 62953947.7109375, Total Reconstruction Loss: 16015685259264.0\n",
      "2023-07-19 15:28:15,690 - INFO - Save model at epoch 252\n",
      "0it [00:00, ?it/s]2023-07-19 15:28:15,797 - INFO - Epoch: [253/600], Step: [1/591], Loss: 121382040.0, KL Divergence: 838.93603515625, Reconstruction Loss: 121381200.0\n",
      "117it [00:11, 10.59it/s]2023-07-19 15:28:26,988 - INFO - Epoch: [253/600], Step: [119/591], Loss: 293172160.0, KL Divergence: 831.5496215820312, Reconstruction Loss: 293171328.0\n",
      "235it [00:22, 10.62it/s]2023-07-19 15:28:38,056 - INFO - Epoch: [253/600], Step: [237/591], Loss: 235190096.0, KL Divergence: 818.7503051757812, Reconstruction Loss: 235189280.0\n",
      "353it [00:33, 11.20it/s]2023-07-19 15:28:48,963 - INFO - Epoch: [253/600], Step: [355/591], Loss: 283843328.0, KL Divergence: 826.5530395507812, Reconstruction Loss: 283842496.0\n",
      "471it [00:44, 10.56it/s]2023-07-19 15:28:59,918 - INFO - Epoch: [253/600], Step: [473/591], Loss: 265391120.0, KL Divergence: 824.5781860351562, Reconstruction Loss: 265390288.0\n",
      "589it [00:55, 10.78it/s]2023-07-19 15:29:10,859 - INFO - Epoch: [253/600], Step: [591/591], Loss: 199364272.0, KL Divergence: 835.6790771484375, Reconstruction Loss: 199363440.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 15:29:10,862 - INFO - Epoch: [253/600], Total Loss: 16319244252160.0, Total KL Divergence: 62403167.40625, Total Reconstruction Loss: 16319181801472.0\n",
      "2023-07-19 15:29:10,903 - INFO - Save model at epoch 253\n",
      "0it [00:00, ?it/s]2023-07-19 15:29:11,024 - INFO - Epoch: [254/600], Step: [1/591], Loss: 115100904.0, KL Divergence: 829.3634643554688, Reconstruction Loss: 115100072.0\n",
      "117it [00:10, 10.83it/s]2023-07-19 15:29:22,012 - INFO - Epoch: [254/600], Step: [119/591], Loss: 293341600.0, KL Divergence: 823.9296875, Reconstruction Loss: 293340768.0\n",
      "235it [00:21, 11.02it/s]2023-07-19 15:29:33,008 - INFO - Epoch: [254/600], Step: [237/591], Loss: 230992064.0, KL Divergence: 822.2783813476562, Reconstruction Loss: 230991248.0\n",
      "353it [00:32, 11.13it/s]2023-07-19 15:29:43,918 - INFO - Epoch: [254/600], Step: [355/591], Loss: 276922368.0, KL Divergence: 819.4432983398438, Reconstruction Loss: 276921536.0\n",
      "471it [00:43, 10.73it/s]2023-07-19 15:29:54,845 - INFO - Epoch: [254/600], Step: [473/591], Loss: 253920640.0, KL Divergence: 823.8703002929688, Reconstruction Loss: 253919824.0\n",
      "589it [00:54, 11.06it/s]2023-07-19 15:30:05,723 - INFO - Epoch: [254/600], Step: [591/591], Loss: 201296624.0, KL Divergence: 838.0960693359375, Reconstruction Loss: 201295792.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 15:30:05,725 - INFO - Epoch: [254/600], Total Loss: 15982350153728.0, Total KL Divergence: 62216121.046875, Total Reconstruction Loss: 15982287906816.0\n",
      "2023-07-19 15:30:05,769 - INFO - Save model at epoch 254\n",
      "0it [00:00, ?it/s]2023-07-19 15:30:05,904 - INFO - Epoch: [255/600], Step: [1/591], Loss: 115704496.0, KL Divergence: 832.3192138671875, Reconstruction Loss: 115703664.0\n",
      "117it [00:10, 10.85it/s]2023-07-19 15:30:16,804 - INFO - Epoch: [255/600], Step: [119/591], Loss: 293022464.0, KL Divergence: 827.3131103515625, Reconstruction Loss: 293021632.0\n",
      "235it [00:21, 11.01it/s]2023-07-19 15:30:27,761 - INFO - Epoch: [255/600], Step: [237/591], Loss: 230556592.0, KL Divergence: 829.4000244140625, Reconstruction Loss: 230555760.0\n",
      "353it [00:32, 10.84it/s]2023-07-19 15:30:38,706 - INFO - Epoch: [255/600], Step: [355/591], Loss: 279661376.0, KL Divergence: 829.6183471679688, Reconstruction Loss: 279660544.0\n",
      "471it [00:43, 10.66it/s]2023-07-19 15:30:49,739 - INFO - Epoch: [255/600], Step: [473/591], Loss: 243132512.0, KL Divergence: 829.7698974609375, Reconstruction Loss: 243131680.0\n",
      "589it [00:54, 10.56it/s]2023-07-19 15:31:00,669 - INFO - Epoch: [255/600], Step: [591/591], Loss: 198254784.0, KL Divergence: 846.3204956054688, Reconstruction Loss: 198253936.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 15:31:00,671 - INFO - Epoch: [255/600], Total Loss: 15990300331008.0, Total KL Divergence: 62647890.1640625, Total Reconstruction Loss: 15990237650944.0\n",
      "2023-07-19 15:31:00,712 - INFO - Save model at epoch 255\n",
      "0it [00:00, ?it/s]2023-07-19 15:31:00,831 - INFO - Epoch: [256/600], Step: [1/591], Loss: 128228488.0, KL Divergence: 841.2794799804688, Reconstruction Loss: 128227648.0\n",
      "118it [00:11, 10.66it/s]2023-07-19 15:31:11,857 - INFO - Epoch: [256/600], Step: [119/591], Loss: 292960512.0, KL Divergence: 830.3278198242188, Reconstruction Loss: 292959680.0\n",
      "236it [00:21, 10.88it/s]2023-07-19 15:31:22,801 - INFO - Epoch: [256/600], Step: [237/591], Loss: 232042608.0, KL Divergence: 822.4225463867188, Reconstruction Loss: 232041792.0\n",
      "354it [00:32, 10.59it/s]2023-07-19 15:31:33,793 - INFO - Epoch: [256/600], Step: [355/591], Loss: 290063648.0, KL Divergence: 826.1602172851562, Reconstruction Loss: 290062816.0\n",
      "472it [00:44, 10.73it/s]2023-07-19 15:31:44,862 - INFO - Epoch: [256/600], Step: [473/591], Loss: 268436352.0, KL Divergence: 823.6180419921875, Reconstruction Loss: 268435520.0\n",
      "590it [00:55, 10.65it/s]2023-07-19 15:31:55,797 - INFO - Epoch: [256/600], Step: [591/591], Loss: 209543216.0, KL Divergence: 840.8751831054688, Reconstruction Loss: 209542368.0\n",
      "591it [00:55, 10.73it/s]\n",
      "2023-07-19 15:31:55,799 - INFO - Epoch: [256/600], Total Loss: 15954349045760.0, Total KL Divergence: 62640736.9453125, Total Reconstruction Loss: 15954286376960.0\n",
      "2023-07-19 15:31:55,842 - INFO - Save model at epoch 256\n",
      "0it [00:00, ?it/s]2023-07-19 15:31:55,959 - INFO - Epoch: [257/600], Step: [1/591], Loss: 127473080.0, KL Divergence: 839.6019287109375, Reconstruction Loss: 127472240.0\n",
      "117it [00:11, 10.53it/s]2023-07-19 15:32:07,120 - INFO - Epoch: [257/600], Step: [119/591], Loss: 298771712.0, KL Divergence: 829.0003051757812, Reconstruction Loss: 298770880.0\n",
      "236it [00:22, 10.38it/s]2023-07-19 15:32:18,286 - INFO - Epoch: [257/600], Step: [237/591], Loss: 226533712.0, KL Divergence: 830.1058349609375, Reconstruction Loss: 226532880.0\n",
      "354it [00:33, 10.66it/s]2023-07-19 15:32:29,367 - INFO - Epoch: [257/600], Step: [355/591], Loss: 293556064.0, KL Divergence: 832.7495727539062, Reconstruction Loss: 293555232.0\n",
      "472it [00:44, 11.05it/s]2023-07-19 15:32:40,422 - INFO - Epoch: [257/600], Step: [473/591], Loss: 248166032.0, KL Divergence: 829.7520751953125, Reconstruction Loss: 248165200.0\n",
      "590it [00:55, 10.84it/s]2023-07-19 15:32:51,417 - INFO - Epoch: [257/600], Step: [591/591], Loss: 196301200.0, KL Divergence: 845.2091674804688, Reconstruction Loss: 196300352.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 15:32:51,418 - INFO - Epoch: [257/600], Total Loss: 16137268203520.0, Total KL Divergence: 62933468.5703125, Total Reconstruction Loss: 16137205252096.0\n",
      "2023-07-19 15:32:51,465 - INFO - Save model at epoch 257\n",
      "0it [00:00, ?it/s]2023-07-19 15:32:51,573 - INFO - Epoch: [258/600], Step: [1/591], Loss: 117531640.0, KL Divergence: 843.2568359375, Reconstruction Loss: 117530800.0\n",
      "117it [00:10, 10.71it/s]2023-07-19 15:33:02,648 - INFO - Epoch: [258/600], Step: [119/591], Loss: 309424288.0, KL Divergence: 835.0695190429688, Reconstruction Loss: 309423456.0\n",
      "235it [00:22, 10.76it/s]2023-07-19 15:33:13,765 - INFO - Epoch: [258/600], Step: [237/591], Loss: 219156144.0, KL Divergence: 830.2357177734375, Reconstruction Loss: 219155312.0\n",
      "353it [00:33, 10.90it/s]2023-07-19 15:33:24,730 - INFO - Epoch: [258/600], Step: [355/591], Loss: 298088288.0, KL Divergence: 835.891357421875, Reconstruction Loss: 298087456.0\n",
      "471it [00:44, 10.82it/s]2023-07-19 15:33:35,809 - INFO - Epoch: [258/600], Step: [473/591], Loss: 253410288.0, KL Divergence: 833.7120361328125, Reconstruction Loss: 253409456.0\n",
      "589it [00:55, 10.60it/s]2023-07-19 15:33:46,764 - INFO - Epoch: [258/600], Step: [591/591], Loss: 201306256.0, KL Divergence: 848.314453125, Reconstruction Loss: 201305408.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 15:33:46,766 - INFO - Epoch: [258/600], Total Loss: 16203982361600.0, Total KL Divergence: 63234377.671875, Total Reconstruction Loss: 16203919199232.0\n",
      "2023-07-19 15:33:46,810 - INFO - Save model at epoch 258\n",
      "0it [00:00, ?it/s]2023-07-19 15:33:46,917 - INFO - Epoch: [259/600], Step: [1/591], Loss: 121412960.0, KL Divergence: 844.9092407226562, Reconstruction Loss: 121412112.0\n",
      "117it [00:10, 10.93it/s]2023-07-19 15:33:57,877 - INFO - Epoch: [259/600], Step: [119/591], Loss: 291362944.0, KL Divergence: 836.9517211914062, Reconstruction Loss: 291362112.0\n",
      "236it [00:22, 10.83it/s]2023-07-19 15:34:08,997 - INFO - Epoch: [259/600], Step: [237/591], Loss: 218498688.0, KL Divergence: 832.7742919921875, Reconstruction Loss: 218497856.0\n",
      "354it [00:33, 10.85it/s]2023-07-19 15:34:20,088 - INFO - Epoch: [259/600], Step: [355/591], Loss: 287162912.0, KL Divergence: 831.5901489257812, Reconstruction Loss: 287162080.0\n",
      "472it [00:44, 10.83it/s]2023-07-19 15:34:31,236 - INFO - Epoch: [259/600], Step: [473/591], Loss: 247722480.0, KL Divergence: 836.41064453125, Reconstruction Loss: 247721648.0\n",
      "590it [00:55, 10.53it/s]2023-07-19 15:34:42,317 - INFO - Epoch: [259/600], Step: [591/591], Loss: 204178736.0, KL Divergence: 850.08349609375, Reconstruction Loss: 204177888.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 15:34:42,318 - INFO - Epoch: [259/600], Total Loss: 15890084488192.0, Total KL Divergence: 63209241.5, Total Reconstruction Loss: 15890021306368.0\n",
      "2023-07-19 15:34:42,360 - INFO - Save model at epoch 259\n",
      "0it [00:00, ?it/s]2023-07-19 15:34:42,474 - INFO - Epoch: [260/600], Step: [1/591], Loss: 115773072.0, KL Divergence: 846.22216796875, Reconstruction Loss: 115772224.0\n",
      "118it [00:11, 10.87it/s]2023-07-19 15:34:53,622 - INFO - Epoch: [260/600], Step: [119/591], Loss: 292966848.0, KL Divergence: 840.3883056640625, Reconstruction Loss: 292966016.0\n",
      "236it [00:22, 10.80it/s]2023-07-19 15:35:04,734 - INFO - Epoch: [260/600], Step: [237/591], Loss: 216544784.0, KL Divergence: 837.7649536132812, Reconstruction Loss: 216543952.0\n",
      "354it [00:33, 10.50it/s]2023-07-19 15:35:15,883 - INFO - Epoch: [260/600], Step: [355/591], Loss: 317248768.0, KL Divergence: 841.89208984375, Reconstruction Loss: 317247936.0\n",
      "471it [00:44, 10.50it/s]2023-07-19 15:35:27,142 - INFO - Epoch: [260/600], Step: [473/591], Loss: 260402544.0, KL Divergence: 839.7841796875, Reconstruction Loss: 260401712.0\n",
      "589it [00:55, 10.50it/s]2023-07-19 15:35:38,085 - INFO - Epoch: [260/600], Step: [591/591], Loss: 208463568.0, KL Divergence: 853.3802490234375, Reconstruction Loss: 208462720.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 15:35:38,087 - INFO - Epoch: [260/600], Total Loss: 15787213314048.0, Total KL Divergence: 63649415.0859375, Total Reconstruction Loss: 15787149701120.0\n",
      "2023-07-19 15:35:38,128 - INFO - Save model at epoch 260\n",
      "0it [00:00, ?it/s]2023-07-19 15:35:38,238 - INFO - Epoch: [261/600], Step: [1/591], Loss: 116445584.0, KL Divergence: 851.7335815429688, Reconstruction Loss: 116444736.0\n",
      "117it [00:11, 10.71it/s]2023-07-19 15:35:49,420 - INFO - Epoch: [261/600], Step: [119/591], Loss: 286430304.0, KL Divergence: 850.57666015625, Reconstruction Loss: 286429440.0\n",
      "235it [00:22, 10.63it/s]2023-07-19 15:36:00,519 - INFO - Epoch: [261/600], Step: [237/591], Loss: 219889488.0, KL Divergence: 843.7027587890625, Reconstruction Loss: 219888640.0\n",
      "353it [00:33, 10.64it/s]2023-07-19 15:36:11,582 - INFO - Epoch: [261/600], Step: [355/591], Loss: 287823808.0, KL Divergence: 843.9295654296875, Reconstruction Loss: 287822976.0\n",
      "471it [00:44, 10.80it/s]2023-07-19 15:36:22,578 - INFO - Epoch: [261/600], Step: [473/591], Loss: 248407968.0, KL Divergence: 846.911376953125, Reconstruction Loss: 248407120.0\n",
      "589it [00:55, 10.27it/s]2023-07-19 15:36:33,578 - INFO - Epoch: [261/600], Step: [591/591], Loss: 209077328.0, KL Divergence: 864.9840698242188, Reconstruction Loss: 209076464.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 15:36:33,580 - INFO - Epoch: [261/600], Total Loss: 15785591902208.0, Total KL Divergence: 64164747.5625, Total Reconstruction Loss: 15785527746560.0\n",
      "2023-07-19 15:36:33,623 - INFO - Save model at epoch 261\n",
      "0it [00:00, ?it/s]2023-07-19 15:36:33,736 - INFO - Epoch: [262/600], Step: [1/591], Loss: 115832744.0, KL Divergence: 863.1476440429688, Reconstruction Loss: 115831880.0\n",
      "117it [00:10, 10.73it/s]2023-07-19 15:36:44,670 - INFO - Epoch: [262/600], Step: [119/591], Loss: 291773536.0, KL Divergence: 858.8260498046875, Reconstruction Loss: 291772672.0\n",
      "235it [00:21, 10.83it/s]2023-07-19 15:36:55,724 - INFO - Epoch: [262/600], Step: [237/591], Loss: 219906832.0, KL Divergence: 856.2222290039062, Reconstruction Loss: 219905968.0\n",
      "353it [00:32, 10.84it/s]2023-07-19 15:37:06,637 - INFO - Epoch: [262/600], Step: [355/591], Loss: 278342240.0, KL Divergence: 849.9560546875, Reconstruction Loss: 278341376.0\n",
      "471it [00:43, 10.31it/s]2023-07-19 15:37:17,778 - INFO - Epoch: [262/600], Step: [473/591], Loss: 256177904.0, KL Divergence: 848.810302734375, Reconstruction Loss: 256177056.0\n",
      "589it [00:55, 10.36it/s]2023-07-19 15:37:28,836 - INFO - Epoch: [262/600], Step: [591/591], Loss: 212370640.0, KL Divergence: 857.578125, Reconstruction Loss: 212369776.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 15:37:28,838 - INFO - Epoch: [262/600], Total Loss: 15728338357248.0, Total KL Divergence: 64652288.7578125, Total Reconstruction Loss: 15728273653760.0\n",
      "2023-07-19 15:37:28,880 - INFO - Save model at epoch 262\n",
      "0it [00:00, ?it/s]2023-07-19 15:37:29,002 - INFO - Epoch: [263/600], Step: [1/591], Loss: 117638856.0, KL Divergence: 855.6835327148438, Reconstruction Loss: 117638000.0\n",
      "117it [00:10, 10.61it/s]2023-07-19 15:37:40,035 - INFO - Epoch: [263/600], Step: [119/591], Loss: 301917824.0, KL Divergence: 849.543212890625, Reconstruction Loss: 301916960.0\n",
      "235it [00:22, 10.39it/s]2023-07-19 15:37:51,168 - INFO - Epoch: [263/600], Step: [237/591], Loss: 217376544.0, KL Divergence: 846.2504272460938, Reconstruction Loss: 217375696.0\n",
      "353it [00:33, 10.36it/s]2023-07-19 15:38:02,194 - INFO - Epoch: [263/600], Step: [355/591], Loss: 297712576.0, KL Divergence: 849.415771484375, Reconstruction Loss: 297711712.0\n",
      "471it [00:44, 10.82it/s]2023-07-19 15:38:13,227 - INFO - Epoch: [263/600], Step: [473/591], Loss: 251369840.0, KL Divergence: 848.518798828125, Reconstruction Loss: 251368992.0\n",
      "589it [00:55, 10.83it/s]2023-07-19 15:38:24,197 - INFO - Epoch: [263/600], Step: [591/591], Loss: 194965328.0, KL Divergence: 860.7174682617188, Reconstruction Loss: 194964464.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 15:38:24,199 - INFO - Epoch: [263/600], Total Loss: 15972644436992.0, Total KL Divergence: 64349890.0390625, Total Reconstruction Loss: 15972580058112.0\n",
      "2023-07-19 15:38:24,242 - INFO - Save model at epoch 263\n",
      "0it [00:00, ?it/s]2023-07-19 15:38:24,376 - INFO - Epoch: [264/600], Step: [1/591], Loss: 115787464.0, KL Divergence: 857.548828125, Reconstruction Loss: 115786608.0\n",
      "117it [00:11, 10.50it/s]2023-07-19 15:38:35,497 - INFO - Epoch: [264/600], Step: [119/591], Loss: 303823136.0, KL Divergence: 852.3843994140625, Reconstruction Loss: 303822272.0\n",
      "235it [00:22, 10.89it/s]2023-07-19 15:38:46,585 - INFO - Epoch: [264/600], Step: [237/591], Loss: 218736032.0, KL Divergence: 851.3431396484375, Reconstruction Loss: 218735184.0\n",
      "353it [00:33, 10.92it/s]2023-07-19 15:38:57,481 - INFO - Epoch: [264/600], Step: [355/591], Loss: 301723424.0, KL Divergence: 853.4462890625, Reconstruction Loss: 301722560.0\n",
      "471it [00:43, 10.62it/s]2023-07-19 15:39:08,397 - INFO - Epoch: [264/600], Step: [473/591], Loss: 245322864.0, KL Divergence: 854.8107299804688, Reconstruction Loss: 245322016.0\n",
      "589it [00:54, 10.95it/s]2023-07-19 15:39:19,246 - INFO - Epoch: [264/600], Step: [591/591], Loss: 203223808.0, KL Divergence: 860.6080932617188, Reconstruction Loss: 203222944.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 15:39:19,248 - INFO - Epoch: [264/600], Total Loss: 15928667626496.0, Total KL Divergence: 64536749.296875, Total Reconstruction Loss: 15928603070464.0\n",
      "2023-07-19 15:39:19,289 - INFO - Save model at epoch 264\n",
      "0it [00:00, ?it/s]2023-07-19 15:39:19,404 - INFO - Epoch: [265/600], Step: [1/591], Loss: 116057208.0, KL Divergence: 858.5482177734375, Reconstruction Loss: 116056352.0\n",
      "117it [00:10, 10.78it/s]2023-07-19 15:39:30,230 - INFO - Epoch: [265/600], Step: [119/591], Loss: 295997952.0, KL Divergence: 848.3633422851562, Reconstruction Loss: 295997088.0\n",
      "235it [00:21, 10.88it/s]2023-07-19 15:39:41,284 - INFO - Epoch: [265/600], Step: [237/591], Loss: 220890992.0, KL Divergence: 849.756103515625, Reconstruction Loss: 220890144.0\n",
      "353it [00:32, 10.74it/s]2023-07-19 15:39:52,077 - INFO - Epoch: [265/600], Step: [355/591], Loss: 304628960.0, KL Divergence: 845.3556518554688, Reconstruction Loss: 304628128.0\n",
      "471it [00:43, 10.85it/s]2023-07-19 15:40:02,935 - INFO - Epoch: [265/600], Step: [473/591], Loss: 286332384.0, KL Divergence: 845.26806640625, Reconstruction Loss: 286331552.0\n",
      "589it [00:54, 10.82it/s]2023-07-19 15:40:13,918 - INFO - Epoch: [265/600], Step: [591/591], Loss: 226939440.0, KL Divergence: 852.7570190429688, Reconstruction Loss: 226938592.0\n",
      "591it [00:54, 10.82it/s]\n",
      "2023-07-19 15:40:13,921 - INFO - Epoch: [265/600], Total Loss: 15885754897408.0, Total KL Divergence: 64187281.875, Total Reconstruction Loss: 15885690700800.0\n",
      "2023-07-19 15:40:13,962 - INFO - Save model at epoch 265\n",
      "0it [00:00, ?it/s]2023-07-19 15:40:14,068 - INFO - Epoch: [266/600], Step: [1/591], Loss: 118721632.0, KL Divergence: 852.078369140625, Reconstruction Loss: 118720776.0\n",
      "117it [00:10, 10.99it/s]2023-07-19 15:40:24,865 - INFO - Epoch: [266/600], Step: [119/591], Loss: 301580064.0, KL Divergence: 848.607421875, Reconstruction Loss: 301579200.0\n",
      "235it [00:21, 10.20it/s]2023-07-19 15:40:35,983 - INFO - Epoch: [266/600], Step: [237/591], Loss: 217945072.0, KL Divergence: 853.06689453125, Reconstruction Loss: 217944224.0\n",
      "353it [00:32, 11.03it/s]2023-07-19 15:40:46,863 - INFO - Epoch: [266/600], Step: [355/591], Loss: 284510368.0, KL Divergence: 850.921875, Reconstruction Loss: 284509504.0\n",
      "471it [00:43, 10.85it/s]2023-07-19 15:40:57,871 - INFO - Epoch: [266/600], Step: [473/591], Loss: 247198352.0, KL Divergence: 850.9188232421875, Reconstruction Loss: 247197504.0\n",
      "589it [00:54, 10.44it/s]2023-07-19 15:41:08,633 - INFO - Epoch: [266/600], Step: [591/591], Loss: 246736880.0, KL Divergence: 853.45947265625, Reconstruction Loss: 246736032.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 15:41:08,635 - INFO - Epoch: [266/600], Total Loss: 15870198082560.0, Total KL Divergence: 64292775.15625, Total Reconstruction Loss: 15870133783552.0\n",
      "2023-07-19 15:41:08,682 - INFO - Save model at epoch 266\n",
      "0it [00:00, ?it/s]2023-07-19 15:41:08,791 - INFO - Epoch: [267/600], Step: [1/591], Loss: 120039880.0, KL Divergence: 852.9281005859375, Reconstruction Loss: 120039024.0\n",
      "117it [00:10, 11.07it/s]2023-07-19 15:41:19,798 - INFO - Epoch: [267/600], Step: [119/591], Loss: 287663584.0, KL Divergence: 847.2938232421875, Reconstruction Loss: 287662752.0\n",
      "235it [00:21, 11.18it/s]2023-07-19 15:41:30,727 - INFO - Epoch: [267/600], Step: [237/591], Loss: 218606128.0, KL Divergence: 854.8880615234375, Reconstruction Loss: 218605280.0\n",
      "353it [00:32, 10.79it/s]2023-07-19 15:41:41,650 - INFO - Epoch: [267/600], Step: [355/591], Loss: 286130656.0, KL Divergence: 854.497802734375, Reconstruction Loss: 286129792.0\n",
      "471it [00:43, 10.61it/s]2023-07-19 15:41:52,725 - INFO - Epoch: [267/600], Step: [473/591], Loss: 242718080.0, KL Divergence: 856.5499267578125, Reconstruction Loss: 242717216.0\n",
      "589it [00:54, 10.55it/s]2023-07-19 15:42:03,685 - INFO - Epoch: [267/600], Step: [591/591], Loss: 202077024.0, KL Divergence: 859.4589233398438, Reconstruction Loss: 202076160.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 15:42:03,687 - INFO - Epoch: [267/600], Total Loss: 15742586652672.0, Total KL Divergence: 64639903.5546875, Total Reconstruction Loss: 15742522001408.0\n",
      "2023-07-19 15:42:03,727 - INFO - Save model at epoch 267\n",
      "0it [00:00, ?it/s]2023-07-19 15:42:03,839 - INFO - Epoch: [268/600], Step: [1/591], Loss: 121896368.0, KL Divergence: 858.5159912109375, Reconstruction Loss: 121895512.0\n",
      "117it [00:10, 10.97it/s]2023-07-19 15:42:14,841 - INFO - Epoch: [268/600], Step: [119/591], Loss: 292169504.0, KL Divergence: 848.7410888671875, Reconstruction Loss: 292168640.0\n",
      "235it [00:21, 10.74it/s]2023-07-19 15:42:25,885 - INFO - Epoch: [268/600], Step: [237/591], Loss: 223866800.0, KL Divergence: 847.3475952148438, Reconstruction Loss: 223865952.0\n",
      "353it [00:32, 11.06it/s]2023-07-19 15:42:36,671 - INFO - Epoch: [268/600], Step: [355/591], Loss: 284883552.0, KL Divergence: 851.1723022460938, Reconstruction Loss: 284882688.0\n",
      "471it [00:43, 10.59it/s]2023-07-19 15:42:47,537 - INFO - Epoch: [268/600], Step: [473/591], Loss: 238346608.0, KL Divergence: 852.96826171875, Reconstruction Loss: 238345760.0\n",
      "589it [00:54, 10.46it/s]2023-07-19 15:42:58,450 - INFO - Epoch: [268/600], Step: [591/591], Loss: 211502416.0, KL Divergence: 854.369873046875, Reconstruction Loss: 211501568.0\n",
      "591it [00:54, 10.80it/s]\n",
      "2023-07-19 15:42:58,452 - INFO - Epoch: [268/600], Total Loss: 15792365431808.0, Total KL Divergence: 64314229.796875, Total Reconstruction Loss: 15792301084672.0\n",
      "2023-07-19 15:42:58,492 - INFO - Save model at epoch 268\n",
      "0it [00:00, ?it/s]2023-07-19 15:42:58,640 - INFO - Epoch: [269/600], Step: [1/591], Loss: 118566856.0, KL Divergence: 852.3345947265625, Reconstruction Loss: 118566000.0\n",
      "117it [00:11, 10.31it/s]2023-07-19 15:43:09,737 - INFO - Epoch: [269/600], Step: [119/591], Loss: 289534464.0, KL Divergence: 844.1979370117188, Reconstruction Loss: 289533632.0\n",
      "235it [00:22, 10.77it/s]2023-07-19 15:43:20,786 - INFO - Epoch: [269/600], Step: [237/591], Loss: 218620304.0, KL Divergence: 844.0330810546875, Reconstruction Loss: 218619456.0\n",
      "353it [00:32, 10.94it/s]2023-07-19 15:43:31,564 - INFO - Epoch: [269/600], Step: [355/591], Loss: 283005984.0, KL Divergence: 844.3751220703125, Reconstruction Loss: 283005152.0\n",
      "471it [00:43,  9.94it/s]2023-07-19 15:43:42,543 - INFO - Epoch: [269/600], Step: [473/591], Loss: 250011024.0, KL Divergence: 851.4852294921875, Reconstruction Loss: 250010176.0\n",
      "589it [00:54, 10.90it/s]2023-07-19 15:43:53,278 - INFO - Epoch: [269/600], Step: [591/591], Loss: 210723488.0, KL Divergence: 858.8492431640625, Reconstruction Loss: 210722624.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 15:43:53,280 - INFO - Epoch: [269/600], Total Loss: 15704630119424.0, Total KL Divergence: 64008864.6171875, Total Reconstruction Loss: 15704566126592.0\n",
      "2023-07-19 15:43:53,331 - INFO - Save model at epoch 269\n",
      "0it [00:00, ?it/s]2023-07-19 15:43:53,437 - INFO - Epoch: [270/600], Step: [1/591], Loss: 120484320.0, KL Divergence: 856.6551513671875, Reconstruction Loss: 120483464.0\n",
      "117it [00:10, 10.67it/s]2023-07-19 15:44:04,350 - INFO - Epoch: [270/600], Step: [119/591], Loss: 294327872.0, KL Divergence: 847.403564453125, Reconstruction Loss: 294327040.0\n",
      "235it [00:21, 10.95it/s]2023-07-19 15:44:15,344 - INFO - Epoch: [270/600], Step: [237/591], Loss: 216567088.0, KL Divergence: 848.2952880859375, Reconstruction Loss: 216566240.0\n",
      "353it [00:32, 11.07it/s]2023-07-19 15:44:26,097 - INFO - Epoch: [270/600], Step: [355/591], Loss: 327234912.0, KL Divergence: 848.4662475585938, Reconstruction Loss: 327234048.0\n",
      "471it [00:43, 10.60it/s]2023-07-19 15:44:37,003 - INFO - Epoch: [270/600], Step: [473/591], Loss: 264096880.0, KL Divergence: 841.9759521484375, Reconstruction Loss: 264096032.0\n",
      "589it [00:54, 11.03it/s]2023-07-19 15:44:47,680 - INFO - Epoch: [270/600], Step: [591/591], Loss: 217193408.0, KL Divergence: 860.2685546875, Reconstruction Loss: 217192544.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 15:44:47,682 - INFO - Epoch: [270/600], Total Loss: 15872753480704.0, Total KL Divergence: 64181128.5, Total Reconstruction Loss: 15872689326080.0\n",
      "2023-07-19 15:44:47,722 - INFO - Save model at epoch 270\n",
      "0it [00:00, ?it/s]2023-07-19 15:44:47,839 - INFO - Epoch: [271/600], Step: [1/591], Loss: 119816504.0, KL Divergence: 855.272216796875, Reconstruction Loss: 119815648.0\n",
      "117it [00:10, 11.06it/s]2023-07-19 15:44:58,661 - INFO - Epoch: [271/600], Step: [119/591], Loss: 286464128.0, KL Divergence: 837.8729858398438, Reconstruction Loss: 286463296.0\n",
      "235it [00:21, 10.95it/s]2023-07-19 15:45:09,517 - INFO - Epoch: [271/600], Step: [237/591], Loss: 221768112.0, KL Divergence: 846.2271118164062, Reconstruction Loss: 221767264.0\n",
      "353it [00:32, 10.82it/s]2023-07-19 15:45:20,331 - INFO - Epoch: [271/600], Step: [355/591], Loss: 276013568.0, KL Divergence: 842.719970703125, Reconstruction Loss: 276012736.0\n",
      "471it [00:43, 10.33it/s]2023-07-19 15:45:31,287 - INFO - Epoch: [271/600], Step: [473/591], Loss: 275767136.0, KL Divergence: 849.995849609375, Reconstruction Loss: 275766272.0\n",
      "589it [00:54, 11.02it/s]2023-07-19 15:45:42,007 - INFO - Epoch: [271/600], Step: [591/591], Loss: 200392336.0, KL Divergence: 857.1503295898438, Reconstruction Loss: 200391472.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 15:45:42,009 - INFO - Epoch: [271/600], Total Loss: 15857952056320.0, Total KL Divergence: 64029077.0078125, Total Reconstruction Loss: 15857888054272.0\n",
      "2023-07-19 15:45:42,047 - INFO - Save model at epoch 271\n",
      "0it [00:00, ?it/s]2023-07-19 15:45:42,165 - INFO - Epoch: [272/600], Step: [1/591], Loss: 122216088.0, KL Divergence: 854.5128173828125, Reconstruction Loss: 122215232.0\n",
      "117it [00:10, 10.61it/s]2023-07-19 15:45:53,058 - INFO - Epoch: [272/600], Step: [119/591], Loss: 279042880.0, KL Divergence: 837.4982299804688, Reconstruction Loss: 279042048.0\n",
      "235it [00:21, 11.02it/s]2023-07-19 15:46:03,881 - INFO - Epoch: [272/600], Step: [237/591], Loss: 220383616.0, KL Divergence: 841.8072509765625, Reconstruction Loss: 220382768.0\n",
      "353it [00:32, 11.05it/s]2023-07-19 15:46:14,654 - INFO - Epoch: [272/600], Step: [355/591], Loss: 278095936.0, KL Divergence: 846.6842041015625, Reconstruction Loss: 278095104.0\n",
      "471it [00:43, 10.22it/s]2023-07-19 15:46:25,453 - INFO - Epoch: [272/600], Step: [473/591], Loss: 274993408.0, KL Divergence: 851.7596435546875, Reconstruction Loss: 274992544.0\n",
      "589it [00:53, 11.07it/s]2023-07-19 15:46:36,125 - INFO - Epoch: [272/600], Step: [591/591], Loss: 222347936.0, KL Divergence: 858.3057861328125, Reconstruction Loss: 222347072.0\n",
      "591it [00:54, 10.93it/s]\n",
      "2023-07-19 15:46:36,126 - INFO - Epoch: [272/600], Total Loss: 15866954638336.0, Total KL Divergence: 63841427.1328125, Total Reconstruction Loss: 15866890817536.0\n",
      "2023-07-19 15:46:36,168 - INFO - Save model at epoch 272\n",
      "0it [00:00, ?it/s]2023-07-19 15:46:36,285 - INFO - Epoch: [273/600], Step: [1/591], Loss: 119143400.0, KL Divergence: 853.668701171875, Reconstruction Loss: 119142544.0\n",
      "117it [00:10, 10.89it/s]2023-07-19 15:46:47,014 - INFO - Epoch: [273/600], Step: [119/591], Loss: 283513792.0, KL Divergence: 844.7636108398438, Reconstruction Loss: 283512960.0\n",
      "235it [00:21, 10.89it/s]2023-07-19 15:46:57,848 - INFO - Epoch: [273/600], Step: [237/591], Loss: 216799504.0, KL Divergence: 850.933349609375, Reconstruction Loss: 216798656.0\n",
      "353it [00:32, 10.84it/s]2023-07-19 15:47:08,628 - INFO - Epoch: [273/600], Step: [355/591], Loss: 280205888.0, KL Divergence: 847.2218017578125, Reconstruction Loss: 280205056.0\n",
      "471it [00:43, 10.94it/s]2023-07-19 15:47:19,465 - INFO - Epoch: [273/600], Step: [473/591], Loss: 268914048.0, KL Divergence: 855.7393188476562, Reconstruction Loss: 268913184.0\n",
      "589it [00:53, 11.06it/s]2023-07-19 15:47:30,152 - INFO - Epoch: [273/600], Step: [591/591], Loss: 204759008.0, KL Divergence: 863.4134521484375, Reconstruction Loss: 204758144.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 15:47:30,154 - INFO - Epoch: [273/600], Total Loss: 15718234513408.0, Total KL Divergence: 64365356.578125, Total Reconstruction Loss: 15718170134528.0\n",
      "2023-07-19 15:47:30,194 - INFO - Save model at epoch 273\n",
      "0it [00:00, ?it/s]2023-07-19 15:47:30,332 - INFO - Epoch: [274/600], Step: [1/591], Loss: 122239856.0, KL Divergence: 861.52099609375, Reconstruction Loss: 122238992.0\n",
      "117it [00:10, 11.02it/s]2023-07-19 15:47:41,064 - INFO - Epoch: [274/600], Step: [119/591], Loss: 294408704.0, KL Divergence: 847.7396240234375, Reconstruction Loss: 294407872.0\n",
      "235it [00:21, 11.14it/s]2023-07-19 15:47:51,826 - INFO - Epoch: [274/600], Step: [237/591], Loss: 214742832.0, KL Divergence: 849.3192138671875, Reconstruction Loss: 214741984.0\n",
      "353it [00:32, 10.99it/s]2023-07-19 15:48:02,583 - INFO - Epoch: [274/600], Step: [355/591], Loss: 270964416.0, KL Divergence: 842.9254150390625, Reconstruction Loss: 270963584.0\n",
      "471it [00:42, 10.94it/s]2023-07-19 15:48:13,314 - INFO - Epoch: [274/600], Step: [473/591], Loss: 269856480.0, KL Divergence: 858.3185424804688, Reconstruction Loss: 269855616.0\n",
      "589it [00:53, 10.99it/s]2023-07-19 15:48:24,048 - INFO - Epoch: [274/600], Step: [591/591], Loss: 200351888.0, KL Divergence: 856.0028076171875, Reconstruction Loss: 200351024.0\n",
      "591it [00:53, 10.98it/s]\n",
      "2023-07-19 15:48:24,050 - INFO - Epoch: [274/600], Total Loss: 15620493889536.0, Total KL Divergence: 64212981.984375, Total Reconstruction Loss: 15620429677568.0\n",
      "2023-07-19 15:48:24,103 - INFO - Save model at epoch 274\n",
      "0it [00:00, ?it/s]2023-07-19 15:48:24,221 - INFO - Epoch: [275/600], Step: [1/591], Loss: 117027216.0, KL Divergence: 852.8809814453125, Reconstruction Loss: 117026360.0\n",
      "117it [00:10, 11.16it/s]2023-07-19 15:48:34,944 - INFO - Epoch: [275/600], Step: [119/591], Loss: 281663520.0, KL Divergence: 837.812744140625, Reconstruction Loss: 281662688.0\n",
      "235it [00:21, 11.07it/s]2023-07-19 15:48:45,762 - INFO - Epoch: [275/600], Step: [237/591], Loss: 217429216.0, KL Divergence: 838.9577026367188, Reconstruction Loss: 217428384.0\n",
      "353it [00:32, 10.90it/s]2023-07-19 15:48:56,562 - INFO - Epoch: [275/600], Step: [355/591], Loss: 280840768.0, KL Divergence: 833.058349609375, Reconstruction Loss: 280839936.0\n",
      "471it [00:43, 10.55it/s]2023-07-19 15:49:07,502 - INFO - Epoch: [275/600], Step: [473/591], Loss: 304635360.0, KL Divergence: 844.369140625, Reconstruction Loss: 304634528.0\n",
      "589it [00:54, 11.03it/s]2023-07-19 15:49:18,540 - INFO - Epoch: [275/600], Step: [591/591], Loss: 211451904.0, KL Divergence: 851.0817260742188, Reconstruction Loss: 211451056.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 15:49:18,542 - INFO - Epoch: [275/600], Total Loss: 15720887373824.0, Total KL Divergence: 63590854.0625, Total Reconstruction Loss: 15720823812096.0\n",
      "2023-07-19 15:49:18,582 - INFO - Save model at epoch 275\n",
      "0it [00:00, ?it/s]2023-07-19 15:49:18,706 - INFO - Epoch: [276/600], Step: [1/591], Loss: 122111008.0, KL Divergence: 849.3387451171875, Reconstruction Loss: 122110160.0\n",
      "117it [00:10, 10.61it/s]2023-07-19 15:49:29,681 - INFO - Epoch: [276/600], Step: [119/591], Loss: 284801792.0, KL Divergence: 839.2015380859375, Reconstruction Loss: 284800960.0\n",
      "235it [00:21, 10.73it/s]2023-07-19 15:49:40,624 - INFO - Epoch: [276/600], Step: [237/591], Loss: 220329504.0, KL Divergence: 851.87451171875, Reconstruction Loss: 220328656.0\n",
      "353it [00:32, 10.87it/s]2023-07-19 15:49:51,655 - INFO - Epoch: [276/600], Step: [355/591], Loss: 274208352.0, KL Divergence: 848.964111328125, Reconstruction Loss: 274207488.0\n",
      "471it [00:43, 10.97it/s]2023-07-19 15:50:02,491 - INFO - Epoch: [276/600], Step: [473/591], Loss: 261664656.0, KL Divergence: 847.5784912109375, Reconstruction Loss: 261663808.0\n",
      "589it [00:54, 11.02it/s]2023-07-19 15:50:13,312 - INFO - Epoch: [276/600], Step: [591/591], Loss: 202479712.0, KL Divergence: 858.9093017578125, Reconstruction Loss: 202478848.0\n",
      "591it [00:54, 10.80it/s]\n",
      "2023-07-19 15:50:13,314 - INFO - Epoch: [276/600], Total Loss: 15812279254016.0, Total KL Divergence: 64145740.203125, Total Reconstruction Loss: 15812215102464.0\n",
      "2023-07-19 15:50:13,355 - INFO - Save model at epoch 276\n",
      "0it [00:00, ?it/s]2023-07-19 15:50:13,475 - INFO - Epoch: [277/600], Step: [1/591], Loss: 120062232.0, KL Divergence: 856.2822265625, Reconstruction Loss: 120061376.0\n",
      "118it [00:11, 10.99it/s]2023-07-19 15:50:24,509 - INFO - Epoch: [277/600], Step: [119/591], Loss: 283077248.0, KL Divergence: 842.4227905273438, Reconstruction Loss: 283076416.0\n",
      "236it [00:22, 10.76it/s]2023-07-19 15:50:35,553 - INFO - Epoch: [277/600], Step: [237/591], Loss: 223213120.0, KL Divergence: 853.7811279296875, Reconstruction Loss: 223212272.0\n",
      "354it [00:33, 11.07it/s]2023-07-19 15:50:46,525 - INFO - Epoch: [277/600], Step: [355/591], Loss: 267831440.0, KL Divergence: 848.6708984375, Reconstruction Loss: 267830592.0\n",
      "472it [00:43, 10.98it/s]2023-07-19 15:50:57,318 - INFO - Epoch: [277/600], Step: [473/591], Loss: 265445856.0, KL Divergence: 855.1516723632812, Reconstruction Loss: 265445008.0\n",
      "590it [00:54, 10.86it/s]2023-07-19 15:51:08,159 - INFO - Epoch: [277/600], Step: [591/591], Loss: 203308240.0, KL Divergence: 861.05126953125, Reconstruction Loss: 203307376.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 15:51:08,161 - INFO - Epoch: [277/600], Total Loss: 15781646076928.0, Total KL Divergence: 64354274.5703125, Total Reconstruction Loss: 15781581713408.0\n",
      "2023-07-19 15:51:08,200 - INFO - Save model at epoch 277\n",
      "0it [00:00, ?it/s]2023-07-19 15:51:08,302 - INFO - Epoch: [278/600], Step: [1/591], Loss: 119737528.0, KL Divergence: 856.4464721679688, Reconstruction Loss: 119736672.0\n",
      "118it [00:10, 10.74it/s]2023-07-19 15:51:19,256 - INFO - Epoch: [278/600], Step: [119/591], Loss: 283637664.0, KL Divergence: 849.4404907226562, Reconstruction Loss: 283636800.0\n",
      "236it [00:21, 10.71it/s]2023-07-19 15:51:30,102 - INFO - Epoch: [278/600], Step: [237/591], Loss: 220890432.0, KL Divergence: 857.5929565429688, Reconstruction Loss: 220889568.0\n",
      "354it [00:32, 11.61it/s]2023-07-19 15:51:40,802 - INFO - Epoch: [278/600], Step: [355/591], Loss: 276725600.0, KL Divergence: 852.4313354492188, Reconstruction Loss: 276724736.0\n",
      "472it [00:43, 10.72it/s]2023-07-19 15:51:51,590 - INFO - Epoch: [278/600], Step: [473/591], Loss: 248274864.0, KL Divergence: 853.1930541992188, Reconstruction Loss: 248274016.0\n",
      "590it [00:54, 10.72it/s]2023-07-19 15:52:02,563 - INFO - Epoch: [278/600], Step: [591/591], Loss: 221621264.0, KL Divergence: 860.8790893554688, Reconstruction Loss: 221620400.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 15:52:02,565 - INFO - Epoch: [278/600], Total Loss: 15771856968704.0, Total KL Divergence: 64566834.3828125, Total Reconstruction Loss: 15771792374784.0\n",
      "2023-07-19 15:52:02,602 - INFO - Save model at epoch 278\n",
      "0it [00:00, ?it/s]2023-07-19 15:52:02,726 - INFO - Epoch: [279/600], Step: [1/591], Loss: 120780640.0, KL Divergence: 858.5196533203125, Reconstruction Loss: 120779784.0\n",
      "118it [00:11, 10.87it/s]2023-07-19 15:52:13,784 - INFO - Epoch: [279/600], Step: [119/591], Loss: 278428448.0, KL Divergence: 846.2321166992188, Reconstruction Loss: 278427616.0\n",
      "236it [00:21, 11.06it/s]2023-07-19 15:52:24,667 - INFO - Epoch: [279/600], Step: [237/591], Loss: 213935056.0, KL Divergence: 854.4028930664062, Reconstruction Loss: 213934208.0\n",
      "354it [00:32, 10.79it/s]2023-07-19 15:52:35,522 - INFO - Epoch: [279/600], Step: [355/591], Loss: 264269808.0, KL Divergence: 850.067626953125, Reconstruction Loss: 264268960.0\n",
      "472it [00:43, 10.57it/s]2023-07-19 15:52:46,519 - INFO - Epoch: [279/600], Step: [473/591], Loss: 250611920.0, KL Divergence: 862.5237426757812, Reconstruction Loss: 250611056.0\n",
      "590it [00:54, 10.66it/s]2023-07-19 15:52:57,431 - INFO - Epoch: [279/600], Step: [591/591], Loss: 205646240.0, KL Divergence: 868.0895385742188, Reconstruction Loss: 205645376.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 15:52:57,432 - INFO - Epoch: [279/600], Total Loss: 15796618186752.0, Total KL Divergence: 64543341.078125, Total Reconstruction Loss: 15796553614336.0\n",
      "2023-07-19 15:52:57,471 - INFO - Save model at epoch 279\n",
      "0it [00:00, ?it/s]2023-07-19 15:52:57,612 - INFO - Epoch: [280/600], Step: [1/591], Loss: 115277432.0, KL Divergence: 865.7666015625, Reconstruction Loss: 115276568.0\n",
      "117it [00:10, 11.11it/s]2023-07-19 15:53:08,461 - INFO - Epoch: [280/600], Step: [119/591], Loss: 276567488.0, KL Divergence: 852.8907470703125, Reconstruction Loss: 276566624.0\n",
      "235it [00:21, 10.84it/s]2023-07-19 15:53:19,514 - INFO - Epoch: [280/600], Step: [237/591], Loss: 217289584.0, KL Divergence: 856.1259765625, Reconstruction Loss: 217288720.0\n",
      "353it [00:32, 10.90it/s]2023-07-19 15:53:30,559 - INFO - Epoch: [280/600], Step: [355/591], Loss: 271619104.0, KL Divergence: 853.9720458984375, Reconstruction Loss: 271618240.0\n",
      "471it [00:43, 10.55it/s]2023-07-19 15:53:41,537 - INFO - Epoch: [280/600], Step: [473/591], Loss: 244027072.0, KL Divergence: 860.150390625, Reconstruction Loss: 244026208.0\n",
      "589it [00:54, 10.84it/s]2023-07-19 15:53:52,515 - INFO - Epoch: [280/600], Step: [591/591], Loss: 216528224.0, KL Divergence: 869.6393432617188, Reconstruction Loss: 216527360.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 15:53:52,516 - INFO - Epoch: [280/600], Total Loss: 15925838587904.0, Total KL Divergence: 64869789.3828125, Total Reconstruction Loss: 15925773696000.0\n",
      "2023-07-19 15:53:52,556 - INFO - Save model at epoch 280\n",
      "0it [00:00, ?it/s]2023-07-19 15:53:52,672 - INFO - Epoch: [281/600], Step: [1/591], Loss: 113300088.0, KL Divergence: 866.3623046875, Reconstruction Loss: 113299224.0\n",
      "117it [00:10, 10.99it/s]2023-07-19 15:54:03,553 - INFO - Epoch: [281/600], Step: [119/591], Loss: 285007872.0, KL Divergence: 858.6107177734375, Reconstruction Loss: 285007008.0\n",
      "235it [00:21, 10.79it/s]2023-07-19 15:54:14,511 - INFO - Epoch: [281/600], Step: [237/591], Loss: 214934256.0, KL Divergence: 866.0698852539062, Reconstruction Loss: 214933392.0\n",
      "353it [00:32, 10.68it/s]2023-07-19 15:54:25,393 - INFO - Epoch: [281/600], Step: [355/591], Loss: 273133088.0, KL Divergence: 859.806884765625, Reconstruction Loss: 273132224.0\n",
      "471it [00:43, 11.01it/s]2023-07-19 15:54:36,202 - INFO - Epoch: [281/600], Step: [473/591], Loss: 244557680.0, KL Divergence: 861.3846435546875, Reconstruction Loss: 244556816.0\n",
      "589it [00:54, 11.09it/s]2023-07-19 15:54:47,132 - INFO - Epoch: [281/600], Step: [591/591], Loss: 198883824.0, KL Divergence: 874.1546630859375, Reconstruction Loss: 198882944.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 15:54:47,135 - INFO - Epoch: [281/600], Total Loss: 15909841971200.0, Total KL Divergence: 65258814.8359375, Total Reconstruction Loss: 15909776672768.0\n",
      "2023-07-19 15:54:47,174 - INFO - Save model at epoch 281\n",
      "0it [00:00, ?it/s]2023-07-19 15:54:47,306 - INFO - Epoch: [282/600], Step: [1/591], Loss: 116917256.0, KL Divergence: 871.544189453125, Reconstruction Loss: 116916384.0\n",
      "117it [00:10, 10.29it/s]2023-07-19 15:54:58,356 - INFO - Epoch: [282/600], Step: [119/591], Loss: 294039840.0, KL Divergence: 855.5341796875, Reconstruction Loss: 294038976.0\n",
      "235it [00:21, 11.02it/s]2023-07-19 15:55:09,314 - INFO - Epoch: [282/600], Step: [237/591], Loss: 222652064.0, KL Divergence: 859.4560546875, Reconstruction Loss: 222651200.0\n",
      "353it [00:32, 10.71it/s]2023-07-19 15:55:20,316 - INFO - Epoch: [282/600], Step: [355/591], Loss: 275298496.0, KL Divergence: 859.046630859375, Reconstruction Loss: 275297632.0\n",
      "471it [00:44, 10.73it/s]2023-07-19 15:55:31,401 - INFO - Epoch: [282/600], Step: [473/591], Loss: 273557728.0, KL Divergence: 865.1730346679688, Reconstruction Loss: 273556864.0\n",
      "589it [00:54, 10.95it/s]2023-07-19 15:55:42,299 - INFO - Epoch: [282/600], Step: [591/591], Loss: 197521104.0, KL Divergence: 874.4295654296875, Reconstruction Loss: 197520224.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 15:55:42,301 - INFO - Epoch: [282/600], Total Loss: 15930334408704.0, Total KL Divergence: 65141429.59375, Total Reconstruction Loss: 15930269234176.0\n",
      "2023-07-19 15:55:42,340 - INFO - Save model at epoch 282\n",
      "0it [00:00, ?it/s]2023-07-19 15:55:42,447 - INFO - Epoch: [283/600], Step: [1/591], Loss: 114166856.0, KL Divergence: 871.9110107421875, Reconstruction Loss: 114165984.0\n",
      "117it [00:10, 10.95it/s]2023-07-19 15:55:53,296 - INFO - Epoch: [283/600], Step: [119/591], Loss: 281930880.0, KL Divergence: 860.1220092773438, Reconstruction Loss: 281930016.0\n",
      "235it [00:21, 10.92it/s]2023-07-19 15:56:04,271 - INFO - Epoch: [283/600], Step: [237/591], Loss: 224852576.0, KL Divergence: 862.6018676757812, Reconstruction Loss: 224851712.0\n",
      "353it [00:32, 10.50it/s]2023-07-19 15:56:15,252 - INFO - Epoch: [283/600], Step: [355/591], Loss: 284546400.0, KL Divergence: 861.038818359375, Reconstruction Loss: 284545536.0\n",
      "471it [00:43, 10.98it/s]2023-07-19 15:56:25,906 - INFO - Epoch: [283/600], Step: [473/591], Loss: 261349856.0, KL Divergence: 856.170166015625, Reconstruction Loss: 261348992.0\n",
      "589it [00:53, 11.20it/s]2023-07-19 15:56:36,470 - INFO - Epoch: [283/600], Step: [591/591], Loss: 191871056.0, KL Divergence: 872.0042724609375, Reconstruction Loss: 191870176.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 15:56:36,472 - INFO - Epoch: [283/600], Total Loss: 15965469375488.0, Total KL Divergence: 65198082.0, Total Reconstruction Loss: 15965404151808.0\n",
      "2023-07-19 15:56:36,516 - INFO - Save model at epoch 283\n",
      "0it [00:00, ?it/s]2023-07-19 15:56:36,621 - INFO - Epoch: [284/600], Step: [1/591], Loss: 118080480.0, KL Divergence: 869.0784301757812, Reconstruction Loss: 118079608.0\n",
      "118it [00:10, 11.20it/s]2023-07-19 15:56:47,265 - INFO - Epoch: [284/600], Step: [119/591], Loss: 291346432.0, KL Divergence: 865.8070068359375, Reconstruction Loss: 291345568.0\n",
      "236it [00:21, 11.17it/s]2023-07-19 15:56:58,036 - INFO - Epoch: [284/600], Step: [237/591], Loss: 218229744.0, KL Divergence: 866.927978515625, Reconstruction Loss: 218228880.0\n",
      "354it [00:31, 10.76it/s]2023-07-19 15:57:08,626 - INFO - Epoch: [284/600], Step: [355/591], Loss: 275136064.0, KL Divergence: 867.1685791015625, Reconstruction Loss: 275135200.0\n",
      "472it [00:42, 10.97it/s]2023-07-19 15:57:19,171 - INFO - Epoch: [284/600], Step: [473/591], Loss: 262168400.0, KL Divergence: 869.1112670898438, Reconstruction Loss: 262167536.0\n",
      "590it [00:53, 10.65it/s]2023-07-19 15:57:29,949 - INFO - Epoch: [284/600], Step: [591/591], Loss: 205329648.0, KL Divergence: 882.6484375, Reconstruction Loss: 205328768.0\n",
      "591it [00:53, 11.06it/s]\n",
      "2023-07-19 15:57:29,951 - INFO - Epoch: [284/600], Total Loss: 15926232916992.0, Total KL Divergence: 65682310.140625, Total Reconstruction Loss: 15926167249920.0\n",
      "2023-07-19 15:57:29,989 - INFO - Save model at epoch 284\n",
      "0it [00:00, ?it/s]2023-07-19 15:57:30,113 - INFO - Epoch: [285/600], Step: [1/591], Loss: 115569984.0, KL Divergence: 881.5089111328125, Reconstruction Loss: 115569104.0\n",
      "117it [00:10, 10.65it/s]2023-07-19 15:57:41,158 - INFO - Epoch: [285/600], Step: [119/591], Loss: 283071488.0, KL Divergence: 865.416259765625, Reconstruction Loss: 283070624.0\n",
      "235it [00:22, 10.48it/s]2023-07-19 15:57:52,356 - INFO - Epoch: [285/600], Step: [237/591], Loss: 219343392.0, KL Divergence: 876.30126953125, Reconstruction Loss: 219342512.0\n",
      "353it [00:33, 10.68it/s]2023-07-19 15:58:03,438 - INFO - Epoch: [285/600], Step: [355/591], Loss: 281815584.0, KL Divergence: 866.9945678710938, Reconstruction Loss: 281814720.0\n",
      "471it [00:44, 10.86it/s]2023-07-19 15:58:14,470 - INFO - Epoch: [285/600], Step: [473/591], Loss: 256342112.0, KL Divergence: 870.7880859375, Reconstruction Loss: 256341248.0\n",
      "589it [00:55, 11.10it/s]2023-07-19 15:58:25,345 - INFO - Epoch: [285/600], Step: [591/591], Loss: 200553808.0, KL Divergence: 880.5997314453125, Reconstruction Loss: 200552928.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 15:58:25,347 - INFO - Epoch: [285/600], Total Loss: 15788980032512.0, Total KL Divergence: 65876722.53125, Total Reconstruction Loss: 15788914194432.0\n",
      "2023-07-19 15:58:25,386 - INFO - Save model at epoch 285\n",
      "0it [00:00, ?it/s]2023-07-19 15:58:25,499 - INFO - Epoch: [286/600], Step: [1/591], Loss: 115512456.0, KL Divergence: 879.8009033203125, Reconstruction Loss: 115511576.0\n",
      "117it [00:10, 11.29it/s]2023-07-19 15:58:36,093 - INFO - Epoch: [286/600], Step: [119/591], Loss: 284821984.0, KL Divergence: 866.73681640625, Reconstruction Loss: 284821120.0\n",
      "235it [00:21, 11.37it/s]2023-07-19 15:58:46,676 - INFO - Epoch: [286/600], Step: [237/591], Loss: 220421344.0, KL Divergence: 877.866943359375, Reconstruction Loss: 220420464.0\n",
      "353it [00:31, 11.25it/s]2023-07-19 15:58:57,217 - INFO - Epoch: [286/600], Step: [355/591], Loss: 268935840.0, KL Divergence: 867.9049682617188, Reconstruction Loss: 268934976.0\n",
      "471it [00:42, 11.07it/s]2023-07-19 15:59:07,858 - INFO - Epoch: [286/600], Step: [473/591], Loss: 264134224.0, KL Divergence: 866.71142578125, Reconstruction Loss: 264133360.0\n",
      "589it [00:52, 11.25it/s]2023-07-19 15:59:18,503 - INFO - Epoch: [286/600], Step: [591/591], Loss: 196786448.0, KL Divergence: 876.2560424804688, Reconstruction Loss: 196785568.0\n",
      "591it [00:53, 11.13it/s]\n",
      "2023-07-19 15:59:18,505 - INFO - Epoch: [286/600], Total Loss: 15588619402240.0, Total KL Divergence: 65756193.4609375, Total Reconstruction Loss: 15588553695232.0\n",
      "2023-07-19 15:59:18,554 - INFO - Save model at epoch 286\n",
      "0it [00:00, ?it/s]2023-07-19 15:59:18,660 - INFO - Epoch: [287/600], Step: [1/591], Loss: 113294488.0, KL Divergence: 876.52197265625, Reconstruction Loss: 113293608.0\n",
      "118it [00:10, 11.11it/s]2023-07-19 15:59:29,156 - INFO - Epoch: [287/600], Step: [119/591], Loss: 287678816.0, KL Divergence: 863.0401611328125, Reconstruction Loss: 287677952.0\n",
      "236it [00:21, 10.95it/s]2023-07-19 15:59:40,003 - INFO - Epoch: [287/600], Step: [237/591], Loss: 216299568.0, KL Divergence: 874.28515625, Reconstruction Loss: 216298688.0\n",
      "354it [00:32, 10.70it/s]2023-07-19 15:59:50,899 - INFO - Epoch: [287/600], Step: [355/591], Loss: 279374112.0, KL Divergence: 867.0596923828125, Reconstruction Loss: 279373248.0\n",
      "472it [00:43, 10.67it/s]2023-07-19 16:00:01,759 - INFO - Epoch: [287/600], Step: [473/591], Loss: 241435280.0, KL Divergence: 869.2579345703125, Reconstruction Loss: 241434416.0\n",
      "589it [00:54, 11.31it/s]2023-07-19 16:00:12,714 - INFO - Epoch: [287/600], Step: [591/591], Loss: 191847776.0, KL Divergence: 890.046142578125, Reconstruction Loss: 191846880.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 16:00:12,717 - INFO - Epoch: [287/600], Total Loss: 15777747789824.0, Total KL Divergence: 65797905.84375, Total Reconstruction Loss: 15777682028544.0\n",
      "2023-07-19 16:00:12,756 - INFO - Save model at epoch 287\n",
      "0it [00:00, ?it/s]2023-07-19 16:00:12,848 - INFO - Epoch: [288/600], Step: [1/591], Loss: 122293416.0, KL Divergence: 886.6661376953125, Reconstruction Loss: 122292528.0\n",
      "118it [00:10, 11.19it/s]2023-07-19 16:00:23,402 - INFO - Epoch: [288/600], Step: [119/591], Loss: 275967552.0, KL Divergence: 869.69873046875, Reconstruction Loss: 275966688.0\n",
      "236it [00:21, 11.09it/s]2023-07-19 16:00:33,999 - INFO - Epoch: [288/600], Step: [237/591], Loss: 210774560.0, KL Divergence: 876.9244384765625, Reconstruction Loss: 210773680.0\n",
      "354it [00:31, 10.92it/s]2023-07-19 16:00:44,582 - INFO - Epoch: [288/600], Step: [355/591], Loss: 276362176.0, KL Divergence: 864.5477905273438, Reconstruction Loss: 276361312.0\n",
      "472it [00:42, 11.08it/s]2023-07-19 16:00:55,149 - INFO - Epoch: [288/600], Step: [473/591], Loss: 236877840.0, KL Divergence: 877.1304321289062, Reconstruction Loss: 236876960.0\n",
      "590it [00:53, 11.03it/s]2023-07-19 16:01:05,850 - INFO - Epoch: [288/600], Step: [591/591], Loss: 203465568.0, KL Divergence: 883.106201171875, Reconstruction Loss: 203464688.0\n",
      "591it [00:53, 11.13it/s]\n",
      "2023-07-19 16:01:05,852 - INFO - Epoch: [288/600], Total Loss: 15453924255744.0, Total KL Divergence: 66055324.7265625, Total Reconstruction Loss: 15453858247680.0\n",
      "2023-07-19 16:01:05,894 - INFO - Save model at epoch 288\n",
      "0it [00:00, ?it/s]2023-07-19 16:01:05,991 - INFO - Epoch: [289/600], Step: [1/591], Loss: 117367232.0, KL Divergence: 883.2635498046875, Reconstruction Loss: 117366352.0\n",
      "118it [00:10, 10.80it/s]2023-07-19 16:01:16,523 - INFO - Epoch: [289/600], Step: [119/591], Loss: 278534752.0, KL Divergence: 872.4505615234375, Reconstruction Loss: 278533888.0\n",
      "236it [00:21, 11.10it/s]2023-07-19 16:01:27,354 - INFO - Epoch: [289/600], Step: [237/591], Loss: 207810864.0, KL Divergence: 881.0416259765625, Reconstruction Loss: 207809984.0\n",
      "354it [00:32, 10.86it/s]2023-07-19 16:01:38,226 - INFO - Epoch: [289/600], Step: [355/591], Loss: 282540768.0, KL Divergence: 871.5079956054688, Reconstruction Loss: 282539904.0\n",
      "472it [00:43, 11.06it/s]2023-07-19 16:01:49,040 - INFO - Epoch: [289/600], Step: [473/591], Loss: 245064864.0, KL Divergence: 874.0396728515625, Reconstruction Loss: 245063984.0\n",
      "590it [00:53, 11.08it/s]2023-07-19 16:01:59,771 - INFO - Epoch: [289/600], Step: [591/591], Loss: 192363808.0, KL Divergence: 885.5834350585938, Reconstruction Loss: 192362928.0\n",
      "591it [00:53, 10.97it/s]\n",
      "2023-07-19 16:01:59,773 - INFO - Epoch: [289/600], Total Loss: 15429401241600.0, Total KL Divergence: 66181682.3828125, Total Reconstruction Loss: 15429335070720.0\n",
      "2023-07-19 16:01:59,832 - INFO - Save model at epoch 289\n",
      "0it [00:00, ?it/s]2023-07-19 16:01:59,937 - INFO - Epoch: [290/600], Step: [1/591], Loss: 115405256.0, KL Divergence: 884.2581787109375, Reconstruction Loss: 115404368.0\n",
      "117it [00:10, 10.94it/s]2023-07-19 16:02:10,814 - INFO - Epoch: [290/600], Step: [119/591], Loss: 283733824.0, KL Divergence: 875.1428833007812, Reconstruction Loss: 283732960.0\n",
      "235it [00:21, 11.09it/s]2023-07-19 16:02:21,556 - INFO - Epoch: [290/600], Step: [237/591], Loss: 211091632.0, KL Divergence: 882.39501953125, Reconstruction Loss: 211090752.0\n",
      "353it [00:32, 11.03it/s]2023-07-19 16:02:32,270 - INFO - Epoch: [290/600], Step: [355/591], Loss: 269191584.0, KL Divergence: 873.0042114257812, Reconstruction Loss: 269190720.0\n",
      "471it [00:42, 10.91it/s]2023-07-19 16:02:43,017 - INFO - Epoch: [290/600], Step: [473/591], Loss: 243817392.0, KL Divergence: 880.3748779296875, Reconstruction Loss: 243816512.0\n",
      "589it [00:53, 11.01it/s]2023-07-19 16:02:53,749 - INFO - Epoch: [290/600], Step: [591/591], Loss: 192499152.0, KL Divergence: 887.2515869140625, Reconstruction Loss: 192498272.0\n",
      "591it [00:53, 10.96it/s]\n",
      "2023-07-19 16:02:53,751 - INFO - Epoch: [290/600], Total Loss: 15508920691712.0, Total KL Divergence: 66332361.3515625, Total Reconstruction Loss: 15508854383616.0\n",
      "2023-07-19 16:02:53,789 - INFO - Save model at epoch 290\n",
      "0it [00:00, ?it/s]2023-07-19 16:02:53,895 - INFO - Epoch: [291/600], Step: [1/591], Loss: 116417624.0, KL Divergence: 886.9534301757812, Reconstruction Loss: 116416736.0\n",
      "118it [00:10, 10.95it/s]2023-07-19 16:03:04,721 - INFO - Epoch: [291/600], Step: [119/591], Loss: 286225280.0, KL Divergence: 875.3079223632812, Reconstruction Loss: 286224416.0\n",
      "236it [00:21, 11.05it/s]2023-07-19 16:03:15,567 - INFO - Epoch: [291/600], Step: [237/591], Loss: 210728048.0, KL Divergence: 882.249755859375, Reconstruction Loss: 210727168.0\n",
      "354it [00:32, 10.96it/s]2023-07-19 16:03:26,402 - INFO - Epoch: [291/600], Step: [355/591], Loss: 264842304.0, KL Divergence: 875.6163330078125, Reconstruction Loss: 264841424.0\n",
      "472it [00:43, 10.69it/s]2023-07-19 16:03:37,394 - INFO - Epoch: [291/600], Step: [473/591], Loss: 262662288.0, KL Divergence: 875.3001098632812, Reconstruction Loss: 262661408.0\n",
      "590it [00:54, 10.82it/s]2023-07-19 16:03:48,242 - INFO - Epoch: [291/600], Step: [591/591], Loss: 192291696.0, KL Divergence: 888.8963623046875, Reconstruction Loss: 192290800.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 16:03:48,244 - INFO - Epoch: [291/600], Total Loss: 15701239483392.0, Total KL Divergence: 66338044.7578125, Total Reconstruction Loss: 15701173177344.0\n",
      "2023-07-19 16:03:48,283 - INFO - Save model at epoch 291\n",
      "0it [00:00, ?it/s]2023-07-19 16:03:48,397 - INFO - Epoch: [292/600], Step: [1/591], Loss: 110728168.0, KL Divergence: 887.57568359375, Reconstruction Loss: 110727280.0\n",
      "117it [00:10, 10.71it/s]2023-07-19 16:03:59,389 - INFO - Epoch: [292/600], Step: [119/591], Loss: 273973152.0, KL Divergence: 872.96875, Reconstruction Loss: 273972288.0\n",
      "235it [00:21, 11.05it/s]2023-07-19 16:04:10,302 - INFO - Epoch: [292/600], Step: [237/591], Loss: 211089872.0, KL Divergence: 872.623291015625, Reconstruction Loss: 211088992.0\n",
      "353it [00:32, 10.80it/s]2023-07-19 16:04:21,023 - INFO - Epoch: [292/600], Step: [355/591], Loss: 276185536.0, KL Divergence: 870.167724609375, Reconstruction Loss: 276184672.0\n",
      "471it [00:43, 11.04it/s]2023-07-19 16:04:31,838 - INFO - Epoch: [292/600], Step: [473/591], Loss: 245631936.0, KL Divergence: 874.6673583984375, Reconstruction Loss: 245631056.0\n",
      "589it [00:54, 11.18it/s]2023-07-19 16:04:42,563 - INFO - Epoch: [292/600], Step: [591/591], Loss: 186121632.0, KL Divergence: 886.9954833984375, Reconstruction Loss: 186120752.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 16:04:42,565 - INFO - Epoch: [292/600], Total Loss: 15438240600064.0, Total KL Divergence: 66040209.5625, Total Reconstruction Loss: 15438174598144.0\n",
      "2023-07-19 16:04:42,611 - INFO - Save model at epoch 292\n",
      "0it [00:00, ?it/s]2023-07-19 16:04:42,728 - INFO - Epoch: [293/600], Step: [1/591], Loss: 116582768.0, KL Divergence: 885.0224609375, Reconstruction Loss: 116581880.0\n",
      "118it [00:10, 11.12it/s]2023-07-19 16:04:53,397 - INFO - Epoch: [293/600], Step: [119/591], Loss: 270378304.0, KL Divergence: 867.8660278320312, Reconstruction Loss: 270377440.0\n",
      "236it [00:21, 10.44it/s]2023-07-19 16:05:04,187 - INFO - Epoch: [293/600], Step: [237/591], Loss: 219751072.0, KL Divergence: 872.1484375, Reconstruction Loss: 219750192.0\n",
      "354it [00:32, 10.59it/s]2023-07-19 16:05:15,323 - INFO - Epoch: [293/600], Step: [355/591], Loss: 264209184.0, KL Divergence: 869.7151489257812, Reconstruction Loss: 264208320.0\n",
      "472it [00:43, 10.48it/s]2023-07-19 16:05:26,675 - INFO - Epoch: [293/600], Step: [473/591], Loss: 268239152.0, KL Divergence: 881.5047607421875, Reconstruction Loss: 268238272.0\n",
      "589it [00:55, 10.58it/s]2023-07-19 16:05:37,846 - INFO - Epoch: [293/600], Step: [591/591], Loss: 188784048.0, KL Divergence: 882.7708740234375, Reconstruction Loss: 188783168.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 16:05:37,848 - INFO - Epoch: [293/600], Total Loss: 15373052125184.0, Total KL Divergence: 66061324.671875, Total Reconstruction Loss: 15372986099712.0\n",
      "2023-07-19 16:05:37,889 - INFO - Save model at epoch 293\n",
      "0it [00:00, ?it/s]2023-07-19 16:05:38,001 - INFO - Epoch: [294/600], Step: [1/591], Loss: 122902464.0, KL Divergence: 880.1170654296875, Reconstruction Loss: 122901584.0\n",
      "117it [00:11, 10.86it/s]2023-07-19 16:05:49,109 - INFO - Epoch: [294/600], Step: [119/591], Loss: 272087616.0, KL Divergence: 871.031005859375, Reconstruction Loss: 272086752.0\n",
      "235it [00:22, 10.15it/s]2023-07-19 16:06:00,352 - INFO - Epoch: [294/600], Step: [237/591], Loss: 217148336.0, KL Divergence: 875.8809814453125, Reconstruction Loss: 217147456.0\n",
      "353it [00:33, 11.04it/s]2023-07-19 16:06:11,386 - INFO - Epoch: [294/600], Step: [355/591], Loss: 285210976.0, KL Divergence: 868.3516845703125, Reconstruction Loss: 285210112.0\n",
      "471it [00:44, 10.75it/s]2023-07-19 16:06:22,377 - INFO - Epoch: [294/600], Step: [473/591], Loss: 246445840.0, KL Divergence: 878.1680908203125, Reconstruction Loss: 246444960.0\n",
      "590it [00:55, 10.70it/s]2023-07-19 16:06:33,377 - INFO - Epoch: [294/600], Step: [591/591], Loss: 182575488.0, KL Divergence: 889.7401123046875, Reconstruction Loss: 182574592.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 16:06:33,379 - INFO - Epoch: [294/600], Total Loss: 15449962866688.0, Total KL Divergence: 66068923.875, Total Reconstruction Loss: 15449896816640.0\n",
      "2023-07-19 16:06:33,427 - INFO - Save model at epoch 294\n",
      "0it [00:00, ?it/s]2023-07-19 16:06:33,546 - INFO - Epoch: [295/600], Step: [1/591], Loss: 110673480.0, KL Divergence: 886.7373046875, Reconstruction Loss: 110672592.0\n",
      "117it [00:11, 10.87it/s]2023-07-19 16:06:44,653 - INFO - Epoch: [295/600], Step: [119/591], Loss: 272373376.0, KL Divergence: 866.6769409179688, Reconstruction Loss: 272372512.0\n",
      "236it [00:22, 10.87it/s]2023-07-19 16:06:55,806 - INFO - Epoch: [295/600], Step: [237/591], Loss: 221537776.0, KL Divergence: 881.064453125, Reconstruction Loss: 221536896.0\n",
      "354it [00:33, 11.15it/s]2023-07-19 16:07:06,709 - INFO - Epoch: [295/600], Step: [355/591], Loss: 272500000.0, KL Divergence: 872.277587890625, Reconstruction Loss: 272499136.0\n",
      "472it [00:44, 10.69it/s]2023-07-19 16:07:17,588 - INFO - Epoch: [295/600], Step: [473/591], Loss: 243701664.0, KL Divergence: 861.7681274414062, Reconstruction Loss: 243700800.0\n",
      "590it [00:54, 11.23it/s]2023-07-19 16:07:28,419 - INFO - Epoch: [295/600], Step: [591/591], Loss: 187187680.0, KL Divergence: 881.73681640625, Reconstruction Loss: 187186800.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 16:07:28,420 - INFO - Epoch: [295/600], Total Loss: 15611714360320.0, Total KL Divergence: 65980159.03125, Total Reconstruction Loss: 15611648404480.0\n",
      "2023-07-19 16:07:28,475 - INFO - Save model at epoch 295\n",
      "0it [00:00, ?it/s]2023-07-19 16:07:28,587 - INFO - Epoch: [296/600], Step: [1/591], Loss: 121766528.0, KL Divergence: 877.7074584960938, Reconstruction Loss: 121765648.0\n",
      "117it [00:10, 10.93it/s]2023-07-19 16:07:39,445 - INFO - Epoch: [296/600], Step: [119/591], Loss: 270854208.0, KL Divergence: 859.2072143554688, Reconstruction Loss: 270853344.0\n",
      "235it [00:21, 10.59it/s]2023-07-19 16:07:50,384 - INFO - Epoch: [296/600], Step: [237/591], Loss: 248611008.0, KL Divergence: 875.8638916015625, Reconstruction Loss: 248610128.0\n",
      "353it [00:32, 10.81it/s]2023-07-19 16:08:01,285 - INFO - Epoch: [296/600], Step: [355/591], Loss: 311920416.0, KL Divergence: 871.103515625, Reconstruction Loss: 311919552.0\n",
      "471it [00:43, 10.79it/s]2023-07-19 16:08:12,461 - INFO - Epoch: [296/600], Step: [473/591], Loss: 248521616.0, KL Divergence: 880.4486083984375, Reconstruction Loss: 248520736.0\n",
      "589it [00:54, 10.64it/s]2023-07-19 16:08:23,508 - INFO - Epoch: [296/600], Step: [591/591], Loss: 187553696.0, KL Divergence: 885.04541015625, Reconstruction Loss: 187552816.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 16:08:23,509 - INFO - Epoch: [296/600], Total Loss: 15511117421568.0, Total KL Divergence: 66011405.015625, Total Reconstruction Loss: 15511051416576.0\n",
      "2023-07-19 16:08:23,550 - INFO - Save model at epoch 296\n",
      "0it [00:00, ?it/s]2023-07-19 16:08:23,688 - INFO - Epoch: [297/600], Step: [1/591], Loss: 127302424.0, KL Divergence: 881.911865234375, Reconstruction Loss: 127301544.0\n",
      "117it [00:11, 10.19it/s]2023-07-19 16:08:34,812 - INFO - Epoch: [297/600], Step: [119/591], Loss: 274019808.0, KL Divergence: 864.6742553710938, Reconstruction Loss: 274018944.0\n",
      "236it [00:22, 10.67it/s]2023-07-19 16:08:45,937 - INFO - Epoch: [297/600], Step: [237/591], Loss: 212026080.0, KL Divergence: 878.441162109375, Reconstruction Loss: 212025200.0\n",
      "354it [00:33, 10.65it/s]2023-07-19 16:08:57,133 - INFO - Epoch: [297/600], Step: [355/591], Loss: 273734368.0, KL Divergence: 871.1522827148438, Reconstruction Loss: 273733504.0\n",
      "472it [00:44, 10.61it/s]2023-07-19 16:09:08,183 - INFO - Epoch: [297/600], Step: [473/591], Loss: 238495552.0, KL Divergence: 877.7454833984375, Reconstruction Loss: 238494672.0\n",
      "590it [00:55, 10.68it/s]2023-07-19 16:09:19,139 - INFO - Epoch: [297/600], Step: [591/591], Loss: 184302336.0, KL Divergence: 889.4820556640625, Reconstruction Loss: 184301440.0\n",
      "591it [00:55, 10.63it/s]\n",
      "2023-07-19 16:09:19,140 - INFO - Epoch: [297/600], Total Loss: 15382057421824.0, Total KL Divergence: 66165339.59375, Total Reconstruction Loss: 15381991241728.0\n",
      "2023-07-19 16:09:19,191 - INFO - Save model at epoch 297\n",
      "0it [00:00, ?it/s]2023-07-19 16:09:19,310 - INFO - Epoch: [298/600], Step: [1/591], Loss: 111314456.0, KL Divergence: 887.22509765625, Reconstruction Loss: 111313568.0\n",
      "117it [00:10, 10.86it/s]2023-07-19 16:09:30,240 - INFO - Epoch: [298/600], Step: [119/591], Loss: 273482624.0, KL Divergence: 864.4368896484375, Reconstruction Loss: 273481760.0\n",
      "235it [00:22, 10.57it/s]2023-07-19 16:09:41,499 - INFO - Epoch: [298/600], Step: [237/591], Loss: 211776720.0, KL Divergence: 876.97705078125, Reconstruction Loss: 211775840.0\n",
      "353it [00:33, 10.23it/s]2023-07-19 16:09:52,557 - INFO - Epoch: [298/600], Step: [355/591], Loss: 269318624.0, KL Divergence: 873.5150146484375, Reconstruction Loss: 269317760.0\n",
      "471it [00:44, 10.15it/s]2023-07-19 16:10:03,791 - INFO - Epoch: [298/600], Step: [473/591], Loss: 237654976.0, KL Divergence: 871.507568359375, Reconstruction Loss: 237654112.0\n",
      "589it [00:55, 10.63it/s]2023-07-19 16:10:14,844 - INFO - Epoch: [298/600], Step: [591/591], Loss: 183889504.0, KL Divergence: 883.7318115234375, Reconstruction Loss: 183888624.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 16:10:14,846 - INFO - Epoch: [298/600], Total Loss: 15301661501440.0, Total KL Divergence: 65967083.078125, Total Reconstruction Loss: 15301595568128.0\n",
      "2023-07-19 16:10:14,885 - INFO - Save model at epoch 298\n",
      "0it [00:00, ?it/s]2023-07-19 16:10:15,009 - INFO - Epoch: [299/600], Step: [1/591], Loss: 110737696.0, KL Divergence: 882.8463134765625, Reconstruction Loss: 110736816.0\n",
      "117it [00:10, 10.67it/s]2023-07-19 16:10:26,019 - INFO - Epoch: [299/600], Step: [119/591], Loss: 284619616.0, KL Divergence: 862.9583740234375, Reconstruction Loss: 284618752.0\n",
      "235it [00:22,  9.31it/s]2023-07-19 16:10:37,173 - INFO - Epoch: [299/600], Step: [237/591], Loss: 216075312.0, KL Divergence: 874.9317016601562, Reconstruction Loss: 216074432.0\n",
      "354it [00:33, 10.77it/s]2023-07-19 16:10:48,181 - INFO - Epoch: [299/600], Step: [355/591], Loss: 266366208.0, KL Divergence: 869.5, Reconstruction Loss: 266365344.0\n",
      "472it [00:44, 10.83it/s]2023-07-19 16:10:59,289 - INFO - Epoch: [299/600], Step: [473/591], Loss: 250396256.0, KL Divergence: 870.5723266601562, Reconstruction Loss: 250395392.0\n",
      "590it [00:55, 10.75it/s]2023-07-19 16:11:10,311 - INFO - Epoch: [299/600], Step: [591/591], Loss: 182167376.0, KL Divergence: 884.12109375, Reconstruction Loss: 182166496.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 16:11:10,313 - INFO - Epoch: [299/600], Total Loss: 15302968328192.0, Total KL Divergence: 65842241.953125, Total Reconstruction Loss: 15302902544384.0\n",
      "2023-07-19 16:11:10,352 - INFO - Save model at epoch 299\n",
      "0it [00:00, ?it/s]2023-07-19 16:11:10,487 - INFO - Epoch: [300/600], Step: [1/591], Loss: 110489200.0, KL Divergence: 883.368408203125, Reconstruction Loss: 110488320.0\n",
      "117it [00:10, 10.54it/s]2023-07-19 16:11:21,501 - INFO - Epoch: [300/600], Step: [119/591], Loss: 281763712.0, KL Divergence: 862.582763671875, Reconstruction Loss: 281762848.0\n",
      "235it [00:21, 10.58it/s]2023-07-19 16:11:32,545 - INFO - Epoch: [300/600], Step: [237/591], Loss: 214711248.0, KL Divergence: 873.9290771484375, Reconstruction Loss: 214710368.0\n",
      "353it [00:32, 10.51it/s]2023-07-19 16:11:43,461 - INFO - Epoch: [300/600], Step: [355/591], Loss: 271278816.0, KL Divergence: 866.3260498046875, Reconstruction Loss: 271277952.0\n",
      "471it [00:43, 10.74it/s]2023-07-19 16:11:54,479 - INFO - Epoch: [300/600], Step: [473/591], Loss: 239782912.0, KL Divergence: 869.148681640625, Reconstruction Loss: 239782048.0\n",
      "589it [00:55, 10.48it/s]2023-07-19 16:12:05,692 - INFO - Epoch: [300/600], Step: [591/591], Loss: 187583904.0, KL Divergence: 874.4918212890625, Reconstruction Loss: 187583024.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 16:12:05,694 - INFO - Epoch: [300/600], Total Loss: 15210284123136.0, Total KL Divergence: 65622435.015625, Total Reconstruction Loss: 15210218483712.0\n",
      "2023-07-19 16:12:05,737 - INFO - Save model at epoch 300\n",
      "0it [00:00, ?it/s]2023-07-19 16:12:05,880 - INFO - Epoch: [301/600], Step: [1/591], Loss: 118033656.0, KL Divergence: 873.5576171875, Reconstruction Loss: 118032784.0\n",
      "118it [00:11, 10.68it/s]2023-07-19 16:12:17,118 - INFO - Epoch: [301/600], Step: [119/591], Loss: 276447584.0, KL Divergence: 865.7081298828125, Reconstruction Loss: 276446720.0\n",
      "236it [00:22, 10.49it/s]2023-07-19 16:12:28,036 - INFO - Epoch: [301/600], Step: [237/591], Loss: 211408688.0, KL Divergence: 871.6470947265625, Reconstruction Loss: 211407824.0\n",
      "354it [00:33, 10.63it/s]2023-07-19 16:12:39,056 - INFO - Epoch: [301/600], Step: [355/591], Loss: 261803184.0, KL Divergence: 870.9357299804688, Reconstruction Loss: 261802320.0\n",
      "472it [00:44, 10.41it/s]2023-07-19 16:12:50,183 - INFO - Epoch: [301/600], Step: [473/591], Loss: 250615504.0, KL Divergence: 884.6690673828125, Reconstruction Loss: 250614624.0\n",
      "590it [00:55, 11.14it/s]2023-07-19 16:13:01,271 - INFO - Epoch: [301/600], Step: [591/591], Loss: 184567072.0, KL Divergence: 889.8660888671875, Reconstruction Loss: 184566176.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 16:13:01,272 - INFO - Epoch: [301/600], Total Loss: 15207966808064.0, Total KL Divergence: 66042138.9921875, Total Reconstruction Loss: 15207900794880.0\n",
      "2023-07-19 16:13:01,312 - INFO - Save model at epoch 301\n",
      "0it [00:00, ?it/s]2023-07-19 16:13:01,412 - INFO - Epoch: [302/600], Step: [1/591], Loss: 113277960.0, KL Divergence: 887.6207275390625, Reconstruction Loss: 113277072.0\n",
      "118it [00:10, 11.08it/s]2023-07-19 16:13:12,205 - INFO - Epoch: [302/600], Step: [119/591], Loss: 270692384.0, KL Divergence: 875.3623046875, Reconstruction Loss: 270691520.0\n",
      "236it [00:21, 10.57it/s]2023-07-19 16:13:22,974 - INFO - Epoch: [302/600], Step: [237/591], Loss: 218878928.0, KL Divergence: 875.77197265625, Reconstruction Loss: 218878048.0\n",
      "354it [00:32, 11.02it/s]2023-07-19 16:13:33,759 - INFO - Epoch: [302/600], Step: [355/591], Loss: 282633600.0, KL Divergence: 880.5927124023438, Reconstruction Loss: 282632704.0\n",
      "472it [00:43, 11.03it/s]2023-07-19 16:13:44,505 - INFO - Epoch: [302/600], Step: [473/591], Loss: 237480848.0, KL Divergence: 887.489990234375, Reconstruction Loss: 237479968.0\n",
      "590it [00:53, 11.26it/s]2023-07-19 16:13:55,224 - INFO - Epoch: [302/600], Step: [591/591], Loss: 189726576.0, KL Divergence: 900.5661010742188, Reconstruction Loss: 189725680.0\n",
      "591it [00:53, 10.96it/s]\n",
      "2023-07-19 16:13:55,226 - INFO - Epoch: [302/600], Total Loss: 15394103030784.0, Total KL Divergence: 66762094.265625, Total Reconstruction Loss: 15394036254720.0\n",
      "2023-07-19 16:13:55,299 - INFO - Save model at epoch 302\n",
      "0it [00:00, ?it/s]2023-07-19 16:13:55,407 - INFO - Epoch: [303/600], Step: [1/591], Loss: 110838728.0, KL Divergence: 900.470458984375, Reconstruction Loss: 110837824.0\n",
      "118it [00:10, 10.74it/s]2023-07-19 16:14:06,198 - INFO - Epoch: [303/600], Step: [119/591], Loss: 269236640.0, KL Divergence: 887.22021484375, Reconstruction Loss: 269235744.0\n",
      "236it [00:21, 10.15it/s]2023-07-19 16:14:16,990 - INFO - Epoch: [303/600], Step: [237/591], Loss: 218459008.0, KL Divergence: 888.3223876953125, Reconstruction Loss: 218458112.0\n",
      "354it [00:32, 10.70it/s]2023-07-19 16:14:27,659 - INFO - Epoch: [303/600], Step: [355/591], Loss: 286974688.0, KL Divergence: 884.37109375, Reconstruction Loss: 286973792.0\n",
      "472it [00:43, 11.07it/s]2023-07-19 16:14:38,522 - INFO - Epoch: [303/600], Step: [473/591], Loss: 235559648.0, KL Divergence: 889.00390625, Reconstruction Loss: 235558752.0\n",
      "590it [00:53, 11.31it/s]2023-07-19 16:14:49,225 - INFO - Epoch: [303/600], Step: [591/591], Loss: 188174384.0, KL Divergence: 894.8290405273438, Reconstruction Loss: 188173488.0\n",
      "591it [00:53, 10.96it/s]\n",
      "2023-07-19 16:14:49,227 - INFO - Epoch: [303/600], Total Loss: 15355279035392.0, Total KL Divergence: 67256535.890625, Total Reconstruction Loss: 15355211722752.0\n",
      "2023-07-19 16:14:49,271 - INFO - Save model at epoch 303\n",
      "0it [00:00, ?it/s]2023-07-19 16:14:49,376 - INFO - Epoch: [304/600], Step: [1/591], Loss: 110707440.0, KL Divergence: 895.19189453125, Reconstruction Loss: 110706544.0\n",
      "118it [00:10, 11.16it/s]2023-07-19 16:15:00,095 - INFO - Epoch: [304/600], Step: [119/591], Loss: 267651072.0, KL Divergence: 885.214599609375, Reconstruction Loss: 267650192.0\n",
      "236it [00:21, 10.99it/s]2023-07-19 16:15:10,860 - INFO - Epoch: [304/600], Step: [237/591], Loss: 217408224.0, KL Divergence: 879.3642578125, Reconstruction Loss: 217407344.0\n",
      "354it [00:32, 11.09it/s]2023-07-19 16:15:21,644 - INFO - Epoch: [304/600], Step: [355/591], Loss: 275459680.0, KL Divergence: 885.2154541015625, Reconstruction Loss: 275458784.0\n",
      "472it [00:43, 10.84it/s]2023-07-19 16:15:32,382 - INFO - Epoch: [304/600], Step: [473/591], Loss: 231509776.0, KL Divergence: 883.369384765625, Reconstruction Loss: 231508896.0\n",
      "590it [00:53, 10.98it/s]2023-07-19 16:15:43,148 - INFO - Epoch: [304/600], Step: [591/591], Loss: 185846304.0, KL Divergence: 899.0724487304688, Reconstruction Loss: 185845408.0\n",
      "591it [00:53, 10.97it/s]\n",
      "2023-07-19 16:15:43,149 - INFO - Epoch: [304/600], Total Loss: 15354179343360.0, Total KL Divergence: 67010434.3125, Total Reconstruction Loss: 15354112331776.0\n",
      "2023-07-19 16:15:43,196 - INFO - Save model at epoch 304\n",
      "0it [00:00, ?it/s]2023-07-19 16:15:43,292 - INFO - Epoch: [305/600], Step: [1/591], Loss: 137475232.0, KL Divergence: 897.7684326171875, Reconstruction Loss: 137474336.0\n",
      "118it [00:10, 10.57it/s]2023-07-19 16:15:54,140 - INFO - Epoch: [305/600], Step: [119/591], Loss: 278605696.0, KL Divergence: 883.2837524414062, Reconstruction Loss: 278604800.0\n",
      "236it [00:21, 11.07it/s]2023-07-19 16:16:04,917 - INFO - Epoch: [305/600], Step: [237/591], Loss: 228964784.0, KL Divergence: 887.0953369140625, Reconstruction Loss: 228963904.0\n",
      "354it [00:32, 10.88it/s]2023-07-19 16:16:15,826 - INFO - Epoch: [305/600], Step: [355/591], Loss: 268746208.0, KL Divergence: 884.8699340820312, Reconstruction Loss: 268745312.0\n",
      "472it [00:43, 10.83it/s]2023-07-19 16:16:26,615 - INFO - Epoch: [305/600], Step: [473/591], Loss: 243661360.0, KL Divergence: 886.2625732421875, Reconstruction Loss: 243660480.0\n",
      "590it [00:54, 10.73it/s]2023-07-19 16:16:37,389 - INFO - Epoch: [305/600], Step: [591/591], Loss: 185039536.0, KL Divergence: 897.6701049804688, Reconstruction Loss: 185038640.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 16:16:37,391 - INFO - Epoch: [305/600], Total Loss: 15198704250880.0, Total KL Divergence: 67093507.9375, Total Reconstruction Loss: 15198637150208.0\n",
      "2023-07-19 16:16:37,430 - INFO - Save model at epoch 305\n",
      "0it [00:00, ?it/s]2023-07-19 16:16:37,538 - INFO - Epoch: [306/600], Step: [1/591], Loss: 115982768.0, KL Divergence: 897.1466674804688, Reconstruction Loss: 115981872.0\n",
      "118it [00:10, 11.43it/s]2023-07-19 16:16:48,227 - INFO - Epoch: [306/600], Step: [119/591], Loss: 282601088.0, KL Divergence: 884.7999877929688, Reconstruction Loss: 282600192.0\n",
      "236it [00:21, 10.09it/s]2023-07-19 16:16:59,066 - INFO - Epoch: [306/600], Step: [237/591], Loss: 221954416.0, KL Divergence: 887.9142456054688, Reconstruction Loss: 221953536.0\n",
      "354it [00:32, 11.08it/s]2023-07-19 16:17:09,812 - INFO - Epoch: [306/600], Step: [355/591], Loss: 272679680.0, KL Divergence: 887.566162109375, Reconstruction Loss: 272678784.0\n",
      "472it [00:42, 11.29it/s]2023-07-19 16:17:20,532 - INFO - Epoch: [306/600], Step: [473/591], Loss: 261628032.0, KL Divergence: 891.0250244140625, Reconstruction Loss: 261627136.0\n",
      "590it [00:53, 11.20it/s]2023-07-19 16:17:31,241 - INFO - Epoch: [306/600], Step: [591/591], Loss: 187938048.0, KL Divergence: 890.539794921875, Reconstruction Loss: 187937152.0\n",
      "591it [00:53, 10.99it/s]\n",
      "2023-07-19 16:17:31,242 - INFO - Epoch: [306/600], Total Loss: 15085120166912.0, Total KL Divergence: 67144756.8046875, Total Reconstruction Loss: 15085052990464.0\n",
      "2023-07-19 16:17:31,293 - INFO - Save model at epoch 306\n",
      "0it [00:00, ?it/s]2023-07-19 16:17:31,396 - INFO - Epoch: [307/600], Step: [1/591], Loss: 125216664.0, KL Divergence: 889.837890625, Reconstruction Loss: 125215776.0\n",
      "118it [00:10, 11.22it/s]2023-07-19 16:17:42,085 - INFO - Epoch: [307/600], Step: [119/591], Loss: 295392192.0, KL Divergence: 888.9442138671875, Reconstruction Loss: 295391296.0\n",
      "236it [00:21,  9.91it/s]2023-07-19 16:17:52,856 - INFO - Epoch: [307/600], Step: [237/591], Loss: 218688240.0, KL Divergence: 891.8423461914062, Reconstruction Loss: 218687344.0\n",
      "354it [00:32, 10.81it/s]2023-07-19 16:18:03,654 - INFO - Epoch: [307/600], Step: [355/591], Loss: 266633632.0, KL Divergence: 896.3350830078125, Reconstruction Loss: 266632736.0\n",
      "472it [00:43, 10.95it/s]2023-07-19 16:18:14,429 - INFO - Epoch: [307/600], Step: [473/591], Loss: 258230432.0, KL Divergence: 897.638427734375, Reconstruction Loss: 258229536.0\n",
      "590it [00:53, 10.86it/s]2023-07-19 16:18:25,169 - INFO - Epoch: [307/600], Step: [591/591], Loss: 179035840.0, KL Divergence: 910.0133666992188, Reconstruction Loss: 179034928.0\n",
      "591it [00:53, 10.97it/s]\n",
      "2023-07-19 16:18:25,170 - INFO - Epoch: [307/600], Total Loss: 15048759990272.0, Total KL Divergence: 67636676.6953125, Total Reconstruction Loss: 15048692352000.0\n",
      "2023-07-19 16:18:25,211 - INFO - Save model at epoch 307\n",
      "0it [00:00, ?it/s]2023-07-19 16:18:25,321 - INFO - Epoch: [308/600], Step: [1/591], Loss: 111377264.0, KL Divergence: 907.496337890625, Reconstruction Loss: 111376360.0\n",
      "118it [00:10, 11.23it/s]2023-07-19 16:18:36,027 - INFO - Epoch: [308/600], Step: [119/591], Loss: 273231424.0, KL Divergence: 887.798095703125, Reconstruction Loss: 273230528.0\n",
      "236it [00:21, 11.25it/s]2023-07-19 16:18:46,778 - INFO - Epoch: [308/600], Step: [237/591], Loss: 221382624.0, KL Divergence: 899.3851318359375, Reconstruction Loss: 221381728.0\n",
      "354it [00:32, 10.76it/s]2023-07-19 16:18:57,560 - INFO - Epoch: [308/600], Step: [355/591], Loss: 258729056.0, KL Divergence: 892.24267578125, Reconstruction Loss: 258728160.0\n",
      "472it [00:42, 10.80it/s]2023-07-19 16:19:08,334 - INFO - Epoch: [308/600], Step: [473/591], Loss: 245705312.0, KL Divergence: 895.985595703125, Reconstruction Loss: 245704416.0\n",
      "590it [00:53, 11.00it/s]2023-07-19 16:19:19,034 - INFO - Epoch: [308/600], Step: [591/591], Loss: 177825344.0, KL Divergence: 901.5809326171875, Reconstruction Loss: 177824448.0\n",
      "591it [00:53, 10.98it/s]\n",
      "2023-07-19 16:19:19,035 - INFO - Epoch: [308/600], Total Loss: 15189562498048.0, Total KL Divergence: 67656598.6875, Total Reconstruction Loss: 15189494834176.0\n",
      "2023-07-19 16:19:19,081 - INFO - Save model at epoch 308\n",
      "0it [00:00, ?it/s]2023-07-19 16:19:19,179 - INFO - Epoch: [309/600], Step: [1/591], Loss: 116750632.0, KL Divergence: 900.113037109375, Reconstruction Loss: 116749728.0\n",
      "118it [00:10, 11.16it/s]2023-07-19 16:19:29,890 - INFO - Epoch: [309/600], Step: [119/591], Loss: 269768384.0, KL Divergence: 888.642333984375, Reconstruction Loss: 269767488.0\n",
      "236it [00:21, 11.03it/s]2023-07-19 16:19:40,736 - INFO - Epoch: [309/600], Step: [237/591], Loss: 219096032.0, KL Divergence: 900.4589233398438, Reconstruction Loss: 219095136.0\n",
      "354it [00:32, 11.14it/s]2023-07-19 16:19:51,573 - INFO - Epoch: [309/600], Step: [355/591], Loss: 260598864.0, KL Divergence: 901.135009765625, Reconstruction Loss: 260597968.0\n",
      "472it [00:43, 10.86it/s]2023-07-19 16:20:02,295 - INFO - Epoch: [309/600], Step: [473/591], Loss: 234872256.0, KL Divergence: 902.7744140625, Reconstruction Loss: 234871360.0\n",
      "590it [00:53, 11.59it/s]2023-07-19 16:20:13,028 - INFO - Epoch: [309/600], Step: [591/591], Loss: 184409296.0, KL Divergence: 909.61083984375, Reconstruction Loss: 184408384.0\n",
      "591it [00:53, 10.96it/s]\n",
      "2023-07-19 16:20:13,029 - INFO - Epoch: [309/600], Total Loss: 15376959810560.0, Total KL Divergence: 67902669.484375, Total Reconstruction Loss: 15376891921408.0\n",
      "2023-07-19 16:20:13,073 - INFO - Save model at epoch 309\n",
      "0it [00:00, ?it/s]2023-07-19 16:20:13,176 - INFO - Epoch: [310/600], Step: [1/591], Loss: 119663640.0, KL Divergence: 907.174560546875, Reconstruction Loss: 119662736.0\n",
      "118it [00:10, 10.86it/s]2023-07-19 16:20:23,938 - INFO - Epoch: [310/600], Step: [119/591], Loss: 269424800.0, KL Divergence: 893.7344970703125, Reconstruction Loss: 269423904.0\n",
      "236it [00:21, 10.86it/s]2023-07-19 16:20:34,752 - INFO - Epoch: [310/600], Step: [237/591], Loss: 216063920.0, KL Divergence: 905.3436889648438, Reconstruction Loss: 216063008.0\n",
      "354it [00:32, 11.04it/s]2023-07-19 16:20:45,486 - INFO - Epoch: [310/600], Step: [355/591], Loss: 264217872.0, KL Divergence: 901.493408203125, Reconstruction Loss: 264216976.0\n",
      "472it [00:42, 11.13it/s]2023-07-19 16:20:56,170 - INFO - Epoch: [310/600], Step: [473/591], Loss: 228703664.0, KL Divergence: 906.8157348632812, Reconstruction Loss: 228702752.0\n",
      "590it [00:53, 11.14it/s]2023-07-19 16:21:06,894 - INFO - Epoch: [310/600], Step: [591/591], Loss: 186118640.0, KL Divergence: 912.3248901367188, Reconstruction Loss: 186117728.0\n",
      "591it [00:53, 10.98it/s]\n",
      "2023-07-19 16:21:06,896 - INFO - Epoch: [310/600], Total Loss: 15123378696192.0, Total KL Divergence: 68205237.53125, Total Reconstruction Loss: 15123310505984.0\n",
      "2023-07-19 16:21:06,952 - INFO - Save model at epoch 310\n",
      "0it [00:00, ?it/s]2023-07-19 16:21:07,066 - INFO - Epoch: [311/600], Step: [1/591], Loss: 110788912.0, KL Divergence: 911.340576171875, Reconstruction Loss: 110788000.0\n",
      "118it [00:10, 11.02it/s]2023-07-19 16:21:17,822 - INFO - Epoch: [311/600], Step: [119/591], Loss: 268933184.0, KL Divergence: 896.355224609375, Reconstruction Loss: 268932288.0\n",
      "236it [00:21, 11.07it/s]2023-07-19 16:21:28,582 - INFO - Epoch: [311/600], Step: [237/591], Loss: 210759424.0, KL Divergence: 901.7265625, Reconstruction Loss: 210758528.0\n",
      "354it [00:32, 10.72it/s]2023-07-19 16:21:39,436 - INFO - Epoch: [311/600], Step: [355/591], Loss: 262077520.0, KL Divergence: 901.7369384765625, Reconstruction Loss: 262076624.0\n",
      "472it [00:43, 11.16it/s]2023-07-19 16:21:50,106 - INFO - Epoch: [311/600], Step: [473/591], Loss: 228877792.0, KL Divergence: 903.579345703125, Reconstruction Loss: 228876896.0\n",
      "590it [00:53, 10.62it/s]2023-07-19 16:22:00,823 - INFO - Epoch: [311/600], Step: [591/591], Loss: 182315200.0, KL Divergence: 916.6471557617188, Reconstruction Loss: 182314288.0\n",
      "591it [00:53, 10.97it/s]\n",
      "2023-07-19 16:22:00,825 - INFO - Epoch: [311/600], Total Loss: 14902230096896.0, Total KL Divergence: 68195355.3828125, Total Reconstruction Loss: 14902161928192.0\n",
      "2023-07-19 16:22:00,873 - INFO - Save model at epoch 311\n",
      "0it [00:00, ?it/s]2023-07-19 16:22:00,971 - INFO - Epoch: [312/600], Step: [1/591], Loss: 122761184.0, KL Divergence: 913.6812744140625, Reconstruction Loss: 122760272.0\n",
      "118it [00:10, 10.76it/s]2023-07-19 16:22:11,771 - INFO - Epoch: [312/600], Step: [119/591], Loss: 273354688.0, KL Divergence: 897.3702392578125, Reconstruction Loss: 273353792.0\n",
      "236it [00:21, 10.53it/s]2023-07-19 16:22:22,614 - INFO - Epoch: [312/600], Step: [237/591], Loss: 205716448.0, KL Divergence: 897.9583740234375, Reconstruction Loss: 205715552.0\n",
      "354it [00:32, 11.05it/s]2023-07-19 16:22:33,444 - INFO - Epoch: [312/600], Step: [355/591], Loss: 255097360.0, KL Divergence: 904.8335571289062, Reconstruction Loss: 255096448.0\n",
      "472it [00:43, 10.68it/s]2023-07-19 16:22:44,211 - INFO - Epoch: [312/600], Step: [473/591], Loss: 225700800.0, KL Divergence: 900.9483642578125, Reconstruction Loss: 225699904.0\n",
      "590it [00:54, 11.12it/s]2023-07-19 16:22:55,113 - INFO - Epoch: [312/600], Step: [591/591], Loss: 180598160.0, KL Divergence: 912.69677734375, Reconstruction Loss: 180597248.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 16:22:55,114 - INFO - Epoch: [312/600], Total Loss: 14980262924288.0, Total KL Divergence: 68126065.390625, Total Reconstruction Loss: 14980194843648.0\n",
      "2023-07-19 16:22:55,162 - INFO - Save model at epoch 312\n",
      "0it [00:00, ?it/s]2023-07-19 16:22:55,273 - INFO - Epoch: [313/600], Step: [1/591], Loss: 111622480.0, KL Divergence: 910.0344848632812, Reconstruction Loss: 111621568.0\n",
      "117it [00:10, 10.72it/s]2023-07-19 16:23:06,076 - INFO - Epoch: [313/600], Step: [119/591], Loss: 277394304.0, KL Divergence: 898.1129760742188, Reconstruction Loss: 277393408.0\n",
      "235it [00:21, 11.16it/s]2023-07-19 16:23:16,848 - INFO - Epoch: [313/600], Step: [237/591], Loss: 224227008.0, KL Divergence: 900.1070556640625, Reconstruction Loss: 224226112.0\n",
      "353it [00:32, 11.09it/s]2023-07-19 16:23:27,680 - INFO - Epoch: [313/600], Step: [355/591], Loss: 265976832.0, KL Divergence: 899.2293701171875, Reconstruction Loss: 265975936.0\n",
      "471it [00:43, 10.83it/s]2023-07-19 16:23:38,408 - INFO - Epoch: [313/600], Step: [473/591], Loss: 241014208.0, KL Divergence: 908.758056640625, Reconstruction Loss: 241013296.0\n",
      "589it [00:53, 10.97it/s]2023-07-19 16:23:49,189 - INFO - Epoch: [313/600], Step: [591/591], Loss: 183816704.0, KL Divergence: 922.3421630859375, Reconstruction Loss: 183815776.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 16:23:49,192 - INFO - Epoch: [313/600], Total Loss: 15237091858432.0, Total KL Divergence: 68141815.4140625, Total Reconstruction Loss: 15237023724544.0\n",
      "2023-07-19 16:23:49,233 - INFO - Save model at epoch 313\n",
      "0it [00:00, ?it/s]2023-07-19 16:23:49,333 - INFO - Epoch: [314/600], Step: [1/591], Loss: 113421400.0, KL Divergence: 919.259765625, Reconstruction Loss: 113420480.0\n",
      "118it [00:10, 11.04it/s]2023-07-19 16:24:00,175 - INFO - Epoch: [314/600], Step: [119/591], Loss: 269806016.0, KL Divergence: 902.3859252929688, Reconstruction Loss: 269805120.0\n",
      "236it [00:21, 10.99it/s]2023-07-19 16:24:11,020 - INFO - Epoch: [314/600], Step: [237/591], Loss: 212884528.0, KL Divergence: 914.039306640625, Reconstruction Loss: 212883616.0\n",
      "354it [00:32, 10.81it/s]2023-07-19 16:24:21,855 - INFO - Epoch: [314/600], Step: [355/591], Loss: 259208496.0, KL Divergence: 914.1263427734375, Reconstruction Loss: 259207584.0\n",
      "472it [00:43, 11.05it/s]2023-07-19 16:24:32,695 - INFO - Epoch: [314/600], Step: [473/591], Loss: 243096752.0, KL Divergence: 909.573974609375, Reconstruction Loss: 243095840.0\n",
      "590it [00:54, 11.05it/s]2023-07-19 16:24:43,464 - INFO - Epoch: [314/600], Step: [591/591], Loss: 181837312.0, KL Divergence: 921.2182006835938, Reconstruction Loss: 181836384.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 16:24:43,466 - INFO - Epoch: [314/600], Total Loss: 15130336753664.0, Total KL Divergence: 68815426.03125, Total Reconstruction Loss: 15130267920384.0\n",
      "2023-07-19 16:24:43,533 - INFO - Save model at epoch 314\n",
      "0it [00:00, ?it/s]2023-07-19 16:24:43,638 - INFO - Epoch: [315/600], Step: [1/591], Loss: 110456904.0, KL Divergence: 919.2107543945312, Reconstruction Loss: 110455984.0\n",
      "118it [00:10, 10.98it/s]2023-07-19 16:24:54,433 - INFO - Epoch: [315/600], Step: [119/591], Loss: 279954752.0, KL Divergence: 899.041015625, Reconstruction Loss: 279953856.0\n",
      "236it [00:21, 11.15it/s]2023-07-19 16:25:05,137 - INFO - Epoch: [315/600], Step: [237/591], Loss: 218287456.0, KL Divergence: 914.1566162109375, Reconstruction Loss: 218286544.0\n",
      "354it [00:32, 11.15it/s]2023-07-19 16:25:15,957 - INFO - Epoch: [315/600], Step: [355/591], Loss: 262067952.0, KL Divergence: 908.0567626953125, Reconstruction Loss: 262067040.0\n",
      "472it [00:43, 10.85it/s]2023-07-19 16:25:26,720 - INFO - Epoch: [315/600], Step: [473/591], Loss: 242358528.0, KL Divergence: 902.6705322265625, Reconstruction Loss: 242357632.0\n",
      "590it [00:53, 10.57it/s]2023-07-19 16:25:37,546 - INFO - Epoch: [315/600], Step: [591/591], Loss: 180342736.0, KL Divergence: 921.6864624023438, Reconstruction Loss: 180341808.0\n",
      "591it [00:53, 10.94it/s]\n",
      "2023-07-19 16:25:37,548 - INFO - Epoch: [315/600], Total Loss: 14992001435648.0, Total KL Divergence: 68626236.0, Total Reconstruction Loss: 14991932828672.0\n",
      "2023-07-19 16:25:37,586 - INFO - Save model at epoch 315\n",
      "0it [00:00, ?it/s]2023-07-19 16:25:37,689 - INFO - Epoch: [316/600], Step: [1/591], Loss: 110896888.0, KL Divergence: 919.6724853515625, Reconstruction Loss: 110895968.0\n",
      "118it [00:10, 10.93it/s]2023-07-19 16:25:48,378 - INFO - Epoch: [316/600], Step: [119/591], Loss: 264777696.0, KL Divergence: 902.7232666015625, Reconstruction Loss: 264776800.0\n",
      "236it [00:21, 11.08it/s]2023-07-19 16:25:59,245 - INFO - Epoch: [316/600], Step: [237/591], Loss: 206126400.0, KL Divergence: 909.8693237304688, Reconstruction Loss: 206125488.0\n",
      "354it [00:32, 10.85it/s]2023-07-19 16:26:10,043 - INFO - Epoch: [316/600], Step: [355/591], Loss: 262294784.0, KL Divergence: 906.6121826171875, Reconstruction Loss: 262293872.0\n",
      "472it [00:43, 11.02it/s]2023-07-19 16:26:20,850 - INFO - Epoch: [316/600], Step: [473/591], Loss: 229845792.0, KL Divergence: 913.9527587890625, Reconstruction Loss: 229844880.0\n",
      "590it [00:53, 11.24it/s]2023-07-19 16:26:31,626 - INFO - Epoch: [316/600], Step: [591/591], Loss: 197075216.0, KL Divergence: 913.7496337890625, Reconstruction Loss: 197074304.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 16:26:31,627 - INFO - Epoch: [316/600], Total Loss: 14933190849536.0, Total KL Divergence: 68504474.78125, Total Reconstruction Loss: 14933122380800.0\n",
      "2023-07-19 16:26:31,681 - INFO - Save model at epoch 316\n",
      "0it [00:00, ?it/s]2023-07-19 16:26:31,794 - INFO - Epoch: [317/600], Step: [1/591], Loss: 116413664.0, KL Divergence: 912.204345703125, Reconstruction Loss: 116412752.0\n",
      "118it [00:10, 10.90it/s]2023-07-19 16:26:42,509 - INFO - Epoch: [317/600], Step: [119/591], Loss: 265378240.0, KL Divergence: 895.2501831054688, Reconstruction Loss: 265377344.0\n",
      "236it [00:21, 10.89it/s]2023-07-19 16:26:53,288 - INFO - Epoch: [317/600], Step: [237/591], Loss: 215199584.0, KL Divergence: 907.2660522460938, Reconstruction Loss: 215198672.0\n",
      "354it [00:32, 11.19it/s]2023-07-19 16:27:04,169 - INFO - Epoch: [317/600], Step: [355/591], Loss: 257698656.0, KL Divergence: 904.48974609375, Reconstruction Loss: 257697744.0\n",
      "472it [00:43, 10.93it/s]2023-07-19 16:27:14,888 - INFO - Epoch: [317/600], Step: [473/591], Loss: 231780368.0, KL Divergence: 913.8395385742188, Reconstruction Loss: 231779456.0\n",
      "590it [00:53, 10.91it/s]2023-07-19 16:27:25,623 - INFO - Epoch: [317/600], Step: [591/591], Loss: 183298304.0, KL Divergence: 921.493896484375, Reconstruction Loss: 183297376.0\n",
      "591it [00:53, 10.96it/s]\n",
      "2023-07-19 16:27:25,625 - INFO - Epoch: [317/600], Total Loss: 14961867520000.0, Total KL Divergence: 68539592.90625, Total Reconstruction Loss: 14961799009280.0\n",
      "2023-07-19 16:27:25,667 - INFO - Save model at epoch 317\n",
      "0it [00:00, ?it/s]2023-07-19 16:27:25,771 - INFO - Epoch: [318/600], Step: [1/591], Loss: 111930240.0, KL Divergence: 919.7394409179688, Reconstruction Loss: 111929320.0\n",
      "118it [00:10, 10.96it/s]2023-07-19 16:27:36,501 - INFO - Epoch: [318/600], Step: [119/591], Loss: 265497344.0, KL Divergence: 908.906982421875, Reconstruction Loss: 265496432.0\n",
      "236it [00:21, 11.12it/s]2023-07-19 16:27:47,300 - INFO - Epoch: [318/600], Step: [237/591], Loss: 206949008.0, KL Divergence: 908.5882568359375, Reconstruction Loss: 206948096.0\n",
      "354it [00:32, 11.00it/s]2023-07-19 16:27:58,198 - INFO - Epoch: [318/600], Step: [355/591], Loss: 262591024.0, KL Divergence: 907.557861328125, Reconstruction Loss: 262590112.0\n",
      "472it [00:43, 10.74it/s]2023-07-19 16:28:08,988 - INFO - Epoch: [318/600], Step: [473/591], Loss: 228963248.0, KL Divergence: 911.1651611328125, Reconstruction Loss: 228962336.0\n",
      "590it [00:54, 10.88it/s]2023-07-19 16:28:19,807 - INFO - Epoch: [318/600], Step: [591/591], Loss: 179806064.0, KL Divergence: 916.0724487304688, Reconstruction Loss: 179805152.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 16:28:19,809 - INFO - Epoch: [318/600], Total Loss: 14952929387520.0, Total KL Divergence: 68633759.6484375, Total Reconstruction Loss: 14952860780544.0\n",
      "2023-07-19 16:28:19,857 - INFO - Save model at epoch 318\n",
      "0it [00:00, ?it/s]2023-07-19 16:28:19,959 - INFO - Epoch: [319/600], Step: [1/591], Loss: 108457144.0, KL Divergence: 915.6722412109375, Reconstruction Loss: 108456232.0\n",
      "118it [00:10, 10.96it/s]2023-07-19 16:28:30,781 - INFO - Epoch: [319/600], Step: [119/591], Loss: 272578656.0, KL Divergence: 896.0382080078125, Reconstruction Loss: 272577760.0\n",
      "236it [00:21, 10.93it/s]2023-07-19 16:28:41,569 - INFO - Epoch: [319/600], Step: [237/591], Loss: 217142528.0, KL Divergence: 895.1328735351562, Reconstruction Loss: 217141632.0\n",
      "354it [00:32, 11.05it/s]2023-07-19 16:28:52,393 - INFO - Epoch: [319/600], Step: [355/591], Loss: 265214928.0, KL Divergence: 900.9908447265625, Reconstruction Loss: 265214032.0\n",
      "472it [00:43, 11.01it/s]2023-07-19 16:29:03,143 - INFO - Epoch: [319/600], Step: [473/591], Loss: 224454784.0, KL Divergence: 902.002197265625, Reconstruction Loss: 224453888.0\n",
      "590it [00:53, 11.18it/s]2023-07-19 16:29:13,926 - INFO - Epoch: [319/600], Step: [591/591], Loss: 186068256.0, KL Divergence: 902.7492065429688, Reconstruction Loss: 186067360.0\n",
      "591it [00:54, 10.93it/s]\n",
      "2023-07-19 16:29:13,928 - INFO - Epoch: [319/600], Total Loss: 15020616393728.0, Total KL Divergence: 68139744.7109375, Total Reconstruction Loss: 15020548287488.0\n",
      "2023-07-19 16:29:13,967 - INFO - Save model at epoch 319\n",
      "0it [00:00, ?it/s]2023-07-19 16:29:14,081 - INFO - Epoch: [320/600], Step: [1/591], Loss: 109539784.0, KL Divergence: 903.772705078125, Reconstruction Loss: 109538880.0\n",
      "118it [00:10, 11.22it/s]2023-07-19 16:29:24,858 - INFO - Epoch: [320/600], Step: [119/591], Loss: 268340608.0, KL Divergence: 890.4033203125, Reconstruction Loss: 268339712.0\n",
      "236it [00:21, 11.09it/s]2023-07-19 16:29:35,599 - INFO - Epoch: [320/600], Step: [237/591], Loss: 215135808.0, KL Divergence: 892.8897705078125, Reconstruction Loss: 215134912.0\n",
      "354it [00:32, 11.06it/s]2023-07-19 16:29:46,353 - INFO - Epoch: [320/600], Step: [355/591], Loss: 270201152.0, KL Divergence: 895.1099853515625, Reconstruction Loss: 270200256.0\n",
      "472it [00:43, 10.94it/s]2023-07-19 16:29:57,138 - INFO - Epoch: [320/600], Step: [473/591], Loss: 239190624.0, KL Divergence: 893.0384521484375, Reconstruction Loss: 239189728.0\n",
      "590it [00:53, 11.18it/s]2023-07-19 16:30:07,959 - INFO - Epoch: [320/600], Step: [591/591], Loss: 184082944.0, KL Divergence: 898.13427734375, Reconstruction Loss: 184082048.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 16:30:07,960 - INFO - Epoch: [320/600], Total Loss: 14852996548608.0, Total KL Divergence: 67630111.7421875, Total Reconstruction Loss: 14852928894976.0\n",
      "2023-07-19 16:30:07,998 - INFO - Save model at epoch 320\n",
      "0it [00:00, ?it/s]2023-07-19 16:30:08,114 - INFO - Epoch: [321/600], Step: [1/591], Loss: 118245296.0, KL Divergence: 897.8419189453125, Reconstruction Loss: 118244400.0\n",
      "118it [00:10, 10.90it/s]2023-07-19 16:30:18,834 - INFO - Epoch: [321/600], Step: [119/591], Loss: 263284640.0, KL Divergence: 886.9221801757812, Reconstruction Loss: 263283760.0\n",
      "236it [00:21, 11.00it/s]2023-07-19 16:30:29,638 - INFO - Epoch: [321/600], Step: [237/591], Loss: 209517232.0, KL Divergence: 884.9990234375, Reconstruction Loss: 209516352.0\n",
      "354it [00:32, 11.28it/s]2023-07-19 16:30:40,473 - INFO - Epoch: [321/600], Step: [355/591], Loss: 262266384.0, KL Divergence: 882.0947265625, Reconstruction Loss: 262265504.0\n",
      "472it [00:43, 11.10it/s]2023-07-19 16:30:51,183 - INFO - Epoch: [321/600], Step: [473/591], Loss: 240640848.0, KL Divergence: 883.7049560546875, Reconstruction Loss: 240639968.0\n",
      "590it [00:53, 10.59it/s]2023-07-19 16:31:02,045 - INFO - Epoch: [321/600], Step: [591/591], Loss: 195695600.0, KL Divergence: 876.9769287109375, Reconstruction Loss: 195694720.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 16:31:02,046 - INFO - Epoch: [321/600], Total Loss: 14732867817472.0, Total KL Divergence: 66861839.6328125, Total Reconstruction Loss: 14732800953344.0\n",
      "2023-07-19 16:31:02,089 - INFO - Save model at epoch 321\n",
      "0it [00:00, ?it/s]2023-07-19 16:31:02,195 - INFO - Epoch: [322/600], Step: [1/591], Loss: 113235344.0, KL Divergence: 878.7394409179688, Reconstruction Loss: 113234464.0\n",
      "117it [00:10, 10.88it/s]2023-07-19 16:31:12,991 - INFO - Epoch: [322/600], Step: [119/591], Loss: 259145344.0, KL Divergence: 875.822021484375, Reconstruction Loss: 259144464.0\n",
      "235it [00:21, 11.13it/s]2023-07-19 16:31:23,884 - INFO - Epoch: [322/600], Step: [237/591], Loss: 216017648.0, KL Divergence: 882.5716552734375, Reconstruction Loss: 216016768.0\n",
      "353it [00:32, 10.86it/s]2023-07-19 16:31:34,734 - INFO - Epoch: [322/600], Step: [355/591], Loss: 263902720.0, KL Divergence: 887.092041015625, Reconstruction Loss: 263901840.0\n",
      "471it [00:43, 10.87it/s]2023-07-19 16:31:45,485 - INFO - Epoch: [322/600], Step: [473/591], Loss: 226374000.0, KL Divergence: 882.3388061523438, Reconstruction Loss: 226373120.0\n",
      "589it [00:54, 10.86it/s]2023-07-19 16:31:56,289 - INFO - Epoch: [322/600], Step: [591/591], Loss: 182214752.0, KL Divergence: 890.3175659179688, Reconstruction Loss: 182213856.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 16:31:56,291 - INFO - Epoch: [322/600], Total Loss: 14781679972352.0, Total KL Divergence: 66585691.03125, Total Reconstruction Loss: 14781613371392.0\n",
      "2023-07-19 16:31:56,330 - INFO - Save model at epoch 322\n",
      "0it [00:00, ?it/s]2023-07-19 16:31:56,453 - INFO - Epoch: [323/600], Step: [1/591], Loss: 116654040.0, KL Divergence: 891.0303955078125, Reconstruction Loss: 116653152.0\n",
      "117it [00:10, 10.57it/s]2023-07-19 16:32:07,279 - INFO - Epoch: [323/600], Step: [119/591], Loss: 264823792.0, KL Divergence: 877.45263671875, Reconstruction Loss: 264822912.0\n",
      "235it [00:21, 11.02it/s]2023-07-19 16:32:18,066 - INFO - Epoch: [323/600], Step: [237/591], Loss: 213690048.0, KL Divergence: 890.154052734375, Reconstruction Loss: 213689152.0\n",
      "353it [00:32, 11.32it/s]2023-07-19 16:32:28,901 - INFO - Epoch: [323/600], Step: [355/591], Loss: 267042144.0, KL Divergence: 882.8199462890625, Reconstruction Loss: 267041264.0\n",
      "471it [00:43, 10.98it/s]2023-07-19 16:32:39,694 - INFO - Epoch: [323/600], Step: [473/591], Loss: 236490320.0, KL Divergence: 887.1053466796875, Reconstruction Loss: 236489440.0\n",
      "589it [00:53, 10.51it/s]2023-07-19 16:32:50,472 - INFO - Epoch: [323/600], Step: [591/591], Loss: 176060384.0, KL Divergence: 889.9887084960938, Reconstruction Loss: 176059488.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 16:32:50,474 - INFO - Epoch: [323/600], Total Loss: 14772948348928.0, Total KL Divergence: 66869452.21875, Total Reconstruction Loss: 14772881473536.0\n",
      "2023-07-19 16:32:50,512 - INFO - Save model at epoch 323\n",
      "0it [00:00, ?it/s]2023-07-19 16:32:50,616 - INFO - Epoch: [324/600], Step: [1/591], Loss: 110010728.0, KL Divergence: 891.9370727539062, Reconstruction Loss: 110009840.0\n",
      "118it [00:10, 10.70it/s]2023-07-19 16:33:01,449 - INFO - Epoch: [324/600], Step: [119/591], Loss: 266178208.0, KL Divergence: 886.656494140625, Reconstruction Loss: 266177328.0\n",
      "236it [00:21, 10.82it/s]2023-07-19 16:33:12,257 - INFO - Epoch: [324/600], Step: [237/591], Loss: 204903824.0, KL Divergence: 883.2207641601562, Reconstruction Loss: 204902944.0\n",
      "354it [00:32, 10.53it/s]2023-07-19 16:33:23,108 - INFO - Epoch: [324/600], Step: [355/591], Loss: 275004288.0, KL Divergence: 883.8048706054688, Reconstruction Loss: 275003392.0\n",
      "472it [00:43, 11.12it/s]2023-07-19 16:33:33,849 - INFO - Epoch: [324/600], Step: [473/591], Loss: 247382576.0, KL Divergence: 889.002685546875, Reconstruction Loss: 247381680.0\n",
      "590it [00:54, 10.80it/s]2023-07-19 16:33:44,590 - INFO - Epoch: [324/600], Step: [591/591], Loss: 176774080.0, KL Divergence: 889.5169677734375, Reconstruction Loss: 176773184.0\n",
      "591it [00:54, 10.93it/s]\n",
      "2023-07-19 16:33:44,592 - INFO - Epoch: [324/600], Total Loss: 14854897925120.0, Total KL Divergence: 66941178.9140625, Total Reconstruction Loss: 14854830991360.0\n",
      "2023-07-19 16:33:44,655 - INFO - Save model at epoch 324\n",
      "0it [00:00, ?it/s]2023-07-19 16:33:44,774 - INFO - Epoch: [325/600], Step: [1/591], Loss: 114543992.0, KL Divergence: 890.8162231445312, Reconstruction Loss: 114543104.0\n",
      "117it [00:10, 10.92it/s]2023-07-19 16:33:55,499 - INFO - Epoch: [325/600], Step: [119/591], Loss: 276790144.0, KL Divergence: 888.9392700195312, Reconstruction Loss: 276789248.0\n",
      "235it [00:21, 10.84it/s]2023-07-19 16:34:06,321 - INFO - Epoch: [325/600], Step: [237/591], Loss: 215137792.0, KL Divergence: 898.8502807617188, Reconstruction Loss: 215136896.0\n",
      "353it [00:32, 10.99it/s]2023-07-19 16:34:17,131 - INFO - Epoch: [325/600], Step: [355/591], Loss: 267619216.0, KL Divergence: 900.6727294921875, Reconstruction Loss: 267618320.0\n",
      "471it [00:43, 11.06it/s]2023-07-19 16:34:27,869 - INFO - Epoch: [325/600], Step: [473/591], Loss: 256336848.0, KL Divergence: 904.1827392578125, Reconstruction Loss: 256335936.0\n",
      "589it [00:53, 10.87it/s]2023-07-19 16:34:38,639 - INFO - Epoch: [325/600], Step: [591/591], Loss: 183033584.0, KL Divergence: 909.5281982421875, Reconstruction Loss: 183032672.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 16:34:38,642 - INFO - Epoch: [325/600], Total Loss: 14839836227584.0, Total KL Divergence: 67734621.59375, Total Reconstruction Loss: 14839768489984.0\n",
      "2023-07-19 16:34:38,685 - INFO - Save model at epoch 325\n",
      "0it [00:00, ?it/s]2023-07-19 16:34:38,781 - INFO - Epoch: [326/600], Step: [1/591], Loss: 132360256.0, KL Divergence: 908.12548828125, Reconstruction Loss: 132359344.0\n",
      "118it [00:10, 11.31it/s]2023-07-19 16:34:49,493 - INFO - Epoch: [326/600], Step: [119/591], Loss: 283093888.0, KL Divergence: 898.0328369140625, Reconstruction Loss: 283092992.0\n",
      "236it [00:21, 10.60it/s]2023-07-19 16:35:00,275 - INFO - Epoch: [326/600], Step: [237/591], Loss: 214914080.0, KL Divergence: 903.6238403320312, Reconstruction Loss: 214913184.0\n",
      "354it [00:32, 11.09it/s]2023-07-19 16:35:11,103 - INFO - Epoch: [326/600], Step: [355/591], Loss: 264566560.0, KL Divergence: 896.6806640625, Reconstruction Loss: 264565664.0\n",
      "472it [00:43, 10.53it/s]2023-07-19 16:35:21,864 - INFO - Epoch: [326/600], Step: [473/591], Loss: 253925696.0, KL Divergence: 899.482421875, Reconstruction Loss: 253924800.0\n",
      "590it [00:53, 10.97it/s]2023-07-19 16:35:32,705 - INFO - Epoch: [326/600], Step: [591/591], Loss: 177774928.0, KL Divergence: 906.0828857421875, Reconstruction Loss: 177774016.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 16:35:32,707 - INFO - Epoch: [326/600], Total Loss: 14678550333440.0, Total KL Divergence: 68056312.375, Total Reconstruction Loss: 14678482305024.0\n",
      "2023-07-19 16:35:32,752 - INFO - Save model at epoch 326\n",
      "0it [00:00, ?it/s]2023-07-19 16:35:32,859 - INFO - Epoch: [327/600], Step: [1/591], Loss: 110436760.0, KL Divergence: 905.556396484375, Reconstruction Loss: 110435856.0\n",
      "118it [00:10, 10.93it/s]2023-07-19 16:35:43,572 - INFO - Epoch: [327/600], Step: [119/591], Loss: 281551808.0, KL Divergence: 895.1273193359375, Reconstruction Loss: 281550912.0\n",
      "236it [00:21, 11.13it/s]2023-07-19 16:35:54,360 - INFO - Epoch: [327/600], Step: [237/591], Loss: 204960976.0, KL Divergence: 901.6427612304688, Reconstruction Loss: 204960080.0\n",
      "354it [00:32, 11.01it/s]2023-07-19 16:36:05,194 - INFO - Epoch: [327/600], Step: [355/591], Loss: 272192544.0, KL Divergence: 904.66455078125, Reconstruction Loss: 272191648.0\n",
      "472it [00:43, 11.00it/s]2023-07-19 16:36:15,912 - INFO - Epoch: [327/600], Step: [473/591], Loss: 226913504.0, KL Divergence: 906.0804443359375, Reconstruction Loss: 226912592.0\n",
      "590it [00:53, 10.98it/s]2023-07-19 16:36:26,718 - INFO - Epoch: [327/600], Step: [591/591], Loss: 179104624.0, KL Divergence: 908.9425659179688, Reconstruction Loss: 179103712.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 16:36:26,719 - INFO - Epoch: [327/600], Total Loss: 14704809114624.0, Total KL Divergence: 68159992.6640625, Total Reconstruction Loss: 14704740959232.0\n",
      "2023-07-19 16:36:26,760 - INFO - Save model at epoch 327\n",
      "0it [00:00, ?it/s]2023-07-19 16:36:26,878 - INFO - Epoch: [328/600], Step: [1/591], Loss: 110023168.0, KL Divergence: 910.8844604492188, Reconstruction Loss: 110022256.0\n",
      "117it [00:10, 10.99it/s]2023-07-19 16:36:37,688 - INFO - Epoch: [328/600], Step: [119/591], Loss: 275629184.0, KL Divergence: 898.3961181640625, Reconstruction Loss: 275628288.0\n",
      "235it [00:21, 11.25it/s]2023-07-19 16:36:48,386 - INFO - Epoch: [328/600], Step: [237/591], Loss: 205270704.0, KL Divergence: 907.4006958007812, Reconstruction Loss: 205269792.0\n",
      "353it [00:32, 11.13it/s]2023-07-19 16:36:59,119 - INFO - Epoch: [328/600], Step: [355/591], Loss: 256566304.0, KL Divergence: 901.8848876953125, Reconstruction Loss: 256565408.0\n",
      "471it [00:42, 11.18it/s]2023-07-19 16:37:09,829 - INFO - Epoch: [328/600], Step: [473/591], Loss: 243836416.0, KL Divergence: 904.8078002929688, Reconstruction Loss: 243835504.0\n",
      "589it [00:53, 10.84it/s]2023-07-19 16:37:20,563 - INFO - Epoch: [328/600], Step: [591/591], Loss: 175386048.0, KL Divergence: 912.1171875, Reconstruction Loss: 175385136.0\n",
      "591it [00:53, 10.99it/s]\n",
      "2023-07-19 16:37:20,565 - INFO - Epoch: [328/600], Total Loss: 14562669903872.0, Total KL Divergence: 68359175.703125, Total Reconstruction Loss: 14562601583616.0\n",
      "2023-07-19 16:37:20,607 - INFO - Save model at epoch 328\n",
      "0it [00:00, ?it/s]2023-07-19 16:37:20,707 - INFO - Epoch: [329/600], Step: [1/591], Loss: 113682448.0, KL Divergence: 913.7625732421875, Reconstruction Loss: 113681536.0\n",
      "118it [00:10, 11.23it/s]2023-07-19 16:37:31,438 - INFO - Epoch: [329/600], Step: [119/591], Loss: 260404128.0, KL Divergence: 901.8805541992188, Reconstruction Loss: 260403232.0\n",
      "236it [00:21, 11.02it/s]2023-07-19 16:37:42,261 - INFO - Epoch: [329/600], Step: [237/591], Loss: 206252272.0, KL Divergence: 913.9498291015625, Reconstruction Loss: 206251360.0\n",
      "354it [00:32, 10.73it/s]2023-07-19 16:37:53,197 - INFO - Epoch: [329/600], Step: [355/591], Loss: 257948560.0, KL Divergence: 908.6046752929688, Reconstruction Loss: 257947648.0\n",
      "472it [00:43, 11.09it/s]2023-07-19 16:38:04,023 - INFO - Epoch: [329/600], Step: [473/591], Loss: 234786320.0, KL Divergence: 913.4716796875, Reconstruction Loss: 234785408.0\n",
      "590it [00:54, 10.90it/s]2023-07-19 16:38:14,876 - INFO - Epoch: [329/600], Step: [591/591], Loss: 176322896.0, KL Divergence: 923.7777709960938, Reconstruction Loss: 176321968.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 16:38:14,878 - INFO - Epoch: [329/600], Total Loss: 14530567603200.0, Total KL Divergence: 68770680.5390625, Total Reconstruction Loss: 14530498828288.0\n",
      "2023-07-19 16:38:14,927 - INFO - Save model at epoch 329\n",
      "0it [00:00, ?it/s]2023-07-19 16:38:15,034 - INFO - Epoch: [330/600], Step: [1/591], Loss: 116619128.0, KL Divergence: 925.3858642578125, Reconstruction Loss: 116618200.0\n",
      "118it [00:10, 10.51it/s]2023-07-19 16:38:25,810 - INFO - Epoch: [330/600], Step: [119/591], Loss: 260732736.0, KL Divergence: 901.0185546875, Reconstruction Loss: 260731840.0\n",
      "236it [00:21, 10.75it/s]2023-07-19 16:38:36,654 - INFO - Epoch: [330/600], Step: [237/591], Loss: 208790832.0, KL Divergence: 917.1715698242188, Reconstruction Loss: 208789920.0\n",
      "354it [00:32, 10.82it/s]2023-07-19 16:38:47,533 - INFO - Epoch: [330/600], Step: [355/591], Loss: 268780544.0, KL Divergence: 915.0511474609375, Reconstruction Loss: 268779616.0\n",
      "472it [00:43, 11.01it/s]2023-07-19 16:38:58,365 - INFO - Epoch: [330/600], Step: [473/591], Loss: 229962992.0, KL Divergence: 918.9197387695312, Reconstruction Loss: 229962080.0\n",
      "590it [00:54, 11.01it/s]2023-07-19 16:39:09,145 - INFO - Epoch: [330/600], Step: [591/591], Loss: 172419584.0, KL Divergence: 914.4494018554688, Reconstruction Loss: 172418672.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 16:39:09,147 - INFO - Epoch: [330/600], Total Loss: 14835590633472.0, Total KL Divergence: 68881685.6171875, Total Reconstruction Loss: 14835521725440.0\n",
      "2023-07-19 16:39:09,191 - INFO - Save model at epoch 330\n",
      "0it [00:00, ?it/s]2023-07-19 16:39:09,307 - INFO - Epoch: [331/600], Step: [1/591], Loss: 108409536.0, KL Divergence: 914.924560546875, Reconstruction Loss: 108408624.0\n",
      "117it [00:10, 10.96it/s]2023-07-19 16:39:20,031 - INFO - Epoch: [331/600], Step: [119/591], Loss: 259125376.0, KL Divergence: 905.6488037109375, Reconstruction Loss: 259124464.0\n",
      "235it [00:21, 10.99it/s]2023-07-19 16:39:30,744 - INFO - Epoch: [331/600], Step: [237/591], Loss: 202150912.0, KL Divergence: 912.3082885742188, Reconstruction Loss: 202150000.0\n",
      "353it [00:32, 10.90it/s]2023-07-19 16:39:41,583 - INFO - Epoch: [331/600], Step: [355/591], Loss: 253805776.0, KL Divergence: 913.0523681640625, Reconstruction Loss: 253804864.0\n",
      "471it [00:43, 10.71it/s]2023-07-19 16:39:52,499 - INFO - Epoch: [331/600], Step: [473/591], Loss: 217263952.0, KL Divergence: 918.94775390625, Reconstruction Loss: 217263040.0\n",
      "589it [00:54, 10.70it/s]2023-07-19 16:40:03,349 - INFO - Epoch: [331/600], Step: [591/591], Loss: 170209904.0, KL Divergence: 919.32177734375, Reconstruction Loss: 170208992.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 16:40:03,351 - INFO - Epoch: [331/600], Total Loss: 14498372296704.0, Total KL Divergence: 68927101.796875, Total Reconstruction Loss: 14498303351808.0\n",
      "2023-07-19 16:40:03,411 - INFO - Save model at epoch 331\n",
      "0it [00:00, ?it/s]2023-07-19 16:40:03,519 - INFO - Epoch: [332/600], Step: [1/591], Loss: 110910936.0, KL Divergence: 918.07080078125, Reconstruction Loss: 110910016.0\n",
      "118it [00:10, 10.77it/s]2023-07-19 16:40:14,364 - INFO - Epoch: [332/600], Step: [119/591], Loss: 260053904.0, KL Divergence: 904.7156982421875, Reconstruction Loss: 260052992.0\n",
      "236it [00:21, 10.97it/s]2023-07-19 16:40:25,122 - INFO - Epoch: [332/600], Step: [237/591], Loss: 206246576.0, KL Divergence: 910.3412475585938, Reconstruction Loss: 206245664.0\n",
      "354it [00:32, 10.62it/s]2023-07-19 16:40:35,956 - INFO - Epoch: [332/600], Step: [355/591], Loss: 250924640.0, KL Divergence: 910.6212158203125, Reconstruction Loss: 250923728.0\n",
      "472it [00:43, 11.45it/s]2023-07-19 16:40:46,803 - INFO - Epoch: [332/600], Step: [473/591], Loss: 219806544.0, KL Divergence: 912.37109375, Reconstruction Loss: 219805632.0\n",
      "590it [00:54, 10.59it/s]2023-07-19 16:40:57,521 - INFO - Epoch: [332/600], Step: [591/591], Loss: 173250176.0, KL Divergence: 916.1961669921875, Reconstruction Loss: 173249264.0\n",
      "591it [00:54, 10.93it/s]\n",
      "2023-07-19 16:40:57,523 - INFO - Epoch: [332/600], Total Loss: 14541931924480.0, Total KL Divergence: 68738380.1015625, Total Reconstruction Loss: 14541863182336.0\n",
      "2023-07-19 16:40:57,565 - INFO - Save model at epoch 332\n",
      "0it [00:00, ?it/s]2023-07-19 16:40:57,679 - INFO - Epoch: [333/600], Step: [1/591], Loss: 113656768.0, KL Divergence: 916.3101806640625, Reconstruction Loss: 113655848.0\n",
      "117it [00:10, 10.98it/s]2023-07-19 16:41:08,416 - INFO - Epoch: [333/600], Step: [119/591], Loss: 261913008.0, KL Divergence: 898.4912719726562, Reconstruction Loss: 261912112.0\n",
      "235it [00:21, 11.19it/s]2023-07-19 16:41:19,385 - INFO - Epoch: [333/600], Step: [237/591], Loss: 210117120.0, KL Divergence: 909.8499755859375, Reconstruction Loss: 210116208.0\n",
      "353it [00:32, 10.87it/s]2023-07-19 16:41:30,168 - INFO - Epoch: [333/600], Step: [355/591], Loss: 263142976.0, KL Divergence: 912.5689697265625, Reconstruction Loss: 263142064.0\n",
      "471it [00:43, 11.14it/s]2023-07-19 16:41:40,906 - INFO - Epoch: [333/600], Step: [473/591], Loss: 245505792.0, KL Divergence: 912.696533203125, Reconstruction Loss: 245504880.0\n",
      "589it [00:53, 10.57it/s]2023-07-19 16:41:51,716 - INFO - Epoch: [333/600], Step: [591/591], Loss: 181209344.0, KL Divergence: 923.2633056640625, Reconstruction Loss: 181208416.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 16:41:51,718 - INFO - Epoch: [333/600], Total Loss: 14871975425024.0, Total KL Divergence: 68867758.78125, Total Reconstruction Loss: 14871906557952.0\n",
      "2023-07-19 16:41:51,761 - INFO - Save model at epoch 333\n",
      "0it [00:00, ?it/s]2023-07-19 16:41:51,857 - INFO - Epoch: [334/600], Step: [1/591], Loss: 111981488.0, KL Divergence: 920.9749755859375, Reconstruction Loss: 111980568.0\n",
      "118it [00:10, 11.08it/s]2023-07-19 16:42:02,685 - INFO - Epoch: [334/600], Step: [119/591], Loss: 263380480.0, KL Divergence: 907.5455322265625, Reconstruction Loss: 263379568.0\n",
      "236it [00:21, 10.79it/s]2023-07-19 16:42:13,612 - INFO - Epoch: [334/600], Step: [237/591], Loss: 202872016.0, KL Divergence: 918.718505859375, Reconstruction Loss: 202871104.0\n",
      "354it [00:32, 10.92it/s]2023-07-19 16:42:24,413 - INFO - Epoch: [334/600], Step: [355/591], Loss: 285790880.0, KL Divergence: 915.8743896484375, Reconstruction Loss: 285789952.0\n",
      "472it [00:43, 10.97it/s]2023-07-19 16:42:35,328 - INFO - Epoch: [334/600], Step: [473/591], Loss: 225026704.0, KL Divergence: 915.2100830078125, Reconstruction Loss: 225025792.0\n",
      "590it [00:54, 10.78it/s]2023-07-19 16:42:46,097 - INFO - Epoch: [334/600], Step: [591/591], Loss: 185035664.0, KL Divergence: 922.482666015625, Reconstruction Loss: 185034736.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 16:42:46,099 - INFO - Epoch: [334/600], Total Loss: 14663078133760.0, Total KL Divergence: 69147635.328125, Total Reconstruction Loss: 14663008975872.0\n",
      "2023-07-19 16:42:46,141 - INFO - Save model at epoch 334\n",
      "0it [00:00, ?it/s]2023-07-19 16:42:46,262 - INFO - Epoch: [335/600], Step: [1/591], Loss: 110961640.0, KL Divergence: 921.0140380859375, Reconstruction Loss: 110960720.0\n",
      "117it [00:10, 11.10it/s]2023-07-19 16:42:57,072 - INFO - Epoch: [335/600], Step: [119/591], Loss: 263815664.0, KL Divergence: 904.85400390625, Reconstruction Loss: 263814752.0\n",
      "235it [00:21, 11.00it/s]2023-07-19 16:43:07,858 - INFO - Epoch: [335/600], Step: [237/591], Loss: 205691104.0, KL Divergence: 921.0892333984375, Reconstruction Loss: 205690176.0\n",
      "353it [00:32, 11.25it/s]2023-07-19 16:43:18,580 - INFO - Epoch: [335/600], Step: [355/591], Loss: 251439376.0, KL Divergence: 915.6658935546875, Reconstruction Loss: 251438464.0\n",
      "471it [00:42, 10.80it/s]2023-07-19 16:43:29,336 - INFO - Epoch: [335/600], Step: [473/591], Loss: 226131680.0, KL Divergence: 912.7280883789062, Reconstruction Loss: 226130768.0\n",
      "589it [00:53, 10.17it/s]2023-07-19 16:43:40,030 - INFO - Epoch: [335/600], Step: [591/591], Loss: 185308480.0, KL Divergence: 908.7770385742188, Reconstruction Loss: 185307568.0\n",
      "591it [00:53, 10.97it/s]\n",
      "2023-07-19 16:43:40,032 - INFO - Epoch: [335/600], Total Loss: 14450277008384.0, Total KL Divergence: 68989602.0234375, Total Reconstruction Loss: 14450207988736.0\n",
      "2023-07-19 16:43:40,074 - INFO - Save model at epoch 335\n",
      "0it [00:00, ?it/s]2023-07-19 16:43:40,178 - INFO - Epoch: [336/600], Step: [1/591], Loss: 110390768.0, KL Divergence: 910.7279052734375, Reconstruction Loss: 110389856.0\n",
      "118it [00:10, 11.13it/s]2023-07-19 16:43:50,877 - INFO - Epoch: [336/600], Step: [119/591], Loss: 259181344.0, KL Divergence: 904.033935546875, Reconstruction Loss: 259180432.0\n",
      "236it [00:21, 10.76it/s]2023-07-19 16:44:01,641 - INFO - Epoch: [336/600], Step: [237/591], Loss: 203589184.0, KL Divergence: 919.3408203125, Reconstruction Loss: 203588272.0\n",
      "354it [00:32, 10.67it/s]2023-07-19 16:44:12,514 - INFO - Epoch: [336/600], Step: [355/591], Loss: 255445200.0, KL Divergence: 913.5321044921875, Reconstruction Loss: 255444288.0\n",
      "472it [00:43, 10.99it/s]2023-07-19 16:44:23,303 - INFO - Epoch: [336/600], Step: [473/591], Loss: 225390832.0, KL Divergence: 915.0182495117188, Reconstruction Loss: 225389920.0\n",
      "590it [00:53, 10.88it/s]2023-07-19 16:44:33,986 - INFO - Epoch: [336/600], Step: [591/591], Loss: 190790352.0, KL Divergence: 919.81640625, Reconstruction Loss: 190789440.0\n",
      "591it [00:53, 10.96it/s]\n",
      "2023-07-19 16:44:33,987 - INFO - Epoch: [336/600], Total Loss: 14544978544640.0, Total KL Divergence: 68933339.1484375, Total Reconstruction Loss: 14544909603840.0\n",
      "2023-07-19 16:44:34,033 - INFO - Save model at epoch 336\n",
      "0it [00:00, ?it/s]2023-07-19 16:44:34,138 - INFO - Epoch: [337/600], Step: [1/591], Loss: 108896584.0, KL Divergence: 920.315185546875, Reconstruction Loss: 108895664.0\n",
      "118it [00:10, 11.37it/s]2023-07-19 16:44:44,928 - INFO - Epoch: [337/600], Step: [119/591], Loss: 267582384.0, KL Divergence: 907.5239868164062, Reconstruction Loss: 267581472.0\n",
      "236it [00:21, 11.10it/s]2023-07-19 16:44:55,661 - INFO - Epoch: [337/600], Step: [237/591], Loss: 206911392.0, KL Divergence: 922.7052001953125, Reconstruction Loss: 206910464.0\n",
      "354it [00:32, 11.16it/s]2023-07-19 16:45:06,509 - INFO - Epoch: [337/600], Step: [355/591], Loss: 252740688.0, KL Divergence: 917.1898193359375, Reconstruction Loss: 252739776.0\n",
      "472it [00:43, 10.75it/s]2023-07-19 16:45:17,280 - INFO - Epoch: [337/600], Step: [473/591], Loss: 225404912.0, KL Divergence: 916.2100219726562, Reconstruction Loss: 225404000.0\n",
      "590it [00:53, 11.38it/s]2023-07-19 16:45:28,041 - INFO - Epoch: [337/600], Step: [591/591], Loss: 176819232.0, KL Divergence: 923.2943115234375, Reconstruction Loss: 176818304.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 16:45:28,042 - INFO - Epoch: [337/600], Total Loss: 14575824731136.0, Total KL Divergence: 69170729.5703125, Total Reconstruction Loss: 14575755546624.0\n",
      "2023-07-19 16:45:28,147 - INFO - Save model at epoch 337\n",
      "0it [00:00, ?it/s]2023-07-19 16:45:28,242 - INFO - Epoch: [338/600], Step: [1/591], Loss: 110504216.0, KL Divergence: 922.6506958007812, Reconstruction Loss: 110503296.0\n",
      "118it [00:10, 10.97it/s]2023-07-19 16:45:38,877 - INFO - Epoch: [338/600], Step: [119/591], Loss: 265888576.0, KL Divergence: 913.7006225585938, Reconstruction Loss: 265887664.0\n",
      "236it [00:21, 11.27it/s]2023-07-19 16:45:49,589 - INFO - Epoch: [338/600], Step: [237/591], Loss: 201222576.0, KL Divergence: 924.802734375, Reconstruction Loss: 201221648.0\n",
      "354it [00:32, 11.01it/s]2023-07-19 16:46:00,443 - INFO - Epoch: [338/600], Step: [355/591], Loss: 253593984.0, KL Divergence: 922.030029296875, Reconstruction Loss: 253593056.0\n",
      "472it [00:42, 10.99it/s]2023-07-19 16:46:11,218 - INFO - Epoch: [338/600], Step: [473/591], Loss: 227219824.0, KL Divergence: 922.3565673828125, Reconstruction Loss: 227218896.0\n",
      "590it [00:53, 11.25it/s]2023-07-19 16:46:21,975 - INFO - Epoch: [338/600], Step: [591/591], Loss: 173372832.0, KL Divergence: 932.2604370117188, Reconstruction Loss: 173371904.0\n",
      "591it [00:53, 10.98it/s]\n",
      "2023-07-19 16:46:21,977 - INFO - Epoch: [338/600], Total Loss: 14533820736512.0, Total KL Divergence: 69577434.4921875, Total Reconstruction Loss: 14533751156736.0\n",
      "2023-07-19 16:46:22,034 - INFO - Save model at epoch 338\n",
      "0it [00:00, ?it/s]2023-07-19 16:46:22,142 - INFO - Epoch: [339/600], Step: [1/591], Loss: 137172384.0, KL Divergence: 932.2518310546875, Reconstruction Loss: 137171456.0\n",
      "117it [00:10, 10.61it/s]2023-07-19 16:46:32,950 - INFO - Epoch: [339/600], Step: [119/591], Loss: 274215040.0, KL Divergence: 911.2698974609375, Reconstruction Loss: 274214144.0\n",
      "235it [00:21, 10.88it/s]2023-07-19 16:46:43,717 - INFO - Epoch: [339/600], Step: [237/591], Loss: 203172864.0, KL Divergence: 927.5567016601562, Reconstruction Loss: 203171936.0\n",
      "353it [00:32, 11.01it/s]2023-07-19 16:46:54,408 - INFO - Epoch: [339/600], Step: [355/591], Loss: 261547424.0, KL Divergence: 920.8729248046875, Reconstruction Loss: 261546496.0\n",
      "471it [00:42, 10.60it/s]2023-07-19 16:47:05,214 - INFO - Epoch: [339/600], Step: [473/591], Loss: 219417200.0, KL Divergence: 918.774169921875, Reconstruction Loss: 219416288.0\n",
      "589it [00:53, 10.94it/s]2023-07-19 16:47:15,900 - INFO - Epoch: [339/600], Step: [591/591], Loss: 172418480.0, KL Divergence: 925.8626708984375, Reconstruction Loss: 172417552.0\n",
      "591it [00:53, 10.97it/s]\n",
      "2023-07-19 16:47:15,902 - INFO - Epoch: [339/600], Total Loss: 14514095113216.0, Total KL Divergence: 69464956.34375, Total Reconstruction Loss: 14514025665536.0\n",
      "2023-07-19 16:47:15,954 - INFO - Save model at epoch 339\n",
      "0it [00:00, ?it/s]2023-07-19 16:47:16,073 - INFO - Epoch: [340/600], Step: [1/591], Loss: 117692072.0, KL Divergence: 926.7945556640625, Reconstruction Loss: 117691144.0\n",
      "117it [00:10, 11.28it/s]2023-07-19 16:47:26,985 - INFO - Epoch: [340/600], Step: [119/591], Loss: 273190784.0, KL Divergence: 909.782958984375, Reconstruction Loss: 273189888.0\n",
      "235it [00:21, 11.04it/s]2023-07-19 16:47:37,697 - INFO - Epoch: [340/600], Step: [237/591], Loss: 204978368.0, KL Divergence: 915.57666015625, Reconstruction Loss: 204977456.0\n",
      "353it [00:32, 11.06it/s]2023-07-19 16:47:48,476 - INFO - Epoch: [340/600], Step: [355/591], Loss: 248970336.0, KL Divergence: 914.7694091796875, Reconstruction Loss: 248969424.0\n",
      "471it [00:43, 11.22it/s]2023-07-19 16:47:59,193 - INFO - Epoch: [340/600], Step: [473/591], Loss: 221381536.0, KL Divergence: 912.7173461914062, Reconstruction Loss: 221380624.0\n",
      "589it [00:53, 10.99it/s]2023-07-19 16:48:09,897 - INFO - Epoch: [340/600], Step: [591/591], Loss: 181864560.0, KL Divergence: 916.1539306640625, Reconstruction Loss: 181863648.0\n",
      "591it [00:53, 10.96it/s]\n",
      "2023-07-19 16:48:09,899 - INFO - Epoch: [340/600], Total Loss: 14423608849408.0, Total KL Divergence: 69050470.7734375, Total Reconstruction Loss: 14423539761152.0\n",
      "2023-07-19 16:48:09,947 - INFO - Save model at epoch 340\n",
      "0it [00:00, ?it/s]2023-07-19 16:48:10,045 - INFO - Epoch: [341/600], Step: [1/591], Loss: 113198904.0, KL Divergence: 916.986083984375, Reconstruction Loss: 113197984.0\n",
      "118it [00:10, 11.21it/s]2023-07-19 16:48:20,879 - INFO - Epoch: [341/600], Step: [119/591], Loss: 266615808.0, KL Divergence: 905.55908203125, Reconstruction Loss: 266614896.0\n",
      "236it [00:21, 10.81it/s]2023-07-19 16:48:31,715 - INFO - Epoch: [341/600], Step: [237/591], Loss: 207208240.0, KL Divergence: 911.2347412109375, Reconstruction Loss: 207207328.0\n",
      "354it [00:32, 10.67it/s]2023-07-19 16:48:42,598 - INFO - Epoch: [341/600], Step: [355/591], Loss: 255533744.0, KL Divergence: 916.0220947265625, Reconstruction Loss: 255532832.0\n",
      "472it [00:43, 10.99it/s]2023-07-19 16:48:53,419 - INFO - Epoch: [341/600], Step: [473/591], Loss: 227498432.0, KL Divergence: 913.8876342773438, Reconstruction Loss: 227497520.0\n",
      "590it [00:54, 11.15it/s]2023-07-19 16:49:04,274 - INFO - Epoch: [341/600], Step: [591/591], Loss: 171505056.0, KL Divergence: 924.057861328125, Reconstruction Loss: 171504128.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 16:49:04,275 - INFO - Epoch: [341/600], Total Loss: 14571145071616.0, Total KL Divergence: 69022923.625, Total Reconstruction Loss: 14571076037632.0\n",
      "2023-07-19 16:49:04,326 - INFO - Save model at epoch 341\n",
      "0it [00:00, ?it/s]2023-07-19 16:49:04,428 - INFO - Epoch: [342/600], Step: [1/591], Loss: 116011376.0, KL Divergence: 926.578857421875, Reconstruction Loss: 116010448.0\n",
      "118it [00:10, 10.81it/s]2023-07-19 16:49:15,311 - INFO - Epoch: [342/600], Step: [119/591], Loss: 263939776.0, KL Divergence: 914.0650024414062, Reconstruction Loss: 263938864.0\n",
      "236it [00:21, 11.28it/s]2023-07-19 16:49:26,021 - INFO - Epoch: [342/600], Step: [237/591], Loss: 202470032.0, KL Divergence: 918.0699462890625, Reconstruction Loss: 202469120.0\n",
      "354it [00:32, 10.65it/s]2023-07-19 16:49:36,819 - INFO - Epoch: [342/600], Step: [355/591], Loss: 267138992.0, KL Divergence: 919.805419921875, Reconstruction Loss: 267138080.0\n",
      "472it [00:43, 11.02it/s]2023-07-19 16:49:47,575 - INFO - Epoch: [342/600], Step: [473/591], Loss: 218766048.0, KL Divergence: 913.146728515625, Reconstruction Loss: 218765136.0\n",
      "590it [00:53, 10.96it/s]2023-07-19 16:49:58,374 - INFO - Epoch: [342/600], Step: [591/591], Loss: 183530944.0, KL Divergence: 926.7713623046875, Reconstruction Loss: 183530016.0\n",
      "591it [00:54, 10.94it/s]\n",
      "2023-07-19 16:49:58,376 - INFO - Epoch: [342/600], Total Loss: 14591034441728.0, Total KL Divergence: 69223092.890625, Total Reconstruction Loss: 14590965215232.0\n",
      "2023-07-19 16:49:58,426 - INFO - Save model at epoch 342\n",
      "0it [00:00, ?it/s]2023-07-19 16:49:58,540 - INFO - Epoch: [343/600], Step: [1/591], Loss: 115185888.0, KL Divergence: 925.73876953125, Reconstruction Loss: 115184960.0\n",
      "118it [00:10, 11.27it/s]2023-07-19 16:50:09,423 - INFO - Epoch: [343/600], Step: [119/591], Loss: 267166128.0, KL Divergence: 909.1096801757812, Reconstruction Loss: 267165216.0\n",
      "236it [00:21, 11.10it/s]2023-07-19 16:50:20,284 - INFO - Epoch: [343/600], Step: [237/591], Loss: 202194240.0, KL Divergence: 922.6075439453125, Reconstruction Loss: 202193312.0\n",
      "354it [00:32, 10.81it/s]2023-07-19 16:50:31,135 - INFO - Epoch: [343/600], Step: [355/591], Loss: 262754992.0, KL Divergence: 916.8023681640625, Reconstruction Loss: 262754080.0\n",
      "472it [00:43, 11.29it/s]2023-07-19 16:50:41,857 - INFO - Epoch: [343/600], Step: [473/591], Loss: 218418176.0, KL Divergence: 915.155517578125, Reconstruction Loss: 218417264.0\n",
      "590it [00:54, 10.82it/s]2023-07-19 16:50:52,606 - INFO - Epoch: [343/600], Step: [591/591], Loss: 187496832.0, KL Divergence: 922.8106689453125, Reconstruction Loss: 187495904.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 16:50:52,609 - INFO - Epoch: [343/600], Total Loss: 14589406356480.0, Total KL Divergence: 69321254.796875, Total Reconstruction Loss: 14589337008128.0\n",
      "2023-07-19 16:50:52,650 - INFO - Save model at epoch 343\n",
      "0it [00:00, ?it/s]2023-07-19 16:50:52,757 - INFO - Epoch: [344/600], Step: [1/591], Loss: 109363704.0, KL Divergence: 923.8831176757812, Reconstruction Loss: 109362784.0\n",
      "118it [00:10, 11.08it/s]2023-07-19 16:51:03,573 - INFO - Epoch: [344/600], Step: [119/591], Loss: 269946976.0, KL Divergence: 913.3768310546875, Reconstruction Loss: 269946048.0\n",
      "236it [00:21, 10.43it/s]2023-07-19 16:51:14,418 - INFO - Epoch: [344/600], Step: [237/591], Loss: 202050688.0, KL Divergence: 928.9693603515625, Reconstruction Loss: 202049760.0\n",
      "354it [00:32, 10.63it/s]2023-07-19 16:51:25,166 - INFO - Epoch: [344/600], Step: [355/591], Loss: 255195616.0, KL Divergence: 922.6915283203125, Reconstruction Loss: 255194688.0\n",
      "472it [00:43, 10.70it/s]2023-07-19 16:51:35,902 - INFO - Epoch: [344/600], Step: [473/591], Loss: 214844352.0, KL Divergence: 926.2376708984375, Reconstruction Loss: 214843424.0\n",
      "590it [00:54, 10.68it/s]2023-07-19 16:51:46,738 - INFO - Epoch: [344/600], Step: [591/591], Loss: 177823264.0, KL Divergence: 927.138916015625, Reconstruction Loss: 177822336.0\n",
      "591it [00:54, 10.93it/s]\n",
      "2023-07-19 16:51:46,740 - INFO - Epoch: [344/600], Total Loss: 14660626523136.0, Total KL Divergence: 69843891.1640625, Total Reconstruction Loss: 14660556674048.0\n",
      "2023-07-19 16:51:46,805 - INFO - Save model at epoch 344\n",
      "0it [00:00, ?it/s]2023-07-19 16:51:46,899 - INFO - Epoch: [345/600], Step: [1/591], Loss: 108640064.0, KL Divergence: 927.49560546875, Reconstruction Loss: 108639136.0\n",
      "118it [00:10, 10.77it/s]2023-07-19 16:51:57,704 - INFO - Epoch: [345/600], Step: [119/591], Loss: 269605536.0, KL Divergence: 917.6997680664062, Reconstruction Loss: 269604608.0\n",
      "236it [00:21, 10.88it/s]2023-07-19 16:52:08,530 - INFO - Epoch: [345/600], Step: [237/591], Loss: 200556960.0, KL Divergence: 930.6005249023438, Reconstruction Loss: 200556032.0\n",
      "354it [00:32, 10.94it/s]2023-07-19 16:52:19,516 - INFO - Epoch: [345/600], Step: [355/591], Loss: 251708736.0, KL Divergence: 923.4263916015625, Reconstruction Loss: 251707808.0\n",
      "472it [00:43, 11.02it/s]2023-07-19 16:52:30,236 - INFO - Epoch: [345/600], Step: [473/591], Loss: 213342944.0, KL Divergence: 931.1603393554688, Reconstruction Loss: 213342016.0\n",
      "590it [00:54, 11.09it/s]2023-07-19 16:52:41,039 - INFO - Epoch: [345/600], Step: [591/591], Loss: 185224336.0, KL Divergence: 938.1058349609375, Reconstruction Loss: 185223392.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 16:52:41,041 - INFO - Epoch: [345/600], Total Loss: 14500331458560.0, Total KL Divergence: 70116910.140625, Total Reconstruction Loss: 14500261331968.0\n",
      "2023-07-19 16:52:41,089 - INFO - Save model at epoch 345\n",
      "0it [00:00, ?it/s]2023-07-19 16:52:41,184 - INFO - Epoch: [346/600], Step: [1/591], Loss: 113423800.0, KL Divergence: 939.0679321289062, Reconstruction Loss: 113422864.0\n",
      "118it [00:11, 10.87it/s]2023-07-19 16:52:52,202 - INFO - Epoch: [346/600], Step: [119/591], Loss: 258612000.0, KL Divergence: 923.6173095703125, Reconstruction Loss: 258611072.0\n",
      "236it [00:21, 10.84it/s]2023-07-19 16:53:03,057 - INFO - Epoch: [346/600], Step: [237/591], Loss: 198086768.0, KL Divergence: 930.8961181640625, Reconstruction Loss: 198085840.0\n",
      "354it [00:32, 11.07it/s]2023-07-19 16:53:13,935 - INFO - Epoch: [346/600], Step: [355/591], Loss: 250980224.0, KL Divergence: 926.1771240234375, Reconstruction Loss: 250979296.0\n",
      "472it [00:43, 11.17it/s]2023-07-19 16:53:24,762 - INFO - Epoch: [346/600], Step: [473/591], Loss: 211980256.0, KL Divergence: 932.3422241210938, Reconstruction Loss: 211979328.0\n",
      "590it [00:54, 11.14it/s]2023-07-19 16:53:35,444 - INFO - Epoch: [346/600], Step: [591/591], Loss: 173704784.0, KL Divergence: 942.4098510742188, Reconstruction Loss: 173703840.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 16:53:35,445 - INFO - Epoch: [346/600], Total Loss: 14344117176320.0, Total KL Divergence: 70294304.140625, Total Reconstruction Loss: 14344046910464.0\n",
      "2023-07-19 16:53:35,490 - INFO - Save model at epoch 346\n",
      "0it [00:00, ?it/s]2023-07-19 16:53:35,596 - INFO - Epoch: [347/600], Step: [1/591], Loss: 113828440.0, KL Divergence: 940.41064453125, Reconstruction Loss: 113827496.0\n",
      "117it [00:10, 10.90it/s]2023-07-19 16:53:46,326 - INFO - Epoch: [347/600], Step: [119/591], Loss: 256193152.0, KL Divergence: 921.540771484375, Reconstruction Loss: 256192224.0\n",
      "235it [00:21, 10.96it/s]2023-07-19 16:53:57,121 - INFO - Epoch: [347/600], Step: [237/591], Loss: 200093952.0, KL Divergence: 930.67529296875, Reconstruction Loss: 200093024.0\n",
      "353it [00:32, 10.53it/s]2023-07-19 16:54:07,979 - INFO - Epoch: [347/600], Step: [355/591], Loss: 251843008.0, KL Divergence: 925.4393310546875, Reconstruction Loss: 251842080.0\n",
      "471it [00:43, 10.94it/s]2023-07-19 16:54:18,822 - INFO - Epoch: [347/600], Step: [473/591], Loss: 217319216.0, KL Divergence: 925.564697265625, Reconstruction Loss: 217318288.0\n",
      "589it [00:53, 10.93it/s]2023-07-19 16:54:29,577 - INFO - Epoch: [347/600], Step: [591/591], Loss: 171734800.0, KL Divergence: 939.1597900390625, Reconstruction Loss: 171733856.0\n",
      "591it [00:54, 10.93it/s]\n",
      "2023-07-19 16:54:29,579 - INFO - Epoch: [347/600], Total Loss: 14252576462848.0, Total KL Divergence: 70121881.375, Total Reconstruction Loss: 14252506331136.0\n",
      "2023-07-19 16:54:29,618 - INFO - Save model at epoch 347\n",
      "0it [00:00, ?it/s]2023-07-19 16:54:29,726 - INFO - Epoch: [348/600], Step: [1/591], Loss: 111967960.0, KL Divergence: 938.761962890625, Reconstruction Loss: 111967024.0\n",
      "118it [00:10, 11.07it/s]2023-07-19 16:54:40,597 - INFO - Epoch: [348/600], Step: [119/591], Loss: 266798720.0, KL Divergence: 922.8876953125, Reconstruction Loss: 266797792.0\n",
      "236it [00:21, 11.00it/s]2023-07-19 16:54:51,370 - INFO - Epoch: [348/600], Step: [237/591], Loss: 201894944.0, KL Divergence: 927.4988403320312, Reconstruction Loss: 201894016.0\n",
      "354it [00:32, 10.71it/s]2023-07-19 16:55:02,247 - INFO - Epoch: [348/600], Step: [355/591], Loss: 248968064.0, KL Divergence: 929.302734375, Reconstruction Loss: 248967136.0\n",
      "472it [00:43, 11.42it/s]2023-07-19 16:55:13,063 - INFO - Epoch: [348/600], Step: [473/591], Loss: 213338704.0, KL Divergence: 924.6481323242188, Reconstruction Loss: 213337776.0\n",
      "590it [00:54, 10.92it/s]2023-07-19 16:55:23,816 - INFO - Epoch: [348/600], Step: [591/591], Loss: 172778208.0, KL Divergence: 936.9061279296875, Reconstruction Loss: 172777264.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 16:55:23,818 - INFO - Epoch: [348/600], Total Loss: 14177298708480.0, Total KL Divergence: 70092504.2734375, Total Reconstruction Loss: 14177228605440.0\n",
      "2023-07-19 16:55:23,867 - INFO - Save model at epoch 348\n",
      "0it [00:00, ?it/s]2023-07-19 16:55:23,971 - INFO - Epoch: [349/600], Step: [1/591], Loss: 120625528.0, KL Divergence: 938.7766723632812, Reconstruction Loss: 120624592.0\n",
      "118it [00:10, 10.92it/s]2023-07-19 16:55:34,798 - INFO - Epoch: [349/600], Step: [119/591], Loss: 261281280.0, KL Divergence: 921.3699340820312, Reconstruction Loss: 261280352.0\n",
      "236it [00:21, 11.21it/s]2023-07-19 16:55:45,632 - INFO - Epoch: [349/600], Step: [237/591], Loss: 206196896.0, KL Divergence: 927.4391479492188, Reconstruction Loss: 206195968.0\n",
      "354it [00:32, 11.05it/s]2023-07-19 16:55:56,564 - INFO - Epoch: [349/600], Step: [355/591], Loss: 252328160.0, KL Divergence: 928.28076171875, Reconstruction Loss: 252327232.0\n",
      "472it [00:43, 11.06it/s]2023-07-19 16:56:07,612 - INFO - Epoch: [349/600], Step: [473/591], Loss: 221394608.0, KL Divergence: 926.1282958984375, Reconstruction Loss: 221393680.0\n",
      "590it [00:54, 10.92it/s]2023-07-19 16:56:18,363 - INFO - Epoch: [349/600], Step: [591/591], Loss: 183401360.0, KL Divergence: 930.9285888671875, Reconstruction Loss: 183400432.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 16:56:18,365 - INFO - Epoch: [349/600], Total Loss: 14330021918720.0, Total KL Divergence: 70020326.5859375, Total Reconstruction Loss: 14329951898624.0\n",
      "2023-07-19 16:56:18,414 - INFO - Save model at epoch 349\n",
      "0it [00:00, ?it/s]2023-07-19 16:56:18,530 - INFO - Epoch: [350/600], Step: [1/591], Loss: 131799240.0, KL Divergence: 934.384765625, Reconstruction Loss: 131798304.0\n",
      "117it [00:10, 10.92it/s]2023-07-19 16:56:29,402 - INFO - Epoch: [350/600], Step: [119/591], Loss: 255708400.0, KL Divergence: 919.635009765625, Reconstruction Loss: 255707488.0\n",
      "235it [00:21, 11.02it/s]2023-07-19 16:56:40,167 - INFO - Epoch: [350/600], Step: [237/591], Loss: 215296720.0, KL Divergence: 926.3177490234375, Reconstruction Loss: 215295792.0\n",
      "353it [00:32, 11.29it/s]2023-07-19 16:56:50,880 - INFO - Epoch: [350/600], Step: [355/591], Loss: 251260144.0, KL Divergence: 924.912109375, Reconstruction Loss: 251259216.0\n",
      "471it [00:43, 10.68it/s]2023-07-19 16:57:01,692 - INFO - Epoch: [350/600], Step: [473/591], Loss: 220234480.0, KL Divergence: 927.7047119140625, Reconstruction Loss: 220233552.0\n",
      "589it [00:53, 10.99it/s]2023-07-19 16:57:12,376 - INFO - Epoch: [350/600], Step: [591/591], Loss: 174998784.0, KL Divergence: 930.2418212890625, Reconstruction Loss: 174997856.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 16:57:12,379 - INFO - Epoch: [350/600], Total Loss: 14430342325248.0, Total KL Divergence: 69808954.734375, Total Reconstruction Loss: 14430272504832.0\n",
      "2023-07-19 16:57:12,424 - INFO - Save model at epoch 350\n",
      "0it [00:00, ?it/s]2023-07-19 16:57:12,523 - INFO - Epoch: [351/600], Step: [1/591], Loss: 119623168.0, KL Divergence: 929.0778198242188, Reconstruction Loss: 119622240.0\n",
      "118it [00:10, 10.91it/s]2023-07-19 16:57:23,372 - INFO - Epoch: [351/600], Step: [119/591], Loss: 255230144.0, KL Divergence: 908.4766845703125, Reconstruction Loss: 255229232.0\n",
      "236it [00:21, 11.15it/s]2023-07-19 16:57:34,120 - INFO - Epoch: [351/600], Step: [237/591], Loss: 205872752.0, KL Divergence: 919.3857421875, Reconstruction Loss: 205871840.0\n",
      "354it [00:32, 11.24it/s]2023-07-19 16:57:44,844 - INFO - Epoch: [351/600], Step: [355/591], Loss: 245772592.0, KL Divergence: 923.2281494140625, Reconstruction Loss: 245771664.0\n",
      "472it [00:43, 10.88it/s]2023-07-19 16:57:55,633 - INFO - Epoch: [351/600], Step: [473/591], Loss: 213353952.0, KL Divergence: 926.1915283203125, Reconstruction Loss: 213353024.0\n",
      "590it [00:53, 11.24it/s]2023-07-19 16:58:06,377 - INFO - Epoch: [351/600], Step: [591/591], Loss: 189025632.0, KL Divergence: 932.5807495117188, Reconstruction Loss: 189024704.0\n",
      "591it [00:53, 10.95it/s]\n",
      "2023-07-19 16:58:06,380 - INFO - Epoch: [351/600], Total Loss: 14444280865792.0, Total KL Divergence: 69561090.40625, Total Reconstruction Loss: 14444211277824.0\n",
      "2023-07-19 16:58:06,428 - INFO - Save model at epoch 351\n",
      "0it [00:00, ?it/s]2023-07-19 16:58:06,541 - INFO - Epoch: [352/600], Step: [1/591], Loss: 121914032.0, KL Divergence: 931.7652587890625, Reconstruction Loss: 121913104.0\n",
      "118it [00:11, 10.43it/s]2023-07-19 16:58:17,708 - INFO - Epoch: [352/600], Step: [119/591], Loss: 268373728.0, KL Divergence: 916.0574951171875, Reconstruction Loss: 268372816.0\n",
      "236it [00:22, 10.59it/s]2023-07-19 16:58:28,786 - INFO - Epoch: [352/600], Step: [237/591], Loss: 202698304.0, KL Divergence: 927.4995727539062, Reconstruction Loss: 202697376.0\n",
      "354it [00:33, 10.92it/s]2023-07-19 16:58:39,781 - INFO - Epoch: [352/600], Step: [355/591], Loss: 247850016.0, KL Divergence: 925.34814453125, Reconstruction Loss: 247849088.0\n",
      "472it [00:44, 11.18it/s]2023-07-19 16:58:50,587 - INFO - Epoch: [352/600], Step: [473/591], Loss: 218927712.0, KL Divergence: 932.79443359375, Reconstruction Loss: 218926784.0\n",
      "590it [00:54, 10.69it/s]2023-07-19 16:59:01,388 - INFO - Epoch: [352/600], Step: [591/591], Loss: 181592400.0, KL Divergence: 933.2890625, Reconstruction Loss: 181591472.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 16:59:01,390 - INFO - Epoch: [352/600], Total Loss: 14437068820480.0, Total KL Divergence: 70017463.7265625, Total Reconstruction Loss: 14436998824960.0\n",
      "2023-07-19 16:59:01,430 - INFO - Save model at epoch 352\n",
      "0it [00:00, ?it/s]2023-07-19 16:59:01,533 - INFO - Epoch: [353/600], Step: [1/591], Loss: 115398312.0, KL Divergence: 934.4069213867188, Reconstruction Loss: 115397376.0\n",
      "118it [00:10, 10.87it/s]2023-07-19 16:59:12,428 - INFO - Epoch: [353/600], Step: [119/591], Loss: 269183936.0, KL Divergence: 918.5458374023438, Reconstruction Loss: 269183008.0\n",
      "236it [00:21, 10.88it/s]2023-07-19 16:59:23,226 - INFO - Epoch: [353/600], Step: [237/591], Loss: 200450176.0, KL Divergence: 925.28271484375, Reconstruction Loss: 200449248.0\n",
      "354it [00:32, 11.25it/s]2023-07-19 16:59:33,991 - INFO - Epoch: [353/600], Step: [355/591], Loss: 262053472.0, KL Divergence: 922.7969360351562, Reconstruction Loss: 262052544.0\n",
      "472it [00:43, 10.97it/s]2023-07-19 16:59:44,794 - INFO - Epoch: [353/600], Step: [473/591], Loss: 216559696.0, KL Divergence: 925.9121704101562, Reconstruction Loss: 216558768.0\n",
      "590it [00:54, 10.74it/s]2023-07-19 16:59:55,618 - INFO - Epoch: [353/600], Step: [591/591], Loss: 170547952.0, KL Divergence: 938.3173828125, Reconstruction Loss: 170547008.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 16:59:55,620 - INFO - Epoch: [353/600], Total Loss: 14526781819904.0, Total KL Divergence: 69844008.4375, Total Reconstruction Loss: 14526711972864.0\n",
      "2023-07-19 16:59:55,661 - INFO - Save model at epoch 353\n",
      "0it [00:00, ?it/s]2023-07-19 16:59:55,769 - INFO - Epoch: [354/600], Step: [1/591], Loss: 105544760.0, KL Divergence: 936.778076171875, Reconstruction Loss: 105543824.0\n",
      "118it [00:10, 11.10it/s]2023-07-19 17:00:06,607 - INFO - Epoch: [354/600], Step: [119/591], Loss: 256952688.0, KL Divergence: 919.1494140625, Reconstruction Loss: 256951776.0\n",
      "236it [00:21, 10.60it/s]2023-07-19 17:00:17,488 - INFO - Epoch: [354/600], Step: [237/591], Loss: 203168320.0, KL Divergence: 934.6796264648438, Reconstruction Loss: 203167392.0\n",
      "354it [00:32, 10.99it/s]2023-07-19 17:00:28,356 - INFO - Epoch: [354/600], Step: [355/591], Loss: 251200528.0, KL Divergence: 934.20703125, Reconstruction Loss: 251199600.0\n",
      "472it [00:43, 11.27it/s]2023-07-19 17:00:39,175 - INFO - Epoch: [354/600], Step: [473/591], Loss: 223930304.0, KL Divergence: 925.9686279296875, Reconstruction Loss: 223929376.0\n",
      "590it [00:54, 10.88it/s]2023-07-19 17:00:49,978 - INFO - Epoch: [354/600], Step: [591/591], Loss: 172614160.0, KL Divergence: 944.797119140625, Reconstruction Loss: 172613216.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 17:00:49,980 - INFO - Epoch: [354/600], Total Loss: 14366953175040.0, Total KL Divergence: 70185508.34375, Total Reconstruction Loss: 14366882997248.0\n",
      "2023-07-19 17:00:50,019 - INFO - Save model at epoch 354\n",
      "0it [00:00, ?it/s]2023-07-19 17:00:50,139 - INFO - Epoch: [355/600], Step: [1/591], Loss: 106004672.0, KL Divergence: 943.0397338867188, Reconstruction Loss: 106003728.0\n",
      "117it [00:10, 10.39it/s]2023-07-19 17:01:01,074 - INFO - Epoch: [355/600], Step: [119/591], Loss: 262198224.0, KL Divergence: 927.645751953125, Reconstruction Loss: 262197296.0\n",
      "235it [00:21, 10.90it/s]2023-07-19 17:01:12,008 - INFO - Epoch: [355/600], Step: [237/591], Loss: 209989984.0, KL Divergence: 944.0091552734375, Reconstruction Loss: 209989040.0\n",
      "353it [00:32, 10.37it/s]2023-07-19 17:01:22,962 - INFO - Epoch: [355/600], Step: [355/591], Loss: 244931040.0, KL Divergence: 932.8016357421875, Reconstruction Loss: 244930112.0\n",
      "471it [00:43, 11.00it/s]2023-07-19 17:01:33,791 - INFO - Epoch: [355/600], Step: [473/591], Loss: 217160608.0, KL Divergence: 926.6200561523438, Reconstruction Loss: 217159680.0\n",
      "589it [00:54, 11.02it/s]2023-07-19 17:01:44,548 - INFO - Epoch: [355/600], Step: [591/591], Loss: 187070432.0, KL Divergence: 941.34228515625, Reconstruction Loss: 187069488.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 17:01:44,550 - INFO - Epoch: [355/600], Total Loss: 14407735474176.0, Total KL Divergence: 70548647.6796875, Total Reconstruction Loss: 14407664911360.0\n",
      "2023-07-19 17:01:44,611 - INFO - Save model at epoch 355\n",
      "0it [00:00, ?it/s]2023-07-19 17:01:44,718 - INFO - Epoch: [356/600], Step: [1/591], Loss: 107961240.0, KL Divergence: 942.2258911132812, Reconstruction Loss: 107960296.0\n",
      "117it [00:10, 11.10it/s]2023-07-19 17:01:55,673 - INFO - Epoch: [356/600], Step: [119/591], Loss: 256618976.0, KL Divergence: 930.3134765625, Reconstruction Loss: 256618048.0\n",
      "235it [00:21, 10.55it/s]2023-07-19 17:02:06,562 - INFO - Epoch: [356/600], Step: [237/591], Loss: 206653840.0, KL Divergence: 945.388916015625, Reconstruction Loss: 206652896.0\n",
      "353it [00:32, 10.85it/s]2023-07-19 17:02:17,376 - INFO - Epoch: [356/600], Step: [355/591], Loss: 246993616.0, KL Divergence: 940.8510131835938, Reconstruction Loss: 246992672.0\n",
      "471it [00:43, 10.63it/s]2023-07-19 17:02:28,253 - INFO - Epoch: [356/600], Step: [473/591], Loss: 220022464.0, KL Divergence: 932.8603515625, Reconstruction Loss: 220021536.0\n",
      "589it [00:54, 11.10it/s]2023-07-19 17:02:39,100 - INFO - Epoch: [356/600], Step: [591/591], Loss: 172998464.0, KL Divergence: 943.220703125, Reconstruction Loss: 172997520.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 17:02:39,102 - INFO - Epoch: [356/600], Total Loss: 14453791754240.0, Total KL Divergence: 70793351.2890625, Total Reconstruction Loss: 14453720994816.0\n",
      "2023-07-19 17:02:39,140 - INFO - Save model at epoch 356\n",
      "0it [00:00, ?it/s]2023-07-19 17:02:39,247 - INFO - Epoch: [357/600], Step: [1/591], Loss: 111786560.0, KL Divergence: 945.9267578125, Reconstruction Loss: 111785616.0\n",
      "118it [00:10, 10.96it/s]2023-07-19 17:02:50,097 - INFO - Epoch: [357/600], Step: [119/591], Loss: 258874560.0, KL Divergence: 937.794677734375, Reconstruction Loss: 258873616.0\n",
      "236it [00:21, 10.78it/s]2023-07-19 17:03:00,963 - INFO - Epoch: [357/600], Step: [237/591], Loss: 212276720.0, KL Divergence: 948.5515747070312, Reconstruction Loss: 212275776.0\n",
      "354it [00:32, 10.80it/s]2023-07-19 17:03:11,844 - INFO - Epoch: [357/600], Step: [355/591], Loss: 245452960.0, KL Divergence: 933.9716796875, Reconstruction Loss: 245452032.0\n",
      "472it [00:43, 11.18it/s]2023-07-19 17:03:22,645 - INFO - Epoch: [357/600], Step: [473/591], Loss: 230253376.0, KL Divergence: 934.1779174804688, Reconstruction Loss: 230252448.0\n",
      "590it [00:54, 10.82it/s]2023-07-19 17:03:33,420 - INFO - Epoch: [357/600], Step: [591/591], Loss: 171799808.0, KL Divergence: 952.0499877929688, Reconstruction Loss: 171798848.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 17:03:33,422 - INFO - Epoch: [357/600], Total Loss: 14580994365440.0, Total KL Divergence: 70782712.4296875, Total Reconstruction Loss: 14580923594752.0\n",
      "2023-07-19 17:03:33,474 - INFO - Save model at epoch 357\n",
      "0it [00:00, ?it/s]2023-07-19 17:03:33,591 - INFO - Epoch: [358/600], Step: [1/591], Loss: 123968040.0, KL Divergence: 952.5573120117188, Reconstruction Loss: 123967088.0\n",
      "117it [00:10, 10.52it/s]2023-07-19 17:03:44,411 - INFO - Epoch: [358/600], Step: [119/591], Loss: 259051152.0, KL Divergence: 932.5833740234375, Reconstruction Loss: 259050224.0\n",
      "235it [00:21, 11.02it/s]2023-07-19 17:03:55,175 - INFO - Epoch: [358/600], Step: [237/591], Loss: 205400720.0, KL Divergence: 940.9215087890625, Reconstruction Loss: 205399776.0\n",
      "353it [00:32, 10.87it/s]2023-07-19 17:04:06,041 - INFO - Epoch: [358/600], Step: [355/591], Loss: 253769408.0, KL Divergence: 943.7264404296875, Reconstruction Loss: 253768464.0\n",
      "471it [00:43, 11.03it/s]2023-07-19 17:04:16,799 - INFO - Epoch: [358/600], Step: [473/591], Loss: 235917696.0, KL Divergence: 935.78076171875, Reconstruction Loss: 235916768.0\n",
      "589it [00:53, 11.13it/s]2023-07-19 17:04:27,557 - INFO - Epoch: [358/600], Step: [591/591], Loss: 191446768.0, KL Divergence: 958.8058471679688, Reconstruction Loss: 191445808.0\n",
      "591it [00:54, 10.93it/s]\n",
      "2023-07-19 17:04:27,559 - INFO - Epoch: [358/600], Total Loss: 14776646703104.0, Total KL Divergence: 70962410.0390625, Total Reconstruction Loss: 14776575770624.0\n",
      "2023-07-19 17:04:27,605 - INFO - Save model at epoch 358\n",
      "0it [00:00, ?it/s]2023-07-19 17:04:27,737 - INFO - Epoch: [359/600], Step: [1/591], Loss: 115607920.0, KL Divergence: 956.0111083984375, Reconstruction Loss: 115606960.0\n",
      "118it [00:10, 10.67it/s]2023-07-19 17:04:38,675 - INFO - Epoch: [359/600], Step: [119/591], Loss: 256900832.0, KL Divergence: 937.9483642578125, Reconstruction Loss: 256899888.0\n",
      "236it [00:21, 10.69it/s]2023-07-19 17:04:49,597 - INFO - Epoch: [359/600], Step: [237/591], Loss: 197801712.0, KL Divergence: 944.4135131835938, Reconstruction Loss: 197800768.0\n",
      "354it [00:32, 10.88it/s]2023-07-19 17:05:00,410 - INFO - Epoch: [359/600], Step: [355/591], Loss: 251821904.0, KL Divergence: 946.7723999023438, Reconstruction Loss: 251820960.0\n",
      "472it [00:43, 11.25it/s]2023-07-19 17:05:11,195 - INFO - Epoch: [359/600], Step: [473/591], Loss: 229075168.0, KL Divergence: 942.11865234375, Reconstruction Loss: 229074224.0\n",
      "590it [00:54, 10.74it/s]2023-07-19 17:05:21,976 - INFO - Epoch: [359/600], Step: [591/591], Loss: 173470144.0, KL Divergence: 958.5443115234375, Reconstruction Loss: 173469184.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 17:05:21,978 - INFO - Epoch: [359/600], Total Loss: 14543551996928.0, Total KL Divergence: 71322608.8984375, Total Reconstruction Loss: 14543480677376.0\n",
      "2023-07-19 17:05:22,019 - INFO - Save model at epoch 359\n",
      "0it [00:00, ?it/s]2023-07-19 17:05:22,118 - INFO - Epoch: [360/600], Step: [1/591], Loss: 107447840.0, KL Divergence: 956.231689453125, Reconstruction Loss: 107446880.0\n",
      "118it [00:10, 11.18it/s]2023-07-19 17:05:32,977 - INFO - Epoch: [360/600], Step: [119/591], Loss: 254202784.0, KL Divergence: 936.9152221679688, Reconstruction Loss: 254201840.0\n",
      "236it [00:21, 10.80it/s]2023-07-19 17:05:43,800 - INFO - Epoch: [360/600], Step: [237/591], Loss: 197673584.0, KL Divergence: 946.3045654296875, Reconstruction Loss: 197672640.0\n",
      "354it [00:32, 11.13it/s]2023-07-19 17:05:54,553 - INFO - Epoch: [360/600], Step: [355/591], Loss: 249186736.0, KL Divergence: 943.73779296875, Reconstruction Loss: 249185792.0\n",
      "472it [00:43, 10.94it/s]2023-07-19 17:06:05,357 - INFO - Epoch: [360/600], Step: [473/591], Loss: 216233424.0, KL Divergence: 942.683349609375, Reconstruction Loss: 216232480.0\n",
      "590it [00:54, 10.70it/s]2023-07-19 17:06:16,194 - INFO - Epoch: [360/600], Step: [591/591], Loss: 171094688.0, KL Divergence: 952.0958862304688, Reconstruction Loss: 171093728.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 17:06:16,195 - INFO - Epoch: [360/600], Total Loss: 14156201612288.0, Total KL Divergence: 71294806.25, Total Reconstruction Loss: 14156130304000.0\n",
      "2023-07-19 17:06:16,235 - INFO - Save model at epoch 360\n",
      "0it [00:00, ?it/s]2023-07-19 17:06:16,336 - INFO - Epoch: [361/600], Step: [1/591], Loss: 110639144.0, KL Divergence: 952.3038330078125, Reconstruction Loss: 110638192.0\n",
      "118it [00:10, 10.84it/s]2023-07-19 17:06:27,223 - INFO - Epoch: [361/600], Step: [119/591], Loss: 248764336.0, KL Divergence: 938.144287109375, Reconstruction Loss: 248763392.0\n",
      "236it [00:21, 10.37it/s]2023-07-19 17:06:38,101 - INFO - Epoch: [361/600], Step: [237/591], Loss: 197398160.0, KL Divergence: 950.5069580078125, Reconstruction Loss: 197397216.0\n",
      "354it [00:32, 10.96it/s]2023-07-19 17:06:48,928 - INFO - Epoch: [361/600], Step: [355/591], Loss: 258209584.0, KL Divergence: 942.7889404296875, Reconstruction Loss: 258208640.0\n",
      "472it [00:43, 11.21it/s]2023-07-19 17:06:59,628 - INFO - Epoch: [361/600], Step: [473/591], Loss: 237017520.0, KL Divergence: 947.8431396484375, Reconstruction Loss: 237016576.0\n",
      "590it [00:54, 11.12it/s]2023-07-19 17:07:10,370 - INFO - Epoch: [361/600], Step: [591/591], Loss: 182335840.0, KL Divergence: 951.5482788085938, Reconstruction Loss: 182334896.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 17:07:10,371 - INFO - Epoch: [361/600], Total Loss: 14249253314560.0, Total KL Divergence: 71262884.3203125, Total Reconstruction Loss: 14249182073856.0\n",
      "2023-07-19 17:07:10,433 - INFO - Save model at epoch 361\n",
      "0it [00:00, ?it/s]2023-07-19 17:07:10,548 - INFO - Epoch: [362/600], Step: [1/591], Loss: 116816520.0, KL Divergence: 950.9891967773438, Reconstruction Loss: 116815568.0\n",
      "117it [00:10, 11.23it/s]2023-07-19 17:07:21,464 - INFO - Epoch: [362/600], Step: [119/591], Loss: 248695696.0, KL Divergence: 930.8092651367188, Reconstruction Loss: 248694768.0\n",
      "235it [00:21, 10.71it/s]2023-07-19 17:07:32,349 - INFO - Epoch: [362/600], Step: [237/591], Loss: 200417136.0, KL Divergence: 945.615478515625, Reconstruction Loss: 200416192.0\n",
      "353it [00:32, 10.96it/s]2023-07-19 17:07:43,198 - INFO - Epoch: [362/600], Step: [355/591], Loss: 249794256.0, KL Divergence: 944.0784301757812, Reconstruction Loss: 249793312.0\n",
      "471it [00:43, 11.09it/s]2023-07-19 17:07:54,007 - INFO - Epoch: [362/600], Step: [473/591], Loss: 217169216.0, KL Divergence: 936.390625, Reconstruction Loss: 217168272.0\n",
      "589it [00:54, 10.84it/s]2023-07-19 17:08:04,749 - INFO - Epoch: [362/600], Step: [591/591], Loss: 170877648.0, KL Divergence: 951.6227416992188, Reconstruction Loss: 170876704.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 17:08:04,751 - INFO - Epoch: [362/600], Total Loss: 14228835709952.0, Total KL Divergence: 71022569.0, Total Reconstruction Loss: 14228764700672.0\n",
      "2023-07-19 17:08:04,794 - INFO - Save model at epoch 362\n",
      "0it [00:00, ?it/s]2023-07-19 17:08:04,917 - INFO - Epoch: [363/600], Step: [1/591], Loss: 108817856.0, KL Divergence: 951.720703125, Reconstruction Loss: 108816904.0\n",
      "118it [00:10, 11.15it/s]2023-07-19 17:08:15,755 - INFO - Epoch: [363/600], Step: [119/591], Loss: 249402080.0, KL Divergence: 933.6433715820312, Reconstruction Loss: 249401152.0\n",
      "236it [00:21, 10.27it/s]2023-07-19 17:08:26,686 - INFO - Epoch: [363/600], Step: [237/591], Loss: 202323264.0, KL Divergence: 939.5336303710938, Reconstruction Loss: 202322320.0\n",
      "354it [00:32, 11.19it/s]2023-07-19 17:08:37,520 - INFO - Epoch: [363/600], Step: [355/591], Loss: 245813616.0, KL Divergence: 940.5660400390625, Reconstruction Loss: 245812672.0\n",
      "472it [00:43, 10.78it/s]2023-07-19 17:08:48,301 - INFO - Epoch: [363/600], Step: [473/591], Loss: 221148816.0, KL Divergence: 942.6363525390625, Reconstruction Loss: 221147872.0\n",
      "590it [00:54, 10.77it/s]2023-07-19 17:08:59,113 - INFO - Epoch: [363/600], Step: [591/591], Loss: 173326976.0, KL Divergence: 952.5947265625, Reconstruction Loss: 173326016.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 17:08:59,114 - INFO - Epoch: [363/600], Total Loss: 14102428581888.0, Total KL Divergence: 71079797.828125, Total Reconstruction Loss: 14102357523456.0\n",
      "2023-07-19 17:08:59,156 - INFO - Save model at epoch 363\n",
      "0it [00:00, ?it/s]2023-07-19 17:08:59,255 - INFO - Epoch: [364/600], Step: [1/591], Loss: 114171792.0, KL Divergence: 954.2552490234375, Reconstruction Loss: 114170840.0\n",
      "118it [00:10, 11.02it/s]2023-07-19 17:09:10,240 - INFO - Epoch: [364/600], Step: [119/591], Loss: 252099424.0, KL Divergence: 932.2862548828125, Reconstruction Loss: 252098496.0\n",
      "236it [00:21, 10.79it/s]2023-07-19 17:09:21,108 - INFO - Epoch: [364/600], Step: [237/591], Loss: 200822928.0, KL Divergence: 944.1495971679688, Reconstruction Loss: 200821984.0\n",
      "353it [00:32, 11.27it/s]2023-07-19 17:09:31,931 - INFO - Epoch: [364/600], Step: [355/591], Loss: 243941040.0, KL Divergence: 945.8084106445312, Reconstruction Loss: 243940096.0\n",
      "471it [00:43, 11.00it/s]2023-07-19 17:09:42,716 - INFO - Epoch: [364/600], Step: [473/591], Loss: 226528112.0, KL Divergence: 942.9652099609375, Reconstruction Loss: 226527168.0\n",
      "589it [00:54, 11.10it/s]2023-07-19 17:09:53,524 - INFO - Epoch: [364/600], Step: [591/591], Loss: 178223296.0, KL Divergence: 950.3538818359375, Reconstruction Loss: 178222352.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 17:09:53,526 - INFO - Epoch: [364/600], Total Loss: 14172238246912.0, Total KL Divergence: 71198075.1953125, Total Reconstruction Loss: 14172167055360.0\n",
      "2023-07-19 17:09:53,565 - INFO - Save model at epoch 364\n",
      "0it [00:00, ?it/s]2023-07-19 17:09:53,673 - INFO - Epoch: [365/600], Step: [1/591], Loss: 112193048.0, KL Divergence: 953.8219604492188, Reconstruction Loss: 112192096.0\n",
      "118it [00:10, 10.97it/s]2023-07-19 17:10:04,533 - INFO - Epoch: [365/600], Step: [119/591], Loss: 256774944.0, KL Divergence: 937.9342041015625, Reconstruction Loss: 256774000.0\n",
      "236it [00:21, 11.02it/s]2023-07-19 17:10:15,321 - INFO - Epoch: [365/600], Step: [237/591], Loss: 201520464.0, KL Divergence: 949.9498291015625, Reconstruction Loss: 201519520.0\n",
      "354it [00:32, 10.86it/s]2023-07-19 17:10:26,291 - INFO - Epoch: [365/600], Step: [355/591], Loss: 255125776.0, KL Divergence: 947.7410278320312, Reconstruction Loss: 255124832.0\n",
      "472it [00:43, 11.05it/s]2023-07-19 17:10:37,083 - INFO - Epoch: [365/600], Step: [473/591], Loss: 233674528.0, KL Divergence: 950.6607666015625, Reconstruction Loss: 233673584.0\n",
      "590it [00:54, 10.86it/s]2023-07-19 17:10:47,770 - INFO - Epoch: [365/600], Step: [591/591], Loss: 181194256.0, KL Divergence: 948.710205078125, Reconstruction Loss: 181193312.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 17:10:47,772 - INFO - Epoch: [365/600], Total Loss: 14189717334016.0, Total KL Divergence: 71432806.1484375, Total Reconstruction Loss: 14189645880320.0\n",
      "2023-07-19 17:10:47,817 - INFO - Save model at epoch 365\n",
      "0it [00:00, ?it/s]2023-07-19 17:10:47,927 - INFO - Epoch: [366/600], Step: [1/591], Loss: 110759216.0, KL Divergence: 954.050537109375, Reconstruction Loss: 110758264.0\n",
      "118it [00:10, 10.90it/s]2023-07-19 17:10:58,794 - INFO - Epoch: [366/600], Step: [119/591], Loss: 247460048.0, KL Divergence: 932.231201171875, Reconstruction Loss: 247459120.0\n",
      "236it [00:21, 11.18it/s]2023-07-19 17:11:09,528 - INFO - Epoch: [366/600], Step: [237/591], Loss: 203032912.0, KL Divergence: 950.144775390625, Reconstruction Loss: 203031968.0\n",
      "354it [00:32, 10.51it/s]2023-07-19 17:11:20,357 - INFO - Epoch: [366/600], Step: [355/591], Loss: 245997936.0, KL Divergence: 943.3531494140625, Reconstruction Loss: 245996992.0\n",
      "472it [00:43, 10.82it/s]2023-07-19 17:11:31,262 - INFO - Epoch: [366/600], Step: [473/591], Loss: 228179632.0, KL Divergence: 941.14208984375, Reconstruction Loss: 228178688.0\n",
      "590it [00:54, 10.91it/s]2023-07-19 17:11:42,117 - INFO - Epoch: [366/600], Step: [591/591], Loss: 168307440.0, KL Divergence: 942.5902099609375, Reconstruction Loss: 168306496.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 17:11:42,119 - INFO - Epoch: [366/600], Total Loss: 14132845473792.0, Total KL Divergence: 71079421.734375, Total Reconstruction Loss: 14132774416384.0\n",
      "2023-07-19 17:11:42,166 - INFO - Save model at epoch 366\n",
      "0it [00:00, ?it/s]2023-07-19 17:11:42,283 - INFO - Epoch: [367/600], Step: [1/591], Loss: 113023720.0, KL Divergence: 948.763427734375, Reconstruction Loss: 113022768.0\n",
      "118it [00:10, 11.15it/s]2023-07-19 17:11:53,137 - INFO - Epoch: [367/600], Step: [119/591], Loss: 246815488.0, KL Divergence: 935.606201171875, Reconstruction Loss: 246814560.0\n",
      "236it [00:21, 10.71it/s]2023-07-19 17:12:03,914 - INFO - Epoch: [367/600], Step: [237/591], Loss: 202926960.0, KL Divergence: 948.0740966796875, Reconstruction Loss: 202926016.0\n",
      "354it [00:32, 10.76it/s]2023-07-19 17:12:14,799 - INFO - Epoch: [367/600], Step: [355/591], Loss: 242067792.0, KL Divergence: 945.27294921875, Reconstruction Loss: 242066848.0\n",
      "472it [00:43, 11.01it/s]2023-07-19 17:12:25,558 - INFO - Epoch: [367/600], Step: [473/591], Loss: 237637056.0, KL Divergence: 947.1842041015625, Reconstruction Loss: 237636112.0\n",
      "590it [00:54, 10.96it/s]2023-07-19 17:12:36,244 - INFO - Epoch: [367/600], Step: [591/591], Loss: 172153664.0, KL Divergence: 959.0424194335938, Reconstruction Loss: 172152704.0\n",
      "591it [00:54, 10.93it/s]\n",
      "2023-07-19 17:12:36,245 - INFO - Epoch: [367/600], Total Loss: 14166731607040.0, Total KL Divergence: 71339102.9765625, Total Reconstruction Loss: 14166660275200.0\n",
      "2023-07-19 17:12:36,286 - INFO - Save model at epoch 367\n",
      "0it [00:00, ?it/s]2023-07-19 17:12:36,402 - INFO - Epoch: [368/600], Step: [1/591], Loss: 110431136.0, KL Divergence: 962.7745361328125, Reconstruction Loss: 110430176.0\n",
      "118it [00:10, 10.62it/s]2023-07-19 17:12:47,248 - INFO - Epoch: [368/600], Step: [119/591], Loss: 249410768.0, KL Divergence: 944.0648193359375, Reconstruction Loss: 249409824.0\n",
      "236it [00:21, 11.05it/s]2023-07-19 17:12:58,055 - INFO - Epoch: [368/600], Step: [237/591], Loss: 202742704.0, KL Divergence: 957.8240966796875, Reconstruction Loss: 202741744.0\n",
      "354it [00:32, 10.97it/s]2023-07-19 17:13:08,904 - INFO - Epoch: [368/600], Step: [355/591], Loss: 241106256.0, KL Divergence: 958.5658569335938, Reconstruction Loss: 241105296.0\n",
      "472it [00:43, 10.87it/s]2023-07-19 17:13:19,782 - INFO - Epoch: [368/600], Step: [473/591], Loss: 226119648.0, KL Divergence: 956.9879150390625, Reconstruction Loss: 226118688.0\n",
      "590it [00:54, 10.84it/s]2023-07-19 17:13:30,573 - INFO - Epoch: [368/600], Step: [591/591], Loss: 169338352.0, KL Divergence: 956.8876342773438, Reconstruction Loss: 169337392.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 17:13:30,574 - INFO - Epoch: [368/600], Total Loss: 14086612038656.0, Total KL Divergence: 72230993.2578125, Total Reconstruction Loss: 14086539826176.0\n",
      "2023-07-19 17:13:30,621 - INFO - Save model at epoch 368\n",
      "0it [00:00, ?it/s]2023-07-19 17:13:30,737 - INFO - Epoch: [369/600], Step: [1/591], Loss: 113926288.0, KL Divergence: 960.82080078125, Reconstruction Loss: 113925328.0\n",
      "118it [00:11, 11.17it/s]2023-07-19 17:13:41,739 - INFO - Epoch: [369/600], Step: [119/591], Loss: 248506608.0, KL Divergence: 943.3825073242188, Reconstruction Loss: 248505664.0\n",
      "236it [00:21, 10.68it/s]2023-07-19 17:13:52,492 - INFO - Epoch: [369/600], Step: [237/591], Loss: 201895792.0, KL Divergence: 946.6337890625, Reconstruction Loss: 201894848.0\n",
      "354it [00:32, 10.37it/s]2023-07-19 17:14:03,373 - INFO - Epoch: [369/600], Step: [355/591], Loss: 242212496.0, KL Divergence: 946.241455078125, Reconstruction Loss: 242211552.0\n",
      "472it [00:43, 10.75it/s]2023-07-19 17:14:14,190 - INFO - Epoch: [369/600], Step: [473/591], Loss: 213391056.0, KL Divergence: 940.5742797851562, Reconstruction Loss: 213390112.0\n",
      "590it [00:54, 11.08it/s]2023-07-19 17:14:24,943 - INFO - Epoch: [369/600], Step: [591/591], Loss: 170241136.0, KL Divergence: 953.3402099609375, Reconstruction Loss: 170240176.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 17:14:24,945 - INFO - Epoch: [369/600], Total Loss: 14009686070272.0, Total KL Divergence: 71435757.2265625, Total Reconstruction Loss: 14009614623744.0\n",
      "2023-07-19 17:14:25,000 - INFO - Save model at epoch 369\n",
      "0it [00:00, ?it/s]2023-07-19 17:14:25,103 - INFO - Epoch: [370/600], Step: [1/591], Loss: 111152784.0, KL Divergence: 957.3743896484375, Reconstruction Loss: 111151824.0\n",
      "118it [00:11, 10.85it/s]2023-07-19 17:14:36,125 - INFO - Epoch: [370/600], Step: [119/591], Loss: 245944864.0, KL Divergence: 942.255615234375, Reconstruction Loss: 245943920.0\n",
      "236it [00:21, 10.56it/s]2023-07-19 17:14:47,011 - INFO - Epoch: [370/600], Step: [237/591], Loss: 203087952.0, KL Divergence: 948.75341796875, Reconstruction Loss: 203087008.0\n",
      "354it [00:32, 10.91it/s]2023-07-19 17:14:57,880 - INFO - Epoch: [370/600], Step: [355/591], Loss: 255197968.0, KL Divergence: 940.995849609375, Reconstruction Loss: 255197024.0\n",
      "472it [00:43, 10.80it/s]2023-07-19 17:15:08,728 - INFO - Epoch: [370/600], Step: [473/591], Loss: 208634128.0, KL Divergence: 940.8638916015625, Reconstruction Loss: 208633184.0\n",
      "590it [00:54, 10.74it/s]2023-07-19 17:15:19,573 - INFO - Epoch: [370/600], Step: [591/591], Loss: 167463760.0, KL Divergence: 947.4523315429688, Reconstruction Loss: 167462816.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 17:15:19,574 - INFO - Epoch: [370/600], Total Loss: 14106918285312.0, Total KL Divergence: 71168587.921875, Total Reconstruction Loss: 14106847134720.0\n",
      "2023-07-19 17:15:19,614 - INFO - Save model at epoch 370\n",
      "0it [00:00, ?it/s]2023-07-19 17:15:19,729 - INFO - Epoch: [371/600], Step: [1/591], Loss: 110948400.0, KL Divergence: 951.0045776367188, Reconstruction Loss: 110947448.0\n",
      "118it [00:10, 10.98it/s]2023-07-19 17:15:30,607 - INFO - Epoch: [371/600], Step: [119/591], Loss: 245674144.0, KL Divergence: 931.366455078125, Reconstruction Loss: 245673216.0\n",
      "236it [00:21, 10.91it/s]2023-07-19 17:15:41,456 - INFO - Epoch: [371/600], Step: [237/591], Loss: 201729712.0, KL Divergence: 945.19384765625, Reconstruction Loss: 201728768.0\n",
      "354it [00:32, 10.58it/s]2023-07-19 17:15:52,362 - INFO - Epoch: [371/600], Step: [355/591], Loss: 242409520.0, KL Divergence: 943.2684326171875, Reconstruction Loss: 242408576.0\n",
      "472it [00:43, 10.69it/s]2023-07-19 17:16:03,234 - INFO - Epoch: [371/600], Step: [473/591], Loss: 216824256.0, KL Divergence: 939.2200317382812, Reconstruction Loss: 216823312.0\n",
      "590it [00:54, 11.11it/s]2023-07-19 17:16:14,063 - INFO - Epoch: [371/600], Step: [591/591], Loss: 175466464.0, KL Divergence: 941.3131103515625, Reconstruction Loss: 175465520.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 17:16:14,064 - INFO - Epoch: [371/600], Total Loss: 13936826158080.0, Total KL Divergence: 70925148.8046875, Total Reconstruction Loss: 13936755272704.0\n",
      "2023-07-19 17:16:14,126 - INFO - Save model at epoch 371\n",
      "0it [00:00, ?it/s]2023-07-19 17:16:14,224 - INFO - Epoch: [372/600], Step: [1/591], Loss: 113881472.0, KL Divergence: 945.4036254882812, Reconstruction Loss: 113880528.0\n",
      "118it [00:10, 10.95it/s]2023-07-19 17:16:25,175 - INFO - Epoch: [372/600], Step: [119/591], Loss: 249158272.0, KL Divergence: 933.8504028320312, Reconstruction Loss: 249157344.0\n",
      "236it [00:21, 10.83it/s]2023-07-19 17:16:35,975 - INFO - Epoch: [372/600], Step: [237/591], Loss: 206917456.0, KL Divergence: 948.3370971679688, Reconstruction Loss: 206916512.0\n",
      "354it [00:32, 11.01it/s]2023-07-19 17:16:46,836 - INFO - Epoch: [372/600], Step: [355/591], Loss: 247400800.0, KL Divergence: 941.1537475585938, Reconstruction Loss: 247399856.0\n",
      "472it [00:43, 10.72it/s]2023-07-19 17:16:57,633 - INFO - Epoch: [372/600], Step: [473/591], Loss: 225346128.0, KL Divergence: 939.0303344726562, Reconstruction Loss: 225345184.0\n",
      "590it [00:54, 10.93it/s]2023-07-19 17:17:08,434 - INFO - Epoch: [372/600], Step: [591/591], Loss: 162703936.0, KL Divergence: 948.1163940429688, Reconstruction Loss: 162702992.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 17:17:08,437 - INFO - Epoch: [372/600], Total Loss: 14017679714304.0, Total KL Divergence: 71007854.8125, Total Reconstruction Loss: 14017608714240.0\n",
      "2023-07-19 17:17:08,476 - INFO - Save model at epoch 372\n",
      "0it [00:00, ?it/s]2023-07-19 17:17:08,597 - INFO - Epoch: [373/600], Step: [1/591], Loss: 115526488.0, KL Divergence: 950.591796875, Reconstruction Loss: 115525536.0\n",
      "117it [00:10, 10.91it/s]2023-07-19 17:17:19,489 - INFO - Epoch: [373/600], Step: [119/591], Loss: 247640800.0, KL Divergence: 934.3621826171875, Reconstruction Loss: 247639872.0\n",
      "235it [00:21, 11.03it/s]2023-07-19 17:17:30,374 - INFO - Epoch: [373/600], Step: [237/591], Loss: 199602320.0, KL Divergence: 947.1348876953125, Reconstruction Loss: 199601376.0\n",
      "353it [00:32, 10.55it/s]2023-07-19 17:17:41,266 - INFO - Epoch: [373/600], Step: [355/591], Loss: 275796000.0, KL Divergence: 941.976318359375, Reconstruction Loss: 275795072.0\n",
      "471it [00:43, 11.25it/s]2023-07-19 17:17:52,058 - INFO - Epoch: [373/600], Step: [473/591], Loss: 224808256.0, KL Divergence: 944.1884765625, Reconstruction Loss: 224807312.0\n",
      "589it [00:54, 11.08it/s]2023-07-19 17:18:02,818 - INFO - Epoch: [373/600], Step: [591/591], Loss: 168479216.0, KL Divergence: 960.734375, Reconstruction Loss: 168478256.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 17:18:02,821 - INFO - Epoch: [373/600], Total Loss: 14102559995904.0, Total KL Divergence: 71164685.15625, Total Reconstruction Loss: 14102488854528.0\n",
      "2023-07-19 17:18:02,870 - INFO - Save model at epoch 373\n",
      "0it [00:00, ?it/s]2023-07-19 17:18:02,970 - INFO - Epoch: [374/600], Step: [1/591], Loss: 111471056.0, KL Divergence: 961.393798828125, Reconstruction Loss: 111470096.0\n",
      "118it [00:10, 10.55it/s]2023-07-19 17:18:13,964 - INFO - Epoch: [374/600], Step: [119/591], Loss: 255172432.0, KL Divergence: 944.12744140625, Reconstruction Loss: 255171488.0\n",
      "236it [00:21, 11.00it/s]2023-07-19 17:18:24,880 - INFO - Epoch: [374/600], Step: [237/591], Loss: 197663136.0, KL Divergence: 960.2891845703125, Reconstruction Loss: 197662176.0\n",
      "354it [00:32, 10.42it/s]2023-07-19 17:18:35,911 - INFO - Epoch: [374/600], Step: [355/591], Loss: 267403568.0, KL Divergence: 956.127685546875, Reconstruction Loss: 267402608.0\n",
      "472it [00:43, 10.98it/s]2023-07-19 17:18:46,781 - INFO - Epoch: [374/600], Step: [473/591], Loss: 216984704.0, KL Divergence: 954.7601318359375, Reconstruction Loss: 216983744.0\n",
      "590it [00:54, 10.79it/s]2023-07-19 17:18:57,563 - INFO - Epoch: [374/600], Step: [591/591], Loss: 176096048.0, KL Divergence: 960.5162353515625, Reconstruction Loss: 176095088.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 17:18:57,565 - INFO - Epoch: [374/600], Total Loss: 14023266459648.0, Total KL Divergence: 71917746.53125, Total Reconstruction Loss: 14023194555392.0\n",
      "2023-07-19 17:18:57,607 - INFO - Save model at epoch 374\n",
      "0it [00:00, ?it/s]2023-07-19 17:18:57,711 - INFO - Epoch: [375/600], Step: [1/591], Loss: 109474768.0, KL Divergence: 962.9271240234375, Reconstruction Loss: 109473808.0\n",
      "118it [00:10, 11.18it/s]2023-07-19 17:19:08,520 - INFO - Epoch: [375/600], Step: [119/591], Loss: 248912416.0, KL Divergence: 944.9871826171875, Reconstruction Loss: 248911472.0\n",
      "236it [00:21, 11.00it/s]2023-07-19 17:19:19,323 - INFO - Epoch: [375/600], Step: [237/591], Loss: 202675280.0, KL Divergence: 944.5869140625, Reconstruction Loss: 202674336.0\n",
      "354it [00:32, 10.49it/s]2023-07-19 17:19:30,222 - INFO - Epoch: [375/600], Step: [355/591], Loss: 244462736.0, KL Divergence: 948.4073486328125, Reconstruction Loss: 244461792.0\n",
      "472it [00:43, 10.99it/s]2023-07-19 17:19:41,022 - INFO - Epoch: [375/600], Step: [473/591], Loss: 223429248.0, KL Divergence: 952.9681396484375, Reconstruction Loss: 223428288.0\n",
      "590it [00:54, 11.07it/s]2023-07-19 17:19:51,768 - INFO - Epoch: [375/600], Step: [591/591], Loss: 174450560.0, KL Divergence: 952.3577880859375, Reconstruction Loss: 174449600.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 17:19:51,769 - INFO - Epoch: [375/600], Total Loss: 14083413186560.0, Total KL Divergence: 71559461.3125, Total Reconstruction Loss: 14083341607936.0\n",
      "2023-07-19 17:19:51,808 - INFO - Save model at epoch 375\n",
      "0it [00:00, ?it/s]2023-07-19 17:19:51,924 - INFO - Epoch: [376/600], Step: [1/591], Loss: 109392856.0, KL Divergence: 956.59326171875, Reconstruction Loss: 109391896.0\n",
      "117it [00:10, 10.96it/s]2023-07-19 17:20:02,842 - INFO - Epoch: [376/600], Step: [119/591], Loss: 252365232.0, KL Divergence: 936.5880126953125, Reconstruction Loss: 252364288.0\n",
      "235it [00:21, 11.19it/s]2023-07-19 17:20:13,658 - INFO - Epoch: [376/600], Step: [237/591], Loss: 201866768.0, KL Divergence: 952.8349609375, Reconstruction Loss: 201865808.0\n",
      "353it [00:32, 10.59it/s]2023-07-19 17:20:24,495 - INFO - Epoch: [376/600], Step: [355/591], Loss: 257736928.0, KL Divergence: 948.878662109375, Reconstruction Loss: 257735984.0\n",
      "471it [00:43, 10.77it/s]2023-07-19 17:20:35,301 - INFO - Epoch: [376/600], Step: [473/591], Loss: 219749408.0, KL Divergence: 953.1860961914062, Reconstruction Loss: 219748448.0\n",
      "589it [00:54, 10.95it/s]2023-07-19 17:20:46,188 - INFO - Epoch: [376/600], Step: [591/591], Loss: 178224064.0, KL Divergence: 951.7169799804688, Reconstruction Loss: 178223120.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 17:20:46,190 - INFO - Epoch: [376/600], Total Loss: 14016303068160.0, Total KL Divergence: 71530719.8671875, Total Reconstruction Loss: 14016231525376.0\n",
      "2023-07-19 17:20:46,232 - INFO - Save model at epoch 376\n",
      "0it [00:00, ?it/s]2023-07-19 17:20:46,344 - INFO - Epoch: [377/600], Step: [1/591], Loss: 109302128.0, KL Divergence: 956.9326171875, Reconstruction Loss: 109301168.0\n",
      "118it [00:10, 11.02it/s]2023-07-19 17:20:57,267 - INFO - Epoch: [377/600], Step: [119/591], Loss: 253506704.0, KL Divergence: 940.041015625, Reconstruction Loss: 253505760.0\n",
      "236it [00:21, 11.00it/s]2023-07-19 17:21:08,140 - INFO - Epoch: [377/600], Step: [237/591], Loss: 196832848.0, KL Divergence: 956.1165161132812, Reconstruction Loss: 196831888.0\n",
      "354it [00:32,  9.96it/s]2023-07-19 17:21:19,030 - INFO - Epoch: [377/600], Step: [355/591], Loss: 242940912.0, KL Divergence: 952.0897216796875, Reconstruction Loss: 242939952.0\n",
      "472it [00:43, 11.05it/s]2023-07-19 17:21:29,809 - INFO - Epoch: [377/600], Step: [473/591], Loss: 217208624.0, KL Divergence: 951.6427612304688, Reconstruction Loss: 217207680.0\n",
      "590it [00:54, 10.72it/s]2023-07-19 17:21:40,648 - INFO - Epoch: [377/600], Step: [591/591], Loss: 209648000.0, KL Divergence: 957.3263549804688, Reconstruction Loss: 209647040.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 17:21:40,650 - INFO - Epoch: [377/600], Total Loss: 14087488300032.0, Total KL Divergence: 71682566.0546875, Total Reconstruction Loss: 14087416604672.0\n",
      "2023-07-19 17:21:40,698 - INFO - Save model at epoch 377\n",
      "0it [00:00, ?it/s]2023-07-19 17:21:40,797 - INFO - Epoch: [378/600], Step: [1/591], Loss: 112702920.0, KL Divergence: 960.2144775390625, Reconstruction Loss: 112701960.0\n",
      "118it [00:10, 10.99it/s]2023-07-19 17:21:51,731 - INFO - Epoch: [378/600], Step: [119/591], Loss: 255006160.0, KL Divergence: 934.0096435546875, Reconstruction Loss: 255005232.0\n",
      "236it [00:21, 10.55it/s]2023-07-19 17:22:02,647 - INFO - Epoch: [378/600], Step: [237/591], Loss: 193895456.0, KL Divergence: 951.293701171875, Reconstruction Loss: 193894512.0\n",
      "354it [00:32, 11.12it/s]2023-07-19 17:22:13,521 - INFO - Epoch: [378/600], Step: [355/591], Loss: 239371760.0, KL Divergence: 951.421142578125, Reconstruction Loss: 239370816.0\n",
      "472it [00:43, 10.89it/s]2023-07-19 17:22:24,410 - INFO - Epoch: [378/600], Step: [473/591], Loss: 210307216.0, KL Divergence: 940.6868896484375, Reconstruction Loss: 210306272.0\n",
      "590it [00:54, 10.68it/s]2023-07-19 17:22:35,238 - INFO - Epoch: [378/600], Step: [591/591], Loss: 179488720.0, KL Divergence: 943.6471557617188, Reconstruction Loss: 179487776.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 17:22:35,240 - INFO - Epoch: [378/600], Total Loss: 14081589331968.0, Total KL Divergence: 71270751.109375, Total Reconstruction Loss: 14081518060544.0\n",
      "2023-07-19 17:22:35,285 - INFO - Save model at epoch 378\n",
      "0it [00:00, ?it/s]2023-07-19 17:22:35,394 - INFO - Epoch: [379/600], Step: [1/591], Loss: 108939832.0, KL Divergence: 947.6429443359375, Reconstruction Loss: 108938888.0\n",
      "118it [00:10, 10.78it/s]2023-07-19 17:22:46,279 - INFO - Epoch: [379/600], Step: [119/591], Loss: 248486752.0, KL Divergence: 926.9395751953125, Reconstruction Loss: 248485824.0\n",
      "236it [00:21, 10.59it/s]2023-07-19 17:22:57,269 - INFO - Epoch: [379/600], Step: [237/591], Loss: 198351424.0, KL Divergence: 949.70654296875, Reconstruction Loss: 198350480.0\n",
      "354it [00:32, 10.92it/s]2023-07-19 17:23:08,187 - INFO - Epoch: [379/600], Step: [355/591], Loss: 243442272.0, KL Divergence: 945.2294311523438, Reconstruction Loss: 243441328.0\n",
      "472it [00:43, 10.94it/s]2023-07-19 17:23:18,982 - INFO - Epoch: [379/600], Step: [473/591], Loss: 208571040.0, KL Divergence: 947.5949096679688, Reconstruction Loss: 208570096.0\n",
      "590it [00:54, 11.04it/s]2023-07-19 17:23:29,813 - INFO - Epoch: [379/600], Step: [591/591], Loss: 170773776.0, KL Divergence: 950.4454956054688, Reconstruction Loss: 170772832.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 17:23:29,815 - INFO - Epoch: [379/600], Total Loss: 13836307159040.0, Total KL Divergence: 71240185.8046875, Total Reconstruction Loss: 13836235927552.0\n",
      "2023-07-19 17:23:29,873 - INFO - Save model at epoch 379\n",
      "0it [00:00, ?it/s]2023-07-19 17:23:29,970 - INFO - Epoch: [380/600], Step: [1/591], Loss: 110518904.0, KL Divergence: 955.3778076171875, Reconstruction Loss: 110517952.0\n",
      "118it [00:10, 11.01it/s]2023-07-19 17:23:40,799 - INFO - Epoch: [380/600], Step: [119/591], Loss: 247134832.0, KL Divergence: 939.7744750976562, Reconstruction Loss: 247133888.0\n",
      "236it [00:21, 10.93it/s]2023-07-19 17:23:51,741 - INFO - Epoch: [380/600], Step: [237/591], Loss: 208286144.0, KL Divergence: 961.2559814453125, Reconstruction Loss: 208285184.0\n",
      "354it [00:32, 10.81it/s]2023-07-19 17:24:02,542 - INFO - Epoch: [380/600], Step: [355/591], Loss: 242938512.0, KL Divergence: 949.8594970703125, Reconstruction Loss: 242937568.0\n",
      "471it [00:43, 11.26it/s]2023-07-19 17:24:13,328 - INFO - Epoch: [380/600], Step: [473/591], Loss: 233258144.0, KL Divergence: 951.8074951171875, Reconstruction Loss: 233257200.0\n",
      "589it [00:54, 10.97it/s]2023-07-19 17:24:24,099 - INFO - Epoch: [380/600], Step: [591/591], Loss: 179757168.0, KL Divergence: 955.3245849609375, Reconstruction Loss: 179756208.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 17:24:24,101 - INFO - Epoch: [380/600], Total Loss: 13985889234944.0, Total KL Divergence: 71864970.8359375, Total Reconstruction Loss: 13985817356288.0\n",
      "2023-07-19 17:24:24,141 - INFO - Save model at epoch 380\n",
      "0it [00:00, ?it/s]2023-07-19 17:24:24,249 - INFO - Epoch: [381/600], Step: [1/591], Loss: 116154768.0, KL Divergence: 961.91455078125, Reconstruction Loss: 116153808.0\n",
      "118it [00:10, 11.17it/s]2023-07-19 17:24:35,138 - INFO - Epoch: [381/600], Step: [119/591], Loss: 246325536.0, KL Divergence: 952.1207275390625, Reconstruction Loss: 246324576.0\n",
      "236it [00:21, 10.81it/s]2023-07-19 17:24:46,006 - INFO - Epoch: [381/600], Step: [237/591], Loss: 199191536.0, KL Divergence: 965.19482421875, Reconstruction Loss: 199190576.0\n",
      "354it [00:32, 11.08it/s]2023-07-19 17:24:56,909 - INFO - Epoch: [381/600], Step: [355/591], Loss: 245633312.0, KL Divergence: 952.9148559570312, Reconstruction Loss: 245632352.0\n",
      "472it [00:43, 10.72it/s]2023-07-19 17:25:07,826 - INFO - Epoch: [381/600], Step: [473/591], Loss: 207351840.0, KL Divergence: 960.183349609375, Reconstruction Loss: 207350880.0\n",
      "590it [00:54, 10.98it/s]2023-07-19 17:25:18,626 - INFO - Epoch: [381/600], Step: [591/591], Loss: 168095696.0, KL Divergence: 956.5047607421875, Reconstruction Loss: 168094736.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 17:25:18,628 - INFO - Epoch: [381/600], Total Loss: 13999764311040.0, Total KL Divergence: 72088951.140625, Total Reconstruction Loss: 13999692227584.0\n",
      "2023-07-19 17:25:18,669 - INFO - Save model at epoch 381\n",
      "0it [00:00, ?it/s]2023-07-19 17:25:18,794 - INFO - Epoch: [382/600], Step: [1/591], Loss: 107363912.0, KL Divergence: 961.4005126953125, Reconstruction Loss: 107362952.0\n",
      "117it [00:10, 10.66it/s]2023-07-19 17:25:29,715 - INFO - Epoch: [382/600], Step: [119/591], Loss: 243012304.0, KL Divergence: 945.128662109375, Reconstruction Loss: 243011360.0\n",
      "235it [00:21, 10.39it/s]2023-07-19 17:25:40,659 - INFO - Epoch: [382/600], Step: [237/591], Loss: 191435536.0, KL Divergence: 959.437744140625, Reconstruction Loss: 191434576.0\n",
      "353it [00:32, 11.22it/s]2023-07-19 17:25:51,486 - INFO - Epoch: [382/600], Step: [355/591], Loss: 243315104.0, KL Divergence: 952.6956176757812, Reconstruction Loss: 243314144.0\n",
      "471it [00:43, 10.79it/s]2023-07-19 17:26:02,484 - INFO - Epoch: [382/600], Step: [473/591], Loss: 210135904.0, KL Divergence: 955.9067993164062, Reconstruction Loss: 210134944.0\n",
      "589it [00:54, 10.67it/s]2023-07-19 17:26:13,308 - INFO - Epoch: [382/600], Step: [591/591], Loss: 169803616.0, KL Divergence: 953.9796752929688, Reconstruction Loss: 169802656.0\n",
      "591it [00:54, 10.82it/s]\n",
      "2023-07-19 17:26:13,311 - INFO - Epoch: [382/600], Total Loss: 13785123996672.0, Total KL Divergence: 72011896.984375, Total Reconstruction Loss: 13785051988992.0\n",
      "2023-07-19 17:26:13,351 - INFO - Save model at epoch 382\n",
      "0it [00:00, ?it/s]2023-07-19 17:26:13,457 - INFO - Epoch: [383/600], Step: [1/591], Loss: 114839360.0, KL Divergence: 958.488525390625, Reconstruction Loss: 114838400.0\n",
      "118it [00:10, 10.75it/s]2023-07-19 17:26:24,444 - INFO - Epoch: [383/600], Step: [119/591], Loss: 240114384.0, KL Divergence: 946.9410400390625, Reconstruction Loss: 240113440.0\n",
      "236it [00:21, 10.75it/s]2023-07-19 17:26:35,176 - INFO - Epoch: [383/600], Step: [237/591], Loss: 192300864.0, KL Divergence: 962.7176513671875, Reconstruction Loss: 192299904.0\n",
      "354it [00:32, 10.70it/s]2023-07-19 17:26:46,068 - INFO - Epoch: [383/600], Step: [355/591], Loss: 242885168.0, KL Divergence: 950.8428955078125, Reconstruction Loss: 242884224.0\n",
      "472it [00:43, 11.05it/s]2023-07-19 17:26:56,935 - INFO - Epoch: [383/600], Step: [473/591], Loss: 206599424.0, KL Divergence: 947.4408569335938, Reconstruction Loss: 206598480.0\n",
      "590it [00:54, 11.02it/s]2023-07-19 17:27:07,804 - INFO - Epoch: [383/600], Step: [591/591], Loss: 167024592.0, KL Divergence: 953.1749877929688, Reconstruction Loss: 167023632.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 17:27:07,806 - INFO - Epoch: [383/600], Total Loss: 13747228105728.0, Total KL Divergence: 71842126.1796875, Total Reconstruction Loss: 13747156243456.0\n",
      "2023-07-19 17:27:07,850 - INFO - Save model at epoch 383\n",
      "0it [00:00, ?it/s]2023-07-19 17:27:07,966 - INFO - Epoch: [384/600], Step: [1/591], Loss: 109329592.0, KL Divergence: 958.8226318359375, Reconstruction Loss: 109328632.0\n",
      "117it [00:10, 10.90it/s]2023-07-19 17:27:18,846 - INFO - Epoch: [384/600], Step: [119/591], Loss: 242774032.0, KL Divergence: 944.4774169921875, Reconstruction Loss: 242773088.0\n",
      "235it [00:21, 11.31it/s]2023-07-19 17:27:29,671 - INFO - Epoch: [384/600], Step: [237/591], Loss: 193690256.0, KL Divergence: 960.0477294921875, Reconstruction Loss: 193689296.0\n",
      "353it [00:32, 11.13it/s]2023-07-19 17:27:40,453 - INFO - Epoch: [384/600], Step: [355/591], Loss: 246605456.0, KL Divergence: 946.0709228515625, Reconstruction Loss: 246604512.0\n",
      "471it [00:43, 10.91it/s]2023-07-19 17:27:51,288 - INFO - Epoch: [384/600], Step: [473/591], Loss: 202165648.0, KL Divergence: 944.0537109375, Reconstruction Loss: 202164704.0\n",
      "589it [00:54, 10.96it/s]2023-07-19 17:28:02,096 - INFO - Epoch: [384/600], Step: [591/591], Loss: 179100288.0, KL Divergence: 953.1637573242188, Reconstruction Loss: 179099328.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 17:28:02,098 - INFO - Epoch: [384/600], Total Loss: 13805385441280.0, Total KL Divergence: 71680709.859375, Total Reconstruction Loss: 13805313744896.0\n",
      "2023-07-19 17:28:02,147 - INFO - Save model at epoch 384\n",
      "0it [00:00, ?it/s]2023-07-19 17:28:02,262 - INFO - Epoch: [385/600], Step: [1/591], Loss: 107516968.0, KL Divergence: 958.7786254882812, Reconstruction Loss: 107516008.0\n",
      "118it [00:10, 11.02it/s]2023-07-19 17:28:13,123 - INFO - Epoch: [385/600], Step: [119/591], Loss: 241868112.0, KL Divergence: 946.2344970703125, Reconstruction Loss: 241867168.0\n",
      "236it [00:21, 11.04it/s]2023-07-19 17:28:23,980 - INFO - Epoch: [385/600], Step: [237/591], Loss: 211299952.0, KL Divergence: 957.5108642578125, Reconstruction Loss: 211298992.0\n",
      "354it [00:32, 10.56it/s]2023-07-19 17:28:34,821 - INFO - Epoch: [385/600], Step: [355/591], Loss: 261970128.0, KL Divergence: 954.8958740234375, Reconstruction Loss: 261969168.0\n",
      "472it [00:43, 11.20it/s]2023-07-19 17:28:45,661 - INFO - Epoch: [385/600], Step: [473/591], Loss: 217660576.0, KL Divergence: 949.734130859375, Reconstruction Loss: 217659632.0\n",
      "590it [00:54, 10.89it/s]2023-07-19 17:28:56,556 - INFO - Epoch: [385/600], Step: [591/591], Loss: 184668144.0, KL Divergence: 952.828125, Reconstruction Loss: 184667184.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 17:28:56,558 - INFO - Epoch: [385/600], Total Loss: 13987452577792.0, Total KL Divergence: 71860273.9296875, Total Reconstruction Loss: 13987380725760.0\n",
      "2023-07-19 17:28:56,600 - INFO - Save model at epoch 385\n",
      "0it [00:00, ?it/s]2023-07-19 17:28:56,723 - INFO - Epoch: [386/600], Step: [1/591], Loss: 108126752.0, KL Divergence: 958.37060546875, Reconstruction Loss: 108125792.0\n",
      "118it [00:11, 11.08it/s]2023-07-19 17:29:07,812 - INFO - Epoch: [386/600], Step: [119/591], Loss: 244437056.0, KL Divergence: 943.7657470703125, Reconstruction Loss: 244436112.0\n",
      "236it [00:21, 11.17it/s]2023-07-19 17:29:18,725 - INFO - Epoch: [386/600], Step: [237/591], Loss: 202665584.0, KL Divergence: 968.9642333984375, Reconstruction Loss: 202664608.0\n",
      "354it [00:32, 11.10it/s]2023-07-19 17:29:29,637 - INFO - Epoch: [386/600], Step: [355/591], Loss: 249559040.0, KL Divergence: 956.5473022460938, Reconstruction Loss: 249558080.0\n",
      "472it [00:43, 10.55it/s]2023-07-19 17:29:40,507 - INFO - Epoch: [386/600], Step: [473/591], Loss: 213900688.0, KL Divergence: 951.7066650390625, Reconstruction Loss: 213899744.0\n",
      "590it [00:54, 10.78it/s]2023-07-19 17:29:51,305 - INFO - Epoch: [386/600], Step: [591/591], Loss: 181146112.0, KL Divergence: 956.4912109375, Reconstruction Loss: 181145152.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 17:29:51,307 - INFO - Epoch: [386/600], Total Loss: 14081553111040.0, Total KL Divergence: 72160236.7734375, Total Reconstruction Loss: 14081480943616.0\n",
      "2023-07-19 17:29:51,347 - INFO - Save model at epoch 386\n",
      "0it [00:00, ?it/s]2023-07-19 17:29:51,445 - INFO - Epoch: [387/600], Step: [1/591], Loss: 109469344.0, KL Divergence: 963.510498046875, Reconstruction Loss: 109468384.0\n",
      "118it [00:10, 11.21it/s]2023-07-19 17:30:02,345 - INFO - Epoch: [387/600], Step: [119/591], Loss: 243079968.0, KL Divergence: 950.0678100585938, Reconstruction Loss: 243079024.0\n",
      "236it [00:21, 10.98it/s]2023-07-19 17:30:13,149 - INFO - Epoch: [387/600], Step: [237/591], Loss: 207809616.0, KL Divergence: 967.974609375, Reconstruction Loss: 207808656.0\n",
      "354it [00:32, 11.06it/s]2023-07-19 17:30:23,991 - INFO - Epoch: [387/600], Step: [355/591], Loss: 245939520.0, KL Divergence: 963.2279052734375, Reconstruction Loss: 245938560.0\n",
      "472it [00:43, 10.82it/s]2023-07-19 17:30:34,841 - INFO - Epoch: [387/600], Step: [473/591], Loss: 206753584.0, KL Divergence: 958.835205078125, Reconstruction Loss: 206752624.0\n",
      "590it [00:54, 10.92it/s]2023-07-19 17:30:45,619 - INFO - Epoch: [387/600], Step: [591/591], Loss: 181101856.0, KL Divergence: 954.01806640625, Reconstruction Loss: 181100896.0\n",
      "591it [00:54, 10.89it/s]\n",
      "2023-07-19 17:30:45,621 - INFO - Epoch: [387/600], Total Loss: 14005676384256.0, Total KL Divergence: 72511162.296875, Total Reconstruction Loss: 14005603880960.0\n",
      "2023-07-19 17:30:45,685 - INFO - Save model at epoch 387\n",
      "0it [00:00, ?it/s]2023-07-19 17:30:45,793 - INFO - Epoch: [388/600], Step: [1/591], Loss: 116572208.0, KL Divergence: 959.9757080078125, Reconstruction Loss: 116571248.0\n",
      "118it [00:10, 10.89it/s]2023-07-19 17:30:56,600 - INFO - Epoch: [388/600], Step: [119/591], Loss: 241031136.0, KL Divergence: 953.374755859375, Reconstruction Loss: 241030176.0\n",
      "236it [00:21, 10.83it/s]2023-07-19 17:31:07,460 - INFO - Epoch: [388/600], Step: [237/591], Loss: 198646240.0, KL Divergence: 959.8214721679688, Reconstruction Loss: 198645280.0\n",
      "354it [00:32, 11.14it/s]2023-07-19 17:31:18,244 - INFO - Epoch: [388/600], Step: [355/591], Loss: 239055936.0, KL Divergence: 965.96630859375, Reconstruction Loss: 239054976.0\n",
      "472it [00:43, 11.08it/s]2023-07-19 17:31:29,085 - INFO - Epoch: [388/600], Step: [473/591], Loss: 204606320.0, KL Divergence: 955.62890625, Reconstruction Loss: 204605360.0\n",
      "590it [00:54, 10.84it/s]2023-07-19 17:31:39,844 - INFO - Epoch: [388/600], Step: [591/591], Loss: 176098496.0, KL Divergence: 958.9472045898438, Reconstruction Loss: 176097536.0\n",
      "591it [00:54, 10.92it/s]\n",
      "2023-07-19 17:31:39,845 - INFO - Epoch: [388/600], Total Loss: 13897723650048.0, Total KL Divergence: 72531269.8046875, Total Reconstruction Loss: 13897651101696.0\n",
      "2023-07-19 17:31:39,886 - INFO - Save model at epoch 388\n",
      "0it [00:00, ?it/s]2023-07-19 17:31:40,002 - INFO - Epoch: [389/600], Step: [1/591], Loss: 112643448.0, KL Divergence: 965.104248046875, Reconstruction Loss: 112642480.0\n",
      "118it [00:10, 10.84it/s]2023-07-19 17:31:50,958 - INFO - Epoch: [389/600], Step: [119/591], Loss: 262598496.0, KL Divergence: 953.0875854492188, Reconstruction Loss: 262597536.0\n",
      "236it [00:21, 10.93it/s]2023-07-19 17:32:01,834 - INFO - Epoch: [389/600], Step: [237/591], Loss: 198158256.0, KL Divergence: 958.055419921875, Reconstruction Loss: 198157296.0\n",
      "354it [00:32, 10.90it/s]2023-07-19 17:32:12,578 - INFO - Epoch: [389/600], Step: [355/591], Loss: 243034144.0, KL Divergence: 958.051025390625, Reconstruction Loss: 243033184.0\n",
      "472it [00:43, 11.31it/s]2023-07-19 17:32:23,337 - INFO - Epoch: [389/600], Step: [473/591], Loss: 205361216.0, KL Divergence: 960.5635986328125, Reconstruction Loss: 205360256.0\n",
      "590it [00:54, 11.18it/s]2023-07-19 17:32:34,121 - INFO - Epoch: [389/600], Step: [591/591], Loss: 176235440.0, KL Divergence: 974.5431518554688, Reconstruction Loss: 176234464.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 17:32:34,123 - INFO - Epoch: [389/600], Total Loss: 14026289694720.0, Total KL Divergence: 72378670.5625, Total Reconstruction Loss: 14026217331712.0\n",
      "2023-07-19 17:32:34,170 - INFO - Save model at epoch 389\n",
      "0it [00:00, ?it/s]2023-07-19 17:32:34,278 - INFO - Epoch: [390/600], Step: [1/591], Loss: 113417880.0, KL Divergence: 978.7745361328125, Reconstruction Loss: 113416904.0\n",
      "118it [00:10, 11.17it/s]2023-07-19 17:32:45,092 - INFO - Epoch: [390/600], Step: [119/591], Loss: 256182448.0, KL Divergence: 959.4227294921875, Reconstruction Loss: 256181488.0\n",
      "236it [00:21, 11.09it/s]2023-07-19 17:32:55,972 - INFO - Epoch: [390/600], Step: [237/591], Loss: 200097312.0, KL Divergence: 970.665283203125, Reconstruction Loss: 200096336.0\n",
      "354it [00:32, 11.23it/s]2023-07-19 17:33:06,841 - INFO - Epoch: [390/600], Step: [355/591], Loss: 240691424.0, KL Divergence: 973.44482421875, Reconstruction Loss: 240690448.0\n",
      "472it [00:43, 10.83it/s]2023-07-19 17:33:17,885 - INFO - Epoch: [390/600], Step: [473/591], Loss: 206803952.0, KL Divergence: 965.5040283203125, Reconstruction Loss: 206802992.0\n",
      "590it [00:54, 10.96it/s]2023-07-19 17:33:28,681 - INFO - Epoch: [390/600], Step: [591/591], Loss: 168547216.0, KL Divergence: 973.1620483398438, Reconstruction Loss: 168546240.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 17:33:28,682 - INFO - Epoch: [390/600], Total Loss: 13894901481472.0, Total KL Divergence: 73054122.75, Total Reconstruction Loss: 13894828432384.0\n",
      "2023-07-19 17:33:28,721 - INFO - Save model at epoch 390\n",
      "0it [00:00, ?it/s]2023-07-19 17:33:28,828 - INFO - Epoch: [391/600], Step: [1/591], Loss: 105574912.0, KL Divergence: 975.626220703125, Reconstruction Loss: 105573936.0\n",
      "118it [00:10, 10.94it/s]2023-07-19 17:33:39,728 - INFO - Epoch: [391/600], Step: [119/591], Loss: 249093008.0, KL Divergence: 962.1849975585938, Reconstruction Loss: 249092048.0\n",
      "236it [00:21, 10.80it/s]2023-07-19 17:33:50,553 - INFO - Epoch: [391/600], Step: [237/591], Loss: 195960880.0, KL Divergence: 976.060791015625, Reconstruction Loss: 195959904.0\n",
      "354it [00:32, 10.52it/s]2023-07-19 17:34:01,423 - INFO - Epoch: [391/600], Step: [355/591], Loss: 243578272.0, KL Divergence: 972.4995727539062, Reconstruction Loss: 243577296.0\n",
      "472it [00:43, 10.91it/s]2023-07-19 17:34:12,342 - INFO - Epoch: [391/600], Step: [473/591], Loss: 204704336.0, KL Divergence: 975.7725830078125, Reconstruction Loss: 204703360.0\n",
      "590it [00:54, 10.91it/s]2023-07-19 17:34:23,151 - INFO - Epoch: [391/600], Step: [591/591], Loss: 177387760.0, KL Divergence: 978.4926147460938, Reconstruction Loss: 177386784.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 17:34:23,153 - INFO - Epoch: [391/600], Total Loss: 13783682513920.0, Total KL Divergence: 73323739.9921875, Total Reconstruction Loss: 13783609186304.0\n",
      "2023-07-19 17:34:23,193 - INFO - Save model at epoch 391\n",
      "0it [00:00, ?it/s]2023-07-19 17:34:23,303 - INFO - Epoch: [392/600], Step: [1/591], Loss: 114875464.0, KL Divergence: 984.9811401367188, Reconstruction Loss: 114874480.0\n",
      "118it [00:10, 10.25it/s]2023-07-19 17:34:34,261 - INFO - Epoch: [392/600], Step: [119/591], Loss: 241058864.0, KL Divergence: 974.1051635742188, Reconstruction Loss: 241057888.0\n",
      "236it [00:21, 11.02it/s]2023-07-19 17:34:45,087 - INFO - Epoch: [392/600], Step: [237/591], Loss: 193951648.0, KL Divergence: 984.8328857421875, Reconstruction Loss: 193950656.0\n",
      "354it [00:32, 10.98it/s]2023-07-19 17:34:55,972 - INFO - Epoch: [392/600], Step: [355/591], Loss: 245020880.0, KL Divergence: 979.3492431640625, Reconstruction Loss: 245019904.0\n",
      "472it [00:43, 10.86it/s]2023-07-19 17:35:06,793 - INFO - Epoch: [392/600], Step: [473/591], Loss: 217618624.0, KL Divergence: 982.6586303710938, Reconstruction Loss: 217617648.0\n",
      "590it [00:54, 10.68it/s]2023-07-19 17:35:17,650 - INFO - Epoch: [392/600], Step: [591/591], Loss: 180650560.0, KL Divergence: 977.44384765625, Reconstruction Loss: 180649584.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 17:35:17,652 - INFO - Epoch: [392/600], Total Loss: 13853916285952.0, Total KL Divergence: 73893272.3671875, Total Reconstruction Loss: 13853842383872.0\n",
      "2023-07-19 17:35:17,692 - INFO - Save model at epoch 392\n",
      "0it [00:00, ?it/s]2023-07-19 17:35:17,795 - INFO - Epoch: [393/600], Step: [1/591], Loss: 107712816.0, KL Divergence: 983.6328125, Reconstruction Loss: 107711832.0\n",
      "118it [00:10, 10.98it/s]2023-07-19 17:35:28,645 - INFO - Epoch: [393/600], Step: [119/591], Loss: 245555568.0, KL Divergence: 976.0927734375, Reconstruction Loss: 245554592.0\n",
      "236it [00:21, 10.68it/s]2023-07-19 17:35:39,496 - INFO - Epoch: [393/600], Step: [237/591], Loss: 197631840.0, KL Divergence: 982.1010131835938, Reconstruction Loss: 197630864.0\n",
      "354it [00:32, 11.17it/s]2023-07-19 17:35:50,361 - INFO - Epoch: [393/600], Step: [355/591], Loss: 250856064.0, KL Divergence: 973.676513671875, Reconstruction Loss: 250855088.0\n",
      "472it [00:43, 11.00it/s]2023-07-19 17:36:01,369 - INFO - Epoch: [393/600], Step: [473/591], Loss: 212288080.0, KL Divergence: 982.2268676757812, Reconstruction Loss: 212287104.0\n",
      "590it [00:54, 10.94it/s]2023-07-19 17:36:12,168 - INFO - Epoch: [393/600], Step: [591/591], Loss: 176292608.0, KL Divergence: 978.8211669921875, Reconstruction Loss: 176291632.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 17:36:12,169 - INFO - Epoch: [393/600], Total Loss: 13996592582656.0, Total KL Divergence: 73883040.8046875, Total Reconstruction Loss: 13996518682624.0\n",
      "2023-07-19 17:36:12,211 - INFO - Save model at epoch 393\n",
      "0it [00:00, ?it/s]2023-07-19 17:36:12,320 - INFO - Epoch: [394/600], Step: [1/591], Loss: 109134344.0, KL Divergence: 983.2996826171875, Reconstruction Loss: 109133360.0\n",
      "118it [00:10, 11.03it/s]2023-07-19 17:36:23,240 - INFO - Epoch: [394/600], Step: [119/591], Loss: 241572000.0, KL Divergence: 959.19287109375, Reconstruction Loss: 241571040.0\n",
      "236it [00:21, 11.03it/s]2023-07-19 17:36:34,162 - INFO - Epoch: [394/600], Step: [237/591], Loss: 198032752.0, KL Divergence: 972.448486328125, Reconstruction Loss: 198031776.0\n",
      "354it [00:32, 11.16it/s]2023-07-19 17:36:45,080 - INFO - Epoch: [394/600], Step: [355/591], Loss: 240779328.0, KL Divergence: 977.02880859375, Reconstruction Loss: 240778352.0\n",
      "472it [00:43, 10.90it/s]2023-07-19 17:36:55,985 - INFO - Epoch: [394/600], Step: [473/591], Loss: 216147648.0, KL Divergence: 975.4622192382812, Reconstruction Loss: 216146672.0\n",
      "590it [00:54, 11.01it/s]2023-07-19 17:37:06,768 - INFO - Epoch: [394/600], Step: [591/591], Loss: 173789984.0, KL Divergence: 977.4659423828125, Reconstruction Loss: 173789008.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 17:37:06,770 - INFO - Epoch: [394/600], Total Loss: 13982791405568.0, Total KL Divergence: 73516651.3828125, Total Reconstruction Loss: 13982717883392.0\n",
      "2023-07-19 17:37:06,835 - INFO - Save model at epoch 394\n",
      "0it [00:00, ?it/s]2023-07-19 17:37:06,947 - INFO - Epoch: [395/600], Step: [1/591], Loss: 110550768.0, KL Divergence: 980.5620727539062, Reconstruction Loss: 110549784.0\n",
      "118it [00:10, 11.14it/s]2023-07-19 17:37:17,875 - INFO - Epoch: [395/600], Step: [119/591], Loss: 247730816.0, KL Divergence: 969.0955810546875, Reconstruction Loss: 247729840.0\n",
      "236it [00:21, 10.80it/s]2023-07-19 17:37:28,747 - INFO - Epoch: [395/600], Step: [237/591], Loss: 199671856.0, KL Divergence: 977.8553466796875, Reconstruction Loss: 199670880.0\n",
      "354it [00:32, 10.63it/s]2023-07-19 17:37:39,603 - INFO - Epoch: [395/600], Step: [355/591], Loss: 240328304.0, KL Divergence: 978.9615478515625, Reconstruction Loss: 240327328.0\n",
      "472it [00:43, 10.82it/s]2023-07-19 17:37:50,532 - INFO - Epoch: [395/600], Step: [473/591], Loss: 202865760.0, KL Divergence: 973.2587280273438, Reconstruction Loss: 202864784.0\n",
      "590it [00:54, 10.94it/s]2023-07-19 17:38:01,309 - INFO - Epoch: [395/600], Step: [591/591], Loss: 173641536.0, KL Divergence: 978.0128173828125, Reconstruction Loss: 173640560.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 17:38:01,310 - INFO - Epoch: [395/600], Total Loss: 13770867412992.0, Total KL Divergence: 73630708.4140625, Total Reconstruction Loss: 13770793781248.0\n",
      "2023-07-19 17:38:01,349 - INFO - Save model at epoch 395\n",
      "0it [00:00, ?it/s]2023-07-19 17:38:01,456 - INFO - Epoch: [396/600], Step: [1/591], Loss: 116594120.0, KL Divergence: 982.0082397460938, Reconstruction Loss: 116593136.0\n",
      "118it [00:10, 11.11it/s]2023-07-19 17:38:12,408 - INFO - Epoch: [396/600], Step: [119/591], Loss: 247662544.0, KL Divergence: 963.2216796875, Reconstruction Loss: 247661584.0\n",
      "236it [00:21, 10.44it/s]2023-07-19 17:38:23,238 - INFO - Epoch: [396/600], Step: [237/591], Loss: 193019040.0, KL Divergence: 984.5823974609375, Reconstruction Loss: 193018048.0\n",
      "354it [00:32, 10.92it/s]2023-07-19 17:38:34,119 - INFO - Epoch: [396/600], Step: [355/591], Loss: 241263280.0, KL Divergence: 977.5921630859375, Reconstruction Loss: 241262304.0\n",
      "472it [00:43, 11.12it/s]2023-07-19 17:38:45,024 - INFO - Epoch: [396/600], Step: [473/591], Loss: 203227792.0, KL Divergence: 977.137939453125, Reconstruction Loss: 203226816.0\n",
      "590it [00:54, 10.89it/s]2023-07-19 17:38:55,721 - INFO - Epoch: [396/600], Step: [591/591], Loss: 165392768.0, KL Divergence: 985.4573974609375, Reconstruction Loss: 165391776.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 17:38:55,722 - INFO - Epoch: [396/600], Total Loss: 13695747126272.0, Total KL Divergence: 73646453.1640625, Total Reconstruction Loss: 13695673498624.0\n",
      "2023-07-19 17:38:55,770 - INFO - Save model at epoch 396\n",
      "0it [00:00, ?it/s]2023-07-19 17:38:55,887 - INFO - Epoch: [397/600], Step: [1/591], Loss: 108878272.0, KL Divergence: 988.0740966796875, Reconstruction Loss: 108877280.0\n",
      "118it [00:10, 10.72it/s]2023-07-19 17:39:06,815 - INFO - Epoch: [397/600], Step: [119/591], Loss: 239909392.0, KL Divergence: 968.3590087890625, Reconstruction Loss: 239908416.0\n",
      "236it [00:21, 10.78it/s]2023-07-19 17:39:17,653 - INFO - Epoch: [397/600], Step: [237/591], Loss: 195253488.0, KL Divergence: 978.0499267578125, Reconstruction Loss: 195252512.0\n",
      "354it [00:32, 10.51it/s]2023-07-19 17:39:28,556 - INFO - Epoch: [397/600], Step: [355/591], Loss: 237988208.0, KL Divergence: 977.0547485351562, Reconstruction Loss: 237987232.0\n",
      "472it [00:43, 11.05it/s]2023-07-19 17:39:39,409 - INFO - Epoch: [397/600], Step: [473/591], Loss: 210771952.0, KL Divergence: 980.5810546875, Reconstruction Loss: 210770976.0\n",
      "590it [00:54, 10.76it/s]2023-07-19 17:39:50,141 - INFO - Epoch: [397/600], Step: [591/591], Loss: 185033424.0, KL Divergence: 982.79296875, Reconstruction Loss: 185032448.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 17:39:50,143 - INFO - Epoch: [397/600], Total Loss: 13679873516544.0, Total KL Divergence: 73771866.546875, Total Reconstruction Loss: 13679799736320.0\n",
      "2023-07-19 17:39:50,186 - INFO - Save model at epoch 397\n",
      "0it [00:00, ?it/s]2023-07-19 17:39:50,308 - INFO - Epoch: [398/600], Step: [1/591], Loss: 107581696.0, KL Divergence: 988.7060546875, Reconstruction Loss: 107580704.0\n",
      "117it [00:10, 11.16it/s]2023-07-19 17:40:01,137 - INFO - Epoch: [398/600], Step: [119/591], Loss: 248169312.0, KL Divergence: 970.88525390625, Reconstruction Loss: 248168336.0\n",
      "235it [00:21, 10.82it/s]2023-07-19 17:40:11,991 - INFO - Epoch: [398/600], Step: [237/591], Loss: 197561408.0, KL Divergence: 983.8896484375, Reconstruction Loss: 197560432.0\n",
      "353it [00:32, 10.80it/s]2023-07-19 17:40:22,843 - INFO - Epoch: [398/600], Step: [355/591], Loss: 237182704.0, KL Divergence: 974.4996337890625, Reconstruction Loss: 237181728.0\n",
      "471it [00:43, 11.24it/s]2023-07-19 17:40:33,674 - INFO - Epoch: [398/600], Step: [473/591], Loss: 201895536.0, KL Divergence: 980.541259765625, Reconstruction Loss: 201894560.0\n",
      "589it [00:54, 11.10it/s]2023-07-19 17:40:44,439 - INFO - Epoch: [398/600], Step: [591/591], Loss: 175875680.0, KL Divergence: 975.12255859375, Reconstruction Loss: 175874704.0\n",
      "591it [00:54, 10.90it/s]\n",
      "2023-07-19 17:40:44,441 - INFO - Epoch: [398/600], Total Loss: 13700281349120.0, Total KL Divergence: 73892479.0078125, Total Reconstruction Loss: 13700207451136.0\n",
      "2023-07-19 17:40:44,484 - INFO - Save model at epoch 398\n",
      "0it [00:00, ?it/s]2023-07-19 17:40:44,608 - INFO - Epoch: [399/600], Step: [1/591], Loss: 108043760.0, KL Divergence: 979.5104370117188, Reconstruction Loss: 108042784.0\n",
      "117it [00:10, 11.23it/s]2023-07-19 17:40:55,461 - INFO - Epoch: [399/600], Step: [119/591], Loss: 245782640.0, KL Divergence: 967.6503295898438, Reconstruction Loss: 245781680.0\n",
      "235it [00:21, 11.06it/s]2023-07-19 17:41:06,233 - INFO - Epoch: [399/600], Step: [237/591], Loss: 193312048.0, KL Divergence: 977.6241455078125, Reconstruction Loss: 193311072.0\n",
      "353it [00:32, 10.76it/s]2023-07-19 17:41:17,150 - INFO - Epoch: [399/600], Step: [355/591], Loss: 237203888.0, KL Divergence: 970.7703857421875, Reconstruction Loss: 237202912.0\n",
      "471it [00:43, 10.84it/s]2023-07-19 17:41:27,975 - INFO - Epoch: [399/600], Step: [473/591], Loss: 202454544.0, KL Divergence: 974.6785888671875, Reconstruction Loss: 202453568.0\n",
      "589it [00:54, 10.61it/s]2023-07-19 17:41:38,817 - INFO - Epoch: [399/600], Step: [591/591], Loss: 173860432.0, KL Divergence: 982.8275756835938, Reconstruction Loss: 173859456.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 17:41:38,818 - INFO - Epoch: [399/600], Total Loss: 13823609553920.0, Total KL Divergence: 73624990.953125, Total Reconstruction Loss: 13823535918080.0\n",
      "2023-07-19 17:41:38,863 - INFO - Save model at epoch 399\n",
      "0it [00:00, ?it/s]2023-07-19 17:41:38,964 - INFO - Epoch: [400/600], Step: [1/591], Loss: 104851632.0, KL Divergence: 985.9403076171875, Reconstruction Loss: 104850648.0\n",
      "118it [00:10, 10.77it/s]2023-07-19 17:41:49,954 - INFO - Epoch: [400/600], Step: [119/591], Loss: 252037136.0, KL Divergence: 973.212646484375, Reconstruction Loss: 252036160.0\n",
      "236it [00:21, 10.31it/s]2023-07-19 17:42:00,834 - INFO - Epoch: [400/600], Step: [237/591], Loss: 195772320.0, KL Divergence: 984.8076171875, Reconstruction Loss: 195771328.0\n",
      "354it [00:32, 11.31it/s]2023-07-19 17:42:11,662 - INFO - Epoch: [400/600], Step: [355/591], Loss: 264795696.0, KL Divergence: 979.429931640625, Reconstruction Loss: 264794720.0\n",
      "472it [00:43, 11.13it/s]2023-07-19 17:42:22,571 - INFO - Epoch: [400/600], Step: [473/591], Loss: 222541344.0, KL Divergence: 991.5623779296875, Reconstruction Loss: 222540352.0\n",
      "590it [00:54, 11.03it/s]2023-07-19 17:42:33,391 - INFO - Epoch: [400/600], Step: [591/591], Loss: 170451936.0, KL Divergence: 997.9437255859375, Reconstruction Loss: 170450944.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 17:42:33,392 - INFO - Epoch: [400/600], Total Loss: 13875146835968.0, Total KL Divergence: 74112784.6953125, Total Reconstruction Loss: 13875072715776.0\n",
      "2023-07-19 17:42:33,434 - INFO - Save model at epoch 400\n",
      "0it [00:00, ?it/s]2023-07-19 17:42:33,545 - INFO - Epoch: [401/600], Step: [1/591], Loss: 106457112.0, KL Divergence: 998.048095703125, Reconstruction Loss: 106456112.0\n",
      "117it [00:10, 10.77it/s]2023-07-19 17:42:44,555 - INFO - Epoch: [401/600], Step: [119/591], Loss: 243187040.0, KL Divergence: 977.383056640625, Reconstruction Loss: 243186064.0\n",
      "235it [00:21, 11.04it/s]2023-07-19 17:42:55,419 - INFO - Epoch: [401/600], Step: [237/591], Loss: 190084832.0, KL Divergence: 991.3167724609375, Reconstruction Loss: 190083840.0\n",
      "353it [00:32, 11.02it/s]2023-07-19 17:43:06,313 - INFO - Epoch: [401/600], Step: [355/591], Loss: 236636720.0, KL Divergence: 987.0892333984375, Reconstruction Loss: 236635728.0\n",
      "471it [00:43, 11.26it/s]2023-07-19 17:43:17,141 - INFO - Epoch: [401/600], Step: [473/591], Loss: 206069920.0, KL Divergence: 991.6785278320312, Reconstruction Loss: 206068928.0\n",
      "589it [00:54, 10.88it/s]2023-07-19 17:43:27,982 - INFO - Epoch: [401/600], Step: [591/591], Loss: 174114080.0, KL Divergence: 997.505126953125, Reconstruction Loss: 174113088.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 17:43:27,984 - INFO - Epoch: [401/600], Total Loss: 13645548372992.0, Total KL Divergence: 74564606.5078125, Total Reconstruction Loss: 13645473766400.0\n",
      "2023-07-19 17:43:28,032 - INFO - Save model at epoch 401\n",
      "0it [00:00, ?it/s]2023-07-19 17:43:28,134 - INFO - Epoch: [402/600], Step: [1/591], Loss: 107783368.0, KL Divergence: 999.1080322265625, Reconstruction Loss: 107782368.0\n",
      "118it [00:11, 10.82it/s]2023-07-19 17:43:39,185 - INFO - Epoch: [402/600], Step: [119/591], Loss: 239504368.0, KL Divergence: 978.1185302734375, Reconstruction Loss: 239503392.0\n",
      "236it [00:21, 10.73it/s]2023-07-19 17:43:50,065 - INFO - Epoch: [402/600], Step: [237/591], Loss: 189296592.0, KL Divergence: 1003.561767578125, Reconstruction Loss: 189295584.0\n",
      "354it [00:32, 10.61it/s]2023-07-19 17:44:00,976 - INFO - Epoch: [402/600], Step: [355/591], Loss: 233093024.0, KL Divergence: 991.03515625, Reconstruction Loss: 233092032.0\n",
      "472it [00:43, 10.76it/s]2023-07-19 17:44:12,033 - INFO - Epoch: [402/600], Step: [473/591], Loss: 215194176.0, KL Divergence: 983.3093872070312, Reconstruction Loss: 215193200.0\n",
      "590it [00:54, 10.66it/s]2023-07-19 17:44:22,814 - INFO - Epoch: [402/600], Step: [591/591], Loss: 175391184.0, KL Divergence: 990.2360229492188, Reconstruction Loss: 175390192.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 17:44:22,816 - INFO - Epoch: [402/600], Total Loss: 13611333700608.0, Total KL Divergence: 74687744.5, Total Reconstruction Loss: 13611259009024.0\n",
      "2023-07-19 17:44:22,861 - INFO - Save model at epoch 402\n",
      "0it [00:00, ?it/s]2023-07-19 17:44:22,977 - INFO - Epoch: [403/600], Step: [1/591], Loss: 104556648.0, KL Divergence: 993.19873046875, Reconstruction Loss: 104555656.0\n",
      "117it [00:10, 10.85it/s]2023-07-19 17:44:33,887 - INFO - Epoch: [403/600], Step: [119/591], Loss: 238228752.0, KL Divergence: 977.1026000976562, Reconstruction Loss: 238227776.0\n",
      "235it [00:21, 10.80it/s]2023-07-19 17:44:44,690 - INFO - Epoch: [403/600], Step: [237/591], Loss: 189790304.0, KL Divergence: 989.65576171875, Reconstruction Loss: 189789312.0\n",
      "353it [00:32, 10.70it/s]2023-07-19 17:44:55,545 - INFO - Epoch: [403/600], Step: [355/591], Loss: 262863760.0, KL Divergence: 983.856689453125, Reconstruction Loss: 262862784.0\n",
      "471it [00:43, 10.29it/s]2023-07-19 17:45:06,487 - INFO - Epoch: [403/600], Step: [473/591], Loss: 221221904.0, KL Divergence: 990.705322265625, Reconstruction Loss: 221220912.0\n",
      "589it [00:54, 11.09it/s]2023-07-19 17:45:17,187 - INFO - Epoch: [403/600], Step: [591/591], Loss: 189943200.0, KL Divergence: 987.022705078125, Reconstruction Loss: 189942208.0\n",
      "591it [00:54, 10.88it/s]\n",
      "2023-07-19 17:45:17,189 - INFO - Epoch: [403/600], Total Loss: 13912507465728.0, Total KL Divergence: 74402453.7734375, Total Reconstruction Loss: 13912433072128.0\n",
      "2023-07-19 17:45:17,235 - INFO - Save model at epoch 403\n",
      "0it [00:00, ?it/s]2023-07-19 17:45:17,341 - INFO - Epoch: [404/600], Step: [1/591], Loss: 109234224.0, KL Divergence: 991.7174682617188, Reconstruction Loss: 109233232.0\n",
      "118it [00:10, 10.81it/s]2023-07-19 17:45:28,291 - INFO - Epoch: [404/600], Step: [119/591], Loss: 244120192.0, KL Divergence: 970.5640258789062, Reconstruction Loss: 244119216.0\n",
      "236it [00:21, 10.61it/s]2023-07-19 17:45:39,234 - INFO - Epoch: [404/600], Step: [237/591], Loss: 190128304.0, KL Divergence: 994.3392333984375, Reconstruction Loss: 190127312.0\n",
      "354it [00:32, 11.07it/s]2023-07-19 17:45:49,990 - INFO - Epoch: [404/600], Step: [355/591], Loss: 263618752.0, KL Divergence: 982.926513671875, Reconstruction Loss: 263617776.0\n",
      "472it [00:43, 10.65it/s]2023-07-19 17:46:00,896 - INFO - Epoch: [404/600], Step: [473/591], Loss: 209998624.0, KL Divergence: 981.88427734375, Reconstruction Loss: 209997648.0\n",
      "590it [00:54, 10.45it/s]2023-07-19 17:46:11,705 - INFO - Epoch: [404/600], Step: [591/591], Loss: 194710144.0, KL Divergence: 977.0018310546875, Reconstruction Loss: 194709168.0\n",
      "591it [00:54, 10.85it/s]\n",
      "2023-07-19 17:46:11,707 - INFO - Epoch: [404/600], Total Loss: 13935338613760.0, Total KL Divergence: 74280981.15625, Total Reconstruction Loss: 13935264320512.0\n",
      "2023-07-19 17:46:11,745 - INFO - Save model at epoch 404\n",
      "0it [00:00, ?it/s]2023-07-19 17:46:11,851 - INFO - Epoch: [405/600], Step: [1/591], Loss: 105542680.0, KL Divergence: 980.5247802734375, Reconstruction Loss: 105541696.0\n",
      "118it [00:11, 10.95it/s]2023-07-19 17:46:22,885 - INFO - Epoch: [405/600], Step: [119/591], Loss: 240467568.0, KL Divergence: 963.51025390625, Reconstruction Loss: 240466608.0\n",
      "236it [00:21, 10.68it/s]2023-07-19 17:46:33,828 - INFO - Epoch: [405/600], Step: [237/591], Loss: 189121952.0, KL Divergence: 977.9547119140625, Reconstruction Loss: 189120976.0\n",
      "354it [00:32, 10.90it/s]2023-07-19 17:46:44,748 - INFO - Epoch: [405/600], Step: [355/591], Loss: 242959760.0, KL Divergence: 979.5831298828125, Reconstruction Loss: 242958784.0\n",
      "472it [00:43, 11.22it/s]2023-07-19 17:46:55,640 - INFO - Epoch: [405/600], Step: [473/591], Loss: 211402416.0, KL Divergence: 977.3746948242188, Reconstruction Loss: 211401440.0\n",
      "590it [00:54, 10.77it/s]2023-07-19 17:47:06,434 - INFO - Epoch: [405/600], Step: [591/591], Loss: 173285648.0, KL Divergence: 981.3310546875, Reconstruction Loss: 173284672.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 17:47:06,436 - INFO - Epoch: [405/600], Total Loss: 13747514589184.0, Total KL Divergence: 73815627.84375, Total Reconstruction Loss: 13747440768000.0\n",
      "2023-07-19 17:47:06,482 - INFO - Save model at epoch 405\n",
      "0it [00:00, ?it/s]2023-07-19 17:47:06,597 - INFO - Epoch: [406/600], Step: [1/591], Loss: 110701496.0, KL Divergence: 983.4765625, Reconstruction Loss: 110700512.0\n",
      "118it [00:10, 10.97it/s]2023-07-19 17:47:17,456 - INFO - Epoch: [406/600], Step: [119/591], Loss: 235954432.0, KL Divergence: 969.5596313476562, Reconstruction Loss: 235953456.0\n",
      "236it [00:21, 10.85it/s]2023-07-19 17:47:28,242 - INFO - Epoch: [406/600], Step: [237/591], Loss: 194292096.0, KL Divergence: 976.369140625, Reconstruction Loss: 194291120.0\n",
      "354it [00:32, 11.26it/s]2023-07-19 17:47:39,045 - INFO - Epoch: [406/600], Step: [355/591], Loss: 250864592.0, KL Divergence: 976.869140625, Reconstruction Loss: 250863616.0\n",
      "472it [00:43, 10.92it/s]2023-07-19 17:47:49,897 - INFO - Epoch: [406/600], Step: [473/591], Loss: 215040896.0, KL Divergence: 974.4074096679688, Reconstruction Loss: 215039920.0\n",
      "590it [00:54, 11.06it/s]2023-07-19 17:48:00,666 - INFO - Epoch: [406/600], Step: [591/591], Loss: 174345024.0, KL Divergence: 985.7679443359375, Reconstruction Loss: 174344032.0\n",
      "591it [00:54, 10.91it/s]\n",
      "2023-07-19 17:48:00,668 - INFO - Epoch: [406/600], Total Loss: 13594347847680.0, Total KL Divergence: 73864284.234375, Total Reconstruction Loss: 13594273972224.0\n",
      "2023-07-19 17:48:00,718 - INFO - Save model at epoch 406\n",
      "0it [00:00, ?it/s]2023-07-19 17:48:00,834 - INFO - Epoch: [407/600], Step: [1/591], Loss: 107102728.0, KL Divergence: 989.282958984375, Reconstruction Loss: 107101736.0\n",
      "118it [00:10, 10.50it/s]2023-07-19 17:48:11,751 - INFO - Epoch: [407/600], Step: [119/591], Loss: 235190976.0, KL Divergence: 978.5232543945312, Reconstruction Loss: 235190000.0\n",
      "236it [00:21, 10.80it/s]2023-07-19 17:48:22,563 - INFO - Epoch: [407/600], Step: [237/591], Loss: 191864352.0, KL Divergence: 994.1822509765625, Reconstruction Loss: 191863360.0\n",
      "354it [00:32, 11.06it/s]2023-07-19 17:48:33,399 - INFO - Epoch: [407/600], Step: [355/591], Loss: 239187136.0, KL Divergence: 980.9273681640625, Reconstruction Loss: 239186160.0\n",
      "472it [00:43, 10.81it/s]2023-07-19 17:48:44,282 - INFO - Epoch: [407/600], Step: [473/591], Loss: 216112064.0, KL Divergence: 977.93359375, Reconstruction Loss: 216111088.0\n",
      "590it [00:54, 10.68it/s]2023-07-19 17:48:55,085 - INFO - Epoch: [407/600], Step: [591/591], Loss: 171286976.0, KL Divergence: 985.19482421875, Reconstruction Loss: 171285984.0\n",
      "591it [00:54, 10.87it/s]\n",
      "2023-07-19 17:48:55,087 - INFO - Epoch: [407/600], Total Loss: 13463862565888.0, Total KL Divergence: 74116182.8828125, Total Reconstruction Loss: 13463788437504.0\n",
      "2023-07-19 17:48:55,131 - INFO - Save model at epoch 407\n",
      "0it [00:00, ?it/s]2023-07-19 17:48:55,225 - INFO - Epoch: [408/600], Step: [1/591], Loss: 104774576.0, KL Divergence: 988.0794677734375, Reconstruction Loss: 104773584.0\n",
      "118it [00:11,  9.92it/s]2023-07-19 17:49:06,292 - INFO - Epoch: [408/600], Step: [119/591], Loss: 238275552.0, KL Divergence: 968.9154052734375, Reconstruction Loss: 238274576.0\n",
      "236it [00:21, 10.84it/s]2023-07-19 17:49:17,146 - INFO - Epoch: [408/600], Step: [237/591], Loss: 187139872.0, KL Divergence: 984.7135620117188, Reconstruction Loss: 187138880.0\n",
      "354it [00:32, 11.11it/s]2023-07-19 17:49:27,975 - INFO - Epoch: [408/600], Step: [355/591], Loss: 239616144.0, KL Divergence: 977.617431640625, Reconstruction Loss: 239615168.0\n",
      "472it [00:43, 10.90it/s]2023-07-19 17:49:38,899 - INFO - Epoch: [408/600], Step: [473/591], Loss: 216457888.0, KL Divergence: 975.1300659179688, Reconstruction Loss: 216456912.0\n",
      "590it [00:54, 10.45it/s]2023-07-19 17:49:49,792 - INFO - Epoch: [408/600], Step: [591/591], Loss: 166994976.0, KL Divergence: 985.9849853515625, Reconstruction Loss: 166993984.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 17:49:49,794 - INFO - Epoch: [408/600], Total Loss: 13385670782976.0, Total KL Divergence: 73801191.5, Total Reconstruction Loss: 13385596972032.0\n",
      "2023-07-19 17:49:49,832 - INFO - Save model at epoch 408\n",
      "0it [00:00, ?it/s]2023-07-19 17:49:49,930 - INFO - Epoch: [409/600], Step: [1/591], Loss: 101841472.0, KL Divergence: 988.33154296875, Reconstruction Loss: 101840480.0\n",
      "118it [00:10, 10.83it/s]2023-07-19 17:50:00,906 - INFO - Epoch: [409/600], Step: [119/591], Loss: 235143280.0, KL Divergence: 977.0440673828125, Reconstruction Loss: 235142304.0\n",
      "236it [00:21, 10.81it/s]2023-07-19 17:50:11,909 - INFO - Epoch: [409/600], Step: [237/591], Loss: 192058128.0, KL Divergence: 994.8500366210938, Reconstruction Loss: 192057136.0\n",
      "354it [00:32, 11.03it/s]2023-07-19 17:50:22,871 - INFO - Epoch: [409/600], Step: [355/591], Loss: 233910032.0, KL Divergence: 981.45166015625, Reconstruction Loss: 233909056.0\n",
      "472it [00:43, 10.74it/s]2023-07-19 17:50:33,777 - INFO - Epoch: [409/600], Step: [473/591], Loss: 203137200.0, KL Divergence: 978.1585083007812, Reconstruction Loss: 203136224.0\n",
      "590it [00:54, 10.61it/s]2023-07-19 17:50:44,683 - INFO - Epoch: [409/600], Step: [591/591], Loss: 171471072.0, KL Divergence: 988.4010009765625, Reconstruction Loss: 171470080.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 17:50:44,686 - INFO - Epoch: [409/600], Total Loss: 13581868222464.0, Total KL Divergence: 74181959.109375, Total Reconstruction Loss: 13581794024448.0\n",
      "2023-07-19 17:50:44,731 - INFO - Save model at epoch 409\n",
      "0it [00:00, ?it/s]2023-07-19 17:50:44,849 - INFO - Epoch: [410/600], Step: [1/591], Loss: 112206600.0, KL Divergence: 989.98388671875, Reconstruction Loss: 112205608.0\n",
      "117it [00:10, 10.45it/s]2023-07-19 17:50:55,652 - INFO - Epoch: [410/600], Step: [119/591], Loss: 237784592.0, KL Divergence: 972.1876220703125, Reconstruction Loss: 237783616.0\n",
      "235it [00:21, 10.99it/s]2023-07-19 17:51:06,719 - INFO - Epoch: [410/600], Step: [237/591], Loss: 193502592.0, KL Divergence: 996.1162109375, Reconstruction Loss: 193501600.0\n",
      "353it [00:32, 11.12it/s]2023-07-19 17:51:17,637 - INFO - Epoch: [410/600], Step: [355/591], Loss: 232192816.0, KL Divergence: 984.890869140625, Reconstruction Loss: 232191824.0\n",
      "471it [00:43, 10.72it/s]2023-07-19 17:51:28,432 - INFO - Epoch: [410/600], Step: [473/591], Loss: 225433952.0, KL Divergence: 995.2935791015625, Reconstruction Loss: 225432960.0\n",
      "589it [00:54, 11.20it/s]2023-07-19 17:51:39,186 - INFO - Epoch: [410/600], Step: [591/591], Loss: 169488816.0, KL Divergence: 994.471435546875, Reconstruction Loss: 169487824.0\n",
      "591it [00:54, 10.86it/s]\n",
      "2023-07-19 17:51:39,188 - INFO - Epoch: [410/600], Total Loss: 13701907705856.0, Total KL Divergence: 74559933.4296875, Total Reconstruction Loss: 13701833144320.0\n",
      "2023-07-19 17:51:39,231 - INFO - Save model at epoch 410\n",
      "0it [00:00, ?it/s]2023-07-19 17:51:39,336 - INFO - Epoch: [411/600], Step: [1/591], Loss: 113132392.0, KL Divergence: 999.4698486328125, Reconstruction Loss: 113131392.0\n",
      "118it [00:10, 10.05it/s]2023-07-19 17:51:50,241 - INFO - Epoch: [411/600], Step: [119/591], Loss: 233822016.0, KL Divergence: 986.36181640625, Reconstruction Loss: 233821024.0\n",
      "236it [00:21, 10.97it/s]2023-07-19 17:52:01,123 - INFO - Epoch: [411/600], Step: [237/591], Loss: 188394464.0, KL Divergence: 996.3052978515625, Reconstruction Loss: 188393472.0\n",
      "354it [00:32, 11.02it/s]2023-07-19 17:52:11,972 - INFO - Epoch: [411/600], Step: [355/591], Loss: 235244720.0, KL Divergence: 993.15478515625, Reconstruction Loss: 235243728.0\n",
      "472it [00:43, 10.77it/s]2023-07-19 17:52:22,938 - INFO - Epoch: [411/600], Step: [473/591], Loss: 217076064.0, KL Divergence: 995.1883544921875, Reconstruction Loss: 217075072.0\n",
      "590it [00:54, 11.00it/s]2023-07-19 17:52:33,764 - INFO - Epoch: [411/600], Step: [591/591], Loss: 174183424.0, KL Divergence: 998.2940673828125, Reconstruction Loss: 174182432.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 17:52:33,766 - INFO - Epoch: [411/600], Total Loss: 13617696340992.0, Total KL Divergence: 74959506.7734375, Total Reconstruction Loss: 13617621387264.0\n",
      "2023-07-19 17:52:33,808 - INFO - Save model at epoch 411\n",
      "0it [00:00, ?it/s]2023-07-19 17:52:33,924 - INFO - Epoch: [412/600], Step: [1/591], Loss: 107124792.0, KL Divergence: 1002.418212890625, Reconstruction Loss: 107123792.0\n",
      "117it [00:10, 10.85it/s]2023-07-19 17:52:44,861 - INFO - Epoch: [412/600], Step: [119/591], Loss: 235678784.0, KL Divergence: 985.4353637695312, Reconstruction Loss: 235677792.0\n",
      "235it [00:21, 10.84it/s]2023-07-19 17:52:55,845 - INFO - Epoch: [412/600], Step: [237/591], Loss: 200444752.0, KL Divergence: 993.753173828125, Reconstruction Loss: 200443760.0\n",
      "353it [00:32, 11.14it/s]2023-07-19 17:53:06,657 - INFO - Epoch: [412/600], Step: [355/591], Loss: 241006176.0, KL Divergence: 996.251953125, Reconstruction Loss: 241005184.0\n",
      "471it [00:43, 10.70it/s]2023-07-19 17:53:17,545 - INFO - Epoch: [412/600], Step: [473/591], Loss: 241820288.0, KL Divergence: 991.7852783203125, Reconstruction Loss: 241819296.0\n",
      "589it [00:54, 10.81it/s]2023-07-19 17:53:28,465 - INFO - Epoch: [412/600], Step: [591/591], Loss: 186448960.0, KL Divergence: 999.3939208984375, Reconstruction Loss: 186447968.0\n",
      "591it [00:54, 10.82it/s]\n",
      "2023-07-19 17:53:28,466 - INFO - Epoch: [412/600], Total Loss: 13663713287168.0, Total KL Divergence: 75031746.3515625, Total Reconstruction Loss: 13663638266880.0\n",
      "2023-07-19 17:53:28,506 - INFO - Save model at epoch 412\n",
      "0it [00:00, ?it/s]2023-07-19 17:53:28,613 - INFO - Epoch: [413/600], Step: [1/591], Loss: 122831720.0, KL Divergence: 1003.4155883789062, Reconstruction Loss: 122830720.0\n",
      "118it [00:10, 10.66it/s]2023-07-19 17:53:39,560 - INFO - Epoch: [413/600], Step: [119/591], Loss: 238215104.0, KL Divergence: 987.56005859375, Reconstruction Loss: 238214112.0\n",
      "236it [00:21, 10.59it/s]2023-07-19 17:53:50,578 - INFO - Epoch: [413/600], Step: [237/591], Loss: 196121232.0, KL Divergence: 1002.4652099609375, Reconstruction Loss: 196120224.0\n",
      "354it [00:32, 10.76it/s]2023-07-19 17:54:01,520 - INFO - Epoch: [413/600], Step: [355/591], Loss: 233295168.0, KL Divergence: 998.003662109375, Reconstruction Loss: 233294176.0\n",
      "472it [00:43, 10.79it/s]2023-07-19 17:54:12,606 - INFO - Epoch: [413/600], Step: [473/591], Loss: 215340960.0, KL Divergence: 1000.1953125, Reconstruction Loss: 215339952.0\n",
      "590it [00:54, 10.89it/s]2023-07-19 17:54:23,449 - INFO - Epoch: [413/600], Step: [591/591], Loss: 169053184.0, KL Divergence: 999.6288452148438, Reconstruction Loss: 169052192.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 17:54:23,452 - INFO - Epoch: [413/600], Total Loss: 13616259305472.0, Total KL Divergence: 75173265.2890625, Total Reconstruction Loss: 13616184118272.0\n",
      "2023-07-19 17:54:23,506 - INFO - Save model at epoch 413\n",
      "0it [00:00, ?it/s]2023-07-19 17:54:23,607 - INFO - Epoch: [414/600], Step: [1/591], Loss: 107220672.0, KL Divergence: 1001.9647827148438, Reconstruction Loss: 107219672.0\n",
      "118it [00:10, 10.91it/s]2023-07-19 17:54:34,561 - INFO - Epoch: [414/600], Step: [119/591], Loss: 239177296.0, KL Divergence: 982.80078125, Reconstruction Loss: 239176320.0\n",
      "235it [00:21, 11.01it/s]2023-07-19 17:54:45,584 - INFO - Epoch: [414/600], Step: [237/591], Loss: 190306320.0, KL Divergence: 1004.6053466796875, Reconstruction Loss: 190305312.0\n",
      "353it [00:32, 10.86it/s]2023-07-19 17:54:56,472 - INFO - Epoch: [414/600], Step: [355/591], Loss: 231751376.0, KL Divergence: 992.9801025390625, Reconstruction Loss: 231750384.0\n",
      "471it [00:43, 10.87it/s]2023-07-19 17:55:07,410 - INFO - Epoch: [414/600], Step: [473/591], Loss: 210518464.0, KL Divergence: 986.6859130859375, Reconstruction Loss: 210517472.0\n",
      "589it [00:54, 10.95it/s]2023-07-19 17:55:18,256 - INFO - Epoch: [414/600], Step: [591/591], Loss: 162133664.0, KL Divergence: 992.158203125, Reconstruction Loss: 162132672.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 17:55:18,258 - INFO - Epoch: [414/600], Total Loss: 13533576578048.0, Total KL Divergence: 74838292.4765625, Total Reconstruction Loss: 13533501743104.0\n",
      "2023-07-19 17:55:18,306 - INFO - Save model at epoch 414\n",
      "0it [00:00, ?it/s]2023-07-19 17:55:18,438 - INFO - Epoch: [415/600], Step: [1/591], Loss: 101013112.0, KL Divergence: 996.6420288085938, Reconstruction Loss: 101012112.0\n",
      "117it [00:10, 10.65it/s]2023-07-19 17:55:29,445 - INFO - Epoch: [415/600], Step: [119/591], Loss: 234973824.0, KL Divergence: 977.4367065429688, Reconstruction Loss: 234972848.0\n",
      "235it [00:21, 10.80it/s]2023-07-19 17:55:40,450 - INFO - Epoch: [415/600], Step: [237/591], Loss: 198641760.0, KL Divergence: 997.122802734375, Reconstruction Loss: 198640768.0\n",
      "353it [00:32, 10.74it/s]2023-07-19 17:55:51,413 - INFO - Epoch: [415/600], Step: [355/591], Loss: 236036272.0, KL Divergence: 989.939208984375, Reconstruction Loss: 236035280.0\n",
      "471it [00:43, 10.82it/s]2023-07-19 17:56:02,411 - INFO - Epoch: [415/600], Step: [473/591], Loss: 204973088.0, KL Divergence: 987.0004272460938, Reconstruction Loss: 204972096.0\n",
      "589it [00:54, 11.04it/s]2023-07-19 17:56:13,206 - INFO - Epoch: [415/600], Step: [591/591], Loss: 162992720.0, KL Divergence: 1001.21826171875, Reconstruction Loss: 162991712.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 17:56:13,208 - INFO - Epoch: [415/600], Total Loss: 13508905207808.0, Total KL Divergence: 74739549.171875, Total Reconstruction Loss: 13508830472192.0\n",
      "2023-07-19 17:56:13,248 - INFO - Save model at epoch 415\n",
      "0it [00:00, ?it/s]2023-07-19 17:56:13,357 - INFO - Epoch: [416/600], Step: [1/591], Loss: 104056216.0, KL Divergence: 1005.5472412109375, Reconstruction Loss: 104055208.0\n",
      "118it [00:10, 10.87it/s]2023-07-19 17:56:24,278 - INFO - Epoch: [416/600], Step: [119/591], Loss: 237759520.0, KL Divergence: 978.576904296875, Reconstruction Loss: 237758544.0\n",
      "236it [00:21, 11.30it/s]2023-07-19 17:56:35,190 - INFO - Epoch: [416/600], Step: [237/591], Loss: 196102752.0, KL Divergence: 997.47021484375, Reconstruction Loss: 196101760.0\n",
      "354it [00:32, 10.95it/s]2023-07-19 17:56:46,107 - INFO - Epoch: [416/600], Step: [355/591], Loss: 235857664.0, KL Divergence: 994.2967529296875, Reconstruction Loss: 235856672.0\n",
      "472it [00:43, 11.17it/s]2023-07-19 17:56:57,104 - INFO - Epoch: [416/600], Step: [473/591], Loss: 199993568.0, KL Divergence: 989.746826171875, Reconstruction Loss: 199992576.0\n",
      "590it [00:54, 10.57it/s]2023-07-19 17:57:08,051 - INFO - Epoch: [416/600], Step: [591/591], Loss: 172289840.0, KL Divergence: 998.2365112304688, Reconstruction Loss: 172288848.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 17:57:08,052 - INFO - Epoch: [416/600], Total Loss: 13685138268160.0, Total KL Divergence: 74791074.171875, Total Reconstruction Loss: 13685063491584.0\n",
      "2023-07-19 17:57:08,109 - INFO - Save model at epoch 416\n",
      "0it [00:00, ?it/s]2023-07-19 17:57:08,231 - INFO - Epoch: [417/600], Step: [1/591], Loss: 106162664.0, KL Divergence: 1001.2822265625, Reconstruction Loss: 106161664.0\n",
      "117it [00:14, 10.65it/s]2023-07-19 17:57:22,712 - INFO - Epoch: [417/600], Step: [119/591], Loss: 234037520.0, KL Divergence: 970.99853515625, Reconstruction Loss: 234036544.0\n",
      "236it [00:25, 10.49it/s]2023-07-19 17:57:33,722 - INFO - Epoch: [417/600], Step: [237/591], Loss: 191979232.0, KL Divergence: 989.9661865234375, Reconstruction Loss: 191978240.0\n",
      "354it [00:36, 10.77it/s]2023-07-19 17:57:44,723 - INFO - Epoch: [417/600], Step: [355/591], Loss: 236637552.0, KL Divergence: 982.177734375, Reconstruction Loss: 236636576.0\n",
      "472it [00:47, 10.53it/s]2023-07-19 17:57:55,705 - INFO - Epoch: [417/600], Step: [473/591], Loss: 203953360.0, KL Divergence: 980.1595458984375, Reconstruction Loss: 203952384.0\n",
      "590it [00:58, 10.99it/s]2023-07-19 17:58:06,451 - INFO - Epoch: [417/600], Step: [591/591], Loss: 177630720.0, KL Divergence: 1003.0473022460938, Reconstruction Loss: 177629712.0\n",
      "591it [00:58, 10.13it/s]\n",
      "2023-07-19 17:58:06,452 - INFO - Epoch: [417/600], Total Loss: 13504224874496.0, Total KL Divergence: 74309284.390625, Total Reconstruction Loss: 13504150552576.0\n",
      "2023-07-19 17:58:06,499 - INFO - Save model at epoch 417\n",
      "0it [00:00, ?it/s]2023-07-19 17:58:06,610 - INFO - Epoch: [418/600], Step: [1/591], Loss: 109454384.0, KL Divergence: 1007.0074462890625, Reconstruction Loss: 109453376.0\n",
      "117it [00:10, 10.89it/s]2023-07-19 17:58:17,662 - INFO - Epoch: [418/600], Step: [119/591], Loss: 234404320.0, KL Divergence: 984.5108642578125, Reconstruction Loss: 234403328.0\n",
      "235it [00:21, 11.26it/s]2023-07-19 17:58:28,620 - INFO - Epoch: [418/600], Step: [237/591], Loss: 192515584.0, KL Divergence: 994.4285888671875, Reconstruction Loss: 192514592.0\n",
      "353it [00:32, 10.86it/s]2023-07-19 17:58:39,481 - INFO - Epoch: [418/600], Step: [355/591], Loss: 231410112.0, KL Divergence: 988.3524780273438, Reconstruction Loss: 231409120.0\n",
      "471it [00:43, 10.68it/s]2023-07-19 17:58:50,504 - INFO - Epoch: [418/600], Step: [473/591], Loss: 201027280.0, KL Divergence: 989.1756591796875, Reconstruction Loss: 201026288.0\n",
      "589it [00:54, 10.72it/s]2023-07-19 17:59:01,415 - INFO - Epoch: [418/600], Step: [591/591], Loss: 166002480.0, KL Divergence: 1000.2570190429688, Reconstruction Loss: 166001472.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 17:59:01,417 - INFO - Epoch: [418/600], Total Loss: 13323537688576.0, Total KL Divergence: 74663290.0625, Total Reconstruction Loss: 13323463024640.0\n",
      "2023-07-19 17:59:01,469 - INFO - Save model at epoch 418\n",
      "0it [00:00, ?it/s]2023-07-19 17:59:01,587 - INFO - Epoch: [419/600], Step: [1/591], Loss: 115661448.0, KL Divergence: 1003.4237060546875, Reconstruction Loss: 115660448.0\n",
      "117it [00:10, 10.56it/s]2023-07-19 17:59:12,475 - INFO - Epoch: [419/600], Step: [119/591], Loss: 239419200.0, KL Divergence: 981.996337890625, Reconstruction Loss: 239418224.0\n",
      "235it [00:21, 10.75it/s]2023-07-19 17:59:23,441 - INFO - Epoch: [419/600], Step: [237/591], Loss: 193199760.0, KL Divergence: 1000.0932006835938, Reconstruction Loss: 193198752.0\n",
      "353it [00:32, 10.71it/s]2023-07-19 17:59:34,372 - INFO - Epoch: [419/600], Step: [355/591], Loss: 233182880.0, KL Divergence: 985.559814453125, Reconstruction Loss: 233181888.0\n",
      "471it [00:43, 10.59it/s]2023-07-19 17:59:45,444 - INFO - Epoch: [419/600], Step: [473/591], Loss: 204104672.0, KL Divergence: 992.4339599609375, Reconstruction Loss: 204103680.0\n",
      "589it [00:54, 10.53it/s]2023-07-19 17:59:56,332 - INFO - Epoch: [419/600], Step: [591/591], Loss: 158171488.0, KL Divergence: 995.85400390625, Reconstruction Loss: 158170496.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 17:59:56,334 - INFO - Epoch: [419/600], Total Loss: 13353536850944.0, Total KL Divergence: 74780004.0, Total Reconstruction Loss: 13353462080512.0\n",
      "2023-07-19 17:59:56,379 - INFO - Save model at epoch 419\n",
      "0it [00:00, ?it/s]2023-07-19 17:59:56,478 - INFO - Epoch: [420/600], Step: [1/591], Loss: 108881992.0, KL Divergence: 1000.8052978515625, Reconstruction Loss: 108880992.0\n",
      "118it [00:11, 10.45it/s]2023-07-19 18:00:07,580 - INFO - Epoch: [420/600], Step: [119/591], Loss: 244832528.0, KL Divergence: 985.5795288085938, Reconstruction Loss: 244831536.0\n",
      "236it [00:22, 11.06it/s]2023-07-19 18:00:18,551 - INFO - Epoch: [420/600], Step: [237/591], Loss: 191492368.0, KL Divergence: 995.0574340820312, Reconstruction Loss: 191491376.0\n",
      "354it [00:33, 10.99it/s]2023-07-19 18:00:29,545 - INFO - Epoch: [420/600], Step: [355/591], Loss: 235373216.0, KL Divergence: 985.8783569335938, Reconstruction Loss: 235372224.0\n",
      "472it [00:44, 10.76it/s]2023-07-19 18:00:40,626 - INFO - Epoch: [420/600], Step: [473/591], Loss: 204449280.0, KL Divergence: 982.5262451171875, Reconstruction Loss: 204448304.0\n",
      "590it [00:55, 11.07it/s]2023-07-19 18:00:51,524 - INFO - Epoch: [420/600], Step: [591/591], Loss: 167628368.0, KL Divergence: 996.5236206054688, Reconstruction Loss: 167627376.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 18:00:51,525 - INFO - Epoch: [420/600], Total Loss: 13471614760960.0, Total KL Divergence: 74526845.65625, Total Reconstruction Loss: 13471540238336.0\n",
      "2023-07-19 18:00:51,568 - INFO - Save model at epoch 420\n",
      "0it [00:00, ?it/s]2023-07-19 18:00:51,672 - INFO - Epoch: [421/600], Step: [1/591], Loss: 107506848.0, KL Divergence: 1001.98681640625, Reconstruction Loss: 107505848.0\n",
      "118it [00:11, 10.60it/s]2023-07-19 18:01:02,717 - INFO - Epoch: [421/600], Step: [119/591], Loss: 251658128.0, KL Divergence: 979.2660522460938, Reconstruction Loss: 251657152.0\n",
      "236it [00:22, 10.46it/s]2023-07-19 18:01:13,762 - INFO - Epoch: [421/600], Step: [237/591], Loss: 187715520.0, KL Divergence: 993.5655517578125, Reconstruction Loss: 187714528.0\n",
      "354it [00:33, 10.52it/s]2023-07-19 18:01:24,707 - INFO - Epoch: [421/600], Step: [355/591], Loss: 247581792.0, KL Divergence: 987.385986328125, Reconstruction Loss: 247580800.0\n",
      "472it [00:44, 10.71it/s]2023-07-19 18:01:35,791 - INFO - Epoch: [421/600], Step: [473/591], Loss: 209786448.0, KL Divergence: 987.8709716796875, Reconstruction Loss: 209785456.0\n",
      "590it [00:54, 11.14it/s]2023-07-19 18:01:46,571 - INFO - Epoch: [421/600], Step: [591/591], Loss: 183993184.0, KL Divergence: 996.5330810546875, Reconstruction Loss: 183992192.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 18:01:46,573 - INFO - Epoch: [421/600], Total Loss: 13587790574592.0, Total KL Divergence: 74509948.2890625, Total Reconstruction Loss: 13587716084736.0\n",
      "2023-07-19 18:01:46,626 - INFO - Save model at epoch 421\n",
      "0it [00:00, ?it/s]2023-07-19 18:01:46,730 - INFO - Epoch: [422/600], Step: [1/591], Loss: 112781032.0, KL Divergence: 1003.8333129882812, Reconstruction Loss: 112780032.0\n",
      "118it [00:10, 11.22it/s]2023-07-19 18:01:57,604 - INFO - Epoch: [422/600], Step: [119/591], Loss: 281814240.0, KL Divergence: 984.861572265625, Reconstruction Loss: 281813248.0\n",
      "236it [00:21, 10.77it/s]2023-07-19 18:02:08,709 - INFO - Epoch: [422/600], Step: [237/591], Loss: 189450976.0, KL Divergence: 1002.34912109375, Reconstruction Loss: 189449968.0\n",
      "354it [00:33, 10.77it/s]2023-07-19 18:02:19,858 - INFO - Epoch: [422/600], Step: [355/591], Loss: 235635936.0, KL Divergence: 1000.3348999023438, Reconstruction Loss: 235634928.0\n",
      "472it [00:44, 10.76it/s]2023-07-19 18:02:30,925 - INFO - Epoch: [422/600], Step: [473/591], Loss: 213365248.0, KL Divergence: 998.11474609375, Reconstruction Loss: 213364256.0\n",
      "590it [00:55, 11.02it/s]2023-07-19 18:02:41,742 - INFO - Epoch: [422/600], Step: [591/591], Loss: 175898912.0, KL Divergence: 1001.0521240234375, Reconstruction Loss: 175897904.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 18:02:41,743 - INFO - Epoch: [422/600], Total Loss: 13709227581440.0, Total KL Divergence: 75217437.6640625, Total Reconstruction Loss: 13709152335872.0\n",
      "2023-07-19 18:02:41,792 - INFO - Save model at epoch 422\n",
      "0it [00:00, ?it/s]2023-07-19 18:02:41,900 - INFO - Epoch: [423/600], Step: [1/591], Loss: 103730128.0, KL Divergence: 1006.9402465820312, Reconstruction Loss: 103729120.0\n",
      "118it [00:10, 10.92it/s]2023-07-19 18:02:52,815 - INFO - Epoch: [423/600], Step: [119/591], Loss: 243965008.0, KL Divergence: 983.1592407226562, Reconstruction Loss: 243964032.0\n",
      "236it [00:21, 10.97it/s]2023-07-19 18:03:03,760 - INFO - Epoch: [423/600], Step: [237/591], Loss: 186700784.0, KL Divergence: 1004.35498046875, Reconstruction Loss: 186699776.0\n",
      "354it [00:32, 10.59it/s]2023-07-19 18:03:14,718 - INFO - Epoch: [423/600], Step: [355/591], Loss: 232337472.0, KL Divergence: 1001.4954223632812, Reconstruction Loss: 232336464.0\n",
      "472it [00:43, 10.82it/s]2023-07-19 18:03:25,711 - INFO - Epoch: [423/600], Step: [473/591], Loss: 201430048.0, KL Divergence: 999.4930419921875, Reconstruction Loss: 201429056.0\n",
      "590it [00:54, 10.53it/s]2023-07-19 18:03:36,623 - INFO - Epoch: [423/600], Step: [591/591], Loss: 186738464.0, KL Divergence: 1004.7967529296875, Reconstruction Loss: 186737456.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 18:03:36,625 - INFO - Epoch: [423/600], Total Loss: 13541075912704.0, Total KL Divergence: 75477466.1875, Total Reconstruction Loss: 13541000432640.0\n",
      "2023-07-19 18:03:36,663 - INFO - Save model at epoch 423\n",
      "0it [00:00, ?it/s]2023-07-19 18:03:36,774 - INFO - Epoch: [424/600], Step: [1/591], Loss: 106060072.0, KL Divergence: 1014.080322265625, Reconstruction Loss: 106059056.0\n",
      "118it [00:10, 10.82it/s]2023-07-19 18:03:47,786 - INFO - Epoch: [424/600], Step: [119/591], Loss: 234185504.0, KL Divergence: 996.809326171875, Reconstruction Loss: 234184512.0\n",
      "236it [00:22, 10.91it/s]2023-07-19 18:03:58,780 - INFO - Epoch: [424/600], Step: [237/591], Loss: 186374800.0, KL Divergence: 1012.45751953125, Reconstruction Loss: 186373792.0\n",
      "354it [00:32, 11.01it/s]2023-07-19 18:04:09,777 - INFO - Epoch: [424/600], Step: [355/591], Loss: 231905264.0, KL Divergence: 1008.5281372070312, Reconstruction Loss: 231904256.0\n",
      "472it [00:44, 10.95it/s]2023-07-19 18:04:20,897 - INFO - Epoch: [424/600], Step: [473/591], Loss: 206619824.0, KL Divergence: 1002.6781005859375, Reconstruction Loss: 206618816.0\n",
      "590it [00:54, 10.81it/s]2023-07-19 18:04:31,727 - INFO - Epoch: [424/600], Step: [591/591], Loss: 183706976.0, KL Divergence: 999.9547119140625, Reconstruction Loss: 183705984.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 18:04:31,729 - INFO - Epoch: [424/600], Total Loss: 13402944283648.0, Total KL Divergence: 75998724.4921875, Total Reconstruction Loss: 13402868299776.0\n",
      "2023-07-19 18:04:31,769 - INFO - Save model at epoch 424\n",
      "0it [00:00, ?it/s]2023-07-19 18:04:31,867 - INFO - Epoch: [425/600], Step: [1/591], Loss: 106393920.0, KL Divergence: 1009.741455078125, Reconstruction Loss: 106392912.0\n",
      "118it [00:10, 10.83it/s]2023-07-19 18:04:42,851 - INFO - Epoch: [425/600], Step: [119/591], Loss: 229673632.0, KL Divergence: 988.042236328125, Reconstruction Loss: 229672640.0\n",
      "236it [00:22, 10.71it/s]2023-07-19 18:04:53,989 - INFO - Epoch: [425/600], Step: [237/591], Loss: 187057296.0, KL Divergence: 1009.0748291015625, Reconstruction Loss: 187056288.0\n",
      "354it [00:33, 10.75it/s]2023-07-19 18:05:04,950 - INFO - Epoch: [425/600], Step: [355/591], Loss: 233275920.0, KL Divergence: 1000.7984619140625, Reconstruction Loss: 233274912.0\n",
      "472it [00:43, 10.92it/s]2023-07-19 18:05:15,901 - INFO - Epoch: [425/600], Step: [473/591], Loss: 208128672.0, KL Divergence: 991.638916015625, Reconstruction Loss: 208127680.0\n",
      "590it [00:54, 10.89it/s]2023-07-19 18:05:26,827 - INFO - Epoch: [425/600], Step: [591/591], Loss: 165004528.0, KL Divergence: 1007.15673828125, Reconstruction Loss: 165003520.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 18:05:26,829 - INFO - Epoch: [425/600], Total Loss: 13402975866880.0, Total KL Divergence: 75487453.15625, Total Reconstruction Loss: 13402900393984.0\n",
      "2023-07-19 18:05:26,871 - INFO - Save model at epoch 425\n",
      "0it [00:00, ?it/s]2023-07-19 18:05:26,993 - INFO - Epoch: [426/600], Step: [1/591], Loss: 103845960.0, KL Divergence: 1014.251220703125, Reconstruction Loss: 103844944.0\n",
      "117it [00:10, 10.79it/s]2023-07-19 18:05:37,882 - INFO - Epoch: [426/600], Step: [119/591], Loss: 231998096.0, KL Divergence: 992.9554443359375, Reconstruction Loss: 231997104.0\n",
      "235it [00:21, 10.40it/s]2023-07-19 18:05:48,824 - INFO - Epoch: [426/600], Step: [237/591], Loss: 189013008.0, KL Divergence: 1011.8114624023438, Reconstruction Loss: 189012000.0\n",
      "353it [00:32, 10.28it/s]2023-07-19 18:05:59,738 - INFO - Epoch: [426/600], Step: [355/591], Loss: 235782976.0, KL Divergence: 996.0201416015625, Reconstruction Loss: 235781984.0\n",
      "471it [00:43, 10.78it/s]2023-07-19 18:06:10,815 - INFO - Epoch: [426/600], Step: [473/591], Loss: 206569408.0, KL Divergence: 998.3955078125, Reconstruction Loss: 206568416.0\n",
      "589it [00:54, 10.13it/s]2023-07-19 18:06:21,741 - INFO - Epoch: [426/600], Step: [591/591], Loss: 162122880.0, KL Divergence: 999.4176635742188, Reconstruction Loss: 162121888.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 18:06:21,743 - INFO - Epoch: [426/600], Total Loss: 13383335696384.0, Total KL Divergence: 75559351.1015625, Total Reconstruction Loss: 13383260143616.0\n",
      "2023-07-19 18:06:21,783 - INFO - Save model at epoch 426\n",
      "0it [00:00, ?it/s]2023-07-19 18:06:21,892 - INFO - Epoch: [427/600], Step: [1/591], Loss: 105571632.0, KL Divergence: 1007.0379638671875, Reconstruction Loss: 105570624.0\n",
      "118it [00:11, 11.10it/s]2023-07-19 18:06:32,987 - INFO - Epoch: [427/600], Step: [119/591], Loss: 234852064.0, KL Divergence: 987.8370361328125, Reconstruction Loss: 234851072.0\n",
      "236it [00:21, 11.04it/s]2023-07-19 18:06:43,866 - INFO - Epoch: [427/600], Step: [237/591], Loss: 188021312.0, KL Divergence: 1012.16552734375, Reconstruction Loss: 188020304.0\n",
      "354it [00:32, 10.75it/s]2023-07-19 18:06:54,744 - INFO - Epoch: [427/600], Step: [355/591], Loss: 235257376.0, KL Divergence: 999.7200317382812, Reconstruction Loss: 235256384.0\n",
      "472it [00:43, 10.91it/s]2023-07-19 18:07:05,670 - INFO - Epoch: [427/600], Step: [473/591], Loss: 199068704.0, KL Divergence: 996.8276977539062, Reconstruction Loss: 199067712.0\n",
      "590it [00:54, 10.54it/s]2023-07-19 18:07:16,470 - INFO - Epoch: [427/600], Step: [591/591], Loss: 170850976.0, KL Divergence: 998.8915405273438, Reconstruction Loss: 170849984.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 18:07:16,472 - INFO - Epoch: [427/600], Total Loss: 13344868190208.0, Total KL Divergence: 75386737.390625, Total Reconstruction Loss: 13344792762368.0\n",
      "2023-07-19 18:07:16,511 - INFO - Save model at epoch 427\n",
      "0it [00:00, ?it/s]2023-07-19 18:07:16,614 - INFO - Epoch: [428/600], Step: [1/591], Loss: 110435120.0, KL Divergence: 1006.06005859375, Reconstruction Loss: 110434112.0\n",
      "118it [00:10, 10.97it/s]2023-07-19 18:07:27,458 - INFO - Epoch: [428/600], Step: [119/591], Loss: 239370064.0, KL Divergence: 989.293701171875, Reconstruction Loss: 239369072.0\n",
      "236it [00:21, 11.14it/s]2023-07-19 18:07:38,478 - INFO - Epoch: [428/600], Step: [237/591], Loss: 189262000.0, KL Divergence: 1006.7733154296875, Reconstruction Loss: 189260992.0\n",
      "354it [00:32, 10.45it/s]2023-07-19 18:07:49,359 - INFO - Epoch: [428/600], Step: [355/591], Loss: 232835280.0, KL Divergence: 999.8744506835938, Reconstruction Loss: 232834288.0\n",
      "471it [00:43, 10.90it/s]2023-07-19 18:08:00,339 - INFO - Epoch: [428/600], Step: [473/591], Loss: 203854336.0, KL Divergence: 1000.6961669921875, Reconstruction Loss: 203853328.0\n",
      "589it [00:54, 10.92it/s]2023-07-19 18:08:11,208 - INFO - Epoch: [428/600], Step: [591/591], Loss: 172189824.0, KL Divergence: 1003.395751953125, Reconstruction Loss: 172188816.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 18:08:11,211 - INFO - Epoch: [428/600], Total Loss: 13273461258240.0, Total KL Divergence: 75472409.65625, Total Reconstruction Loss: 13273385776128.0\n",
      "2023-07-19 18:08:11,253 - INFO - Save model at epoch 428\n",
      "0it [00:00, ?it/s]2023-07-19 18:08:11,359 - INFO - Epoch: [429/600], Step: [1/591], Loss: 106401824.0, KL Divergence: 1008.7540283203125, Reconstruction Loss: 106400816.0\n",
      "117it [00:10, 10.91it/s]2023-07-19 18:08:22,257 - INFO - Epoch: [429/600], Step: [119/591], Loss: 237834800.0, KL Divergence: 994.46875, Reconstruction Loss: 237833808.0\n",
      "235it [00:21, 11.07it/s]2023-07-19 18:08:33,282 - INFO - Epoch: [429/600], Step: [237/591], Loss: 192126352.0, KL Divergence: 1008.885009765625, Reconstruction Loss: 192125344.0\n",
      "353it [00:32, 11.00it/s]2023-07-19 18:08:44,242 - INFO - Epoch: [429/600], Step: [355/591], Loss: 234432496.0, KL Divergence: 1000.6231079101562, Reconstruction Loss: 234431488.0\n",
      "471it [00:43, 10.40it/s]2023-07-19 18:08:55,202 - INFO - Epoch: [429/600], Step: [473/591], Loss: 200879472.0, KL Divergence: 1001.2778930664062, Reconstruction Loss: 200878464.0\n",
      "589it [00:54, 10.67it/s]2023-07-19 18:09:06,154 - INFO - Epoch: [429/600], Step: [591/591], Loss: 161209808.0, KL Divergence: 1013.7052001953125, Reconstruction Loss: 161208800.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 18:09:06,156 - INFO - Epoch: [429/600], Total Loss: 13248627499008.0, Total KL Divergence: 75734361.609375, Total Reconstruction Loss: 13248551755776.0\n",
      "2023-07-19 18:09:06,201 - INFO - Save model at epoch 429\n",
      "0it [00:00, ?it/s]2023-07-19 18:09:06,319 - INFO - Epoch: [430/600], Step: [1/591], Loss: 101039320.0, KL Divergence: 1018.6771240234375, Reconstruction Loss: 101038304.0\n",
      "118it [00:11, 10.77it/s]2023-07-19 18:09:17,332 - INFO - Epoch: [430/600], Step: [119/591], Loss: 239990288.0, KL Divergence: 1001.465087890625, Reconstruction Loss: 239989280.0\n",
      "236it [00:22, 10.50it/s]2023-07-19 18:09:28,400 - INFO - Epoch: [430/600], Step: [237/591], Loss: 190453456.0, KL Divergence: 1014.4309692382812, Reconstruction Loss: 190452448.0\n",
      "354it [00:33, 10.64it/s]2023-07-19 18:09:39,382 - INFO - Epoch: [430/600], Step: [355/591], Loss: 228273328.0, KL Divergence: 1017.77099609375, Reconstruction Loss: 228272304.0\n",
      "472it [00:43, 11.03it/s]2023-07-19 18:09:50,224 - INFO - Epoch: [430/600], Step: [473/591], Loss: 240257056.0, KL Divergence: 1012.0445556640625, Reconstruction Loss: 240256048.0\n",
      "590it [00:54, 10.95it/s]2023-07-19 18:10:00,898 - INFO - Epoch: [430/600], Step: [591/591], Loss: 163354096.0, KL Divergence: 1018.8408203125, Reconstruction Loss: 163353072.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 18:10:00,900 - INFO - Epoch: [430/600], Total Loss: 13396307326976.0, Total KL Divergence: 76333489.625, Total Reconstruction Loss: 13396230965248.0\n",
      "2023-07-19 18:10:00,956 - INFO - Save model at epoch 430\n",
      "0it [00:00, ?it/s]2023-07-19 18:10:01,063 - INFO - Epoch: [431/600], Step: [1/591], Loss: 101530080.0, KL Divergence: 1024.5784912109375, Reconstruction Loss: 101529056.0\n",
      "118it [00:10, 10.62it/s]2023-07-19 18:10:12,033 - INFO - Epoch: [431/600], Step: [119/591], Loss: 247024176.0, KL Divergence: 1006.5296630859375, Reconstruction Loss: 247023168.0\n",
      "236it [00:21, 10.68it/s]2023-07-19 18:10:22,954 - INFO - Epoch: [431/600], Step: [237/591], Loss: 187286096.0, KL Divergence: 1020.1300048828125, Reconstruction Loss: 187285072.0\n",
      "354it [00:32, 11.08it/s]2023-07-19 18:10:33,853 - INFO - Epoch: [431/600], Step: [355/591], Loss: 237749472.0, KL Divergence: 1017.5155029296875, Reconstruction Loss: 237748448.0\n",
      "472it [00:43, 10.70it/s]2023-07-19 18:10:44,805 - INFO - Epoch: [431/600], Step: [473/591], Loss: 201832848.0, KL Divergence: 1012.1630859375, Reconstruction Loss: 201831840.0\n",
      "590it [00:54, 10.85it/s]2023-07-19 18:10:55,748 - INFO - Epoch: [431/600], Step: [591/591], Loss: 162733760.0, KL Divergence: 1018.8607177734375, Reconstruction Loss: 162732736.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 18:10:55,750 - INFO - Epoch: [431/600], Total Loss: 13401398223872.0, Total KL Divergence: 76707667.96875, Total Reconstruction Loss: 13401321520128.0\n",
      "2023-07-19 18:10:55,790 - INFO - Save model at epoch 431\n",
      "0it [00:00, ?it/s]2023-07-19 18:10:55,896 - INFO - Epoch: [432/600], Step: [1/591], Loss: 103389256.0, KL Divergence: 1026.392578125, Reconstruction Loss: 103388232.0\n",
      "118it [00:10, 11.07it/s]2023-07-19 18:11:06,861 - INFO - Epoch: [432/600], Step: [119/591], Loss: 245291248.0, KL Divergence: 1007.1465454101562, Reconstruction Loss: 245290240.0\n",
      "236it [00:22, 10.77it/s]2023-07-19 18:11:17,968 - INFO - Epoch: [432/600], Step: [237/591], Loss: 186386752.0, KL Divergence: 1019.09033203125, Reconstruction Loss: 186385728.0\n",
      "354it [00:33, 10.47it/s]2023-07-19 18:11:29,039 - INFO - Epoch: [432/600], Step: [355/591], Loss: 237729744.0, KL Divergence: 1015.439697265625, Reconstruction Loss: 237728736.0\n",
      "472it [00:44, 10.58it/s]2023-07-19 18:11:39,910 - INFO - Epoch: [432/600], Step: [473/591], Loss: 199639680.0, KL Divergence: 1026.261962890625, Reconstruction Loss: 199638656.0\n",
      "590it [00:54, 10.53it/s]2023-07-19 18:11:50,716 - INFO - Epoch: [432/600], Step: [591/591], Loss: 164779968.0, KL Divergence: 1027.290283203125, Reconstruction Loss: 164778944.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 18:11:50,717 - INFO - Epoch: [432/600], Total Loss: 13350305847296.0, Total KL Divergence: 76814340.7109375, Total Reconstruction Loss: 13350229026816.0\n",
      "2023-07-19 18:11:50,757 - INFO - Save model at epoch 432\n",
      "0it [00:00, ?it/s]2023-07-19 18:11:50,863 - INFO - Epoch: [433/600], Step: [1/591], Loss: 103359312.0, KL Divergence: 1034.058837890625, Reconstruction Loss: 103358280.0\n",
      "118it [00:11, 10.68it/s]2023-07-19 18:12:01,892 - INFO - Epoch: [433/600], Step: [119/591], Loss: 239237264.0, KL Divergence: 1016.0211181640625, Reconstruction Loss: 239236240.0\n",
      "236it [00:22, 10.82it/s]2023-07-19 18:12:12,867 - INFO - Epoch: [433/600], Step: [237/591], Loss: 189803872.0, KL Divergence: 1028.499755859375, Reconstruction Loss: 189802848.0\n",
      "354it [00:32, 10.81it/s]2023-07-19 18:12:23,756 - INFO - Epoch: [433/600], Step: [355/591], Loss: 228288864.0, KL Divergence: 1018.8759765625, Reconstruction Loss: 228287840.0\n",
      "472it [00:43, 10.79it/s]2023-07-19 18:12:34,779 - INFO - Epoch: [433/600], Step: [473/591], Loss: 210521376.0, KL Divergence: 1024.10205078125, Reconstruction Loss: 210520352.0\n",
      "590it [00:54, 11.23it/s]2023-07-19 18:12:45,545 - INFO - Epoch: [433/600], Step: [591/591], Loss: 168643856.0, KL Divergence: 1033.5535888671875, Reconstruction Loss: 168642816.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 18:12:45,546 - INFO - Epoch: [433/600], Total Loss: 13443449195520.0, Total KL Divergence: 77154477.09375, Total Reconstruction Loss: 13443372063744.0\n",
      "2023-07-19 18:12:45,586 - INFO - Save model at epoch 433\n",
      "0it [00:00, ?it/s]2023-07-19 18:12:45,698 - INFO - Epoch: [434/600], Step: [1/591], Loss: 106283216.0, KL Divergence: 1040.4447021484375, Reconstruction Loss: 106282176.0\n",
      "117it [00:10, 11.02it/s]2023-07-19 18:12:56,620 - INFO - Epoch: [434/600], Step: [119/591], Loss: 232074192.0, KL Divergence: 1014.3333129882812, Reconstruction Loss: 232073184.0\n",
      "235it [00:21, 11.07it/s]2023-07-19 18:13:07,559 - INFO - Epoch: [434/600], Step: [237/591], Loss: 185811904.0, KL Divergence: 1023.8869018554688, Reconstruction Loss: 185810880.0\n",
      "353it [00:32, 10.85it/s]2023-07-19 18:13:18,509 - INFO - Epoch: [434/600], Step: [355/591], Loss: 234335360.0, KL Divergence: 1029.295166015625, Reconstruction Loss: 234334336.0\n",
      "471it [00:43, 10.89it/s]2023-07-19 18:13:29,498 - INFO - Epoch: [434/600], Step: [473/591], Loss: 213855488.0, KL Divergence: 1021.982421875, Reconstruction Loss: 213854464.0\n",
      "589it [00:54, 10.92it/s]2023-07-19 18:13:40,395 - INFO - Epoch: [434/600], Step: [591/591], Loss: 165620320.0, KL Divergence: 1030.37841796875, Reconstruction Loss: 165619296.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 18:13:40,398 - INFO - Epoch: [434/600], Total Loss: 13412191187968.0, Total KL Divergence: 77256366.359375, Total Reconstruction Loss: 13412113946624.0\n",
      "2023-07-19 18:13:40,442 - INFO - Save model at epoch 434\n",
      "0it [00:00, ?it/s]2023-07-19 18:13:40,562 - INFO - Epoch: [435/600], Step: [1/591], Loss: 106800128.0, KL Divergence: 1037.6346435546875, Reconstruction Loss: 106799088.0\n",
      "118it [00:10, 10.72it/s]2023-07-19 18:13:51,504 - INFO - Epoch: [435/600], Step: [119/591], Loss: 235910272.0, KL Divergence: 1013.5706176757812, Reconstruction Loss: 235909264.0\n",
      "236it [00:21, 10.92it/s]2023-07-19 18:14:02,407 - INFO - Epoch: [435/600], Step: [237/591], Loss: 187883024.0, KL Divergence: 1026.300048828125, Reconstruction Loss: 187882000.0\n",
      "354it [00:32, 11.15it/s]2023-07-19 18:14:13,281 - INFO - Epoch: [435/600], Step: [355/591], Loss: 241140160.0, KL Divergence: 1027.3138427734375, Reconstruction Loss: 241139136.0\n",
      "472it [00:43, 10.49it/s]2023-07-19 18:14:24,239 - INFO - Epoch: [435/600], Step: [473/591], Loss: 211845216.0, KL Divergence: 1023.3068237304688, Reconstruction Loss: 211844192.0\n",
      "590it [00:54, 11.24it/s]2023-07-19 18:14:35,125 - INFO - Epoch: [435/600], Step: [591/591], Loss: 160684000.0, KL Divergence: 1030.55224609375, Reconstruction Loss: 160682976.0\n",
      "591it [00:54, 10.81it/s]\n",
      "2023-07-19 18:14:35,128 - INFO - Epoch: [435/600], Total Loss: 13420747023360.0, Total KL Divergence: 77329464.0234375, Total Reconstruction Loss: 13420669690880.0\n",
      "2023-07-19 18:14:35,173 - INFO - Save model at epoch 435\n",
      "0it [00:00, ?it/s]2023-07-19 18:14:35,291 - INFO - Epoch: [436/600], Step: [1/591], Loss: 108889136.0, KL Divergence: 1034.53369140625, Reconstruction Loss: 108888104.0\n",
      "117it [00:10, 11.11it/s]2023-07-19 18:14:46,186 - INFO - Epoch: [436/600], Step: [119/591], Loss: 236498640.0, KL Divergence: 1011.6890869140625, Reconstruction Loss: 236497632.0\n",
      "235it [00:21, 10.82it/s]2023-07-19 18:14:57,189 - INFO - Epoch: [436/600], Step: [237/591], Loss: 191230848.0, KL Divergence: 1030.7657470703125, Reconstruction Loss: 191229824.0\n",
      "353it [00:32, 10.65it/s]2023-07-19 18:15:08,093 - INFO - Epoch: [436/600], Step: [355/591], Loss: 234071328.0, KL Divergence: 1024.312255859375, Reconstruction Loss: 234070304.0\n",
      "471it [00:43, 10.66it/s]2023-07-19 18:15:19,074 - INFO - Epoch: [436/600], Step: [473/591], Loss: 202688896.0, KL Divergence: 1023.58251953125, Reconstruction Loss: 202687872.0\n",
      "589it [00:54, 10.48it/s]2023-07-19 18:15:29,971 - INFO - Epoch: [436/600], Step: [591/591], Loss: 159211344.0, KL Divergence: 1038.5238037109375, Reconstruction Loss: 159210304.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 18:15:29,973 - INFO - Epoch: [436/600], Total Loss: 13362091758592.0, Total KL Divergence: 77418310.5234375, Total Reconstruction Loss: 13362014347264.0\n",
      "2023-07-19 18:15:30,012 - INFO - Save model at epoch 436\n",
      "0it [00:00, ?it/s]2023-07-19 18:15:30,139 - INFO - Epoch: [437/600], Step: [1/591], Loss: 103956552.0, KL Divergence: 1041.9658203125, Reconstruction Loss: 103955512.0\n",
      "117it [00:10, 10.82it/s]2023-07-19 18:15:41,138 - INFO - Epoch: [437/600], Step: [119/591], Loss: 238837792.0, KL Divergence: 1019.147705078125, Reconstruction Loss: 238836768.0\n",
      "235it [00:21, 11.14it/s]2023-07-19 18:15:51,994 - INFO - Epoch: [437/600], Step: [237/591], Loss: 188637008.0, KL Divergence: 1029.50732421875, Reconstruction Loss: 188635984.0\n",
      "353it [00:32, 10.77it/s]2023-07-19 18:16:02,922 - INFO - Epoch: [437/600], Step: [355/591], Loss: 227373968.0, KL Divergence: 1029.8603515625, Reconstruction Loss: 227372944.0\n",
      "471it [00:43, 10.54it/s]2023-07-19 18:16:13,817 - INFO - Epoch: [437/600], Step: [473/591], Loss: 201346624.0, KL Divergence: 1022.2286376953125, Reconstruction Loss: 201345600.0\n",
      "589it [00:54, 10.86it/s]2023-07-19 18:16:24,778 - INFO - Epoch: [437/600], Step: [591/591], Loss: 171552256.0, KL Divergence: 1023.25732421875, Reconstruction Loss: 171551232.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 18:16:24,780 - INFO - Epoch: [437/600], Total Loss: 13255588146176.0, Total KL Divergence: 77390252.125, Total Reconstruction Loss: 13255510743040.0\n",
      "2023-07-19 18:16:24,819 - INFO - Save model at epoch 437\n",
      "0it [00:00, ?it/s]2023-07-19 18:16:24,933 - INFO - Epoch: [438/600], Step: [1/591], Loss: 111079568.0, KL Divergence: 1028.5655517578125, Reconstruction Loss: 111078536.0\n",
      "118it [00:10, 10.60it/s]2023-07-19 18:16:35,851 - INFO - Epoch: [438/600], Step: [119/591], Loss: 236097824.0, KL Divergence: 1018.580322265625, Reconstruction Loss: 236096800.0\n",
      "236it [00:21, 10.84it/s]2023-07-19 18:16:46,832 - INFO - Epoch: [438/600], Step: [237/591], Loss: 186066768.0, KL Divergence: 1030.3974609375, Reconstruction Loss: 186065744.0\n",
      "354it [00:32, 10.50it/s]2023-07-19 18:16:57,784 - INFO - Epoch: [438/600], Step: [355/591], Loss: 226298112.0, KL Divergence: 1020.53466796875, Reconstruction Loss: 226297088.0\n",
      "472it [00:43,  9.94it/s]2023-07-19 18:17:08,615 - INFO - Epoch: [438/600], Step: [473/591], Loss: 201324160.0, KL Divergence: 1024.0084228515625, Reconstruction Loss: 201323136.0\n",
      "590it [00:54, 10.76it/s]2023-07-19 18:17:19,365 - INFO - Epoch: [438/600], Step: [591/591], Loss: 161711648.0, KL Divergence: 1024.973388671875, Reconstruction Loss: 161710624.0\n",
      "591it [00:54, 10.84it/s]\n",
      "2023-07-19 18:17:19,367 - INFO - Epoch: [438/600], Total Loss: 13320835193856.0, Total KL Divergence: 77246584.5625, Total Reconstruction Loss: 13320757957632.0\n",
      "2023-07-19 18:17:19,407 - INFO - Save model at epoch 438\n",
      "0it [00:00, ?it/s]2023-07-19 18:17:19,525 - INFO - Epoch: [439/600], Step: [1/591], Loss: 107726440.0, KL Divergence: 1032.551025390625, Reconstruction Loss: 107725408.0\n",
      "117it [00:10, 10.64it/s]2023-07-19 18:17:30,465 - INFO - Epoch: [439/600], Step: [119/591], Loss: 237083504.0, KL Divergence: 1011.0202026367188, Reconstruction Loss: 237082496.0\n",
      "235it [00:21, 10.84it/s]2023-07-19 18:17:41,544 - INFO - Epoch: [439/600], Step: [237/591], Loss: 191572992.0, KL Divergence: 1034.0284423828125, Reconstruction Loss: 191571952.0\n",
      "353it [00:32, 10.53it/s]2023-07-19 18:17:52,463 - INFO - Epoch: [439/600], Step: [355/591], Loss: 232610912.0, KL Divergence: 1019.0861206054688, Reconstruction Loss: 232609888.0\n",
      "471it [00:43, 10.63it/s]2023-07-19 18:18:03,495 - INFO - Epoch: [439/600], Step: [473/591], Loss: 238325008.0, KL Divergence: 1010.1923828125, Reconstruction Loss: 238324000.0\n",
      "589it [00:54, 10.85it/s]2023-07-19 18:18:14,527 - INFO - Epoch: [439/600], Step: [591/591], Loss: 161758048.0, KL Divergence: 1030.765380859375, Reconstruction Loss: 161757024.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 18:18:14,529 - INFO - Epoch: [439/600], Total Loss: 13574202405888.0, Total KL Divergence: 76829235.578125, Total Reconstruction Loss: 13574125559808.0\n",
      "2023-07-19 18:18:14,573 - INFO - Save model at epoch 439\n",
      "0it [00:00, ?it/s]2023-07-19 18:18:14,702 - INFO - Epoch: [440/600], Step: [1/591], Loss: 109879760.0, KL Divergence: 1035.96337890625, Reconstruction Loss: 109878728.0\n",
      "118it [00:11, 10.59it/s]2023-07-19 18:18:25,720 - INFO - Epoch: [440/600], Step: [119/591], Loss: 250368576.0, KL Divergence: 1016.8036499023438, Reconstruction Loss: 250367552.0\n",
      "236it [00:22, 10.90it/s]2023-07-19 18:18:36,835 - INFO - Epoch: [440/600], Step: [237/591], Loss: 199536768.0, KL Divergence: 1028.852783203125, Reconstruction Loss: 199535744.0\n",
      "354it [00:33, 10.48it/s]2023-07-19 18:18:47,739 - INFO - Epoch: [440/600], Step: [355/591], Loss: 236938272.0, KL Divergence: 1024.913330078125, Reconstruction Loss: 236937248.0\n",
      "472it [00:44, 10.04it/s]2023-07-19 18:18:58,731 - INFO - Epoch: [440/600], Step: [473/591], Loss: 204851136.0, KL Divergence: 1025.168701171875, Reconstruction Loss: 204850112.0\n",
      "590it [00:55, 10.48it/s]2023-07-19 18:19:09,655 - INFO - Epoch: [440/600], Step: [591/591], Loss: 169624128.0, KL Divergence: 1032.572265625, Reconstruction Loss: 169623088.0\n",
      "591it [00:55, 10.73it/s]\n",
      "2023-07-19 18:19:09,657 - INFO - Epoch: [440/600], Total Loss: 13492687621120.0, Total KL Divergence: 77145499.7890625, Total Reconstruction Loss: 13492610475008.0\n",
      "2023-07-19 18:19:09,697 - INFO - Save model at epoch 440\n",
      "0it [00:00, ?it/s]2023-07-19 18:19:09,804 - INFO - Epoch: [441/600], Step: [1/591], Loss: 108498272.0, KL Divergence: 1037.33251953125, Reconstruction Loss: 108497232.0\n",
      "118it [00:10, 10.85it/s]2023-07-19 18:19:20,749 - INFO - Epoch: [441/600], Step: [119/591], Loss: 233200304.0, KL Divergence: 1010.8325805664062, Reconstruction Loss: 233199296.0\n",
      "236it [00:21, 10.76it/s]2023-07-19 18:19:31,700 - INFO - Epoch: [441/600], Step: [237/591], Loss: 186066848.0, KL Divergence: 1019.6429443359375, Reconstruction Loss: 186065824.0\n",
      "354it [00:32, 10.95it/s]2023-07-19 18:19:42,572 - INFO - Epoch: [441/600], Step: [355/591], Loss: 229511760.0, KL Divergence: 1021.4611206054688, Reconstruction Loss: 229510736.0\n",
      "472it [00:43,  9.27it/s]2023-07-19 18:19:53,620 - INFO - Epoch: [441/600], Step: [473/591], Loss: 206510256.0, KL Divergence: 1013.8983154296875, Reconstruction Loss: 206509248.0\n",
      "589it [00:54, 10.47it/s]2023-07-19 18:20:04,437 - INFO - Epoch: [441/600], Step: [591/591], Loss: 168869056.0, KL Divergence: 1016.134765625, Reconstruction Loss: 168868032.0\n",
      "591it [00:54, 10.80it/s]\n",
      "2023-07-19 18:20:04,439 - INFO - Epoch: [441/600], Total Loss: 13463178943488.0, Total KL Divergence: 76884804.75, Total Reconstruction Loss: 13463102051328.0\n",
      "2023-07-19 18:20:04,478 - INFO - Save model at epoch 441\n",
      "0it [00:00, ?it/s]2023-07-19 18:20:04,601 - INFO - Epoch: [442/600], Step: [1/591], Loss: 106611680.0, KL Divergence: 1023.6909790039062, Reconstruction Loss: 106610656.0\n",
      "117it [00:10, 10.75it/s]2023-07-19 18:20:15,576 - INFO - Epoch: [442/600], Step: [119/591], Loss: 228844784.0, KL Divergence: 1006.5032348632812, Reconstruction Loss: 228843776.0\n",
      "235it [00:21, 10.71it/s]2023-07-19 18:20:26,475 - INFO - Epoch: [442/600], Step: [237/591], Loss: 192046560.0, KL Divergence: 1020.4852294921875, Reconstruction Loss: 192045536.0\n",
      "353it [00:32, 10.56it/s]2023-07-19 18:20:37,506 - INFO - Epoch: [442/600], Step: [355/591], Loss: 230971824.0, KL Divergence: 1014.5968017578125, Reconstruction Loss: 230970816.0\n",
      "471it [00:43, 10.97it/s]2023-07-19 18:20:48,383 - INFO - Epoch: [442/600], Step: [473/591], Loss: 201114560.0, KL Divergence: 1008.6214599609375, Reconstruction Loss: 201113552.0\n",
      "589it [00:54, 10.57it/s]2023-07-19 18:20:59,374 - INFO - Epoch: [442/600], Step: [591/591], Loss: 169761216.0, KL Divergence: 1016.4888916015625, Reconstruction Loss: 169760192.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 18:20:59,376 - INFO - Epoch: [442/600], Total Loss: 13340160150528.0, Total KL Divergence: 76648356.3515625, Total Reconstruction Loss: 13340083501056.0\n",
      "2023-07-19 18:20:59,418 - INFO - Save model at epoch 442\n",
      "0it [00:00, ?it/s]2023-07-19 18:20:59,523 - INFO - Epoch: [443/600], Step: [1/591], Loss: 101742560.0, KL Divergence: 1023.1007690429688, Reconstruction Loss: 101741536.0\n",
      "118it [00:10, 10.67it/s]2023-07-19 18:21:10,517 - INFO - Epoch: [443/600], Step: [119/591], Loss: 231852816.0, KL Divergence: 1006.2540283203125, Reconstruction Loss: 231851808.0\n",
      "236it [00:22, 10.77it/s]2023-07-19 18:21:21,591 - INFO - Epoch: [443/600], Step: [237/591], Loss: 189400000.0, KL Divergence: 1017.6947631835938, Reconstruction Loss: 189398976.0\n",
      "354it [00:32, 10.72it/s]2023-07-19 18:21:32,521 - INFO - Epoch: [443/600], Step: [355/591], Loss: 233229920.0, KL Divergence: 1014.7567138671875, Reconstruction Loss: 233228912.0\n",
      "472it [00:43, 10.59it/s]2023-07-19 18:21:43,441 - INFO - Epoch: [443/600], Step: [473/591], Loss: 204710320.0, KL Divergence: 1010.666259765625, Reconstruction Loss: 204709312.0\n",
      "590it [00:54, 10.86it/s]2023-07-19 18:21:54,425 - INFO - Epoch: [443/600], Step: [591/591], Loss: 168300400.0, KL Divergence: 1015.4953002929688, Reconstruction Loss: 168299392.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 18:21:54,426 - INFO - Epoch: [443/600], Total Loss: 13158956344320.0, Total KL Divergence: 76539864.03125, Total Reconstruction Loss: 13158879796224.0\n",
      "2023-07-19 18:21:54,477 - INFO - Save model at epoch 443\n",
      "0it [00:00, ?it/s]2023-07-19 18:21:54,592 - INFO - Epoch: [444/600], Step: [1/591], Loss: 103629728.0, KL Divergence: 1022.4432373046875, Reconstruction Loss: 103628704.0\n",
      "117it [00:10, 10.81it/s]2023-07-19 18:22:05,567 - INFO - Epoch: [444/600], Step: [119/591], Loss: 230579728.0, KL Divergence: 1005.226806640625, Reconstruction Loss: 230578720.0\n",
      "235it [00:21, 10.97it/s]2023-07-19 18:22:16,560 - INFO - Epoch: [444/600], Step: [237/591], Loss: 189111328.0, KL Divergence: 1021.738037109375, Reconstruction Loss: 189110304.0\n",
      "353it [00:32, 10.65it/s]2023-07-19 18:22:27,484 - INFO - Epoch: [444/600], Step: [355/591], Loss: 231745312.0, KL Divergence: 1016.0176391601562, Reconstruction Loss: 231744288.0\n",
      "471it [00:43, 10.76it/s]2023-07-19 18:22:38,396 - INFO - Epoch: [444/600], Step: [473/591], Loss: 198784736.0, KL Divergence: 1010.094482421875, Reconstruction Loss: 198783728.0\n",
      "589it [00:54, 10.95it/s]2023-07-19 18:22:49,190 - INFO - Epoch: [444/600], Step: [591/591], Loss: 160205264.0, KL Divergence: 1009.6478271484375, Reconstruction Loss: 160204256.0\n",
      "591it [00:54, 10.80it/s]\n",
      "2023-07-19 18:22:49,192 - INFO - Epoch: [444/600], Total Loss: 13146919905280.0, Total KL Divergence: 76413829.5234375, Total Reconstruction Loss: 13146843467776.0\n",
      "2023-07-19 18:22:49,234 - INFO - Save model at epoch 444\n",
      "0it [00:00, ?it/s]2023-07-19 18:22:49,342 - INFO - Epoch: [445/600], Step: [1/591], Loss: 103826520.0, KL Divergence: 1015.5269775390625, Reconstruction Loss: 103825504.0\n",
      "118it [00:10, 10.92it/s]2023-07-19 18:23:00,262 - INFO - Epoch: [445/600], Step: [119/591], Loss: 231391184.0, KL Divergence: 1000.4168701171875, Reconstruction Loss: 231390176.0\n",
      "236it [00:21, 10.53it/s]2023-07-19 18:23:11,260 - INFO - Epoch: [445/600], Step: [237/591], Loss: 184540752.0, KL Divergence: 1024.322509765625, Reconstruction Loss: 184539728.0\n",
      "354it [00:32, 11.12it/s]2023-07-19 18:23:22,171 - INFO - Epoch: [445/600], Step: [355/591], Loss: 229118656.0, KL Divergence: 1016.6773071289062, Reconstruction Loss: 229117632.0\n",
      "472it [00:43, 10.63it/s]2023-07-19 18:23:33,096 - INFO - Epoch: [445/600], Step: [473/591], Loss: 203202560.0, KL Divergence: 1018.91357421875, Reconstruction Loss: 203201536.0\n",
      "590it [00:54, 10.76it/s]2023-07-19 18:23:44,011 - INFO - Epoch: [445/600], Step: [591/591], Loss: 172689488.0, KL Divergence: 1008.7547607421875, Reconstruction Loss: 172688480.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 18:23:44,013 - INFO - Epoch: [445/600], Total Loss: 13186533754880.0, Total KL Divergence: 76413098.9765625, Total Reconstruction Loss: 13186457334784.0\n",
      "2023-07-19 18:23:44,057 - INFO - Save model at epoch 445\n",
      "0it [00:00, ?it/s]2023-07-19 18:23:44,184 - INFO - Epoch: [446/600], Step: [1/591], Loss: 110804248.0, KL Divergence: 1018.3853759765625, Reconstruction Loss: 110803232.0\n",
      "118it [00:10, 10.69it/s]2023-07-19 18:23:55,143 - INFO - Epoch: [446/600], Step: [119/591], Loss: 231089776.0, KL Divergence: 1000.1602783203125, Reconstruction Loss: 231088768.0\n",
      "236it [00:21, 11.11it/s]2023-07-19 18:24:06,044 - INFO - Epoch: [446/600], Step: [237/591], Loss: 186822688.0, KL Divergence: 1023.255615234375, Reconstruction Loss: 186821664.0\n",
      "354it [00:32, 10.62it/s]2023-07-19 18:24:16,988 - INFO - Epoch: [446/600], Step: [355/591], Loss: 226821792.0, KL Divergence: 1020.8922729492188, Reconstruction Loss: 226820768.0\n",
      "472it [00:43, 10.96it/s]2023-07-19 18:24:27,893 - INFO - Epoch: [446/600], Step: [473/591], Loss: 196996592.0, KL Divergence: 1019.0446166992188, Reconstruction Loss: 196995568.0\n",
      "590it [00:54, 10.45it/s]2023-07-19 18:24:38,898 - INFO - Epoch: [446/600], Step: [591/591], Loss: 160908976.0, KL Divergence: 1014.8678588867188, Reconstruction Loss: 160907968.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 18:24:38,899 - INFO - Epoch: [446/600], Total Loss: 13128991737856.0, Total KL Divergence: 76717034.2734375, Total Reconstruction Loss: 13128915025920.0\n",
      "2023-07-19 18:24:38,950 - INFO - Save model at epoch 446\n",
      "0it [00:00, ?it/s]2023-07-19 18:24:39,055 - INFO - Epoch: [447/600], Step: [1/591], Loss: 110510984.0, KL Divergence: 1025.1292724609375, Reconstruction Loss: 110509960.0\n",
      "118it [00:10, 11.16it/s]2023-07-19 18:24:49,936 - INFO - Epoch: [447/600], Step: [119/591], Loss: 229504336.0, KL Divergence: 1011.5704345703125, Reconstruction Loss: 229503328.0\n",
      "236it [00:21, 10.82it/s]2023-07-19 18:25:01,045 - INFO - Epoch: [447/600], Step: [237/591], Loss: 180502512.0, KL Divergence: 1021.8703002929688, Reconstruction Loss: 180501488.0\n",
      "354it [00:32, 10.66it/s]2023-07-19 18:25:11,917 - INFO - Epoch: [447/600], Step: [355/591], Loss: 228769952.0, KL Divergence: 1026.6116943359375, Reconstruction Loss: 228768928.0\n",
      "472it [00:43, 10.68it/s]2023-07-19 18:25:22,796 - INFO - Epoch: [447/600], Step: [473/591], Loss: 211002256.0, KL Divergence: 1025.5093994140625, Reconstruction Loss: 211001232.0\n",
      "590it [00:54, 10.47it/s]2023-07-19 18:25:33,758 - INFO - Epoch: [447/600], Step: [591/591], Loss: 157764272.0, KL Divergence: 1021.4479370117188, Reconstruction Loss: 157763248.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 18:25:33,760 - INFO - Epoch: [447/600], Total Loss: 13075524724736.0, Total KL Divergence: 77032823.7421875, Total Reconstruction Loss: 13075447706624.0\n",
      "2023-07-19 18:25:33,798 - INFO - Save model at epoch 447\n",
      "0it [00:00, ?it/s]2023-07-19 18:25:33,903 - INFO - Epoch: [448/600], Step: [1/591], Loss: 107549904.0, KL Divergence: 1032.6141357421875, Reconstruction Loss: 107548872.0\n",
      "118it [00:11, 10.94it/s]2023-07-19 18:25:44,904 - INFO - Epoch: [448/600], Step: [119/591], Loss: 228756416.0, KL Divergence: 1014.6561279296875, Reconstruction Loss: 228755408.0\n",
      "236it [00:21, 10.46it/s]2023-07-19 18:25:55,891 - INFO - Epoch: [448/600], Step: [237/591], Loss: 185685632.0, KL Divergence: 1022.87890625, Reconstruction Loss: 185684608.0\n",
      "354it [00:33, 10.64it/s]2023-07-19 18:26:06,919 - INFO - Epoch: [448/600], Step: [355/591], Loss: 232031008.0, KL Divergence: 1023.1199340820312, Reconstruction Loss: 232029984.0\n",
      "472it [00:43, 10.74it/s]2023-07-19 18:26:17,896 - INFO - Epoch: [448/600], Step: [473/591], Loss: 210428736.0, KL Divergence: 1024.8883056640625, Reconstruction Loss: 210427712.0\n",
      "590it [00:54, 10.75it/s]2023-07-19 18:26:28,847 - INFO - Epoch: [448/600], Step: [591/591], Loss: 157436384.0, KL Divergence: 1013.8245849609375, Reconstruction Loss: 157435376.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 18:26:28,849 - INFO - Epoch: [448/600], Total Loss: 13077610555392.0, Total KL Divergence: 77031050.921875, Total Reconstruction Loss: 13077533540352.0\n",
      "2023-07-19 18:26:28,894 - INFO - Save model at epoch 448\n",
      "0it [00:00, ?it/s]2023-07-19 18:26:29,008 - INFO - Epoch: [449/600], Step: [1/591], Loss: 117689400.0, KL Divergence: 1024.16552734375, Reconstruction Loss: 117688376.0\n",
      "117it [00:10, 10.62it/s]2023-07-19 18:26:39,944 - INFO - Epoch: [449/600], Step: [119/591], Loss: 232102432.0, KL Divergence: 1007.8530883789062, Reconstruction Loss: 232101424.0\n",
      "235it [00:21, 11.05it/s]2023-07-19 18:26:50,921 - INFO - Epoch: [449/600], Step: [237/591], Loss: 181088656.0, KL Divergence: 1023.9605712890625, Reconstruction Loss: 181087632.0\n",
      "353it [00:32, 11.00it/s]2023-07-19 18:27:01,805 - INFO - Epoch: [449/600], Step: [355/591], Loss: 245486944.0, KL Divergence: 1018.6002197265625, Reconstruction Loss: 245485920.0\n",
      "471it [00:43, 11.00it/s]2023-07-19 18:27:12,762 - INFO - Epoch: [449/600], Step: [473/591], Loss: 203557152.0, KL Divergence: 1016.9437866210938, Reconstruction Loss: 203556128.0\n",
      "589it [00:54, 10.99it/s]2023-07-19 18:27:23,672 - INFO - Epoch: [449/600], Step: [591/591], Loss: 155735744.0, KL Divergence: 1025.702392578125, Reconstruction Loss: 155734720.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 18:27:23,673 - INFO - Epoch: [449/600], Total Loss: 13184141589504.0, Total KL Divergence: 76749763.1953125, Total Reconstruction Loss: 13184064843776.0\n",
      "2023-07-19 18:27:23,720 - INFO - Save model at epoch 449\n",
      "0it [00:00, ?it/s]2023-07-19 18:27:23,830 - INFO - Epoch: [450/600], Step: [1/591], Loss: 128182312.0, KL Divergence: 1033.8994140625, Reconstruction Loss: 128181280.0\n",
      "117it [00:10, 11.06it/s]2023-07-19 18:27:34,811 - INFO - Epoch: [450/600], Step: [119/591], Loss: 234610640.0, KL Divergence: 1008.3052368164062, Reconstruction Loss: 234609632.0\n",
      "235it [00:21, 10.81it/s]2023-07-19 18:27:45,808 - INFO - Epoch: [450/600], Step: [237/591], Loss: 184533120.0, KL Divergence: 1025.21826171875, Reconstruction Loss: 184532096.0\n",
      "353it [00:32, 10.81it/s]2023-07-19 18:27:56,779 - INFO - Epoch: [450/600], Step: [355/591], Loss: 231808960.0, KL Divergence: 1011.66064453125, Reconstruction Loss: 231807952.0\n",
      "471it [00:43, 10.85it/s]2023-07-19 18:28:07,721 - INFO - Epoch: [450/600], Step: [473/591], Loss: 198443904.0, KL Divergence: 1018.3873291015625, Reconstruction Loss: 198442880.0\n",
      "589it [00:54, 10.76it/s]2023-07-19 18:28:18,701 - INFO - Epoch: [450/600], Step: [591/591], Loss: 164891392.0, KL Divergence: 1031.767578125, Reconstruction Loss: 164890368.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 18:28:18,703 - INFO - Epoch: [450/600], Total Loss: 13327977994240.0, Total KL Divergence: 76842198.5078125, Total Reconstruction Loss: 13327901155328.0\n",
      "2023-07-19 18:28:18,745 - INFO - Save model at epoch 450\n",
      "0it [00:00, ?it/s]2023-07-19 18:28:18,853 - INFO - Epoch: [451/600], Step: [1/591], Loss: 128173528.0, KL Divergence: 1038.720458984375, Reconstruction Loss: 128172488.0\n",
      "118it [00:11, 10.95it/s]2023-07-19 18:28:29,872 - INFO - Epoch: [451/600], Step: [119/591], Loss: 227474912.0, KL Divergence: 1010.306640625, Reconstruction Loss: 227473904.0\n",
      "236it [00:21, 10.70it/s]2023-07-19 18:28:40,863 - INFO - Epoch: [451/600], Step: [237/591], Loss: 183633792.0, KL Divergence: 1029.53759765625, Reconstruction Loss: 183632768.0\n",
      "354it [00:32, 10.98it/s]2023-07-19 18:28:51,756 - INFO - Epoch: [451/600], Step: [355/591], Loss: 246653632.0, KL Divergence: 1018.340576171875, Reconstruction Loss: 246652608.0\n",
      "472it [00:43, 10.76it/s]2023-07-19 18:29:02,737 - INFO - Epoch: [451/600], Step: [473/591], Loss: 210302208.0, KL Divergence: 1016.1732177734375, Reconstruction Loss: 210301184.0\n",
      "590it [00:54, 10.76it/s]2023-07-19 18:29:13,725 - INFO - Epoch: [451/600], Step: [591/591], Loss: 164279984.0, KL Divergence: 1025.57421875, Reconstruction Loss: 164278960.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 18:29:13,727 - INFO - Epoch: [451/600], Total Loss: 13371784829952.0, Total KL Divergence: 76900399.046875, Total Reconstruction Loss: 13371707953152.0\n",
      "2023-07-19 18:29:13,773 - INFO - Save model at epoch 451\n",
      "0it [00:00, ?it/s]2023-07-19 18:29:13,881 - INFO - Epoch: [452/600], Step: [1/591], Loss: 115520536.0, KL Divergence: 1032.7073974609375, Reconstruction Loss: 115519504.0\n",
      "118it [00:10, 11.04it/s]2023-07-19 18:29:24,770 - INFO - Epoch: [452/600], Step: [119/591], Loss: 227644416.0, KL Divergence: 1016.2482299804688, Reconstruction Loss: 227643392.0\n",
      "236it [00:21, 10.85it/s]2023-07-19 18:29:35,847 - INFO - Epoch: [452/600], Step: [237/591], Loss: 185546560.0, KL Divergence: 1026.44775390625, Reconstruction Loss: 185545536.0\n",
      "354it [00:32, 10.92it/s]2023-07-19 18:29:46,707 - INFO - Epoch: [452/600], Step: [355/591], Loss: 229963200.0, KL Divergence: 1028.29345703125, Reconstruction Loss: 229962176.0\n",
      "472it [00:43, 10.86it/s]2023-07-19 18:29:57,673 - INFO - Epoch: [452/600], Step: [473/591], Loss: 212836512.0, KL Divergence: 1023.2750244140625, Reconstruction Loss: 212835488.0\n",
      "590it [00:54, 10.53it/s]2023-07-19 18:30:08,714 - INFO - Epoch: [452/600], Step: [591/591], Loss: 166912384.0, KL Divergence: 1030.474365234375, Reconstruction Loss: 166911360.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 18:30:08,715 - INFO - Epoch: [452/600], Total Loss: 13169254681600.0, Total KL Divergence: 77242538.6171875, Total Reconstruction Loss: 13169177433088.0\n",
      "2023-07-19 18:30:08,762 - INFO - Save model at epoch 452\n",
      "0it [00:00, ?it/s]2023-07-19 18:30:08,862 - INFO - Epoch: [453/600], Step: [1/591], Loss: 100543480.0, KL Divergence: 1035.4483642578125, Reconstruction Loss: 100542448.0\n",
      "118it [00:10, 10.89it/s]2023-07-19 18:30:19,815 - INFO - Epoch: [453/600], Step: [119/591], Loss: 225539840.0, KL Divergence: 1022.3601684570312, Reconstruction Loss: 225538816.0\n",
      "236it [00:21, 10.66it/s]2023-07-19 18:30:30,784 - INFO - Epoch: [453/600], Step: [237/591], Loss: 189323680.0, KL Divergence: 1030.7540283203125, Reconstruction Loss: 189322656.0\n",
      "354it [00:32, 11.10it/s]2023-07-19 18:30:41,774 - INFO - Epoch: [453/600], Step: [355/591], Loss: 235541376.0, KL Divergence: 1027.0758056640625, Reconstruction Loss: 235540352.0\n",
      "472it [00:43, 10.37it/s]2023-07-19 18:30:52,829 - INFO - Epoch: [453/600], Step: [473/591], Loss: 219513408.0, KL Divergence: 1021.3162841796875, Reconstruction Loss: 219512384.0\n",
      "590it [00:54, 10.80it/s]2023-07-19 18:31:03,821 - INFO - Epoch: [453/600], Step: [591/591], Loss: 158449488.0, KL Divergence: 1023.648681640625, Reconstruction Loss: 158448464.0\n",
      "591it [00:55, 10.73it/s]\n",
      "2023-07-19 18:31:03,823 - INFO - Epoch: [453/600], Total Loss: 13095391669248.0, Total KL Divergence: 77556910.984375, Total Reconstruction Loss: 13095314108416.0\n",
      "2023-07-19 18:31:03,864 - INFO - Save model at epoch 453\n",
      "0it [00:00, ?it/s]2023-07-19 18:31:03,986 - INFO - Epoch: [454/600], Step: [1/591], Loss: 102551480.0, KL Divergence: 1033.89990234375, Reconstruction Loss: 102550448.0\n",
      "117it [00:10, 11.09it/s]2023-07-19 18:31:14,970 - INFO - Epoch: [454/600], Step: [119/591], Loss: 232763600.0, KL Divergence: 1011.2755126953125, Reconstruction Loss: 232762592.0\n",
      "235it [00:21, 10.56it/s]2023-07-19 18:31:26,040 - INFO - Epoch: [454/600], Step: [237/591], Loss: 181760992.0, KL Divergence: 1033.84716796875, Reconstruction Loss: 181759952.0\n",
      "353it [00:32, 10.73it/s]2023-07-19 18:31:36,917 - INFO - Epoch: [454/600], Step: [355/591], Loss: 225335200.0, KL Divergence: 1022.1856689453125, Reconstruction Loss: 225334176.0\n",
      "471it [00:43, 10.98it/s]2023-07-19 18:31:47,824 - INFO - Epoch: [454/600], Step: [473/591], Loss: 200947600.0, KL Divergence: 1028.9556884765625, Reconstruction Loss: 200946576.0\n",
      "589it [00:54, 10.92it/s]2023-07-19 18:31:58,706 - INFO - Epoch: [454/600], Step: [591/591], Loss: 157263456.0, KL Divergence: 1027.5556640625, Reconstruction Loss: 157262432.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 18:31:58,708 - INFO - Epoch: [454/600], Total Loss: 13129961956352.0, Total KL Divergence: 77192997.6796875, Total Reconstruction Loss: 13129884783616.0\n",
      "2023-07-19 18:31:58,746 - INFO - Save model at epoch 454\n",
      "0it [00:00, ?it/s]2023-07-19 18:31:58,854 - INFO - Epoch: [455/600], Step: [1/591], Loss: 106840904.0, KL Divergence: 1035.8304443359375, Reconstruction Loss: 106839872.0\n",
      "118it [00:10, 10.78it/s]2023-07-19 18:32:09,764 - INFO - Epoch: [455/600], Step: [119/591], Loss: 233005968.0, KL Divergence: 1019.1360473632812, Reconstruction Loss: 233004944.0\n",
      "236it [00:21, 10.94it/s]2023-07-19 18:32:20,781 - INFO - Epoch: [455/600], Step: [237/591], Loss: 184555552.0, KL Divergence: 1038.06884765625, Reconstruction Loss: 184554512.0\n",
      "354it [00:32, 10.73it/s]2023-07-19 18:32:31,737 - INFO - Epoch: [455/600], Step: [355/591], Loss: 232732816.0, KL Divergence: 1031.5516357421875, Reconstruction Loss: 232731792.0\n",
      "472it [00:43, 10.97it/s]2023-07-19 18:32:42,747 - INFO - Epoch: [455/600], Step: [473/591], Loss: 201465712.0, KL Divergence: 1032.140380859375, Reconstruction Loss: 201464672.0\n",
      "590it [00:54, 10.94it/s]2023-07-19 18:32:53,624 - INFO - Epoch: [455/600], Step: [591/591], Loss: 160520272.0, KL Divergence: 1035.834228515625, Reconstruction Loss: 160519232.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 18:32:53,625 - INFO - Epoch: [455/600], Total Loss: 13079554855936.0, Total KL Divergence: 77597770.34375, Total Reconstruction Loss: 13079477244928.0\n",
      "2023-07-19 18:32:53,665 - INFO - Save model at epoch 455\n",
      "0it [00:00, ?it/s]2023-07-19 18:32:53,773 - INFO - Epoch: [456/600], Step: [1/591], Loss: 107482392.0, KL Divergence: 1044.8309326171875, Reconstruction Loss: 107481344.0\n",
      "118it [00:10, 10.99it/s]2023-07-19 18:33:04,728 - INFO - Epoch: [456/600], Step: [119/591], Loss: 233453856.0, KL Divergence: 1025.1729736328125, Reconstruction Loss: 233452832.0\n",
      "236it [00:21, 10.90it/s]2023-07-19 18:33:15,721 - INFO - Epoch: [456/600], Step: [237/591], Loss: 187203888.0, KL Divergence: 1044.8931884765625, Reconstruction Loss: 187202848.0\n",
      "354it [00:32, 10.66it/s]2023-07-19 18:33:26,670 - INFO - Epoch: [456/600], Step: [355/591], Loss: 262472976.0, KL Divergence: 1032.42529296875, Reconstruction Loss: 262471936.0\n",
      "472it [00:43, 10.57it/s]2023-07-19 18:33:37,614 - INFO - Epoch: [456/600], Step: [473/591], Loss: 194842288.0, KL Divergence: 1036.43798828125, Reconstruction Loss: 194841248.0\n",
      "590it [00:54, 10.97it/s]2023-07-19 18:33:48,509 - INFO - Epoch: [456/600], Step: [591/591], Loss: 168160176.0, KL Divergence: 1033.4755859375, Reconstruction Loss: 168159136.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 18:33:48,511 - INFO - Epoch: [456/600], Total Loss: 13149642724352.0, Total KL Divergence: 77942959.9765625, Total Reconstruction Loss: 13149564793856.0\n",
      "2023-07-19 18:33:48,553 - INFO - Save model at epoch 456\n",
      "0it [00:00, ?it/s]2023-07-19 18:33:48,662 - INFO - Epoch: [457/600], Step: [1/591], Loss: 104909232.0, KL Divergence: 1043.867431640625, Reconstruction Loss: 104908192.0\n",
      "118it [00:10, 11.05it/s]2023-07-19 18:33:59,583 - INFO - Epoch: [457/600], Step: [119/591], Loss: 235498432.0, KL Divergence: 1021.947265625, Reconstruction Loss: 235497408.0\n",
      "236it [00:21, 11.05it/s]2023-07-19 18:34:10,477 - INFO - Epoch: [457/600], Step: [237/591], Loss: 185544080.0, KL Divergence: 1042.694580078125, Reconstruction Loss: 185543040.0\n",
      "354it [00:32, 10.81it/s]2023-07-19 18:34:21,442 - INFO - Epoch: [457/600], Step: [355/591], Loss: 230026080.0, KL Divergence: 1025.02783203125, Reconstruction Loss: 230025056.0\n",
      "472it [00:43, 10.91it/s]2023-07-19 18:34:32,401 - INFO - Epoch: [457/600], Step: [473/591], Loss: 197928880.0, KL Divergence: 1032.6253662109375, Reconstruction Loss: 197927840.0\n",
      "590it [00:54, 11.01it/s]2023-07-19 18:34:43,332 - INFO - Epoch: [457/600], Step: [591/591], Loss: 158842544.0, KL Divergence: 1033.887451171875, Reconstruction Loss: 158841504.0\n",
      "591it [00:54, 10.79it/s]\n",
      "2023-07-19 18:34:43,334 - INFO - Epoch: [457/600], Total Loss: 13246332870656.0, Total KL Divergence: 77685869.8671875, Total Reconstruction Loss: 13246255183872.0\n",
      "2023-07-19 18:34:43,393 - INFO - Save model at epoch 457\n",
      "0it [00:00, ?it/s]2023-07-19 18:34:43,488 - INFO - Epoch: [458/600], Step: [1/591], Loss: 106685208.0, KL Divergence: 1044.3338623046875, Reconstruction Loss: 106684160.0\n",
      "118it [00:10, 11.02it/s]2023-07-19 18:34:54,378 - INFO - Epoch: [458/600], Step: [119/591], Loss: 245585072.0, KL Divergence: 1025.419677734375, Reconstruction Loss: 245584048.0\n",
      "236it [00:21, 10.61it/s]2023-07-19 18:35:05,389 - INFO - Epoch: [458/600], Step: [237/591], Loss: 190605360.0, KL Divergence: 1042.965087890625, Reconstruction Loss: 190604320.0\n",
      "354it [00:32, 10.52it/s]2023-07-19 18:35:16,291 - INFO - Epoch: [458/600], Step: [355/591], Loss: 227363696.0, KL Divergence: 1035.242919921875, Reconstruction Loss: 227362656.0\n",
      "472it [00:43, 10.80it/s]2023-07-19 18:35:27,129 - INFO - Epoch: [458/600], Step: [473/591], Loss: 199342192.0, KL Divergence: 1037.3095703125, Reconstruction Loss: 199341152.0\n",
      "590it [00:54, 10.90it/s]2023-07-19 18:35:37,970 - INFO - Epoch: [458/600], Step: [591/591], Loss: 173470816.0, KL Divergence: 1035.68505859375, Reconstruction Loss: 173469776.0\n",
      "591it [00:54, 10.83it/s]\n",
      "2023-07-19 18:35:37,971 - INFO - Epoch: [458/600], Total Loss: 13174325712896.0, Total KL Divergence: 78206834.234375, Total Reconstruction Loss: 13174247542784.0\n",
      "2023-07-19 18:35:38,028 - INFO - Save model at epoch 458\n",
      "0it [00:00, ?it/s]2023-07-19 18:35:38,126 - INFO - Epoch: [459/600], Step: [1/591], Loss: 103176480.0, KL Divergence: 1045.64453125, Reconstruction Loss: 103175432.0\n",
      "118it [00:10, 10.90it/s]2023-07-19 18:35:49,070 - INFO - Epoch: [459/600], Step: [119/591], Loss: 234173184.0, KL Divergence: 1033.40283203125, Reconstruction Loss: 234172144.0\n",
      "236it [00:21, 10.49it/s]2023-07-19 18:36:00,128 - INFO - Epoch: [459/600], Step: [237/591], Loss: 186576928.0, KL Divergence: 1049.6717529296875, Reconstruction Loss: 186575872.0\n",
      "354it [00:32, 10.90it/s]2023-07-19 18:36:11,128 - INFO - Epoch: [459/600], Step: [355/591], Loss: 228363920.0, KL Divergence: 1045.091796875, Reconstruction Loss: 228362880.0\n",
      "472it [00:43, 10.98it/s]2023-07-19 18:36:21,934 - INFO - Epoch: [459/600], Step: [473/591], Loss: 196437376.0, KL Divergence: 1048.2637939453125, Reconstruction Loss: 196436320.0\n",
      "590it [00:54, 10.97it/s]2023-07-19 18:36:32,937 - INFO - Epoch: [459/600], Step: [591/591], Loss: 164406800.0, KL Divergence: 1045.225830078125, Reconstruction Loss: 164405760.0\n",
      "591it [00:54, 10.76it/s]\n",
      "2023-07-19 18:36:32,939 - INFO - Epoch: [459/600], Total Loss: 13171091270656.0, Total KL Divergence: 78793274.953125, Total Reconstruction Loss: 13171012442112.0\n",
      "2023-07-19 18:36:32,984 - INFO - Save model at epoch 459\n",
      "0it [00:00, ?it/s]2023-07-19 18:36:33,094 - INFO - Epoch: [460/600], Step: [1/591], Loss: 104326552.0, KL Divergence: 1056.252197265625, Reconstruction Loss: 104325496.0\n",
      "118it [00:10, 10.93it/s]2023-07-19 18:36:44,034 - INFO - Epoch: [460/600], Step: [119/591], Loss: 229389872.0, KL Divergence: 1043.350341796875, Reconstruction Loss: 229388832.0\n",
      "236it [00:21, 10.75it/s]2023-07-19 18:36:54,984 - INFO - Epoch: [460/600], Step: [237/591], Loss: 195758048.0, KL Divergence: 1057.997314453125, Reconstruction Loss: 195756992.0\n",
      "354it [00:32, 10.67it/s]2023-07-19 18:37:05,957 - INFO - Epoch: [460/600], Step: [355/591], Loss: 236266240.0, KL Divergence: 1057.3992919921875, Reconstruction Loss: 236265184.0\n",
      "472it [00:43, 10.94it/s]2023-07-19 18:37:16,911 - INFO - Epoch: [460/600], Step: [473/591], Loss: 192870240.0, KL Divergence: 1054.0048828125, Reconstruction Loss: 192869184.0\n",
      "590it [00:54, 10.73it/s]2023-07-19 18:37:27,864 - INFO - Epoch: [460/600], Step: [591/591], Loss: 166546288.0, KL Divergence: 1048.027587890625, Reconstruction Loss: 166545232.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 18:37:27,866 - INFO - Epoch: [460/600], Total Loss: 13297093443584.0, Total KL Divergence: 79449859.328125, Total Reconstruction Loss: 13297014020096.0\n",
      "2023-07-19 18:37:27,907 - INFO - Save model at epoch 460\n",
      "0it [00:00, ?it/s]2023-07-19 18:37:28,017 - INFO - Epoch: [461/600], Step: [1/591], Loss: 106253024.0, KL Divergence: 1058.357177734375, Reconstruction Loss: 106251968.0\n",
      "117it [00:10, 10.41it/s]2023-07-19 18:37:38,966 - INFO - Epoch: [461/600], Step: [119/591], Loss: 225769600.0, KL Divergence: 1042.572998046875, Reconstruction Loss: 225768560.0\n",
      "235it [00:21, 10.79it/s]2023-07-19 18:37:49,964 - INFO - Epoch: [461/600], Step: [237/591], Loss: 184976512.0, KL Divergence: 1063.67626953125, Reconstruction Loss: 184975456.0\n",
      "353it [00:32, 11.07it/s]2023-07-19 18:38:00,825 - INFO - Epoch: [461/600], Step: [355/591], Loss: 227669184.0, KL Divergence: 1051.430908203125, Reconstruction Loss: 227668128.0\n",
      "471it [00:43, 10.75it/s]2023-07-19 18:38:11,806 - INFO - Epoch: [461/600], Step: [473/591], Loss: 195892224.0, KL Divergence: 1050.846435546875, Reconstruction Loss: 195891168.0\n",
      "589it [00:54, 10.88it/s]2023-07-19 18:38:22,863 - INFO - Epoch: [461/600], Step: [591/591], Loss: 166482608.0, KL Divergence: 1044.8779296875, Reconstruction Loss: 166481568.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 18:38:22,865 - INFO - Epoch: [461/600], Total Loss: 13040150718464.0, Total KL Divergence: 79277901.578125, Total Reconstruction Loss: 13040071426048.0\n",
      "2023-07-19 18:38:22,903 - INFO - Save model at epoch 461\n",
      "0it [00:00, ?it/s]2023-07-19 18:38:23,008 - INFO - Epoch: [462/600], Step: [1/591], Loss: 99962024.0, KL Divergence: 1055.6343994140625, Reconstruction Loss: 99960968.0\n",
      "117it [00:10, 10.80it/s]2023-07-19 18:38:33,958 - INFO - Epoch: [462/600], Step: [119/591], Loss: 223833168.0, KL Divergence: 1032.0244140625, Reconstruction Loss: 223832128.0\n",
      "235it [00:21, 10.39it/s]2023-07-19 18:38:45,026 - INFO - Epoch: [462/600], Step: [237/591], Loss: 184825200.0, KL Divergence: 1062.4683837890625, Reconstruction Loss: 184824144.0\n",
      "353it [00:32, 10.57it/s]2023-07-19 18:38:56,051 - INFO - Epoch: [462/600], Step: [355/591], Loss: 224253552.0, KL Divergence: 1047.1475830078125, Reconstruction Loss: 224252512.0\n",
      "471it [00:43, 10.43it/s]2023-07-19 18:39:06,988 - INFO - Epoch: [462/600], Step: [473/591], Loss: 201757136.0, KL Divergence: 1043.9793701171875, Reconstruction Loss: 201756096.0\n",
      "589it [00:54, 10.90it/s]2023-07-19 18:39:17,993 - INFO - Epoch: [462/600], Step: [591/591], Loss: 153518256.0, KL Divergence: 1049.2362060546875, Reconstruction Loss: 153517200.0\n",
      "591it [00:55, 10.73it/s]\n",
      "2023-07-19 18:39:17,995 - INFO - Epoch: [462/600], Total Loss: 12969093703680.0, Total KL Divergence: 79012636.4921875, Total Reconstruction Loss: 12969014660096.0\n",
      "2023-07-19 18:39:18,058 - INFO - Save model at epoch 462\n",
      "0it [00:00, ?it/s]2023-07-19 18:39:18,177 - INFO - Epoch: [463/600], Step: [1/591], Loss: 108742608.0, KL Divergence: 1058.042724609375, Reconstruction Loss: 108741552.0\n",
      "117it [00:10, 11.04it/s]2023-07-19 18:39:29,100 - INFO - Epoch: [463/600], Step: [119/591], Loss: 229835792.0, KL Divergence: 1034.9052734375, Reconstruction Loss: 229834752.0\n",
      "235it [00:21, 10.91it/s]2023-07-19 18:39:40,134 - INFO - Epoch: [463/600], Step: [237/591], Loss: 185788480.0, KL Divergence: 1056.919189453125, Reconstruction Loss: 185787424.0\n",
      "353it [00:32, 10.97it/s]2023-07-19 18:39:51,120 - INFO - Epoch: [463/600], Step: [355/591], Loss: 226086784.0, KL Divergence: 1049.513427734375, Reconstruction Loss: 226085728.0\n",
      "471it [00:43, 10.70it/s]2023-07-19 18:40:02,208 - INFO - Epoch: [463/600], Step: [473/591], Loss: 206742384.0, KL Divergence: 1049.910888671875, Reconstruction Loss: 206741328.0\n",
      "589it [00:54, 10.58it/s]2023-07-19 18:40:13,181 - INFO - Epoch: [463/600], Step: [591/591], Loss: 154980864.0, KL Divergence: 1052.683837890625, Reconstruction Loss: 154979808.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 18:40:13,183 - INFO - Epoch: [463/600], Total Loss: 13009238629376.0, Total KL Divergence: 79148916.671875, Total Reconstruction Loss: 13009159468032.0\n",
      "2023-07-19 18:40:13,222 - INFO - Save model at epoch 463\n",
      "0it [00:00, ?it/s]2023-07-19 18:40:13,359 - INFO - Epoch: [464/600], Step: [1/591], Loss: 107870264.0, KL Divergence: 1061.8623046875, Reconstruction Loss: 107869200.0\n",
      "117it [00:10, 11.06it/s]2023-07-19 18:40:24,367 - INFO - Epoch: [464/600], Step: [119/591], Loss: 227930928.0, KL Divergence: 1047.95849609375, Reconstruction Loss: 227929888.0\n",
      "235it [00:22, 10.81it/s]2023-07-19 18:40:35,449 - INFO - Epoch: [464/600], Step: [237/591], Loss: 194018416.0, KL Divergence: 1065.8372802734375, Reconstruction Loss: 194017344.0\n",
      "353it [00:32, 10.85it/s]2023-07-19 18:40:46,326 - INFO - Epoch: [464/600], Step: [355/591], Loss: 232060448.0, KL Divergence: 1053.3037109375, Reconstruction Loss: 232059392.0\n",
      "471it [00:43, 10.86it/s]2023-07-19 18:40:57,311 - INFO - Epoch: [464/600], Step: [473/591], Loss: 204270000.0, KL Divergence: 1060.03125, Reconstruction Loss: 204268944.0\n",
      "589it [00:54, 10.55it/s]2023-07-19 18:41:08,301 - INFO - Epoch: [464/600], Step: [591/591], Loss: 155470768.0, KL Divergence: 1060.967041015625, Reconstruction Loss: 155469712.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 18:41:08,303 - INFO - Epoch: [464/600], Total Loss: 13233960826880.0, Total KL Divergence: 79788440.640625, Total Reconstruction Loss: 13233881012224.0\n",
      "2023-07-19 18:41:08,347 - INFO - Save model at epoch 464\n",
      "0it [00:00, ?it/s]2023-07-19 18:41:08,478 - INFO - Epoch: [465/600], Step: [1/591], Loss: 110304688.0, KL Divergence: 1068.624755859375, Reconstruction Loss: 110303616.0\n",
      "118it [00:10, 10.88it/s]2023-07-19 18:41:19,460 - INFO - Epoch: [465/600], Step: [119/591], Loss: 226795472.0, KL Divergence: 1047.07568359375, Reconstruction Loss: 226794432.0\n",
      "236it [00:22, 10.87it/s]2023-07-19 18:41:30,490 - INFO - Epoch: [465/600], Step: [237/591], Loss: 186681600.0, KL Divergence: 1057.993896484375, Reconstruction Loss: 186680544.0\n",
      "354it [00:32, 11.13it/s]2023-07-19 18:41:41,451 - INFO - Epoch: [465/600], Step: [355/591], Loss: 227540096.0, KL Divergence: 1059.2532958984375, Reconstruction Loss: 227539040.0\n",
      "472it [00:43, 11.06it/s]2023-07-19 18:41:52,382 - INFO - Epoch: [465/600], Step: [473/591], Loss: 217981728.0, KL Divergence: 1061.1395263671875, Reconstruction Loss: 217980672.0\n",
      "590it [00:54, 10.58it/s]2023-07-19 18:42:03,316 - INFO - Epoch: [465/600], Step: [591/591], Loss: 154429328.0, KL Divergence: 1061.6541748046875, Reconstruction Loss: 154428272.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 18:42:03,318 - INFO - Epoch: [465/600], Total Loss: 13161421564928.0, Total KL Divergence: 79881126.9375, Total Reconstruction Loss: 13161341678592.0\n",
      "2023-07-19 18:42:03,362 - INFO - Save model at epoch 465\n",
      "0it [00:00, ?it/s]2023-07-19 18:42:03,466 - INFO - Epoch: [466/600], Step: [1/591], Loss: 100367616.0, KL Divergence: 1071.209716796875, Reconstruction Loss: 100366544.0\n",
      "118it [00:11, 10.82it/s]2023-07-19 18:42:14,639 - INFO - Epoch: [466/600], Step: [119/591], Loss: 229920240.0, KL Divergence: 1043.02587890625, Reconstruction Loss: 229919200.0\n",
      "236it [00:22, 10.66it/s]2023-07-19 18:42:25,633 - INFO - Epoch: [466/600], Step: [237/591], Loss: 185910352.0, KL Divergence: 1065.8333740234375, Reconstruction Loss: 185909280.0\n",
      "354it [00:33, 10.82it/s]2023-07-19 18:42:36,619 - INFO - Epoch: [466/600], Step: [355/591], Loss: 235417696.0, KL Divergence: 1058.5264892578125, Reconstruction Loss: 235416640.0\n",
      "472it [00:44, 10.48it/s]2023-07-19 18:42:47,575 - INFO - Epoch: [466/600], Step: [473/591], Loss: 196305264.0, KL Divergence: 1053.690673828125, Reconstruction Loss: 196304208.0\n",
      "590it [00:55, 10.69it/s]2023-07-19 18:42:58,575 - INFO - Epoch: [466/600], Step: [591/591], Loss: 156357008.0, KL Divergence: 1059.9664306640625, Reconstruction Loss: 156355952.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 18:42:58,576 - INFO - Epoch: [466/600], Total Loss: 13100146945024.0, Total KL Divergence: 79743546.71875, Total Reconstruction Loss: 13100067206144.0\n",
      "2023-07-19 18:42:58,628 - INFO - Save model at epoch 466\n",
      "0it [00:00, ?it/s]2023-07-19 18:42:58,738 - INFO - Epoch: [467/600], Step: [1/591], Loss: 118977304.0, KL Divergence: 1067.63916015625, Reconstruction Loss: 118976240.0\n",
      "118it [00:11, 10.74it/s]2023-07-19 18:43:09,764 - INFO - Epoch: [467/600], Step: [119/591], Loss: 227759344.0, KL Divergence: 1047.6229248046875, Reconstruction Loss: 227758304.0\n",
      "235it [00:22, 10.01it/s]2023-07-19 18:43:20,830 - INFO - Epoch: [467/600], Step: [237/591], Loss: 185869568.0, KL Divergence: 1054.6978759765625, Reconstruction Loss: 185868512.0\n",
      "353it [00:32, 10.85it/s]2023-07-19 18:43:31,787 - INFO - Epoch: [467/600], Step: [355/591], Loss: 233507680.0, KL Divergence: 1050.9732666015625, Reconstruction Loss: 233506624.0\n",
      "471it [00:43, 10.70it/s]2023-07-19 18:43:42,794 - INFO - Epoch: [467/600], Step: [473/591], Loss: 203247408.0, KL Divergence: 1059.442138671875, Reconstruction Loss: 203246352.0\n",
      "589it [00:55, 10.73it/s]2023-07-19 18:43:53,890 - INFO - Epoch: [467/600], Step: [591/591], Loss: 154633120.0, KL Divergence: 1051.341552734375, Reconstruction Loss: 154632064.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 18:43:53,893 - INFO - Epoch: [467/600], Total Loss: 13074419055616.0, Total KL Divergence: 79589081.859375, Total Reconstruction Loss: 13074339446784.0\n",
      "2023-07-19 18:43:53,932 - INFO - Save model at epoch 467\n",
      "0it [00:00, ?it/s]2023-07-19 18:43:54,045 - INFO - Epoch: [468/600], Step: [1/591], Loss: 102580000.0, KL Divergence: 1062.7451171875, Reconstruction Loss: 102578936.0\n",
      "118it [00:11, 10.77it/s]2023-07-19 18:44:05,086 - INFO - Epoch: [468/600], Step: [119/591], Loss: 230373424.0, KL Divergence: 1047.6513671875, Reconstruction Loss: 230372384.0\n",
      "236it [00:22, 10.33it/s]2023-07-19 18:44:16,154 - INFO - Epoch: [468/600], Step: [237/591], Loss: 184434160.0, KL Divergence: 1066.531005859375, Reconstruction Loss: 184433088.0\n",
      "354it [00:33, 10.91it/s]2023-07-19 18:44:27,095 - INFO - Epoch: [468/600], Step: [355/591], Loss: 227127408.0, KL Divergence: 1053.76318359375, Reconstruction Loss: 227126352.0\n",
      "472it [00:44, 10.61it/s]2023-07-19 18:44:38,081 - INFO - Epoch: [468/600], Step: [473/591], Loss: 192503936.0, KL Divergence: 1051.8260498046875, Reconstruction Loss: 192502880.0\n",
      "590it [00:55, 10.72it/s]2023-07-19 18:44:49,034 - INFO - Epoch: [468/600], Step: [591/591], Loss: 158337072.0, KL Divergence: 1047.693603515625, Reconstruction Loss: 158336032.0\n",
      "591it [00:55, 10.73it/s]\n",
      "2023-07-19 18:44:49,036 - INFO - Epoch: [468/600], Total Loss: 12957463336960.0, Total KL Divergence: 79674493.5, Total Reconstruction Loss: 12957383676928.0\n",
      "2023-07-19 18:44:49,082 - INFO - Save model at epoch 468\n",
      "0it [00:00, ?it/s]2023-07-19 18:44:49,207 - INFO - Epoch: [469/600], Step: [1/591], Loss: 101017256.0, KL Divergence: 1059.1121826171875, Reconstruction Loss: 101016200.0\n",
      "118it [00:11, 10.80it/s]2023-07-19 18:45:00,221 - INFO - Epoch: [469/600], Step: [119/591], Loss: 232573472.0, KL Divergence: 1044.9671630859375, Reconstruction Loss: 232572432.0\n",
      "236it [00:22,  9.71it/s]2023-07-19 18:45:11,270 - INFO - Epoch: [469/600], Step: [237/591], Loss: 188118336.0, KL Divergence: 1063.567138671875, Reconstruction Loss: 188117280.0\n",
      "354it [00:33, 10.66it/s]2023-07-19 18:45:22,318 - INFO - Epoch: [469/600], Step: [355/591], Loss: 225237888.0, KL Divergence: 1060.72119140625, Reconstruction Loss: 225236832.0\n",
      "472it [00:44, 10.80it/s]2023-07-19 18:45:33,297 - INFO - Epoch: [469/600], Step: [473/591], Loss: 201143712.0, KL Divergence: 1059.436279296875, Reconstruction Loss: 201142656.0\n",
      "590it [00:55, 10.55it/s]2023-07-19 18:45:44,276 - INFO - Epoch: [469/600], Step: [591/591], Loss: 154844720.0, KL Divergence: 1047.05712890625, Reconstruction Loss: 154843680.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 18:45:44,277 - INFO - Epoch: [469/600], Total Loss: 13052658045952.0, Total KL Divergence: 79815692.8125, Total Reconstruction Loss: 13052578243584.0\n",
      "2023-07-19 18:45:44,317 - INFO - Save model at epoch 469\n",
      "0it [00:00, ?it/s]2023-07-19 18:45:44,425 - INFO - Epoch: [470/600], Step: [1/591], Loss: 101060128.0, KL Divergence: 1058.8427734375, Reconstruction Loss: 101059072.0\n",
      "118it [00:10, 10.90it/s]2023-07-19 18:45:55,394 - INFO - Epoch: [470/600], Step: [119/591], Loss: 236841312.0, KL Divergence: 1048.7421875, Reconstruction Loss: 236840256.0\n",
      "236it [00:21, 10.02it/s]2023-07-19 18:46:06,431 - INFO - Epoch: [470/600], Step: [237/591], Loss: 187743904.0, KL Divergence: 1064.34619140625, Reconstruction Loss: 187742832.0\n",
      "354it [00:32, 10.88it/s]2023-07-19 18:46:17,424 - INFO - Epoch: [470/600], Step: [355/591], Loss: 237129600.0, KL Divergence: 1058.037353515625, Reconstruction Loss: 237128544.0\n",
      "472it [00:43, 10.84it/s]2023-07-19 18:46:28,412 - INFO - Epoch: [470/600], Step: [473/591], Loss: 191618880.0, KL Divergence: 1052.007568359375, Reconstruction Loss: 191617824.0\n",
      "590it [00:54, 10.62it/s]2023-07-19 18:46:39,356 - INFO - Epoch: [470/600], Step: [591/591], Loss: 160019136.0, KL Divergence: 1057.478271484375, Reconstruction Loss: 160018080.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 18:46:39,357 - INFO - Epoch: [470/600], Total Loss: 13121389217792.0, Total KL Divergence: 79556885.828125, Total Reconstruction Loss: 13121309663232.0\n",
      "2023-07-19 18:46:39,402 - INFO - Save model at epoch 470\n",
      "0it [00:00, ?it/s]2023-07-19 18:46:39,509 - INFO - Epoch: [471/600], Step: [1/591], Loss: 100148728.0, KL Divergence: 1065.446533203125, Reconstruction Loss: 100147664.0\n",
      "118it [00:10, 10.89it/s]2023-07-19 18:46:50,484 - INFO - Epoch: [471/600], Step: [119/591], Loss: 230546640.0, KL Divergence: 1054.2860107421875, Reconstruction Loss: 230545584.0\n",
      "236it [00:22, 10.47it/s]2023-07-19 18:47:01,552 - INFO - Epoch: [471/600], Step: [237/591], Loss: 195280832.0, KL Divergence: 1060.5391845703125, Reconstruction Loss: 195279776.0\n",
      "354it [00:33, 10.59it/s]2023-07-19 18:47:12,696 - INFO - Epoch: [471/600], Step: [355/591], Loss: 241941424.0, KL Divergence: 1067.60498046875, Reconstruction Loss: 241940352.0\n",
      "472it [00:44, 10.93it/s]2023-07-19 18:47:23,631 - INFO - Epoch: [471/600], Step: [473/591], Loss: 196226448.0, KL Divergence: 1062.720703125, Reconstruction Loss: 196225392.0\n",
      "590it [00:55, 11.06it/s]2023-07-19 18:47:34,572 - INFO - Epoch: [471/600], Step: [591/591], Loss: 155705904.0, KL Divergence: 1064.13134765625, Reconstruction Loss: 155704832.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 18:47:34,574 - INFO - Epoch: [471/600], Total Loss: 13063635335168.0, Total KL Divergence: 80073690.1875, Total Reconstruction Loss: 13063555256320.0\n",
      "2023-07-19 18:47:34,617 - INFO - Save model at epoch 471\n",
      "0it [00:00, ?it/s]2023-07-19 18:47:34,727 - INFO - Epoch: [472/600], Step: [1/591], Loss: 100005488.0, KL Divergence: 1073.82177734375, Reconstruction Loss: 100004416.0\n",
      "118it [00:10, 10.79it/s]2023-07-19 18:47:45,723 - INFO - Epoch: [472/600], Step: [119/591], Loss: 234035232.0, KL Divergence: 1057.2763671875, Reconstruction Loss: 234034176.0\n",
      "236it [00:21, 10.66it/s]2023-07-19 18:47:56,666 - INFO - Epoch: [472/600], Step: [237/591], Loss: 186709104.0, KL Divergence: 1071.1361083984375, Reconstruction Loss: 186708032.0\n",
      "354it [00:33, 10.14it/s]2023-07-19 18:48:07,830 - INFO - Epoch: [472/600], Step: [355/591], Loss: 223880736.0, KL Divergence: 1067.846923828125, Reconstruction Loss: 223879664.0\n",
      "472it [00:44, 10.97it/s]2023-07-19 18:48:18,850 - INFO - Epoch: [472/600], Step: [473/591], Loss: 204584512.0, KL Divergence: 1059.935546875, Reconstruction Loss: 204583456.0\n",
      "590it [00:55, 10.66it/s]2023-07-19 18:48:29,821 - INFO - Epoch: [472/600], Step: [591/591], Loss: 150915552.0, KL Divergence: 1055.9068603515625, Reconstruction Loss: 150914496.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 18:48:29,823 - INFO - Epoch: [472/600], Total Loss: 12987650676736.0, Total KL Divergence: 80242029.8125, Total Reconstruction Loss: 12987570439168.0\n",
      "2023-07-19 18:48:29,863 - INFO - Save model at epoch 472\n",
      "0it [00:00, ?it/s]2023-07-19 18:48:29,973 - INFO - Epoch: [473/600], Step: [1/591], Loss: 98922632.0, KL Divergence: 1067.426025390625, Reconstruction Loss: 98921568.0\n",
      "118it [00:11, 10.91it/s]2023-07-19 18:48:41,051 - INFO - Epoch: [473/600], Step: [119/591], Loss: 235044672.0, KL Divergence: 1060.19677734375, Reconstruction Loss: 235043616.0\n",
      "236it [00:22, 11.22it/s]2023-07-19 18:48:52,044 - INFO - Epoch: [473/600], Step: [237/591], Loss: 186132304.0, KL Divergence: 1066.519287109375, Reconstruction Loss: 186131232.0\n",
      "354it [00:33, 10.87it/s]2023-07-19 18:49:03,031 - INFO - Epoch: [473/600], Step: [355/591], Loss: 222906848.0, KL Divergence: 1065.3446044921875, Reconstruction Loss: 222905776.0\n",
      "472it [00:44, 10.73it/s]2023-07-19 18:49:13,984 - INFO - Epoch: [473/600], Step: [473/591], Loss: 190692256.0, KL Divergence: 1070.4183349609375, Reconstruction Loss: 190691184.0\n",
      "590it [00:54, 11.07it/s]2023-07-19 18:49:24,896 - INFO - Epoch: [473/600], Step: [591/591], Loss: 155308400.0, KL Divergence: 1067.75390625, Reconstruction Loss: 155307328.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 18:49:24,898 - INFO - Epoch: [473/600], Total Loss: 12995279749120.0, Total KL Divergence: 80286465.40625, Total Reconstruction Loss: 12995199448064.0\n",
      "2023-07-19 18:49:24,936 - INFO - Save model at epoch 473\n",
      "0it [00:00, ?it/s]2023-07-19 18:49:25,051 - INFO - Epoch: [474/600], Step: [1/591], Loss: 108578296.0, KL Divergence: 1077.5810546875, Reconstruction Loss: 108577216.0\n",
      "118it [00:11, 10.53it/s]2023-07-19 18:49:36,126 - INFO - Epoch: [474/600], Step: [119/591], Loss: 236327664.0, KL Divergence: 1061.1456298828125, Reconstruction Loss: 236326608.0\n",
      "236it [00:22, 10.77it/s]2023-07-19 18:49:47,134 - INFO - Epoch: [474/600], Step: [237/591], Loss: 190524416.0, KL Divergence: 1071.49462890625, Reconstruction Loss: 190523344.0\n",
      "354it [00:33, 10.59it/s]2023-07-19 18:49:58,252 - INFO - Epoch: [474/600], Step: [355/591], Loss: 223551024.0, KL Divergence: 1075.92626953125, Reconstruction Loss: 223549952.0\n",
      "472it [00:44, 10.62it/s]2023-07-19 18:50:09,282 - INFO - Epoch: [474/600], Step: [473/591], Loss: 189984192.0, KL Divergence: 1064.50390625, Reconstruction Loss: 189983120.0\n",
      "590it [00:55, 10.73it/s]2023-07-19 18:50:20,328 - INFO - Epoch: [474/600], Step: [591/591], Loss: 165011680.0, KL Divergence: 1070.4573974609375, Reconstruction Loss: 165010608.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 18:50:20,330 - INFO - Epoch: [474/600], Total Loss: 13102087796736.0, Total KL Divergence: 80597725.75, Total Reconstruction Loss: 13102007182336.0\n",
      "2023-07-19 18:50:20,382 - INFO - Save model at epoch 474\n",
      "0it [00:00, ?it/s]2023-07-19 18:50:20,491 - INFO - Epoch: [475/600], Step: [1/591], Loss: 105458368.0, KL Divergence: 1084.829833984375, Reconstruction Loss: 105457280.0\n",
      "118it [00:11, 10.48it/s]2023-07-19 18:50:31,500 - INFO - Epoch: [475/600], Step: [119/591], Loss: 238912400.0, KL Divergence: 1056.88134765625, Reconstruction Loss: 238911344.0\n",
      "236it [00:21, 10.84it/s]2023-07-19 18:50:42,465 - INFO - Epoch: [475/600], Step: [237/591], Loss: 191458976.0, KL Divergence: 1068.7960205078125, Reconstruction Loss: 191457904.0\n",
      "354it [00:32, 10.43it/s]2023-07-19 18:50:53,459 - INFO - Epoch: [475/600], Step: [355/591], Loss: 249589616.0, KL Divergence: 1071.44287109375, Reconstruction Loss: 249588544.0\n",
      "472it [00:43, 10.89it/s]2023-07-19 18:51:04,382 - INFO - Epoch: [475/600], Step: [473/591], Loss: 194946352.0, KL Divergence: 1069.091796875, Reconstruction Loss: 194945280.0\n",
      "590it [00:54, 10.71it/s]2023-07-19 18:51:15,286 - INFO - Epoch: [475/600], Step: [591/591], Loss: 156707152.0, KL Divergence: 1058.906005859375, Reconstruction Loss: 156706096.0\n",
      "591it [00:54, 10.77it/s]\n",
      "2023-07-19 18:51:15,287 - INFO - Epoch: [475/600], Total Loss: 13230524855296.0, Total KL Divergence: 80561536.796875, Total Reconstruction Loss: 13230444296192.0\n",
      "2023-07-19 18:51:15,330 - INFO - Save model at epoch 475\n",
      "0it [00:00, ?it/s]2023-07-19 18:51:15,454 - INFO - Epoch: [476/600], Step: [1/591], Loss: 100035432.0, KL Divergence: 1073.85205078125, Reconstruction Loss: 100034360.0\n",
      "118it [00:11, 10.39it/s]2023-07-19 18:51:26,523 - INFO - Epoch: [476/600], Step: [119/591], Loss: 229427424.0, KL Divergence: 1051.3798828125, Reconstruction Loss: 229426368.0\n",
      "236it [00:22, 10.69it/s]2023-07-19 18:51:37,509 - INFO - Epoch: [476/600], Step: [237/591], Loss: 193228560.0, KL Divergence: 1082.197998046875, Reconstruction Loss: 193227472.0\n",
      "354it [00:32, 11.04it/s]2023-07-19 18:51:48,327 - INFO - Epoch: [476/600], Step: [355/591], Loss: 233147568.0, KL Divergence: 1075.168212890625, Reconstruction Loss: 233146496.0\n",
      "472it [00:43, 10.57it/s]2023-07-19 18:51:59,339 - INFO - Epoch: [476/600], Step: [473/591], Loss: 193024912.0, KL Divergence: 1072.427490234375, Reconstruction Loss: 193023840.0\n",
      "590it [00:54, 10.98it/s]2023-07-19 18:52:10,298 - INFO - Epoch: [476/600], Step: [591/591], Loss: 154548768.0, KL Divergence: 1059.700439453125, Reconstruction Loss: 154547712.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 18:52:10,301 - INFO - Epoch: [476/600], Total Loss: 13433989754880.0, Total KL Divergence: 80628602.5, Total Reconstruction Loss: 13433909107712.0\n",
      "2023-07-19 18:52:10,354 - INFO - Save model at epoch 476\n",
      "0it [00:00, ?it/s]2023-07-19 18:52:10,466 - INFO - Epoch: [477/600], Step: [1/591], Loss: 100210960.0, KL Divergence: 1071.874755859375, Reconstruction Loss: 100209888.0\n",
      "117it [00:10, 10.92it/s]2023-07-19 18:52:21,446 - INFO - Epoch: [477/600], Step: [119/591], Loss: 227555248.0, KL Divergence: 1057.437744140625, Reconstruction Loss: 227554192.0\n",
      "235it [00:21, 10.57it/s]2023-07-19 18:52:32,522 - INFO - Epoch: [477/600], Step: [237/591], Loss: 183308784.0, KL Divergence: 1081.4267578125, Reconstruction Loss: 183307696.0\n",
      "353it [00:32, 10.78it/s]2023-07-19 18:52:43,501 - INFO - Epoch: [477/600], Step: [355/591], Loss: 245449472.0, KL Divergence: 1076.07275390625, Reconstruction Loss: 245448400.0\n",
      "471it [00:43, 10.86it/s]2023-07-19 18:52:54,389 - INFO - Epoch: [477/600], Step: [473/591], Loss: 190004720.0, KL Divergence: 1068.4615478515625, Reconstruction Loss: 190003648.0\n",
      "589it [00:54, 10.62it/s]2023-07-19 18:53:05,317 - INFO - Epoch: [477/600], Step: [591/591], Loss: 155983840.0, KL Divergence: 1064.2783203125, Reconstruction Loss: 155982768.0\n",
      "591it [00:54, 10.75it/s]\n",
      "2023-07-19 18:53:05,319 - INFO - Epoch: [477/600], Total Loss: 13212597381120.0, Total KL Divergence: 80653029.671875, Total Reconstruction Loss: 13212516739072.0\n",
      "2023-07-19 18:53:05,356 - INFO - Save model at epoch 477\n",
      "0it [00:00, ?it/s]2023-07-19 18:53:05,496 - INFO - Epoch: [478/600], Step: [1/591], Loss: 104918864.0, KL Divergence: 1075.0714111328125, Reconstruction Loss: 104917792.0\n",
      "118it [00:10, 10.64it/s]2023-07-19 18:53:16,411 - INFO - Epoch: [478/600], Step: [119/591], Loss: 225138512.0, KL Divergence: 1057.0970458984375, Reconstruction Loss: 225137456.0\n",
      "236it [00:21, 10.88it/s]2023-07-19 18:53:27,489 - INFO - Epoch: [478/600], Step: [237/591], Loss: 190447488.0, KL Divergence: 1072.3421630859375, Reconstruction Loss: 190446416.0\n",
      "354it [00:33, 10.30it/s]2023-07-19 18:53:38,555 - INFO - Epoch: [478/600], Step: [355/591], Loss: 232593072.0, KL Divergence: 1070.06591796875, Reconstruction Loss: 232592000.0\n",
      "472it [00:43, 10.95it/s]2023-07-19 18:53:49,346 - INFO - Epoch: [478/600], Step: [473/591], Loss: 215910848.0, KL Divergence: 1068.264892578125, Reconstruction Loss: 215909776.0\n",
      "590it [00:54, 10.93it/s]2023-07-19 18:54:00,246 - INFO - Epoch: [478/600], Step: [591/591], Loss: 152505568.0, KL Divergence: 1064.478271484375, Reconstruction Loss: 152504496.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 18:54:00,247 - INFO - Epoch: [478/600], Total Loss: 13006461011968.0, Total KL Divergence: 80489573.125, Total Reconstruction Loss: 13006380509184.0\n",
      "2023-07-19 18:54:00,296 - INFO - Save model at epoch 478\n",
      "0it [00:00, ?it/s]2023-07-19 18:54:00,419 - INFO - Epoch: [479/600], Step: [1/591], Loss: 100361736.0, KL Divergence: 1077.714111328125, Reconstruction Loss: 100360656.0\n",
      "118it [00:11, 10.72it/s]2023-07-19 18:54:11,445 - INFO - Epoch: [479/600], Step: [119/591], Loss: 224637776.0, KL Divergence: 1061.1751708984375, Reconstruction Loss: 224636720.0\n",
      "236it [00:22, 10.74it/s]2023-07-19 18:54:22,455 - INFO - Epoch: [479/600], Step: [237/591], Loss: 187139216.0, KL Divergence: 1079.416259765625, Reconstruction Loss: 187138144.0\n",
      "354it [00:33, 10.77it/s]2023-07-19 18:54:33,585 - INFO - Epoch: [479/600], Step: [355/591], Loss: 232372192.0, KL Divergence: 1080.0263671875, Reconstruction Loss: 232371104.0\n",
      "472it [00:44, 10.94it/s]2023-07-19 18:54:44,649 - INFO - Epoch: [479/600], Step: [473/591], Loss: 209754560.0, KL Divergence: 1077.1427001953125, Reconstruction Loss: 209753488.0\n",
      "590it [00:55, 10.70it/s]2023-07-19 18:54:55,672 - INFO - Epoch: [479/600], Step: [591/591], Loss: 156321840.0, KL Divergence: 1064.848876953125, Reconstruction Loss: 156320768.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 18:54:55,674 - INFO - Epoch: [479/600], Total Loss: 12971238092800.0, Total KL Divergence: 80982352.875, Total Reconstruction Loss: 12971157089280.0\n",
      "2023-07-19 18:54:55,713 - INFO - Save model at epoch 479\n",
      "0it [00:00, ?it/s]2023-07-19 18:54:55,834 - INFO - Epoch: [480/600], Step: [1/591], Loss: 101392896.0, KL Divergence: 1078.8465576171875, Reconstruction Loss: 101391816.0\n",
      "117it [00:11, 10.62it/s]2023-07-19 18:55:07,070 - INFO - Epoch: [480/600], Step: [119/591], Loss: 225637008.0, KL Divergence: 1057.086669921875, Reconstruction Loss: 225635952.0\n",
      "235it [00:22, 10.84it/s]2023-07-19 18:55:18,081 - INFO - Epoch: [480/600], Step: [237/591], Loss: 189919696.0, KL Divergence: 1071.9945068359375, Reconstruction Loss: 189918624.0\n",
      "353it [00:33, 11.28it/s]2023-07-19 18:55:29,130 - INFO - Epoch: [480/600], Step: [355/591], Loss: 237461904.0, KL Divergence: 1074.55517578125, Reconstruction Loss: 237460832.0\n",
      "471it [00:44, 10.73it/s]2023-07-19 18:55:40,064 - INFO - Epoch: [480/600], Step: [473/591], Loss: 201020576.0, KL Divergence: 1069.576171875, Reconstruction Loss: 201019504.0\n",
      "589it [00:55, 10.73it/s]2023-07-19 18:55:51,026 - INFO - Epoch: [480/600], Step: [591/591], Loss: 155311536.0, KL Divergence: 1058.6337890625, Reconstruction Loss: 155310480.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 18:55:51,028 - INFO - Epoch: [480/600], Total Loss: 12965589323776.0, Total KL Divergence: 80787225.640625, Total Reconstruction Loss: 12965508542464.0\n",
      "2023-07-19 18:55:51,067 - INFO - Save model at epoch 480\n",
      "0it [00:00, ?it/s]2023-07-19 18:55:51,176 - INFO - Epoch: [481/600], Step: [1/591], Loss: 102466616.0, KL Divergence: 1070.49951171875, Reconstruction Loss: 102465544.0\n",
      "118it [00:11, 10.95it/s]2023-07-19 18:56:02,185 - INFO - Epoch: [481/600], Step: [119/591], Loss: 224705888.0, KL Divergence: 1059.2901611328125, Reconstruction Loss: 224704832.0\n",
      "236it [00:21, 10.81it/s]2023-07-19 18:56:13,128 - INFO - Epoch: [481/600], Step: [237/591], Loss: 182228944.0, KL Divergence: 1073.3505859375, Reconstruction Loss: 182227872.0\n",
      "354it [00:32, 10.61it/s]2023-07-19 18:56:24,092 - INFO - Epoch: [481/600], Step: [355/591], Loss: 227842128.0, KL Divergence: 1076.930908203125, Reconstruction Loss: 227841056.0\n",
      "472it [00:43, 10.45it/s]2023-07-19 18:56:35,119 - INFO - Epoch: [481/600], Step: [473/591], Loss: 193469552.0, KL Divergence: 1072.331787109375, Reconstruction Loss: 193468480.0\n",
      "590it [00:54, 10.75it/s]2023-07-19 18:56:46,121 - INFO - Epoch: [481/600], Step: [591/591], Loss: 158022496.0, KL Divergence: 1066.438232421875, Reconstruction Loss: 158021424.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 18:56:46,123 - INFO - Epoch: [481/600], Total Loss: 12910237193216.0, Total KL Divergence: 80818768.0625, Total Reconstruction Loss: 12910156388352.0\n",
      "2023-07-19 18:56:46,164 - INFO - Save model at epoch 481\n",
      "0it [00:00, ?it/s]2023-07-19 18:56:46,280 - INFO - Epoch: [482/600], Step: [1/591], Loss: 102017032.0, KL Divergence: 1081.22705078125, Reconstruction Loss: 102015952.0\n",
      "117it [00:10, 10.37it/s]2023-07-19 18:56:57,340 - INFO - Epoch: [482/600], Step: [119/591], Loss: 223200144.0, KL Divergence: 1062.97509765625, Reconstruction Loss: 223199088.0\n",
      "235it [00:22, 10.27it/s]2023-07-19 18:57:08,392 - INFO - Epoch: [482/600], Step: [237/591], Loss: 186245808.0, KL Divergence: 1075.25537109375, Reconstruction Loss: 186244736.0\n",
      "353it [00:33, 10.70it/s]2023-07-19 18:57:19,374 - INFO - Epoch: [482/600], Step: [355/591], Loss: 223056400.0, KL Divergence: 1078.393798828125, Reconstruction Loss: 223055328.0\n",
      "471it [00:43, 10.65it/s]2023-07-19 18:57:30,358 - INFO - Epoch: [482/600], Step: [473/591], Loss: 211770128.0, KL Divergence: 1078.0899658203125, Reconstruction Loss: 211769056.0\n",
      "589it [00:54, 10.84it/s]2023-07-19 18:57:41,306 - INFO - Epoch: [482/600], Step: [591/591], Loss: 156294528.0, KL Divergence: 1072.3978271484375, Reconstruction Loss: 156293456.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 18:57:41,308 - INFO - Epoch: [482/600], Total Loss: 12893336588288.0, Total KL Divergence: 81104548.171875, Total Reconstruction Loss: 12893255489536.0\n",
      "2023-07-19 18:57:41,351 - INFO - Save model at epoch 482\n",
      "0it [00:00, ?it/s]2023-07-19 18:57:41,470 - INFO - Epoch: [483/600], Step: [1/591], Loss: 100509920.0, KL Divergence: 1085.73095703125, Reconstruction Loss: 100508832.0\n",
      "117it [00:10, 11.07it/s]2023-07-19 18:57:52,453 - INFO - Epoch: [483/600], Step: [119/591], Loss: 225912624.0, KL Divergence: 1070.0084228515625, Reconstruction Loss: 225911552.0\n",
      "235it [00:21, 11.03it/s]2023-07-19 18:58:03,495 - INFO - Epoch: [483/600], Step: [237/591], Loss: 185909120.0, KL Divergence: 1087.548095703125, Reconstruction Loss: 185908032.0\n",
      "353it [00:33, 10.46it/s]2023-07-19 18:58:14,595 - INFO - Epoch: [483/600], Step: [355/591], Loss: 224910320.0, KL Divergence: 1087.5140380859375, Reconstruction Loss: 224909232.0\n",
      "471it [00:43, 10.99it/s]2023-07-19 18:58:25,551 - INFO - Epoch: [483/600], Step: [473/591], Loss: 200497088.0, KL Divergence: 1084.7620849609375, Reconstruction Loss: 200496000.0\n",
      "589it [00:55, 10.73it/s]2023-07-19 18:58:36,554 - INFO - Epoch: [483/600], Step: [591/591], Loss: 158393312.0, KL Divergence: 1072.22705078125, Reconstruction Loss: 158392240.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 18:58:36,556 - INFO - Epoch: [483/600], Total Loss: 12866889059328.0, Total KL Divergence: 81533042.671875, Total Reconstruction Loss: 12866807524352.0\n",
      "2023-07-19 18:58:36,594 - INFO - Save model at epoch 483\n",
      "0it [00:00, ?it/s]2023-07-19 18:58:36,711 - INFO - Epoch: [484/600], Step: [1/591], Loss: 115374072.0, KL Divergence: 1087.198486328125, Reconstruction Loss: 115372984.0\n",
      "118it [00:11, 11.00it/s]2023-07-19 18:58:47,793 - INFO - Epoch: [484/600], Step: [119/591], Loss: 237758704.0, KL Divergence: 1068.4810791015625, Reconstruction Loss: 237757632.0\n",
      "236it [00:22, 10.77it/s]2023-07-19 18:58:58,759 - INFO - Epoch: [484/600], Step: [237/591], Loss: 181054528.0, KL Divergence: 1095.394287109375, Reconstruction Loss: 181053440.0\n",
      "354it [00:33, 10.44it/s]2023-07-19 18:59:09,848 - INFO - Epoch: [484/600], Step: [355/591], Loss: 223469824.0, KL Divergence: 1086.7034912109375, Reconstruction Loss: 223468736.0\n",
      "472it [00:44, 10.82it/s]2023-07-19 18:59:20,784 - INFO - Epoch: [484/600], Step: [473/591], Loss: 200729216.0, KL Divergence: 1084.270751953125, Reconstruction Loss: 200728128.0\n",
      "590it [00:55, 10.85it/s]2023-07-19 18:59:31,733 - INFO - Epoch: [484/600], Step: [591/591], Loss: 155492144.0, KL Divergence: 1072.57666015625, Reconstruction Loss: 155491072.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 18:59:31,734 - INFO - Epoch: [484/600], Total Loss: 12913131132928.0, Total KL Divergence: 81653192.140625, Total Reconstruction Loss: 12913049484288.0\n",
      "2023-07-19 18:59:31,789 - INFO - Save model at epoch 484\n",
      "0it [00:00, ?it/s]2023-07-19 18:59:31,900 - INFO - Epoch: [485/600], Step: [1/591], Loss: 117953504.0, KL Divergence: 1088.7305908203125, Reconstruction Loss: 117952416.0\n",
      "118it [00:10, 10.80it/s]2023-07-19 18:59:42,906 - INFO - Epoch: [485/600], Step: [119/591], Loss: 224337840.0, KL Divergence: 1071.453857421875, Reconstruction Loss: 224336768.0\n",
      "236it [00:22, 10.88it/s]2023-07-19 18:59:53,954 - INFO - Epoch: [485/600], Step: [237/591], Loss: 178582944.0, KL Divergence: 1088.32958984375, Reconstruction Loss: 178581856.0\n",
      "354it [00:33, 10.05it/s]2023-07-19 19:00:05,033 - INFO - Epoch: [485/600], Step: [355/591], Loss: 229494656.0, KL Divergence: 1081.677001953125, Reconstruction Loss: 229493568.0\n",
      "472it [00:44, 11.09it/s]2023-07-19 19:00:16,010 - INFO - Epoch: [485/600], Step: [473/591], Loss: 190805520.0, KL Divergence: 1089.6248779296875, Reconstruction Loss: 190804432.0\n",
      "590it [00:55, 11.01it/s]2023-07-19 19:00:26,990 - INFO - Epoch: [485/600], Step: [591/591], Loss: 155391680.0, KL Divergence: 1074.5294189453125, Reconstruction Loss: 155390608.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 19:00:26,992 - INFO - Epoch: [485/600], Total Loss: 12884490923008.0, Total KL Divergence: 81628493.890625, Total Reconstruction Loss: 12884409304064.0\n",
      "2023-07-19 19:00:27,042 - INFO - Save model at epoch 485\n",
      "0it [00:00, ?it/s]2023-07-19 19:00:27,162 - INFO - Epoch: [486/600], Step: [1/591], Loss: 107573136.0, KL Divergence: 1090.856201171875, Reconstruction Loss: 107572048.0\n",
      "117it [00:10, 10.84it/s]2023-07-19 19:00:38,149 - INFO - Epoch: [486/600], Step: [119/591], Loss: 218444432.0, KL Divergence: 1074.839599609375, Reconstruction Loss: 218443360.0\n",
      "235it [00:21, 10.66it/s]2023-07-19 19:00:49,117 - INFO - Epoch: [486/600], Step: [237/591], Loss: 178555456.0, KL Divergence: 1090.791259765625, Reconstruction Loss: 178554368.0\n",
      "354it [00:33, 10.49it/s]2023-07-19 19:01:00,174 - INFO - Epoch: [486/600], Step: [355/591], Loss: 229977792.0, KL Divergence: 1089.395751953125, Reconstruction Loss: 229976704.0\n",
      "472it [00:43, 10.94it/s]2023-07-19 19:01:11,103 - INFO - Epoch: [486/600], Step: [473/591], Loss: 188593376.0, KL Divergence: 1088.228759765625, Reconstruction Loss: 188592288.0\n",
      "590it [00:54, 10.55it/s]2023-07-19 19:01:22,096 - INFO - Epoch: [486/600], Step: [591/591], Loss: 156559248.0, KL Divergence: 1072.7041015625, Reconstruction Loss: 156558176.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 19:01:22,097 - INFO - Epoch: [486/600], Total Loss: 12804897113088.0, Total KL Divergence: 81648100.359375, Total Reconstruction Loss: 12804815488000.0\n",
      "2023-07-19 19:01:22,148 - INFO - Save model at epoch 486\n",
      "0it [00:00, ?it/s]2023-07-19 19:01:22,246 - INFO - Epoch: [487/600], Step: [1/591], Loss: 102542600.0, KL Divergence: 1087.09375, Reconstruction Loss: 102541512.0\n",
      "118it [00:11, 10.66it/s]2023-07-19 19:01:33,274 - INFO - Epoch: [487/600], Step: [119/591], Loss: 231057904.0, KL Divergence: 1067.100830078125, Reconstruction Loss: 231056832.0\n",
      "236it [00:21, 11.22it/s]2023-07-19 19:01:44,162 - INFO - Epoch: [487/600], Step: [237/591], Loss: 179993440.0, KL Divergence: 1092.8551025390625, Reconstruction Loss: 179992352.0\n",
      "354it [00:32, 10.83it/s]2023-07-19 19:01:55,021 - INFO - Epoch: [487/600], Step: [355/591], Loss: 236651712.0, KL Divergence: 1083.5018310546875, Reconstruction Loss: 236650624.0\n",
      "472it [00:43, 10.68it/s]2023-07-19 19:02:05,936 - INFO - Epoch: [487/600], Step: [473/591], Loss: 196569376.0, KL Divergence: 1080.815185546875, Reconstruction Loss: 196568288.0\n",
      "590it [00:54, 10.89it/s]2023-07-19 19:02:16,957 - INFO - Epoch: [487/600], Step: [591/591], Loss: 156373776.0, KL Divergence: 1064.05712890625, Reconstruction Loss: 156372704.0\n",
      "591it [00:54, 10.78it/s]\n",
      "2023-07-19 19:02:16,959 - INFO - Epoch: [487/600], Total Loss: 12804225926144.0, Total KL Divergence: 81408492.875, Total Reconstruction Loss: 12804144509952.0\n",
      "2023-07-19 19:02:16,999 - INFO - Save model at epoch 487\n",
      "0it [00:00, ?it/s]2023-07-19 19:02:17,117 - INFO - Epoch: [488/600], Step: [1/591], Loss: 99997032.0, KL Divergence: 1076.562255859375, Reconstruction Loss: 99995952.0\n",
      "118it [00:10, 10.92it/s]2023-07-19 19:02:28,024 - INFO - Epoch: [488/600], Step: [119/591], Loss: 227547488.0, KL Divergence: 1063.80517578125, Reconstruction Loss: 227546432.0\n",
      "236it [00:21, 10.96it/s]2023-07-19 19:02:39,048 - INFO - Epoch: [488/600], Step: [237/591], Loss: 189359232.0, KL Divergence: 1085.3212890625, Reconstruction Loss: 189358144.0\n",
      "354it [00:32, 11.06it/s]2023-07-19 19:02:49,995 - INFO - Epoch: [488/600], Step: [355/591], Loss: 242667952.0, KL Divergence: 1083.27734375, Reconstruction Loss: 242666864.0\n",
      "472it [00:43, 10.80it/s]2023-07-19 19:03:01,021 - INFO - Epoch: [488/600], Step: [473/591], Loss: 195750400.0, KL Divergence: 1083.2415771484375, Reconstruction Loss: 195749312.0\n",
      "590it [00:55, 10.29it/s]2023-07-19 19:03:12,070 - INFO - Epoch: [488/600], Step: [591/591], Loss: 162808336.0, KL Divergence: 1075.2127685546875, Reconstruction Loss: 162807264.0\n",
      "591it [00:55, 10.73it/s]\n",
      "2023-07-19 19:03:12,071 - INFO - Epoch: [488/600], Total Loss: 12882259148800.0, Total KL Divergence: 81420879.265625, Total Reconstruction Loss: 12882177715200.0\n",
      "2023-07-19 19:03:12,116 - INFO - Save model at epoch 488\n",
      "0it [00:00, ?it/s]2023-07-19 19:03:12,227 - INFO - Epoch: [489/600], Step: [1/591], Loss: 107357856.0, KL Divergence: 1088.1339111328125, Reconstruction Loss: 107356768.0\n",
      "118it [00:10, 10.83it/s]2023-07-19 19:03:23,161 - INFO - Epoch: [489/600], Step: [119/591], Loss: 224586496.0, KL Divergence: 1069.1585693359375, Reconstruction Loss: 224585424.0\n",
      "236it [00:21, 10.75it/s]2023-07-19 19:03:34,160 - INFO - Epoch: [489/600], Step: [237/591], Loss: 180996400.0, KL Divergence: 1091.8280029296875, Reconstruction Loss: 180995312.0\n",
      "354it [00:32, 10.86it/s]2023-07-19 19:03:45,176 - INFO - Epoch: [489/600], Step: [355/591], Loss: 228772896.0, KL Divergence: 1081.5269775390625, Reconstruction Loss: 228771808.0\n",
      "472it [00:43, 11.04it/s]2023-07-19 19:03:56,175 - INFO - Epoch: [489/600], Step: [473/591], Loss: 195804480.0, KL Divergence: 1083.9537353515625, Reconstruction Loss: 195803392.0\n",
      "590it [00:54, 10.56it/s]2023-07-19 19:04:07,177 - INFO - Epoch: [489/600], Step: [591/591], Loss: 159820496.0, KL Divergence: 1067.760009765625, Reconstruction Loss: 159819424.0\n",
      "591it [00:55, 10.74it/s]\n",
      "2023-07-19 19:04:07,179 - INFO - Epoch: [489/600], Total Loss: 12913019747328.0, Total KL Divergence: 81600517.515625, Total Reconstruction Loss: 12912938161152.0\n",
      "2023-07-19 19:04:07,220 - INFO - Save model at epoch 489\n",
      "0it [00:00, ?it/s]2023-07-19 19:04:07,328 - INFO - Epoch: [490/600], Step: [1/591], Loss: 107997160.0, KL Divergence: 1083.6483154296875, Reconstruction Loss: 107996080.0\n",
      "118it [00:11, 10.71it/s]2023-07-19 19:04:18,446 - INFO - Epoch: [490/600], Step: [119/591], Loss: 239229936.0, KL Divergence: 1075.349609375, Reconstruction Loss: 239228864.0\n",
      "236it [00:22, 10.80it/s]2023-07-19 19:04:29,492 - INFO - Epoch: [490/600], Step: [237/591], Loss: 180107168.0, KL Divergence: 1092.55517578125, Reconstruction Loss: 180106080.0\n",
      "354it [00:33, 10.73it/s]2023-07-19 19:04:40,566 - INFO - Epoch: [490/600], Step: [355/591], Loss: 237149712.0, KL Divergence: 1079.818603515625, Reconstruction Loss: 237148640.0\n",
      "472it [00:44, 10.58it/s]2023-07-19 19:04:51,584 - INFO - Epoch: [490/600], Step: [473/591], Loss: 203583456.0, KL Divergence: 1082.375, Reconstruction Loss: 203582368.0\n",
      "590it [00:55, 10.74it/s]2023-07-19 19:05:02,650 - INFO - Epoch: [490/600], Step: [591/591], Loss: 164101008.0, KL Divergence: 1069.07666015625, Reconstruction Loss: 164099936.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 19:05:02,652 - INFO - Epoch: [490/600], Total Loss: 12812843552768.0, Total KL Divergence: 81596332.125, Total Reconstruction Loss: 12812761950208.0\n",
      "2023-07-19 19:05:02,694 - INFO - Save model at epoch 490\n",
      "0it [00:00, ?it/s]2023-07-19 19:05:02,809 - INFO - Epoch: [491/600], Step: [1/591], Loss: 107002400.0, KL Divergence: 1087.73876953125, Reconstruction Loss: 107001312.0\n",
      "118it [00:11, 10.66it/s]2023-07-19 19:05:13,816 - INFO - Epoch: [491/600], Step: [119/591], Loss: 251426640.0, KL Divergence: 1069.989013671875, Reconstruction Loss: 251425568.0\n",
      "236it [00:21, 10.66it/s]2023-07-19 19:05:24,761 - INFO - Epoch: [491/600], Step: [237/591], Loss: 184109168.0, KL Divergence: 1093.8643798828125, Reconstruction Loss: 184108080.0\n",
      "353it [00:32, 10.76it/s]2023-07-19 19:05:35,870 - INFO - Epoch: [491/600], Step: [355/591], Loss: 224615536.0, KL Divergence: 1076.0469970703125, Reconstruction Loss: 224614464.0\n",
      "471it [00:44, 10.73it/s]2023-07-19 19:05:46,904 - INFO - Epoch: [491/600], Step: [473/591], Loss: 195146592.0, KL Divergence: 1080.6572265625, Reconstruction Loss: 195145504.0\n",
      "590it [00:55, 10.21it/s]2023-07-19 19:05:57,914 - INFO - Epoch: [491/600], Step: [591/591], Loss: 162876592.0, KL Divergence: 1070.86083984375, Reconstruction Loss: 162875520.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 19:05:57,916 - INFO - Epoch: [491/600], Total Loss: 12909563487232.0, Total KL Divergence: 81296977.34375, Total Reconstruction Loss: 12909482151936.0\n",
      "2023-07-19 19:05:57,955 - INFO - Save model at epoch 491\n",
      "0it [00:00, ?it/s]2023-07-19 19:05:58,067 - INFO - Epoch: [492/600], Step: [1/591], Loss: 105615456.0, KL Divergence: 1086.2242431640625, Reconstruction Loss: 105614368.0\n",
      "118it [00:11, 10.57it/s]2023-07-19 19:06:09,099 - INFO - Epoch: [492/600], Step: [119/591], Loss: 241819376.0, KL Divergence: 1062.3348388671875, Reconstruction Loss: 241818320.0\n",
      "236it [00:22, 10.84it/s]2023-07-19 19:06:20,085 - INFO - Epoch: [492/600], Step: [237/591], Loss: 185168304.0, KL Divergence: 1091.052490234375, Reconstruction Loss: 185167216.0\n",
      "354it [00:33, 10.81it/s]2023-07-19 19:06:31,106 - INFO - Epoch: [492/600], Step: [355/591], Loss: 228354464.0, KL Divergence: 1082.1180419921875, Reconstruction Loss: 228353376.0\n",
      "472it [00:44, 10.55it/s]2023-07-19 19:06:42,280 - INFO - Epoch: [492/600], Step: [473/591], Loss: 200011792.0, KL Divergence: 1086.612060546875, Reconstruction Loss: 200010704.0\n",
      "590it [00:55, 10.57it/s]2023-07-19 19:06:53,401 - INFO - Epoch: [492/600], Step: [591/591], Loss: 159800400.0, KL Divergence: 1070.2728271484375, Reconstruction Loss: 159799328.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 19:06:53,403 - INFO - Epoch: [492/600], Total Loss: 12979915866112.0, Total KL Divergence: 81376191.53125, Total Reconstruction Loss: 12979834485760.0\n",
      "2023-07-19 19:06:53,443 - INFO - Save model at epoch 492\n",
      "0it [00:00, ?it/s]2023-07-19 19:06:53,572 - INFO - Epoch: [493/600], Step: [1/591], Loss: 106333280.0, KL Divergence: 1084.205810546875, Reconstruction Loss: 106332192.0\n",
      "117it [00:10, 10.86it/s]2023-07-19 19:07:04,628 - INFO - Epoch: [493/600], Step: [119/591], Loss: 226054064.0, KL Divergence: 1075.25830078125, Reconstruction Loss: 226052992.0\n",
      "235it [00:22, 10.75it/s]2023-07-19 19:07:15,699 - INFO - Epoch: [493/600], Step: [237/591], Loss: 180976800.0, KL Divergence: 1103.814208984375, Reconstruction Loss: 180975696.0\n",
      "353it [00:33, 10.88it/s]2023-07-19 19:07:26,754 - INFO - Epoch: [493/600], Step: [355/591], Loss: 227976736.0, KL Divergence: 1082.276123046875, Reconstruction Loss: 227975648.0\n",
      "471it [00:44, 10.77it/s]2023-07-19 19:07:37,814 - INFO - Epoch: [493/600], Step: [473/591], Loss: 200921600.0, KL Divergence: 1084.47265625, Reconstruction Loss: 200920512.0\n",
      "589it [00:55, 10.66it/s]2023-07-19 19:07:48,940 - INFO - Epoch: [493/600], Step: [591/591], Loss: 156471136.0, KL Divergence: 1072.3953857421875, Reconstruction Loss: 156470064.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 19:07:48,942 - INFO - Epoch: [493/600], Total Loss: 12932824597504.0, Total KL Divergence: 81778176.375, Total Reconstruction Loss: 12932742800384.0\n",
      "2023-07-19 19:07:48,987 - INFO - Save model at epoch 493\n",
      "0it [00:00, ?it/s]2023-07-19 19:07:49,094 - INFO - Epoch: [494/600], Step: [1/591], Loss: 106423056.0, KL Divergence: 1085.0933837890625, Reconstruction Loss: 106421968.0\n",
      "118it [00:11, 10.21it/s]2023-07-19 19:08:00,268 - INFO - Epoch: [494/600], Step: [119/591], Loss: 218711248.0, KL Divergence: 1076.429931640625, Reconstruction Loss: 218710176.0\n",
      "236it [00:22, 10.67it/s]2023-07-19 19:08:11,265 - INFO - Epoch: [494/600], Step: [237/591], Loss: 181779968.0, KL Divergence: 1097.6165771484375, Reconstruction Loss: 181778864.0\n",
      "354it [00:33, 10.67it/s]2023-07-19 19:08:22,336 - INFO - Epoch: [494/600], Step: [355/591], Loss: 234655136.0, KL Divergence: 1084.41015625, Reconstruction Loss: 234654048.0\n",
      "472it [00:44, 10.65it/s]2023-07-19 19:08:33,428 - INFO - Epoch: [494/600], Step: [473/591], Loss: 202326416.0, KL Divergence: 1084.014404296875, Reconstruction Loss: 202325328.0\n",
      "590it [00:55, 10.84it/s]2023-07-19 19:08:44,397 - INFO - Epoch: [494/600], Step: [591/591], Loss: 157247824.0, KL Divergence: 1078.219482421875, Reconstruction Loss: 157246752.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 19:08:44,399 - INFO - Epoch: [494/600], Total Loss: 12875655284736.0, Total KL Divergence: 81764153.84375, Total Reconstruction Loss: 12875573541888.0\n",
      "2023-07-19 19:08:44,446 - INFO - Save model at epoch 494\n",
      "0it [00:00, ?it/s]2023-07-19 19:08:44,565 - INFO - Epoch: [495/600], Step: [1/591], Loss: 104833560.0, KL Divergence: 1090.94775390625, Reconstruction Loss: 104832472.0\n",
      "118it [00:11, 10.86it/s]2023-07-19 19:08:55,575 - INFO - Epoch: [495/600], Step: [119/591], Loss: 217870544.0, KL Divergence: 1073.052001953125, Reconstruction Loss: 217869472.0\n",
      "236it [00:22, 10.52it/s]2023-07-19 19:09:06,645 - INFO - Epoch: [495/600], Step: [237/591], Loss: 179506912.0, KL Divergence: 1095.084228515625, Reconstruction Loss: 179505824.0\n",
      "354it [00:33, 10.93it/s]2023-07-19 19:09:17,697 - INFO - Epoch: [495/600], Step: [355/591], Loss: 227644992.0, KL Divergence: 1091.4490966796875, Reconstruction Loss: 227643904.0\n",
      "472it [00:44, 10.67it/s]2023-07-19 19:09:28,707 - INFO - Epoch: [495/600], Step: [473/591], Loss: 203398000.0, KL Divergence: 1086.0419921875, Reconstruction Loss: 203396912.0\n",
      "590it [00:55, 10.74it/s]2023-07-19 19:09:39,674 - INFO - Epoch: [495/600], Step: [591/591], Loss: 161416224.0, KL Divergence: 1079.2777099609375, Reconstruction Loss: 161415152.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 19:09:39,676 - INFO - Epoch: [495/600], Total Loss: 12916397511680.0, Total KL Divergence: 82005437.46875, Total Reconstruction Loss: 12916315521024.0\n",
      "2023-07-19 19:09:39,714 - INFO - Save model at epoch 495\n",
      "0it [00:00, ?it/s]2023-07-19 19:09:39,834 - INFO - Epoch: [496/600], Step: [1/591], Loss: 98385936.0, KL Divergence: 1091.452880859375, Reconstruction Loss: 98384848.0\n",
      "117it [00:10, 10.85it/s]2023-07-19 19:09:50,825 - INFO - Epoch: [496/600], Step: [119/591], Loss: 223108880.0, KL Divergence: 1073.807861328125, Reconstruction Loss: 223107808.0\n",
      "235it [00:21, 11.10it/s]2023-07-19 19:10:01,771 - INFO - Epoch: [496/600], Step: [237/591], Loss: 179402656.0, KL Divergence: 1089.79638671875, Reconstruction Loss: 179401568.0\n",
      "353it [00:32, 10.65it/s]2023-07-19 19:10:12,908 - INFO - Epoch: [496/600], Step: [355/591], Loss: 234849984.0, KL Divergence: 1093.140869140625, Reconstruction Loss: 234848896.0\n",
      "471it [00:43, 10.33it/s]2023-07-19 19:10:23,918 - INFO - Epoch: [496/600], Step: [473/591], Loss: 196472288.0, KL Divergence: 1096.6044921875, Reconstruction Loss: 196471184.0\n",
      "589it [00:55, 10.58it/s]2023-07-19 19:10:34,896 - INFO - Epoch: [496/600], Step: [591/591], Loss: 160998000.0, KL Divergence: 1093.972412109375, Reconstruction Loss: 160996912.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 19:10:34,897 - INFO - Epoch: [496/600], Total Loss: 12962597229568.0, Total KL Divergence: 82179851.578125, Total Reconstruction Loss: 12962515062784.0\n",
      "2023-07-19 19:10:34,940 - INFO - Save model at epoch 496\n",
      "0it [00:00, ?it/s]2023-07-19 19:10:35,053 - INFO - Epoch: [497/600], Step: [1/591], Loss: 103009032.0, KL Divergence: 1106.0771484375, Reconstruction Loss: 103007928.0\n",
      "117it [00:10, 10.73it/s]2023-07-19 19:10:46,042 - INFO - Epoch: [497/600], Step: [119/591], Loss: 232067888.0, KL Divergence: 1077.2403564453125, Reconstruction Loss: 232066816.0\n",
      "235it [00:21, 10.82it/s]2023-07-19 19:10:57,085 - INFO - Epoch: [497/600], Step: [237/591], Loss: 178398208.0, KL Divergence: 1091.6102294921875, Reconstruction Loss: 178397120.0\n",
      "353it [00:32, 11.20it/s]2023-07-19 19:11:08,115 - INFO - Epoch: [497/600], Step: [355/591], Loss: 239508928.0, KL Divergence: 1090.967041015625, Reconstruction Loss: 239507840.0\n",
      "471it [00:44, 10.40it/s]2023-07-19 19:11:19,184 - INFO - Epoch: [497/600], Step: [473/591], Loss: 192889584.0, KL Divergence: 1094.227294921875, Reconstruction Loss: 192888496.0\n",
      "589it [00:55, 10.23it/s]2023-07-19 19:11:30,170 - INFO - Epoch: [497/600], Step: [591/591], Loss: 157159280.0, KL Divergence: 1083.1773681640625, Reconstruction Loss: 157158192.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 19:11:30,172 - INFO - Epoch: [497/600], Total Loss: 12909202619392.0, Total KL Divergence: 82258192.5625, Total Reconstruction Loss: 12909120351232.0\n",
      "2023-07-19 19:11:30,216 - INFO - Save model at epoch 497\n",
      "0it [00:00, ?it/s]2023-07-19 19:11:30,340 - INFO - Epoch: [498/600], Step: [1/591], Loss: 101735296.0, KL Divergence: 1094.087890625, Reconstruction Loss: 101734200.0\n",
      "117it [00:11, 10.48it/s]2023-07-19 19:11:41,422 - INFO - Epoch: [498/600], Step: [119/591], Loss: 222009968.0, KL Divergence: 1075.049072265625, Reconstruction Loss: 222008896.0\n",
      "235it [00:21, 10.69it/s]2023-07-19 19:11:52,326 - INFO - Epoch: [498/600], Step: [237/591], Loss: 177689632.0, KL Divergence: 1091.562255859375, Reconstruction Loss: 177688544.0\n",
      "353it [00:32, 10.68it/s]2023-07-19 19:12:03,352 - INFO - Epoch: [498/600], Step: [355/591], Loss: 237546320.0, KL Divergence: 1087.504150390625, Reconstruction Loss: 237545232.0\n",
      "471it [00:43, 11.14it/s]2023-07-19 19:12:14,296 - INFO - Epoch: [498/600], Step: [473/591], Loss: 201064112.0, KL Divergence: 1090.801025390625, Reconstruction Loss: 201063024.0\n",
      "589it [00:54, 10.18it/s]2023-07-19 19:12:25,289 - INFO - Epoch: [498/600], Step: [591/591], Loss: 164602576.0, KL Divergence: 1077.0029296875, Reconstruction Loss: 164601504.0\n",
      "591it [00:55, 10.73it/s]\n",
      "2023-07-19 19:12:25,291 - INFO - Epoch: [498/600], Total Loss: 12853987167232.0, Total KL Divergence: 81989540.359375, Total Reconstruction Loss: 12853905196032.0\n",
      "2023-07-19 19:12:25,334 - INFO - Save model at epoch 498\n",
      "0it [00:00, ?it/s]2023-07-19 19:12:25,442 - INFO - Epoch: [499/600], Step: [1/591], Loss: 111463096.0, KL Divergence: 1088.49072265625, Reconstruction Loss: 111462008.0\n",
      "118it [00:10, 10.70it/s]2023-07-19 19:12:36,387 - INFO - Epoch: [499/600], Step: [119/591], Loss: 226397008.0, KL Divergence: 1072.9296875, Reconstruction Loss: 226395936.0\n",
      "236it [00:21, 10.62it/s]2023-07-19 19:12:47,395 - INFO - Epoch: [499/600], Step: [237/591], Loss: 180452128.0, KL Divergence: 1098.19677734375, Reconstruction Loss: 180451024.0\n",
      "354it [00:32, 10.82it/s]2023-07-19 19:12:58,413 - INFO - Epoch: [499/600], Step: [355/591], Loss: 236563344.0, KL Divergence: 1087.30224609375, Reconstruction Loss: 236562256.0\n",
      "472it [00:43, 10.73it/s]2023-07-19 19:13:09,426 - INFO - Epoch: [499/600], Step: [473/591], Loss: 197162608.0, KL Divergence: 1091.05908203125, Reconstruction Loss: 197161520.0\n",
      "590it [00:55,  9.50it/s]2023-07-19 19:13:20,471 - INFO - Epoch: [499/600], Step: [591/591], Loss: 160510880.0, KL Divergence: 1073.623779296875, Reconstruction Loss: 160509808.0\n",
      "591it [00:55, 10.72it/s]\n",
      "2023-07-19 19:13:20,472 - INFO - Epoch: [499/600], Total Loss: 12828711170048.0, Total KL Divergence: 82066811.484375, Total Reconstruction Loss: 12828629125120.0\n",
      "2023-07-19 19:13:20,512 - INFO - Save model at epoch 499\n",
      "0it [00:00, ?it/s]2023-07-19 19:13:20,624 - INFO - Epoch: [500/600], Step: [1/591], Loss: 108027560.0, KL Divergence: 1087.0498046875, Reconstruction Loss: 108026472.0\n",
      "118it [00:11, 10.88it/s]2023-07-19 19:13:31,710 - INFO - Epoch: [500/600], Step: [119/591], Loss: 231131152.0, KL Divergence: 1070.229736328125, Reconstruction Loss: 231130080.0\n",
      "236it [00:22, 10.89it/s]2023-07-19 19:13:42,683 - INFO - Epoch: [500/600], Step: [237/591], Loss: 179807280.0, KL Divergence: 1091.95654296875, Reconstruction Loss: 179806192.0\n",
      "354it [00:33, 10.55it/s]2023-07-19 19:13:53,806 - INFO - Epoch: [500/600], Step: [355/591], Loss: 232113440.0, KL Divergence: 1086.8154296875, Reconstruction Loss: 232112352.0\n",
      "472it [00:44, 10.46it/s]2023-07-19 19:14:04,830 - INFO - Epoch: [500/600], Step: [473/591], Loss: 198193632.0, KL Divergence: 1087.9971923828125, Reconstruction Loss: 198192544.0\n",
      "590it [00:55, 10.75it/s]2023-07-19 19:14:15,754 - INFO - Epoch: [500/600], Step: [591/591], Loss: 158576336.0, KL Divergence: 1079.597412109375, Reconstruction Loss: 158575264.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 19:14:15,755 - INFO - Epoch: [500/600], Total Loss: 12838403126272.0, Total KL Divergence: 81674925.140625, Total Reconstruction Loss: 12838321454080.0\n",
      "2023-07-19 19:14:15,794 - INFO - Save model at epoch 500\n",
      "0it [00:00, ?it/s]2023-07-19 19:14:15,974 - INFO - Epoch: [501/600], Step: [1/591], Loss: 98667096.0, KL Divergence: 1090.71533203125, Reconstruction Loss: 98666008.0\n",
      "118it [00:11, 10.64it/s]2023-07-19 19:14:27,127 - INFO - Epoch: [501/600], Step: [119/591], Loss: 223038432.0, KL Divergence: 1068.771728515625, Reconstruction Loss: 223037360.0\n",
      "236it [00:22, 11.00it/s]2023-07-19 19:14:38,162 - INFO - Epoch: [501/600], Step: [237/591], Loss: 181308256.0, KL Divergence: 1089.7650146484375, Reconstruction Loss: 181307168.0\n",
      "354it [00:33, 10.81it/s]2023-07-19 19:14:49,203 - INFO - Epoch: [501/600], Step: [355/591], Loss: 219741968.0, KL Divergence: 1091.729248046875, Reconstruction Loss: 219740880.0\n",
      "472it [00:44, 10.69it/s]2023-07-19 19:15:00,227 - INFO - Epoch: [501/600], Step: [473/591], Loss: 201556800.0, KL Divergence: 1094.56787109375, Reconstruction Loss: 201555712.0\n",
      "590it [00:55, 11.11it/s]2023-07-19 19:15:11,189 - INFO - Epoch: [501/600], Step: [591/591], Loss: 162843504.0, KL Divergence: 1083.118408203125, Reconstruction Loss: 162842416.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 19:15:11,191 - INFO - Epoch: [501/600], Total Loss: 12826834068480.0, Total KL Divergence: 81910551.421875, Total Reconstruction Loss: 12826752166912.0\n",
      "2023-07-19 19:15:11,290 - INFO - Save model at epoch 501\n",
      "0it [00:00, ?it/s]2023-07-19 19:15:11,391 - INFO - Epoch: [502/600], Step: [1/591], Loss: 105880912.0, KL Divergence: 1095.3184814453125, Reconstruction Loss: 105879816.0\n",
      "118it [00:10, 10.66it/s]2023-07-19 19:15:22,347 - INFO - Epoch: [502/600], Step: [119/591], Loss: 219378128.0, KL Divergence: 1066.416748046875, Reconstruction Loss: 219377056.0\n",
      "236it [00:22, 10.68it/s]2023-07-19 19:15:33,465 - INFO - Epoch: [502/600], Step: [237/591], Loss: 185954816.0, KL Divergence: 1092.2569580078125, Reconstruction Loss: 185953728.0\n",
      "353it [00:33, 10.70it/s]2023-07-19 19:15:44,663 - INFO - Epoch: [502/600], Step: [355/591], Loss: 219554976.0, KL Divergence: 1086.844482421875, Reconstruction Loss: 219553888.0\n",
      "471it [00:44, 10.90it/s]2023-07-19 19:15:55,614 - INFO - Epoch: [502/600], Step: [473/591], Loss: 213227712.0, KL Divergence: 1089.4638671875, Reconstruction Loss: 213226624.0\n",
      "589it [00:55, 10.55it/s]2023-07-19 19:16:06,638 - INFO - Epoch: [502/600], Step: [591/591], Loss: 167725440.0, KL Divergence: 1089.4267578125, Reconstruction Loss: 167724352.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 19:16:06,640 - INFO - Epoch: [502/600], Total Loss: 13029260566528.0, Total KL Divergence: 81881555.9375, Total Reconstruction Loss: 13029178682368.0\n",
      "2023-07-19 19:16:06,681 - INFO - Save model at epoch 502\n",
      "0it [00:00, ?it/s]2023-07-19 19:16:06,795 - INFO - Epoch: [503/600], Step: [1/591], Loss: 118361832.0, KL Divergence: 1104.6739501953125, Reconstruction Loss: 118360728.0\n",
      "117it [00:10, 10.61it/s]2023-07-19 19:16:17,864 - INFO - Epoch: [503/600], Step: [119/591], Loss: 231207728.0, KL Divergence: 1079.710693359375, Reconstruction Loss: 231206656.0\n",
      "235it [00:22, 11.10it/s]2023-07-19 19:16:28,902 - INFO - Epoch: [503/600], Step: [237/591], Loss: 181272784.0, KL Divergence: 1104.64892578125, Reconstruction Loss: 181271680.0\n",
      "353it [00:32, 10.90it/s]2023-07-19 19:16:39,861 - INFO - Epoch: [503/600], Step: [355/591], Loss: 220819440.0, KL Divergence: 1092.092529296875, Reconstruction Loss: 220818352.0\n",
      "471it [00:43, 10.99it/s]2023-07-19 19:16:50,880 - INFO - Epoch: [503/600], Step: [473/591], Loss: 211814528.0, KL Divergence: 1105.450927734375, Reconstruction Loss: 211813424.0\n",
      "589it [00:55, 10.71it/s]2023-07-19 19:17:01,910 - INFO - Epoch: [503/600], Step: [591/591], Loss: 165597152.0, KL Divergence: 1088.336181640625, Reconstruction Loss: 165596064.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 19:17:01,912 - INFO - Epoch: [503/600], Total Loss: 12913861118976.0, Total KL Divergence: 82568932.25, Total Reconstruction Loss: 12913778546688.0\n",
      "2023-07-19 19:17:01,952 - INFO - Save model at epoch 503\n",
      "0it [00:00, ?it/s]2023-07-19 19:17:02,061 - INFO - Epoch: [504/600], Step: [1/591], Loss: 127356888.0, KL Divergence: 1099.3388671875, Reconstruction Loss: 127355792.0\n",
      "118it [00:11, 10.59it/s]2023-07-19 19:17:13,099 - INFO - Epoch: [504/600], Step: [119/591], Loss: 222500912.0, KL Divergence: 1079.1658935546875, Reconstruction Loss: 222499840.0\n",
      "236it [00:22, 10.64it/s]2023-07-19 19:17:24,263 - INFO - Epoch: [504/600], Step: [237/591], Loss: 180339392.0, KL Divergence: 1108.75244140625, Reconstruction Loss: 180338288.0\n",
      "354it [00:33, 10.76it/s]2023-07-19 19:17:35,339 - INFO - Epoch: [504/600], Step: [355/591], Loss: 228976880.0, KL Divergence: 1097.915771484375, Reconstruction Loss: 228975776.0\n",
      "472it [00:44, 10.50it/s]2023-07-19 19:17:46,447 - INFO - Epoch: [504/600], Step: [473/591], Loss: 208124720.0, KL Divergence: 1108.89892578125, Reconstruction Loss: 208123616.0\n",
      "590it [00:55, 10.42it/s]2023-07-19 19:17:57,479 - INFO - Epoch: [504/600], Step: [591/591], Loss: 153709088.0, KL Divergence: 1098.119140625, Reconstruction Loss: 153707984.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 19:17:57,481 - INFO - Epoch: [504/600], Total Loss: 12801444060160.0, Total KL Divergence: 82759241.578125, Total Reconstruction Loss: 12801361309696.0\n",
      "2023-07-19 19:17:57,526 - INFO - Save model at epoch 504\n",
      "0it [00:00, ?it/s]2023-07-19 19:17:57,625 - INFO - Epoch: [505/600], Step: [1/591], Loss: 110962184.0, KL Divergence: 1111.921630859375, Reconstruction Loss: 110961072.0\n",
      "118it [00:11, 10.55it/s]2023-07-19 19:18:08,674 - INFO - Epoch: [505/600], Step: [119/591], Loss: 224033104.0, KL Divergence: 1091.44482421875, Reconstruction Loss: 224032016.0\n",
      "236it [00:21, 11.16it/s]2023-07-19 19:18:19,605 - INFO - Epoch: [505/600], Step: [237/591], Loss: 180147872.0, KL Divergence: 1109.41796875, Reconstruction Loss: 180146768.0\n",
      "354it [00:33, 10.85it/s]2023-07-19 19:18:30,631 - INFO - Epoch: [505/600], Step: [355/591], Loss: 222253328.0, KL Divergence: 1097.9150390625, Reconstruction Loss: 222252224.0\n",
      "472it [00:44, 10.46it/s]2023-07-19 19:18:41,788 - INFO - Epoch: [505/600], Step: [473/591], Loss: 193526640.0, KL Divergence: 1099.317138671875, Reconstruction Loss: 193525536.0\n",
      "590it [00:55, 10.72it/s]2023-07-19 19:18:52,884 - INFO - Epoch: [505/600], Step: [591/591], Loss: 157062528.0, KL Divergence: 1089.9879150390625, Reconstruction Loss: 157061440.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 19:18:52,887 - INFO - Epoch: [505/600], Total Loss: 12843193448448.0, Total KL Divergence: 82948506.15625, Total Reconstruction Loss: 12843110507520.0\n",
      "2023-07-19 19:18:52,934 - INFO - Save model at epoch 505\n",
      "0it [00:00, ?it/s]2023-07-19 19:18:53,038 - INFO - Epoch: [506/600], Step: [1/591], Loss: 98165760.0, KL Divergence: 1106.783447265625, Reconstruction Loss: 98164656.0\n",
      "118it [00:11, 10.84it/s]2023-07-19 19:19:04,109 - INFO - Epoch: [506/600], Step: [119/591], Loss: 220186624.0, KL Divergence: 1088.6287841796875, Reconstruction Loss: 220185536.0\n",
      "236it [00:22, 10.88it/s]2023-07-19 19:19:15,249 - INFO - Epoch: [506/600], Step: [237/591], Loss: 177781920.0, KL Divergence: 1106.087646484375, Reconstruction Loss: 177780816.0\n",
      "354it [00:33, 10.67it/s]2023-07-19 19:19:26,285 - INFO - Epoch: [506/600], Step: [355/591], Loss: 219775904.0, KL Divergence: 1101.9241943359375, Reconstruction Loss: 219774800.0\n",
      "472it [00:44, 10.34it/s]2023-07-19 19:19:37,421 - INFO - Epoch: [506/600], Step: [473/591], Loss: 204587776.0, KL Divergence: 1089.056884765625, Reconstruction Loss: 204586688.0\n",
      "590it [00:55, 10.65it/s]2023-07-19 19:19:48,435 - INFO - Epoch: [506/600], Step: [591/591], Loss: 156203216.0, KL Divergence: 1086.3017578125, Reconstruction Loss: 156202128.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 19:19:48,436 - INFO - Epoch: [506/600], Total Loss: 12957346158592.0, Total KL Divergence: 82500275.546875, Total Reconstruction Loss: 12957263677440.0\n",
      "2023-07-19 19:19:48,480 - INFO - Save model at epoch 506\n",
      "0it [00:00, ?it/s]2023-07-19 19:19:48,614 - INFO - Epoch: [507/600], Step: [1/591], Loss: 103582552.0, KL Divergence: 1101.755615234375, Reconstruction Loss: 103581448.0\n",
      "117it [00:11, 10.50it/s]2023-07-19 19:19:59,784 - INFO - Epoch: [507/600], Step: [119/591], Loss: 225813472.0, KL Divergence: 1081.0045166015625, Reconstruction Loss: 225812384.0\n",
      "235it [00:22, 10.41it/s]2023-07-19 19:20:10,712 - INFO - Epoch: [507/600], Step: [237/591], Loss: 179117392.0, KL Divergence: 1101.89697265625, Reconstruction Loss: 179116288.0\n",
      "353it [00:33, 11.10it/s]2023-07-19 19:20:21,809 - INFO - Epoch: [507/600], Step: [355/591], Loss: 221005280.0, KL Divergence: 1093.9835205078125, Reconstruction Loss: 221004192.0\n",
      "471it [00:44, 10.79it/s]2023-07-19 19:20:32,866 - INFO - Epoch: [507/600], Step: [473/591], Loss: 197543232.0, KL Divergence: 1099.6119384765625, Reconstruction Loss: 197542128.0\n",
      "589it [00:55, 10.80it/s]2023-07-19 19:20:43,880 - INFO - Epoch: [507/600], Step: [591/591], Loss: 157022128.0, KL Divergence: 1092.554931640625, Reconstruction Loss: 157021040.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 19:20:43,883 - INFO - Epoch: [507/600], Total Loss: 12971103442944.0, Total KL Divergence: 82349013.78125, Total Reconstruction Loss: 12971021090816.0\n",
      "2023-07-19 19:20:43,924 - INFO - Save model at epoch 507\n",
      "0it [00:00, ?it/s]2023-07-19 19:20:44,031 - INFO - Epoch: [508/600], Step: [1/591], Loss: 102167592.0, KL Divergence: 1101.21826171875, Reconstruction Loss: 102166488.0\n",
      "118it [00:11, 10.16it/s]2023-07-19 19:20:55,121 - INFO - Epoch: [508/600], Step: [119/591], Loss: 218329888.0, KL Divergence: 1081.330810546875, Reconstruction Loss: 218328800.0\n",
      "236it [00:22, 10.97it/s]2023-07-19 19:21:06,146 - INFO - Epoch: [508/600], Step: [237/591], Loss: 177765072.0, KL Divergence: 1100.936279296875, Reconstruction Loss: 177763968.0\n",
      "354it [00:33, 10.47it/s]2023-07-19 19:21:17,242 - INFO - Epoch: [508/600], Step: [355/591], Loss: 227174544.0, KL Divergence: 1098.12353515625, Reconstruction Loss: 227173440.0\n",
      "472it [00:44, 11.02it/s]2023-07-19 19:21:28,142 - INFO - Epoch: [508/600], Step: [473/591], Loss: 190991168.0, KL Divergence: 1092.680419921875, Reconstruction Loss: 190990080.0\n",
      "590it [00:55, 10.72it/s]2023-07-19 19:21:39,145 - INFO - Epoch: [508/600], Step: [591/591], Loss: 146976752.0, KL Divergence: 1085.631591796875, Reconstruction Loss: 146975664.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 19:21:39,148 - INFO - Epoch: [508/600], Total Loss: 12892300495872.0, Total KL Divergence: 82392289.84375, Total Reconstruction Loss: 12892218117120.0\n",
      "2023-07-19 19:21:39,202 - INFO - Save model at epoch 508\n",
      "0it [00:00, ?it/s]2023-07-19 19:21:39,313 - INFO - Epoch: [509/600], Step: [1/591], Loss: 106085752.0, KL Divergence: 1097.09716796875, Reconstruction Loss: 106084656.0\n",
      "118it [00:10, 10.80it/s]2023-07-19 19:21:50,313 - INFO - Epoch: [509/600], Step: [119/591], Loss: 234184256.0, KL Divergence: 1073.833984375, Reconstruction Loss: 234183184.0\n",
      "236it [00:22, 10.87it/s]2023-07-19 19:22:01,320 - INFO - Epoch: [509/600], Step: [237/591], Loss: 177146640.0, KL Divergence: 1086.116455078125, Reconstruction Loss: 177145552.0\n",
      "354it [00:33, 10.74it/s]2023-07-19 19:22:12,422 - INFO - Epoch: [509/600], Step: [355/591], Loss: 235905552.0, KL Divergence: 1087.380859375, Reconstruction Loss: 235904464.0\n",
      "472it [00:44, 10.73it/s]2023-07-19 19:22:23,406 - INFO - Epoch: [509/600], Step: [473/591], Loss: 191180512.0, KL Divergence: 1081.7379150390625, Reconstruction Loss: 191179424.0\n",
      "590it [00:55, 10.73it/s]2023-07-19 19:22:34,404 - INFO - Epoch: [509/600], Step: [591/591], Loss: 154716448.0, KL Divergence: 1076.5911865234375, Reconstruction Loss: 154715376.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 19:22:34,406 - INFO - Epoch: [509/600], Total Loss: 12846540003328.0, Total KL Divergence: 81646403.171875, Total Reconstruction Loss: 12846458358784.0\n",
      "2023-07-19 19:22:34,477 - INFO - Save model at epoch 509\n",
      "0it [00:00, ?it/s]2023-07-19 19:22:34,581 - INFO - Epoch: [510/600], Step: [1/591], Loss: 112295224.0, KL Divergence: 1088.6236572265625, Reconstruction Loss: 112294136.0\n",
      "118it [00:11, 10.78it/s]2023-07-19 19:22:45,714 - INFO - Epoch: [510/600], Step: [119/591], Loss: 218384960.0, KL Divergence: 1061.7703857421875, Reconstruction Loss: 218383904.0\n",
      "236it [00:22, 10.45it/s]2023-07-19 19:22:56,742 - INFO - Epoch: [510/600], Step: [237/591], Loss: 176223824.0, KL Divergence: 1077.958251953125, Reconstruction Loss: 176222752.0\n",
      "354it [00:33, 10.98it/s]2023-07-19 19:23:07,772 - INFO - Epoch: [510/600], Step: [355/591], Loss: 222914544.0, KL Divergence: 1084.5859375, Reconstruction Loss: 222913456.0\n",
      "472it [00:44, 10.79it/s]2023-07-19 19:23:18,767 - INFO - Epoch: [510/600], Step: [473/591], Loss: 191647456.0, KL Divergence: 1083.39208984375, Reconstruction Loss: 191646368.0\n",
      "590it [00:55, 10.37it/s]2023-07-19 19:23:29,857 - INFO - Epoch: [510/600], Step: [591/591], Loss: 180830928.0, KL Divergence: 1076.63671875, Reconstruction Loss: 180829856.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 19:23:29,859 - INFO - Epoch: [510/600], Total Loss: 12710254967808.0, Total KL Divergence: 81413130.84375, Total Reconstruction Loss: 12710173552640.0\n",
      "2023-07-19 19:23:29,897 - INFO - Save model at epoch 510\n",
      "0it [00:00, ?it/s]2023-07-19 19:23:30,015 - INFO - Epoch: [511/600], Step: [1/591], Loss: 101365888.0, KL Divergence: 1091.38525390625, Reconstruction Loss: 101364800.0\n",
      "117it [00:10, 10.94it/s]2023-07-19 19:23:41,093 - INFO - Epoch: [511/600], Step: [119/591], Loss: 214756720.0, KL Divergence: 1074.9027099609375, Reconstruction Loss: 214755648.0\n",
      "235it [00:22, 10.35it/s]2023-07-19 19:23:52,194 - INFO - Epoch: [511/600], Step: [237/591], Loss: 181592384.0, KL Divergence: 1087.861572265625, Reconstruction Loss: 181591296.0\n",
      "353it [00:33, 10.78it/s]2023-07-19 19:24:03,334 - INFO - Epoch: [511/600], Step: [355/591], Loss: 219966320.0, KL Divergence: 1096.652587890625, Reconstruction Loss: 219965216.0\n",
      "471it [00:44, 10.31it/s]2023-07-19 19:24:14,479 - INFO - Epoch: [511/600], Step: [473/591], Loss: 193097344.0, KL Divergence: 1086.5941162109375, Reconstruction Loss: 193096256.0\n",
      "589it [00:55, 10.68it/s]2023-07-19 19:24:25,527 - INFO - Epoch: [511/600], Step: [591/591], Loss: 149431696.0, KL Divergence: 1081.8123779296875, Reconstruction Loss: 149430608.0\n",
      "591it [00:55, 10.63it/s]\n",
      "2023-07-19 19:24:25,529 - INFO - Epoch: [511/600], Total Loss: 12682132290560.0, Total KL Divergence: 82013190.640625, Total Reconstruction Loss: 12682050281472.0\n",
      "2023-07-19 19:24:25,588 - INFO - Save model at epoch 511\n",
      "0it [00:00, ?it/s]2023-07-19 19:24:25,699 - INFO - Epoch: [512/600], Step: [1/591], Loss: 100043040.0, KL Divergence: 1100.1982421875, Reconstruction Loss: 100041936.0\n",
      "117it [00:11, 10.93it/s]2023-07-19 19:24:36,886 - INFO - Epoch: [512/600], Step: [119/591], Loss: 217508848.0, KL Divergence: 1075.078125, Reconstruction Loss: 217507776.0\n",
      "235it [00:22, 10.92it/s]2023-07-19 19:24:47,945 - INFO - Epoch: [512/600], Step: [237/591], Loss: 177135520.0, KL Divergence: 1093.176025390625, Reconstruction Loss: 177134432.0\n",
      "353it [00:33, 10.47it/s]2023-07-19 19:24:59,022 - INFO - Epoch: [512/600], Step: [355/591], Loss: 227554992.0, KL Divergence: 1100.341064453125, Reconstruction Loss: 227553888.0\n",
      "471it [00:44, 10.38it/s]2023-07-19 19:25:10,125 - INFO - Epoch: [512/600], Step: [473/591], Loss: 198356128.0, KL Divergence: 1084.5478515625, Reconstruction Loss: 198355040.0\n",
      "589it [00:55, 10.72it/s]2023-07-19 19:25:21,130 - INFO - Epoch: [512/600], Step: [591/591], Loss: 154875760.0, KL Divergence: 1085.759765625, Reconstruction Loss: 154874672.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 19:25:21,131 - INFO - Epoch: [512/600], Total Loss: 12617143629824.0, Total KL Divergence: 82049942.5625, Total Reconstruction Loss: 12617061591040.0\n",
      "2023-07-19 19:25:21,187 - INFO - Save model at epoch 512\n",
      "0it [00:00, ?it/s]2023-07-19 19:25:21,301 - INFO - Epoch: [513/600], Step: [1/591], Loss: 103604664.0, KL Divergence: 1103.664794921875, Reconstruction Loss: 103603560.0\n",
      "118it [00:11, 10.63it/s]2023-07-19 19:25:32,490 - INFO - Epoch: [513/600], Step: [119/591], Loss: 220801504.0, KL Divergence: 1084.32177734375, Reconstruction Loss: 220800416.0\n",
      "236it [00:22, 10.50it/s]2023-07-19 19:25:43,706 - INFO - Epoch: [513/600], Step: [237/591], Loss: 176211408.0, KL Divergence: 1107.551025390625, Reconstruction Loss: 176210304.0\n",
      "354it [00:33, 10.48it/s]2023-07-19 19:25:54,847 - INFO - Epoch: [513/600], Step: [355/591], Loss: 222285200.0, KL Divergence: 1107.234619140625, Reconstruction Loss: 222284096.0\n",
      "472it [00:44, 10.33it/s]2023-07-19 19:26:05,853 - INFO - Epoch: [513/600], Step: [473/591], Loss: 188069792.0, KL Divergence: 1097.308837890625, Reconstruction Loss: 188068688.0\n",
      "590it [00:55, 10.85it/s]2023-07-19 19:26:16,902 - INFO - Epoch: [513/600], Step: [591/591], Loss: 156574192.0, KL Divergence: 1097.010986328125, Reconstruction Loss: 156573088.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 19:26:16,904 - INFO - Epoch: [513/600], Total Loss: 12629351043072.0, Total KL Divergence: 82763489.671875, Total Reconstruction Loss: 12629268280320.0\n",
      "2023-07-19 19:26:16,946 - INFO - Save model at epoch 513\n",
      "0it [00:00, ?it/s]2023-07-19 19:26:17,056 - INFO - Epoch: [514/600], Step: [1/591], Loss: 104873112.0, KL Divergence: 1111.323486328125, Reconstruction Loss: 104872000.0\n",
      "118it [00:11, 11.06it/s]2023-07-19 19:26:28,146 - INFO - Epoch: [514/600], Step: [119/591], Loss: 217432368.0, KL Divergence: 1085.823486328125, Reconstruction Loss: 217431280.0\n",
      "236it [00:22, 10.88it/s]2023-07-19 19:26:39,239 - INFO - Epoch: [514/600], Step: [237/591], Loss: 175607408.0, KL Divergence: 1102.559814453125, Reconstruction Loss: 175606304.0\n",
      "353it [00:33, 10.50it/s]2023-07-19 19:26:50,425 - INFO - Epoch: [514/600], Step: [355/591], Loss: 223542976.0, KL Divergence: 1094.3763427734375, Reconstruction Loss: 223541888.0\n",
      "471it [00:44, 10.95it/s]2023-07-19 19:27:01,387 - INFO - Epoch: [514/600], Step: [473/591], Loss: 187366000.0, KL Divergence: 1097.1822509765625, Reconstruction Loss: 187364896.0\n",
      "589it [00:55, 10.53it/s]2023-07-19 19:27:12,508 - INFO - Epoch: [514/600], Step: [591/591], Loss: 166098736.0, KL Divergence: 1086.75537109375, Reconstruction Loss: 166097648.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 19:27:12,510 - INFO - Epoch: [514/600], Total Loss: 12611092758528.0, Total KL Divergence: 82504724.359375, Total Reconstruction Loss: 12611010258944.0\n",
      "2023-07-19 19:27:12,555 - INFO - Save model at epoch 514\n",
      "0it [00:00, ?it/s]2023-07-19 19:27:12,674 - INFO - Epoch: [515/600], Step: [1/591], Loss: 103045040.0, KL Divergence: 1105.0526123046875, Reconstruction Loss: 103043936.0\n",
      "117it [00:10, 10.55it/s]2023-07-19 19:27:23,694 - INFO - Epoch: [515/600], Step: [119/591], Loss: 222005664.0, KL Divergence: 1078.8988037109375, Reconstruction Loss: 222004592.0\n",
      "235it [00:21, 10.84it/s]2023-07-19 19:27:34,682 - INFO - Epoch: [515/600], Step: [237/591], Loss: 179035600.0, KL Divergence: 1105.085205078125, Reconstruction Loss: 179034496.0\n",
      "353it [00:33, 10.55it/s]2023-07-19 19:27:45,939 - INFO - Epoch: [515/600], Step: [355/591], Loss: 220722320.0, KL Divergence: 1098.841796875, Reconstruction Loss: 220721216.0\n",
      "471it [00:44, 10.83it/s]2023-07-19 19:27:56,971 - INFO - Epoch: [515/600], Step: [473/591], Loss: 190764240.0, KL Divergence: 1093.269775390625, Reconstruction Loss: 190763152.0\n",
      "589it [00:55, 10.79it/s]2023-07-19 19:28:07,979 - INFO - Epoch: [515/600], Step: [591/591], Loss: 166168656.0, KL Divergence: 1092.260009765625, Reconstruction Loss: 166167568.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 19:28:07,980 - INFO - Epoch: [515/600], Total Loss: 12588409664512.0, Total KL Divergence: 82350326.890625, Total Reconstruction Loss: 12588327286784.0\n",
      "2023-07-19 19:28:08,022 - INFO - Save model at epoch 515\n",
      "0it [00:00, ?it/s]2023-07-19 19:28:08,143 - INFO - Epoch: [516/600], Step: [1/591], Loss: 97364400.0, KL Divergence: 1108.0689697265625, Reconstruction Loss: 97363288.0\n",
      "118it [00:11, 10.50it/s]2023-07-19 19:28:19,380 - INFO - Epoch: [516/600], Step: [119/591], Loss: 227404080.0, KL Divergence: 1076.5498046875, Reconstruction Loss: 227403008.0\n",
      "236it [00:22, 10.73it/s]2023-07-19 19:28:30,295 - INFO - Epoch: [516/600], Step: [237/591], Loss: 176516416.0, KL Divergence: 1106.728515625, Reconstruction Loss: 176515312.0\n",
      "354it [00:33, 10.87it/s]2023-07-19 19:28:41,381 - INFO - Epoch: [516/600], Step: [355/591], Loss: 226361568.0, KL Divergence: 1098.192138671875, Reconstruction Loss: 226360464.0\n",
      "472it [00:44, 10.53it/s]2023-07-19 19:28:52,450 - INFO - Epoch: [516/600], Step: [473/591], Loss: 187098752.0, KL Divergence: 1093.9300537109375, Reconstruction Loss: 187097664.0\n",
      "590it [00:55, 10.50it/s]2023-07-19 19:29:03,523 - INFO - Epoch: [516/600], Step: [591/591], Loss: 157855280.0, KL Divergence: 1091.952392578125, Reconstruction Loss: 157854192.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 19:29:03,526 - INFO - Epoch: [516/600], Total Loss: 12516873128960.0, Total KL Divergence: 82395774.5625, Total Reconstruction Loss: 12516790735872.0\n",
      "2023-07-19 19:29:03,575 - INFO - Save model at epoch 516\n",
      "0it [00:00, ?it/s]2023-07-19 19:29:03,687 - INFO - Epoch: [517/600], Step: [1/591], Loss: 100229952.0, KL Divergence: 1104.634765625, Reconstruction Loss: 100228848.0\n",
      "117it [00:10, 11.02it/s]2023-07-19 19:29:14,773 - INFO - Epoch: [517/600], Step: [119/591], Loss: 230917616.0, KL Divergence: 1077.228515625, Reconstruction Loss: 230916544.0\n",
      "235it [00:21, 10.97it/s]2023-07-19 19:29:25,729 - INFO - Epoch: [517/600], Step: [237/591], Loss: 176904928.0, KL Divergence: 1095.5792236328125, Reconstruction Loss: 176903840.0\n",
      "353it [00:33, 10.55it/s]2023-07-19 19:29:36,914 - INFO - Epoch: [517/600], Step: [355/591], Loss: 223515776.0, KL Divergence: 1090.2198486328125, Reconstruction Loss: 223514688.0\n",
      "471it [00:44, 11.13it/s]2023-07-19 19:29:47,848 - INFO - Epoch: [517/600], Step: [473/591], Loss: 193597312.0, KL Divergence: 1087.138671875, Reconstruction Loss: 193596224.0\n",
      "589it [00:55, 11.08it/s]2023-07-19 19:29:58,779 - INFO - Epoch: [517/600], Step: [591/591], Loss: 147893120.0, KL Divergence: 1083.6292724609375, Reconstruction Loss: 147892032.0\n",
      "591it [00:55, 10.71it/s]\n",
      "2023-07-19 19:29:58,780 - INFO - Epoch: [517/600], Total Loss: 12489297057792.0, Total KL Divergence: 81946861.5, Total Reconstruction Loss: 12489215107072.0\n",
      "2023-07-19 19:29:58,820 - INFO - Save model at epoch 517\n",
      "0it [00:00, ?it/s]2023-07-19 19:29:58,935 - INFO - Epoch: [518/600], Step: [1/591], Loss: 104181352.0, KL Divergence: 1101.9056396484375, Reconstruction Loss: 104180248.0\n",
      "118it [00:11, 10.91it/s]2023-07-19 19:30:10,020 - INFO - Epoch: [518/600], Step: [119/591], Loss: 229648784.0, KL Divergence: 1079.0445556640625, Reconstruction Loss: 229647712.0\n",
      "236it [00:22, 10.61it/s]2023-07-19 19:30:21,040 - INFO - Epoch: [518/600], Step: [237/591], Loss: 185551280.0, KL Divergence: 1098.2940673828125, Reconstruction Loss: 185550176.0\n",
      "354it [00:33, 10.84it/s]2023-07-19 19:30:32,074 - INFO - Epoch: [518/600], Step: [355/591], Loss: 225756592.0, KL Divergence: 1079.742431640625, Reconstruction Loss: 225755520.0\n",
      "472it [00:44, 10.35it/s]2023-07-19 19:30:43,064 - INFO - Epoch: [518/600], Step: [473/591], Loss: 204639568.0, KL Divergence: 1087.4072265625, Reconstruction Loss: 204638480.0\n",
      "590it [00:55, 10.42it/s]2023-07-19 19:30:54,179 - INFO - Epoch: [518/600], Step: [591/591], Loss: 149098912.0, KL Divergence: 1083.018310546875, Reconstruction Loss: 149097824.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 19:30:54,181 - INFO - Epoch: [518/600], Total Loss: 12758467935232.0, Total KL Divergence: 81781602.328125, Total Reconstruction Loss: 12758386131968.0\n",
      "2023-07-19 19:30:54,221 - INFO - Save model at epoch 518\n",
      "0it [00:00, ?it/s]2023-07-19 19:30:54,335 - INFO - Epoch: [519/600], Step: [1/591], Loss: 99727744.0, KL Divergence: 1095.9232177734375, Reconstruction Loss: 99726648.0\n",
      "118it [00:11, 10.82it/s]2023-07-19 19:31:05,464 - INFO - Epoch: [519/600], Step: [119/591], Loss: 212308752.0, KL Divergence: 1069.30322265625, Reconstruction Loss: 212307680.0\n",
      "236it [00:22, 10.52it/s]2023-07-19 19:31:16,493 - INFO - Epoch: [519/600], Step: [237/591], Loss: 181189088.0, KL Divergence: 1102.191650390625, Reconstruction Loss: 181187984.0\n",
      "354it [00:33, 10.93it/s]2023-07-19 19:31:27,626 - INFO - Epoch: [519/600], Step: [355/591], Loss: 238045632.0, KL Divergence: 1084.552490234375, Reconstruction Loss: 238044544.0\n",
      "472it [00:44, 10.39it/s]2023-07-19 19:31:38,800 - INFO - Epoch: [519/600], Step: [473/591], Loss: 188448432.0, KL Divergence: 1097.4937744140625, Reconstruction Loss: 188447328.0\n",
      "590it [00:55, 10.78it/s]2023-07-19 19:31:49,806 - INFO - Epoch: [519/600], Step: [591/591], Loss: 155236464.0, KL Divergence: 1082.3529052734375, Reconstruction Loss: 155235376.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 19:31:49,808 - INFO - Epoch: [519/600], Total Loss: 12830742976512.0, Total KL Divergence: 81894478.34375, Total Reconstruction Loss: 12830661076992.0\n",
      "2023-07-19 19:31:49,858 - INFO - Save model at epoch 519\n",
      "0it [00:00, ?it/s]2023-07-19 19:31:49,963 - INFO - Epoch: [520/600], Step: [1/591], Loss: 103305848.0, KL Divergence: 1096.14990234375, Reconstruction Loss: 103304752.0\n",
      "118it [00:11, 11.00it/s]2023-07-19 19:32:01,002 - INFO - Epoch: [520/600], Step: [119/591], Loss: 215948432.0, KL Divergence: 1074.71484375, Reconstruction Loss: 215947360.0\n",
      "236it [00:22, 10.90it/s]2023-07-19 19:32:12,047 - INFO - Epoch: [520/600], Step: [237/591], Loss: 177615824.0, KL Divergence: 1108.444580078125, Reconstruction Loss: 177614720.0\n",
      "353it [00:33, 10.88it/s]2023-07-19 19:32:23,192 - INFO - Epoch: [520/600], Step: [355/591], Loss: 221081488.0, KL Divergence: 1093.693359375, Reconstruction Loss: 221080400.0\n",
      "471it [00:44, 10.48it/s]2023-07-19 19:32:34,333 - INFO - Epoch: [520/600], Step: [473/591], Loss: 185181072.0, KL Divergence: 1102.5574951171875, Reconstruction Loss: 185179968.0\n",
      "589it [00:55, 10.74it/s]2023-07-19 19:32:45,432 - INFO - Epoch: [520/600], Step: [591/591], Loss: 175542768.0, KL Divergence: 1086.98193359375, Reconstruction Loss: 175541680.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 19:32:45,434 - INFO - Epoch: [520/600], Total Loss: 12685278985216.0, Total KL Divergence: 82464137.15625, Total Reconstruction Loss: 12685196520448.0\n",
      "2023-07-19 19:32:45,504 - INFO - Save model at epoch 520\n",
      "0it [00:00, ?it/s]2023-07-19 19:32:45,613 - INFO - Epoch: [521/600], Step: [1/591], Loss: 97955968.0, KL Divergence: 1101.62841796875, Reconstruction Loss: 97954864.0\n",
      "118it [00:11, 10.84it/s]2023-07-19 19:32:56,691 - INFO - Epoch: [521/600], Step: [119/591], Loss: 220445536.0, KL Divergence: 1080.031005859375, Reconstruction Loss: 220444448.0\n",
      "236it [00:22, 10.73it/s]2023-07-19 19:33:07,720 - INFO - Epoch: [521/600], Step: [237/591], Loss: 175058464.0, KL Divergence: 1108.9169921875, Reconstruction Loss: 175057360.0\n",
      "353it [00:33, 10.62it/s]2023-07-19 19:33:18,934 - INFO - Epoch: [521/600], Step: [355/591], Loss: 219467664.0, KL Divergence: 1100.1728515625, Reconstruction Loss: 219466560.0\n",
      "471it [00:44, 10.50it/s]2023-07-19 19:33:30,025 - INFO - Epoch: [521/600], Step: [473/591], Loss: 192633888.0, KL Divergence: 1104.27880859375, Reconstruction Loss: 192632784.0\n",
      "589it [00:55, 10.36it/s]2023-07-19 19:33:41,215 - INFO - Epoch: [521/600], Step: [591/591], Loss: 153188512.0, KL Divergence: 1091.715576171875, Reconstruction Loss: 153187424.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 19:33:41,217 - INFO - Epoch: [521/600], Total Loss: 12700958314496.0, Total KL Divergence: 82624879.40625, Total Reconstruction Loss: 12700875689984.0\n",
      "2023-07-19 19:33:41,261 - INFO - Save model at epoch 521\n",
      "0it [00:00, ?it/s]2023-07-19 19:33:41,385 - INFO - Epoch: [522/600], Step: [1/591], Loss: 98966696.0, KL Divergence: 1108.5640869140625, Reconstruction Loss: 98965584.0\n",
      "117it [00:11, 11.11it/s]2023-07-19 19:33:52,508 - INFO - Epoch: [522/600], Step: [119/591], Loss: 210750368.0, KL Divergence: 1089.552978515625, Reconstruction Loss: 210749280.0\n",
      "235it [00:22, 10.86it/s]2023-07-19 19:34:03,585 - INFO - Epoch: [522/600], Step: [237/591], Loss: 174292096.0, KL Divergence: 1113.345458984375, Reconstruction Loss: 174290976.0\n",
      "353it [00:33, 10.61it/s]2023-07-19 19:34:14,695 - INFO - Epoch: [522/600], Step: [355/591], Loss: 219569312.0, KL Divergence: 1105.5498046875, Reconstruction Loss: 219568208.0\n",
      "471it [00:44, 10.45it/s]2023-07-19 19:34:25,813 - INFO - Epoch: [522/600], Step: [473/591], Loss: 190009856.0, KL Divergence: 1113.08544921875, Reconstruction Loss: 190008736.0\n",
      "589it [00:55, 10.61it/s]2023-07-19 19:34:36,812 - INFO - Epoch: [522/600], Step: [591/591], Loss: 175415360.0, KL Divergence: 1091.06640625, Reconstruction Loss: 175414272.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 19:34:36,814 - INFO - Epoch: [522/600], Total Loss: 12511442453504.0, Total KL Divergence: 83242373.890625, Total Reconstruction Loss: 12511359203328.0\n",
      "2023-07-19 19:34:36,863 - INFO - Save model at epoch 522\n",
      "0it [00:00, ?it/s]2023-07-19 19:34:36,983 - INFO - Epoch: [523/600], Step: [1/591], Loss: 98881512.0, KL Divergence: 1107.433349609375, Reconstruction Loss: 98880408.0\n",
      "118it [00:11, 10.93it/s]2023-07-19 19:34:47,989 - INFO - Epoch: [523/600], Step: [119/591], Loss: 214655008.0, KL Divergence: 1092.888916015625, Reconstruction Loss: 214653920.0\n",
      "236it [00:22, 10.74it/s]2023-07-19 19:34:59,006 - INFO - Epoch: [523/600], Step: [237/591], Loss: 175944560.0, KL Divergence: 1106.397216796875, Reconstruction Loss: 175943456.0\n",
      "354it [00:33, 10.83it/s]2023-07-19 19:35:10,146 - INFO - Epoch: [523/600], Step: [355/591], Loss: 217736656.0, KL Divergence: 1101.746337890625, Reconstruction Loss: 217735552.0\n",
      "471it [00:44, 10.07it/s]2023-07-19 19:35:21,271 - INFO - Epoch: [523/600], Step: [473/591], Loss: 186590608.0, KL Divergence: 1109.95947265625, Reconstruction Loss: 186589504.0\n",
      "589it [00:55, 10.71it/s]2023-07-19 19:35:32,303 - INFO - Epoch: [523/600], Step: [591/591], Loss: 153372576.0, KL Divergence: 1092.35009765625, Reconstruction Loss: 153371488.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 19:35:32,305 - INFO - Epoch: [523/600], Total Loss: 12521215384576.0, Total KL Divergence: 83166962.515625, Total Reconstruction Loss: 12521132219392.0\n",
      "2023-07-19 19:35:32,355 - INFO - Save model at epoch 523\n",
      "0it [00:00, ?it/s]2023-07-19 19:35:32,478 - INFO - Epoch: [524/600], Step: [1/591], Loss: 98634464.0, KL Divergence: 1106.0484619140625, Reconstruction Loss: 98633360.0\n",
      "118it [00:11, 10.85it/s]2023-07-19 19:35:43,551 - INFO - Epoch: [524/600], Step: [119/591], Loss: 213812448.0, KL Divergence: 1093.239013671875, Reconstruction Loss: 213811360.0\n",
      "236it [00:22, 10.79it/s]2023-07-19 19:35:54,619 - INFO - Epoch: [524/600], Step: [237/591], Loss: 178216336.0, KL Divergence: 1112.683349609375, Reconstruction Loss: 178215216.0\n",
      "353it [00:33, 10.48it/s]2023-07-19 19:36:05,713 - INFO - Epoch: [524/600], Step: [355/591], Loss: 225364176.0, KL Divergence: 1105.777099609375, Reconstruction Loss: 225363072.0\n",
      "471it [00:44, 10.76it/s]2023-07-19 19:36:16,722 - INFO - Epoch: [524/600], Step: [473/591], Loss: 190075488.0, KL Divergence: 1111.173095703125, Reconstruction Loss: 190074384.0\n",
      "589it [00:55, 10.99it/s]2023-07-19 19:36:27,694 - INFO - Epoch: [524/600], Step: [591/591], Loss: 155862144.0, KL Divergence: 1093.229736328125, Reconstruction Loss: 155861056.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 19:36:27,696 - INFO - Epoch: [524/600], Total Loss: 12413704005632.0, Total KL Divergence: 83402265.921875, Total Reconstruction Loss: 12413620595712.0\n",
      "2023-07-19 19:36:27,746 - INFO - Save model at epoch 524\n",
      "0it [00:00, ?it/s]2023-07-19 19:36:27,872 - INFO - Epoch: [525/600], Step: [1/591], Loss: 97670344.0, KL Divergence: 1110.8812255859375, Reconstruction Loss: 97669232.0\n",
      "117it [00:11, 10.53it/s]2023-07-19 19:36:38,989 - INFO - Epoch: [525/600], Step: [119/591], Loss: 214044656.0, KL Divergence: 1099.064453125, Reconstruction Loss: 214043552.0\n",
      "235it [00:22, 10.46it/s]2023-07-19 19:36:50,043 - INFO - Epoch: [525/600], Step: [237/591], Loss: 179340816.0, KL Divergence: 1109.84765625, Reconstruction Loss: 179339712.0\n",
      "353it [00:33, 10.50it/s]2023-07-19 19:37:01,156 - INFO - Epoch: [525/600], Step: [355/591], Loss: 222096720.0, KL Divergence: 1111.7587890625, Reconstruction Loss: 222095616.0\n",
      "471it [00:44, 10.84it/s]2023-07-19 19:37:12,076 - INFO - Epoch: [525/600], Step: [473/591], Loss: 201471408.0, KL Divergence: 1112.218505859375, Reconstruction Loss: 201470288.0\n",
      "589it [00:55, 10.91it/s]2023-07-19 19:37:22,994 - INFO - Epoch: [525/600], Step: [591/591], Loss: 155854480.0, KL Divergence: 1098.192626953125, Reconstruction Loss: 155853376.0\n",
      "591it [00:55, 10.70it/s]\n",
      "2023-07-19 19:37:22,996 - INFO - Epoch: [525/600], Total Loss: 12551953741824.0, Total KL Divergence: 83538749.328125, Total Reconstruction Loss: 12551870188544.0\n",
      "2023-07-19 19:37:23,034 - INFO - Save model at epoch 525\n",
      "0it [00:00, ?it/s]2023-07-19 19:37:23,145 - INFO - Epoch: [526/600], Step: [1/591], Loss: 108165304.0, KL Divergence: 1113.0888671875, Reconstruction Loss: 108164192.0\n",
      "118it [00:11, 10.70it/s]2023-07-19 19:37:34,360 - INFO - Epoch: [526/600], Step: [119/591], Loss: 213253696.0, KL Divergence: 1087.1142578125, Reconstruction Loss: 213252608.0\n",
      "236it [00:22, 10.55it/s]2023-07-19 19:37:45,505 - INFO - Epoch: [526/600], Step: [237/591], Loss: 172939744.0, KL Divergence: 1116.4141845703125, Reconstruction Loss: 172938624.0\n",
      "354it [00:33, 10.85it/s]2023-07-19 19:37:56,556 - INFO - Epoch: [526/600], Step: [355/591], Loss: 240787936.0, KL Divergence: 1112.579833984375, Reconstruction Loss: 240786816.0\n",
      "472it [00:44, 10.57it/s]2023-07-19 19:38:07,564 - INFO - Epoch: [526/600], Step: [473/591], Loss: 186004400.0, KL Divergence: 1114.7772216796875, Reconstruction Loss: 186003280.0\n",
      "590it [00:55, 10.69it/s]2023-07-19 19:38:18,597 - INFO - Epoch: [526/600], Step: [591/591], Loss: 151770160.0, KL Divergence: 1097.8656005859375, Reconstruction Loss: 151769056.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 19:38:18,598 - INFO - Epoch: [526/600], Total Loss: 12532055710720.0, Total KL Divergence: 83475955.25, Total Reconstruction Loss: 12531972227072.0\n",
      "2023-07-19 19:38:18,658 - INFO - Save model at epoch 526\n",
      "0it [00:00, ?it/s]2023-07-19 19:38:18,767 - INFO - Epoch: [527/600], Step: [1/591], Loss: 100910328.0, KL Divergence: 1112.74560546875, Reconstruction Loss: 100909216.0\n",
      "118it [00:11, 10.84it/s]2023-07-19 19:38:29,799 - INFO - Epoch: [527/600], Step: [119/591], Loss: 209742592.0, KL Divergence: 1089.032958984375, Reconstruction Loss: 209741504.0\n",
      "236it [00:22, 10.74it/s]2023-07-19 19:38:40,863 - INFO - Epoch: [527/600], Step: [237/591], Loss: 177684928.0, KL Divergence: 1104.3759765625, Reconstruction Loss: 177683824.0\n",
      "354it [00:33, 10.60it/s]2023-07-19 19:38:51,957 - INFO - Epoch: [527/600], Step: [355/591], Loss: 229084800.0, KL Divergence: 1107.363525390625, Reconstruction Loss: 229083696.0\n",
      "472it [00:44, 10.98it/s]2023-07-19 19:39:03,047 - INFO - Epoch: [527/600], Step: [473/591], Loss: 192966288.0, KL Divergence: 1114.817138671875, Reconstruction Loss: 192965168.0\n",
      "590it [00:55, 10.83it/s]2023-07-19 19:39:14,084 - INFO - Epoch: [527/600], Step: [591/591], Loss: 154333296.0, KL Divergence: 1101.7421875, Reconstruction Loss: 154332192.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 19:39:14,086 - INFO - Epoch: [527/600], Total Loss: 12540465775616.0, Total KL Divergence: 83344924.140625, Total Reconstruction Loss: 12540382445568.0\n",
      "2023-07-19 19:39:14,125 - INFO - Save model at epoch 527\n",
      "0it [00:00, ?it/s]2023-07-19 19:39:14,253 - INFO - Epoch: [528/600], Step: [1/591], Loss: 101038112.0, KL Divergence: 1117.209228515625, Reconstruction Loss: 101036992.0\n",
      "117it [00:11, 10.58it/s]2023-07-19 19:39:25,385 - INFO - Epoch: [528/600], Step: [119/591], Loss: 217784448.0, KL Divergence: 1090.995849609375, Reconstruction Loss: 217783360.0\n",
      "235it [00:22, 10.97it/s]2023-07-19 19:39:36,353 - INFO - Epoch: [528/600], Step: [237/591], Loss: 182178848.0, KL Divergence: 1114.01123046875, Reconstruction Loss: 182177728.0\n",
      "353it [00:33, 10.67it/s]2023-07-19 19:39:47,444 - INFO - Epoch: [528/600], Step: [355/591], Loss: 218650640.0, KL Divergence: 1105.114990234375, Reconstruction Loss: 218649536.0\n",
      "471it [00:44, 10.79it/s]2023-07-19 19:39:58,398 - INFO - Epoch: [528/600], Step: [473/591], Loss: 191318256.0, KL Divergence: 1113.0146484375, Reconstruction Loss: 191317136.0\n",
      "589it [00:55, 10.30it/s]2023-07-19 19:40:09,419 - INFO - Epoch: [528/600], Step: [591/591], Loss: 162885312.0, KL Divergence: 1097.0924072265625, Reconstruction Loss: 162884208.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 19:40:09,421 - INFO - Epoch: [528/600], Total Loss: 12576227205120.0, Total KL Divergence: 83474656.890625, Total Reconstruction Loss: 12576143720448.0\n",
      "2023-07-19 19:40:09,469 - INFO - Save model at epoch 528\n",
      "0it [00:00, ?it/s]2023-07-19 19:40:09,581 - INFO - Epoch: [529/600], Step: [1/591], Loss: 104306832.0, KL Divergence: 1112.6473388671875, Reconstruction Loss: 104305720.0\n",
      "118it [00:11, 10.50it/s]2023-07-19 19:40:20,629 - INFO - Epoch: [529/600], Step: [119/591], Loss: 224657712.0, KL Divergence: 1098.1611328125, Reconstruction Loss: 224656608.0\n",
      "236it [00:22, 10.32it/s]2023-07-19 19:40:31,704 - INFO - Epoch: [529/600], Step: [237/591], Loss: 182601632.0, KL Divergence: 1113.3453369140625, Reconstruction Loss: 182600512.0\n",
      "354it [00:33, 10.55it/s]2023-07-19 19:40:42,778 - INFO - Epoch: [529/600], Step: [355/591], Loss: 224127408.0, KL Divergence: 1110.529541015625, Reconstruction Loss: 224126304.0\n",
      "472it [00:44, 10.32it/s]2023-07-19 19:40:53,850 - INFO - Epoch: [529/600], Step: [473/591], Loss: 190628320.0, KL Divergence: 1112.100341796875, Reconstruction Loss: 190627200.0\n",
      "590it [00:55, 11.08it/s]2023-07-19 19:41:04,760 - INFO - Epoch: [529/600], Step: [591/591], Loss: 154758912.0, KL Divergence: 1108.410888671875, Reconstruction Loss: 154757808.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 19:41:04,762 - INFO - Epoch: [529/600], Total Loss: 12553384511488.0, Total KL Divergence: 83668051.234375, Total Reconstruction Loss: 12553300846592.0\n",
      "2023-07-19 19:41:04,807 - INFO - Save model at epoch 529\n",
      "0it [00:00, ?it/s]2023-07-19 19:41:04,916 - INFO - Epoch: [530/600], Step: [1/591], Loss: 101036776.0, KL Divergence: 1124.59765625, Reconstruction Loss: 101035648.0\n",
      "118it [00:11, 11.03it/s]2023-07-19 19:41:16,016 - INFO - Epoch: [530/600], Step: [119/591], Loss: 225934000.0, KL Divergence: 1102.5146484375, Reconstruction Loss: 225932896.0\n",
      "236it [00:22, 10.68it/s]2023-07-19 19:41:27,033 - INFO - Epoch: [530/600], Step: [237/591], Loss: 177258752.0, KL Divergence: 1121.8067626953125, Reconstruction Loss: 177257632.0\n",
      "354it [00:33, 10.37it/s]2023-07-19 19:41:38,215 - INFO - Epoch: [530/600], Step: [355/591], Loss: 219514432.0, KL Divergence: 1117.69189453125, Reconstruction Loss: 219513312.0\n",
      "472it [00:44, 10.74it/s]2023-07-19 19:41:49,272 - INFO - Epoch: [530/600], Step: [473/591], Loss: 194102240.0, KL Divergence: 1122.2515869140625, Reconstruction Loss: 194101120.0\n",
      "590it [00:55, 10.63it/s]2023-07-19 19:42:00,334 - INFO - Epoch: [530/600], Step: [591/591], Loss: 155942496.0, KL Divergence: 1113.9915771484375, Reconstruction Loss: 155941376.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 19:42:00,336 - INFO - Epoch: [530/600], Total Loss: 12605970831360.0, Total KL Divergence: 84242410.1875, Total Reconstruction Loss: 12605886592000.0\n",
      "2023-07-19 19:42:00,375 - INFO - Save model at epoch 530\n",
      "0it [00:00, ?it/s]2023-07-19 19:42:00,480 - INFO - Epoch: [531/600], Step: [1/591], Loss: 103042088.0, KL Divergence: 1128.404052734375, Reconstruction Loss: 103040960.0\n",
      "118it [00:11, 10.84it/s]2023-07-19 19:42:11,689 - INFO - Epoch: [531/600], Step: [119/591], Loss: 216519328.0, KL Divergence: 1113.0562744140625, Reconstruction Loss: 216518208.0\n",
      "236it [00:22, 10.81it/s]2023-07-19 19:42:22,838 - INFO - Epoch: [531/600], Step: [237/591], Loss: 174968960.0, KL Divergence: 1123.16357421875, Reconstruction Loss: 174967840.0\n",
      "354it [00:33, 10.64it/s]2023-07-19 19:42:33,840 - INFO - Epoch: [531/600], Step: [355/591], Loss: 224591104.0, KL Divergence: 1121.154052734375, Reconstruction Loss: 224589984.0\n",
      "472it [00:44, 10.81it/s]2023-07-19 19:42:44,860 - INFO - Epoch: [531/600], Step: [473/591], Loss: 183867312.0, KL Divergence: 1116.0162353515625, Reconstruction Loss: 183866192.0\n",
      "590it [00:55, 10.91it/s]2023-07-19 19:42:55,867 - INFO - Epoch: [531/600], Step: [591/591], Loss: 159745568.0, KL Divergence: 1117.75, Reconstruction Loss: 159744448.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 19:42:55,869 - INFO - Epoch: [531/600], Total Loss: 12600537233408.0, Total KL Divergence: 84470351.265625, Total Reconstruction Loss: 12600452757504.0\n",
      "2023-07-19 19:42:55,911 - INFO - Save model at epoch 531\n",
      "0it [00:00, ?it/s]2023-07-19 19:42:56,038 - INFO - Epoch: [532/600], Step: [1/591], Loss: 103417288.0, KL Divergence: 1131.759765625, Reconstruction Loss: 103416160.0\n",
      "117it [00:11, 10.94it/s]2023-07-19 19:43:07,142 - INFO - Epoch: [532/600], Step: [119/591], Loss: 225178544.0, KL Divergence: 1108.1898193359375, Reconstruction Loss: 225177440.0\n",
      "235it [00:22, 10.78it/s]2023-07-19 19:43:18,196 - INFO - Epoch: [532/600], Step: [237/591], Loss: 174803088.0, KL Divergence: 1116.4140625, Reconstruction Loss: 174801968.0\n",
      "353it [00:33, 10.50it/s]2023-07-19 19:43:29,334 - INFO - Epoch: [532/600], Step: [355/591], Loss: 226839264.0, KL Divergence: 1117.13671875, Reconstruction Loss: 226838144.0\n",
      "471it [00:44, 10.98it/s]2023-07-19 19:43:40,316 - INFO - Epoch: [532/600], Step: [473/591], Loss: 191451616.0, KL Divergence: 1125.400634765625, Reconstruction Loss: 191450496.0\n",
      "589it [00:55, 10.76it/s]2023-07-19 19:43:51,316 - INFO - Epoch: [532/600], Step: [591/591], Loss: 156429856.0, KL Divergence: 1120.1978759765625, Reconstruction Loss: 156428736.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 19:43:51,319 - INFO - Epoch: [532/600], Total Loss: 12572251846656.0, Total KL Divergence: 84246229.203125, Total Reconstruction Loss: 12572167602176.0\n",
      "2023-07-19 19:43:51,358 - INFO - Save model at epoch 532\n",
      "0it [00:00, ?it/s]2023-07-19 19:43:51,463 - INFO - Epoch: [533/600], Step: [1/591], Loss: 109223320.0, KL Divergence: 1134.0467529296875, Reconstruction Loss: 109222184.0\n",
      "118it [00:11, 10.62it/s]2023-07-19 19:44:02,667 - INFO - Epoch: [533/600], Step: [119/591], Loss: 224658048.0, KL Divergence: 1122.29541015625, Reconstruction Loss: 224656928.0\n",
      "236it [00:22, 10.76it/s]2023-07-19 19:44:13,797 - INFO - Epoch: [533/600], Step: [237/591], Loss: 179204448.0, KL Divergence: 1130.951904296875, Reconstruction Loss: 179203312.0\n",
      "354it [00:33, 10.19it/s]2023-07-19 19:44:24,921 - INFO - Epoch: [533/600], Step: [355/591], Loss: 216634496.0, KL Divergence: 1126.7557373046875, Reconstruction Loss: 216633376.0\n",
      "472it [00:44, 10.66it/s]2023-07-19 19:44:36,022 - INFO - Epoch: [533/600], Step: [473/591], Loss: 179426736.0, KL Divergence: 1136.75244140625, Reconstruction Loss: 179425600.0\n",
      "590it [00:55, 10.91it/s]2023-07-19 19:44:46,972 - INFO - Epoch: [533/600], Step: [591/591], Loss: 159600896.0, KL Divergence: 1120.88134765625, Reconstruction Loss: 159599776.0\n",
      "591it [00:55, 10.63it/s]\n",
      "2023-07-19 19:44:46,974 - INFO - Epoch: [533/600], Total Loss: 12532073874432.0, Total KL Divergence: 85230848.734375, Total Reconstruction Loss: 12531988649984.0\n",
      "2023-07-19 19:44:47,017 - INFO - Save model at epoch 533\n",
      "0it [00:00, ?it/s]2023-07-19 19:44:47,137 - INFO - Epoch: [534/600], Step: [1/591], Loss: 118731608.0, KL Divergence: 1136.6904296875, Reconstruction Loss: 118730472.0\n",
      "118it [00:11, 10.96it/s]2023-07-19 19:44:58,213 - INFO - Epoch: [534/600], Step: [119/591], Loss: 214759360.0, KL Divergence: 1121.208740234375, Reconstruction Loss: 214758240.0\n",
      "236it [00:22, 10.56it/s]2023-07-19 19:45:09,402 - INFO - Epoch: [534/600], Step: [237/591], Loss: 183201168.0, KL Divergence: 1127.989013671875, Reconstruction Loss: 183200048.0\n",
      "354it [00:33, 10.08it/s]2023-07-19 19:45:20,519 - INFO - Epoch: [534/600], Step: [355/591], Loss: 219068032.0, KL Divergence: 1133.94287109375, Reconstruction Loss: 219066896.0\n",
      "472it [00:44, 10.65it/s]2023-07-19 19:45:31,579 - INFO - Epoch: [534/600], Step: [473/591], Loss: 188021104.0, KL Divergence: 1141.5390625, Reconstruction Loss: 188019968.0\n",
      "590it [00:55, 10.24it/s]2023-07-19 19:45:42,603 - INFO - Epoch: [534/600], Step: [591/591], Loss: 156031920.0, KL Divergence: 1124.3724365234375, Reconstruction Loss: 156030800.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 19:45:42,605 - INFO - Epoch: [534/600], Total Loss: 12622951020544.0, Total KL Divergence: 85228267.234375, Total Reconstruction Loss: 12622865797120.0\n",
      "2023-07-19 19:45:42,649 - INFO - Save model at epoch 534\n",
      "0it [00:00, ?it/s]2023-07-19 19:45:42,761 - INFO - Epoch: [535/600], Step: [1/591], Loss: 98472120.0, KL Divergence: 1142.3424072265625, Reconstruction Loss: 98470976.0\n",
      "118it [00:11, 10.11it/s]2023-07-19 19:45:53,948 - INFO - Epoch: [535/600], Step: [119/591], Loss: 225612416.0, KL Divergence: 1122.1767578125, Reconstruction Loss: 225611296.0\n",
      "236it [00:22, 10.80it/s]2023-07-19 19:46:04,955 - INFO - Epoch: [535/600], Step: [237/591], Loss: 195237264.0, KL Divergence: 1133.718017578125, Reconstruction Loss: 195236128.0\n",
      "354it [00:33, 10.67it/s]2023-07-19 19:46:16,158 - INFO - Epoch: [535/600], Step: [355/591], Loss: 217162640.0, KL Divergence: 1131.41015625, Reconstruction Loss: 217161504.0\n",
      "472it [00:44, 10.57it/s]2023-07-19 19:46:27,273 - INFO - Epoch: [535/600], Step: [473/591], Loss: 187608000.0, KL Divergence: 1133.593505859375, Reconstruction Loss: 187606864.0\n",
      "590it [00:55, 10.57it/s]2023-07-19 19:46:38,287 - INFO - Epoch: [535/600], Step: [591/591], Loss: 148758400.0, KL Divergence: 1133.6337890625, Reconstruction Loss: 148757264.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 19:46:38,292 - INFO - Epoch: [535/600], Total Loss: 12774343326720.0, Total KL Divergence: 85224416.453125, Total Reconstruction Loss: 12774258086912.0\n",
      "2023-07-19 19:46:38,347 - INFO - Save model at epoch 535\n",
      "0it [00:00, ?it/s]2023-07-19 19:46:38,455 - INFO - Epoch: [536/600], Step: [1/591], Loss: 100675000.0, KL Divergence: 1147.1337890625, Reconstruction Loss: 100673856.0\n",
      "118it [00:11, 10.65it/s]2023-07-19 19:46:49,586 - INFO - Epoch: [536/600], Step: [119/591], Loss: 223301888.0, KL Divergence: 1118.165283203125, Reconstruction Loss: 223300768.0\n",
      "236it [00:22, 10.68it/s]2023-07-19 19:47:00,615 - INFO - Epoch: [536/600], Step: [237/591], Loss: 183922624.0, KL Divergence: 1141.851318359375, Reconstruction Loss: 183921488.0\n",
      "354it [00:33, 11.07it/s]2023-07-19 19:47:11,541 - INFO - Epoch: [536/600], Step: [355/591], Loss: 217077968.0, KL Divergence: 1132.48974609375, Reconstruction Loss: 217076832.0\n",
      "472it [00:44, 10.75it/s]2023-07-19 19:47:22,591 - INFO - Epoch: [536/600], Step: [473/591], Loss: 185630544.0, KL Divergence: 1136.514404296875, Reconstruction Loss: 185629408.0\n",
      "589it [00:55,  9.86it/s]2023-07-19 19:47:33,743 - INFO - Epoch: [536/600], Step: [591/591], Loss: 150191232.0, KL Divergence: 1128.1910400390625, Reconstruction Loss: 150190096.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 19:47:33,745 - INFO - Epoch: [536/600], Total Loss: 12680809578496.0, Total KL Divergence: 85409216.140625, Total Reconstruction Loss: 12680724183040.0\n",
      "2023-07-19 19:47:33,792 - INFO - Save model at epoch 536\n",
      "0it [00:00, ?it/s]2023-07-19 19:47:33,909 - INFO - Epoch: [537/600], Step: [1/591], Loss: 99877008.0, KL Divergence: 1140.145751953125, Reconstruction Loss: 99875864.0\n",
      "118it [00:11, 10.44it/s]2023-07-19 19:47:45,034 - INFO - Epoch: [537/600], Step: [119/591], Loss: 218117696.0, KL Divergence: 1121.8056640625, Reconstruction Loss: 218116576.0\n",
      "236it [00:22, 10.73it/s]2023-07-19 19:47:56,088 - INFO - Epoch: [537/600], Step: [237/591], Loss: 178804544.0, KL Divergence: 1140.443603515625, Reconstruction Loss: 178803408.0\n",
      "354it [00:33,  9.77it/s]2023-07-19 19:48:07,083 - INFO - Epoch: [537/600], Step: [355/591], Loss: 217493760.0, KL Divergence: 1135.529296875, Reconstruction Loss: 217492624.0\n",
      "472it [00:44, 10.83it/s]2023-07-19 19:48:18,143 - INFO - Epoch: [537/600], Step: [473/591], Loss: 182814736.0, KL Divergence: 1139.1107177734375, Reconstruction Loss: 182813600.0\n",
      "590it [00:55, 10.87it/s]2023-07-19 19:48:29,072 - INFO - Epoch: [537/600], Step: [591/591], Loss: 158812928.0, KL Divergence: 1130.48974609375, Reconstruction Loss: 158811792.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 19:48:29,073 - INFO - Epoch: [537/600], Total Loss: 12547712475136.0, Total KL Divergence: 85570800.015625, Total Reconstruction Loss: 12547626906624.0\n",
      "2023-07-19 19:48:29,142 - INFO - Save model at epoch 537\n",
      "0it [00:00, ?it/s]2023-07-19 19:48:29,254 - INFO - Epoch: [538/600], Step: [1/591], Loss: 103665664.0, KL Divergence: 1139.0341796875, Reconstruction Loss: 103664528.0\n",
      "118it [00:11, 10.32it/s]2023-07-19 19:48:40,383 - INFO - Epoch: [538/600], Step: [119/591], Loss: 215812624.0, KL Divergence: 1130.517333984375, Reconstruction Loss: 215811488.0\n",
      "236it [00:22, 10.34it/s]2023-07-19 19:48:51,465 - INFO - Epoch: [538/600], Step: [237/591], Loss: 175201360.0, KL Divergence: 1143.3095703125, Reconstruction Loss: 175200224.0\n",
      "354it [00:33,  9.82it/s]2023-07-19 19:49:02,601 - INFO - Epoch: [538/600], Step: [355/591], Loss: 220787296.0, KL Divergence: 1144.551025390625, Reconstruction Loss: 220786144.0\n",
      "472it [00:44, 10.58it/s]2023-07-19 19:49:13,689 - INFO - Epoch: [538/600], Step: [473/591], Loss: 188441584.0, KL Divergence: 1142.331787109375, Reconstruction Loss: 188440448.0\n",
      "590it [00:55, 10.74it/s]2023-07-19 19:49:24,757 - INFO - Epoch: [538/600], Step: [591/591], Loss: 152243728.0, KL Divergence: 1138.8040771484375, Reconstruction Loss: 152242592.0\n",
      "591it [00:55, 10.63it/s]\n",
      "2023-07-19 19:49:24,759 - INFO - Epoch: [538/600], Total Loss: 12443513175040.0, Total KL Divergence: 85979007.09375, Total Reconstruction Loss: 12443427169280.0\n",
      "2023-07-19 19:49:24,799 - INFO - Save model at epoch 538\n",
      "0it [00:00, ?it/s]2023-07-19 19:49:24,910 - INFO - Epoch: [539/600], Step: [1/591], Loss: 99193768.0, KL Divergence: 1150.7247314453125, Reconstruction Loss: 99192616.0\n",
      "118it [00:11, 10.33it/s]2023-07-19 19:49:36,070 - INFO - Epoch: [539/600], Step: [119/591], Loss: 217263440.0, KL Divergence: 1137.2796630859375, Reconstruction Loss: 217262304.0\n",
      "236it [00:22, 10.37it/s]2023-07-19 19:49:47,159 - INFO - Epoch: [539/600], Step: [237/591], Loss: 177595744.0, KL Divergence: 1148.01025390625, Reconstruction Loss: 177594592.0\n",
      "354it [00:33, 10.51it/s]2023-07-19 19:49:58,176 - INFO - Epoch: [539/600], Step: [355/591], Loss: 221838176.0, KL Divergence: 1147.0806884765625, Reconstruction Loss: 221837024.0\n",
      "471it [00:44, 10.31it/s]2023-07-19 19:50:09,327 - INFO - Epoch: [539/600], Step: [473/591], Loss: 188092272.0, KL Divergence: 1150.489013671875, Reconstruction Loss: 188091120.0\n",
      "589it [00:55, 10.50it/s]2023-07-19 19:50:20,320 - INFO - Epoch: [539/600], Step: [591/591], Loss: 149025392.0, KL Divergence: 1144.8782958984375, Reconstruction Loss: 149024240.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 19:50:20,323 - INFO - Epoch: [539/600], Total Loss: 12467810640896.0, Total KL Divergence: 86422597.953125, Total Reconstruction Loss: 12467724199936.0\n",
      "2023-07-19 19:50:20,370 - INFO - Save model at epoch 539\n",
      "0it [00:00, ?it/s]2023-07-19 19:50:20,476 - INFO - Epoch: [540/600], Step: [1/591], Loss: 101510184.0, KL Divergence: 1159.3507080078125, Reconstruction Loss: 101509024.0\n",
      "118it [00:11, 10.68it/s]2023-07-19 19:50:31,636 - INFO - Epoch: [540/600], Step: [119/591], Loss: 213750928.0, KL Divergence: 1139.28955078125, Reconstruction Loss: 213749792.0\n",
      "236it [00:22, 10.74it/s]2023-07-19 19:50:42,824 - INFO - Epoch: [540/600], Step: [237/591], Loss: 195124640.0, KL Divergence: 1147.963134765625, Reconstruction Loss: 195123488.0\n",
      "354it [00:33, 10.92it/s]2023-07-19 19:50:53,895 - INFO - Epoch: [540/600], Step: [355/591], Loss: 225428560.0, KL Divergence: 1149.928955078125, Reconstruction Loss: 225427408.0\n",
      "472it [00:44, 10.81it/s]2023-07-19 19:51:05,036 - INFO - Epoch: [540/600], Step: [473/591], Loss: 216975264.0, KL Divergence: 1146.591796875, Reconstruction Loss: 216974112.0\n",
      "590it [00:55, 10.53it/s]2023-07-19 19:51:15,942 - INFO - Epoch: [540/600], Step: [591/591], Loss: 151107648.0, KL Divergence: 1142.8349609375, Reconstruction Loss: 151106512.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 19:51:15,943 - INFO - Epoch: [540/600], Total Loss: 12607040612352.0, Total KL Divergence: 86526761.234375, Total Reconstruction Loss: 12606954080256.0\n",
      "2023-07-19 19:51:15,984 - INFO - Save model at epoch 540\n",
      "0it [00:00, ?it/s]2023-07-19 19:51:16,092 - INFO - Epoch: [541/600], Step: [1/591], Loss: 102339152.0, KL Divergence: 1158.12841796875, Reconstruction Loss: 102337992.0\n",
      "118it [00:11, 10.40it/s]2023-07-19 19:51:27,258 - INFO - Epoch: [541/600], Step: [119/591], Loss: 224118656.0, KL Divergence: 1137.082763671875, Reconstruction Loss: 224117520.0\n",
      "236it [00:22, 10.96it/s]2023-07-19 19:51:38,288 - INFO - Epoch: [541/600], Step: [237/591], Loss: 179949728.0, KL Divergence: 1147.020751953125, Reconstruction Loss: 179948576.0\n",
      "354it [00:33, 10.84it/s]2023-07-19 19:51:49,422 - INFO - Epoch: [541/600], Step: [355/591], Loss: 218237536.0, KL Divergence: 1147.667236328125, Reconstruction Loss: 218236384.0\n",
      "471it [00:44, 10.08it/s]2023-07-19 19:52:00,690 - INFO - Epoch: [541/600], Step: [473/591], Loss: 185716768.0, KL Divergence: 1146.9698486328125, Reconstruction Loss: 185715616.0\n",
      "589it [00:55, 10.37it/s]2023-07-19 19:52:11,683 - INFO - Epoch: [541/600], Step: [591/591], Loss: 155172944.0, KL Divergence: 1140.657958984375, Reconstruction Loss: 155171808.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 19:52:11,685 - INFO - Epoch: [541/600], Total Loss: 12445734576128.0, Total KL Divergence: 86406788.53125, Total Reconstruction Loss: 12445648160768.0\n",
      "2023-07-19 19:52:11,738 - INFO - Save model at epoch 541\n",
      "0it [00:00, ?it/s]2023-07-19 19:52:11,845 - INFO - Epoch: [542/600], Step: [1/591], Loss: 99384696.0, KL Divergence: 1158.717041015625, Reconstruction Loss: 99383536.0\n",
      "118it [00:11, 10.36it/s]2023-07-19 19:52:23,122 - INFO - Epoch: [542/600], Step: [119/591], Loss: 208867264.0, KL Divergence: 1139.959228515625, Reconstruction Loss: 208866128.0\n",
      "236it [00:22, 10.90it/s]2023-07-19 19:52:34,253 - INFO - Epoch: [542/600], Step: [237/591], Loss: 178611456.0, KL Divergence: 1152.775390625, Reconstruction Loss: 178610304.0\n",
      "354it [00:33, 10.57it/s]2023-07-19 19:52:45,358 - INFO - Epoch: [542/600], Step: [355/591], Loss: 229499808.0, KL Divergence: 1146.8992919921875, Reconstruction Loss: 229498656.0\n",
      "472it [00:44, 11.11it/s]2023-07-19 19:52:56,470 - INFO - Epoch: [542/600], Step: [473/591], Loss: 183852736.0, KL Divergence: 1151.4248046875, Reconstruction Loss: 183851584.0\n",
      "590it [00:55, 10.61it/s]2023-07-19 19:53:07,582 - INFO - Epoch: [542/600], Step: [591/591], Loss: 156100672.0, KL Divergence: 1144.3392333984375, Reconstruction Loss: 156099520.0\n",
      "591it [00:55, 10.59it/s]\n",
      "2023-07-19 19:53:07,583 - INFO - Epoch: [542/600], Total Loss: 12360584428544.0, Total KL Divergence: 86524540.609375, Total Reconstruction Loss: 12360497904640.0\n",
      "2023-07-19 19:53:07,626 - INFO - Save model at epoch 542\n",
      "0it [00:00, ?it/s]2023-07-19 19:53:07,728 - INFO - Epoch: [543/600], Step: [1/591], Loss: 100234552.0, KL Divergence: 1160.3134765625, Reconstruction Loss: 100233392.0\n",
      "117it [00:10, 10.60it/s]2023-07-19 19:53:18,776 - INFO - Epoch: [543/600], Step: [119/591], Loss: 209773552.0, KL Divergence: 1129.7366943359375, Reconstruction Loss: 209772416.0\n",
      "235it [00:22, 10.40it/s]2023-07-19 19:53:29,870 - INFO - Epoch: [543/600], Step: [237/591], Loss: 177176192.0, KL Divergence: 1150.6943359375, Reconstruction Loss: 177175040.0\n",
      "354it [00:33, 10.77it/s]2023-07-19 19:53:41,208 - INFO - Epoch: [543/600], Step: [355/591], Loss: 223700768.0, KL Divergence: 1148.2998046875, Reconstruction Loss: 223699616.0\n",
      "472it [00:44, 10.43it/s]2023-07-19 19:53:52,281 - INFO - Epoch: [543/600], Step: [473/591], Loss: 189983120.0, KL Divergence: 1149.830810546875, Reconstruction Loss: 189981968.0\n",
      "590it [00:55, 10.57it/s]2023-07-19 19:54:03,394 - INFO - Epoch: [543/600], Step: [591/591], Loss: 156694624.0, KL Divergence: 1140.6121826171875, Reconstruction Loss: 156693488.0\n",
      "591it [00:55, 10.60it/s]\n",
      "2023-07-19 19:54:03,396 - INFO - Epoch: [543/600], Total Loss: 12416029839360.0, Total KL Divergence: 86411408.78125, Total Reconstruction Loss: 12415943449600.0\n",
      "2023-07-19 19:54:03,456 - INFO - Save model at epoch 543\n",
      "0it [00:00, ?it/s]2023-07-19 19:54:03,564 - INFO - Epoch: [544/600], Step: [1/591], Loss: 101124080.0, KL Divergence: 1156.58056640625, Reconstruction Loss: 101122920.0\n",
      "118it [00:11, 10.66it/s]2023-07-19 19:54:14,710 - INFO - Epoch: [544/600], Step: [119/591], Loss: 212320912.0, KL Divergence: 1130.083251953125, Reconstruction Loss: 212319776.0\n",
      "236it [00:22, 10.84it/s]2023-07-19 19:54:25,777 - INFO - Epoch: [544/600], Step: [237/591], Loss: 175547344.0, KL Divergence: 1148.147216796875, Reconstruction Loss: 175546192.0\n",
      "354it [00:33, 10.31it/s]2023-07-19 19:54:36,883 - INFO - Epoch: [544/600], Step: [355/591], Loss: 221660512.0, KL Divergence: 1157.3060302734375, Reconstruction Loss: 221659360.0\n",
      "472it [00:44, 10.84it/s]2023-07-19 19:54:48,009 - INFO - Epoch: [544/600], Step: [473/591], Loss: 221277520.0, KL Divergence: 1164.728271484375, Reconstruction Loss: 221276352.0\n",
      "590it [00:55, 10.64it/s]2023-07-19 19:54:58,997 - INFO - Epoch: [544/600], Step: [591/591], Loss: 151782720.0, KL Divergence: 1151.347900390625, Reconstruction Loss: 151781568.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 19:54:58,999 - INFO - Epoch: [544/600], Total Loss: 12527160433664.0, Total KL Divergence: 86863402.0625, Total Reconstruction Loss: 12527073555456.0\n",
      "2023-07-19 19:54:59,039 - INFO - Save model at epoch 544\n",
      "0it [00:00, ?it/s]2023-07-19 19:54:59,151 - INFO - Epoch: [545/600], Step: [1/591], Loss: 103638752.0, KL Divergence: 1168.948974609375, Reconstruction Loss: 103637584.0\n",
      "117it [00:11, 10.42it/s]2023-07-19 19:55:10,467 - INFO - Epoch: [545/600], Step: [119/591], Loss: 211001600.0, KL Divergence: 1147.031982421875, Reconstruction Loss: 211000448.0\n",
      "235it [00:22, 10.75it/s]2023-07-19 19:55:21,561 - INFO - Epoch: [545/600], Step: [237/591], Loss: 180694320.0, KL Divergence: 1161.99169921875, Reconstruction Loss: 180693152.0\n",
      "353it [00:33, 10.75it/s]2023-07-19 19:55:32,641 - INFO - Epoch: [545/600], Step: [355/591], Loss: 223550864.0, KL Divergence: 1152.82080078125, Reconstruction Loss: 223549712.0\n",
      "471it [00:44, 10.58it/s]2023-07-19 19:55:43,754 - INFO - Epoch: [545/600], Step: [473/591], Loss: 189537136.0, KL Divergence: 1166.49755859375, Reconstruction Loss: 189535968.0\n",
      "589it [00:55, 10.79it/s]2023-07-19 19:55:54,788 - INFO - Epoch: [545/600], Step: [591/591], Loss: 149241968.0, KL Divergence: 1145.8994140625, Reconstruction Loss: 149240816.0\n",
      "591it [00:55, 10.60it/s]\n",
      "2023-07-19 19:55:54,790 - INFO - Epoch: [545/600], Total Loss: 12531465335808.0, Total KL Divergence: 87306180.765625, Total Reconstruction Loss: 12531377995776.0\n",
      "2023-07-19 19:55:54,829 - INFO - Save model at epoch 545\n",
      "0it [00:00, ?it/s]2023-07-19 19:55:54,949 - INFO - Epoch: [546/600], Step: [1/591], Loss: 97272536.0, KL Divergence: 1162.0694580078125, Reconstruction Loss: 97271376.0\n",
      "117it [00:11, 10.52it/s]2023-07-19 19:56:06,116 - INFO - Epoch: [546/600], Step: [119/591], Loss: 215391072.0, KL Divergence: 1139.3077392578125, Reconstruction Loss: 215389936.0\n",
      "235it [00:22, 10.66it/s]2023-07-19 19:56:17,319 - INFO - Epoch: [546/600], Step: [237/591], Loss: 182637008.0, KL Divergence: 1158.234375, Reconstruction Loss: 182635856.0\n",
      "353it [00:33, 10.43it/s]2023-07-19 19:56:28,400 - INFO - Epoch: [546/600], Step: [355/591], Loss: 219712720.0, KL Divergence: 1148.9591064453125, Reconstruction Loss: 219711568.0\n",
      "471it [00:44, 10.33it/s]2023-07-19 19:56:39,625 - INFO - Epoch: [546/600], Step: [473/591], Loss: 195847600.0, KL Divergence: 1160.6328125, Reconstruction Loss: 195846432.0\n",
      "589it [00:55, 11.10it/s]2023-07-19 19:56:50,586 - INFO - Epoch: [546/600], Step: [591/591], Loss: 150329440.0, KL Divergence: 1123.590576171875, Reconstruction Loss: 150328320.0\n",
      "591it [00:55, 10.60it/s]\n",
      "2023-07-19 19:56:50,588 - INFO - Epoch: [546/600], Total Loss: 12501414010880.0, Total KL Divergence: 86544684.40625, Total Reconstruction Loss: 12501327501312.0\n",
      "2023-07-19 19:56:50,631 - INFO - Save model at epoch 546\n",
      "0it [00:00, ?it/s]2023-07-19 19:56:50,743 - INFO - Epoch: [547/600], Step: [1/591], Loss: 98026360.0, KL Divergence: 1140.330322265625, Reconstruction Loss: 98025216.0\n",
      "118it [00:11, 10.86it/s]2023-07-19 19:57:01,783 - INFO - Epoch: [547/600], Step: [119/591], Loss: 212598560.0, KL Divergence: 1123.8885498046875, Reconstruction Loss: 212597440.0\n",
      "235it [00:22, 10.64it/s]2023-07-19 19:57:13,177 - INFO - Epoch: [547/600], Step: [237/591], Loss: 177236128.0, KL Divergence: 1147.133544921875, Reconstruction Loss: 177234976.0\n",
      "353it [00:33, 10.38it/s]2023-07-19 19:57:24,604 - INFO - Epoch: [547/600], Step: [355/591], Loss: 212986672.0, KL Divergence: 1135.3826904296875, Reconstruction Loss: 212985536.0\n",
      "471it [00:45, 10.83it/s]2023-07-19 19:57:35,878 - INFO - Epoch: [547/600], Step: [473/591], Loss: 200433600.0, KL Divergence: 1153.923583984375, Reconstruction Loss: 200432448.0\n",
      "589it [00:56, 10.33it/s]2023-07-19 19:57:47,174 - INFO - Epoch: [547/600], Step: [591/591], Loss: 152771408.0, KL Divergence: 1128.559814453125, Reconstruction Loss: 152770272.0\n",
      "591it [00:56, 10.46it/s]\n",
      "2023-07-19 19:57:47,175 - INFO - Epoch: [547/600], Total Loss: 12491950600192.0, Total KL Divergence: 85885723.96875, Total Reconstruction Loss: 12491864736768.0\n",
      "2023-07-19 19:57:47,214 - INFO - Save model at epoch 547\n",
      "0it [00:00, ?it/s]2023-07-19 19:57:47,329 - INFO - Epoch: [548/600], Step: [1/591], Loss: 98816696.0, KL Divergence: 1146.4228515625, Reconstruction Loss: 98815552.0\n",
      "118it [00:11, 10.72it/s]2023-07-19 19:57:58,642 - INFO - Epoch: [548/600], Step: [119/591], Loss: 220192464.0, KL Divergence: 1117.31982421875, Reconstruction Loss: 220191344.0\n",
      "236it [00:22, 10.80it/s]2023-07-19 19:58:09,814 - INFO - Epoch: [548/600], Step: [237/591], Loss: 177490016.0, KL Divergence: 1148.58203125, Reconstruction Loss: 177488864.0\n",
      "354it [00:33, 10.58it/s]2023-07-19 19:58:20,922 - INFO - Epoch: [548/600], Step: [355/591], Loss: 216826848.0, KL Divergence: 1139.01513671875, Reconstruction Loss: 216825712.0\n",
      "472it [00:44, 10.25it/s]2023-07-19 19:58:32,012 - INFO - Epoch: [548/600], Step: [473/591], Loss: 186847248.0, KL Divergence: 1142.5736083984375, Reconstruction Loss: 186846112.0\n",
      "590it [00:55, 10.54it/s]2023-07-19 19:58:42,957 - INFO - Epoch: [548/600], Step: [591/591], Loss: 162759632.0, KL Divergence: 1119.32470703125, Reconstruction Loss: 162758512.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 19:58:42,958 - INFO - Epoch: [548/600], Total Loss: 12446094834688.0, Total KL Divergence: 85500660.6875, Total Reconstruction Loss: 12446009336832.0\n",
      "2023-07-19 19:58:42,997 - INFO - Save model at epoch 548\n",
      "0it [00:00, ?it/s]2023-07-19 19:58:43,104 - INFO - Epoch: [549/600], Step: [1/591], Loss: 99533152.0, KL Divergence: 1137.589111328125, Reconstruction Loss: 99532016.0\n",
      "118it [00:11, 10.59it/s]2023-07-19 19:58:54,210 - INFO - Epoch: [549/600], Step: [119/591], Loss: 222041312.0, KL Divergence: 1121.947021484375, Reconstruction Loss: 222040192.0\n",
      "236it [00:22, 10.07it/s]2023-07-19 19:59:05,296 - INFO - Epoch: [549/600], Step: [237/591], Loss: 176120352.0, KL Divergence: 1148.900390625, Reconstruction Loss: 176119200.0\n",
      "353it [00:33, 10.67it/s]2023-07-19 19:59:16,496 - INFO - Epoch: [549/600], Step: [355/591], Loss: 214679984.0, KL Divergence: 1143.724365234375, Reconstruction Loss: 214678848.0\n",
      "471it [00:44, 10.88it/s]2023-07-19 19:59:27,676 - INFO - Epoch: [549/600], Step: [473/591], Loss: 185085312.0, KL Divergence: 1145.0673828125, Reconstruction Loss: 185084160.0\n",
      "589it [00:55, 10.81it/s]2023-07-19 19:59:38,681 - INFO - Epoch: [549/600], Step: [591/591], Loss: 155443104.0, KL Divergence: 1133.029541015625, Reconstruction Loss: 155441968.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 19:59:38,682 - INFO - Epoch: [549/600], Total Loss: 12334353262592.0, Total KL Divergence: 85769763.953125, Total Reconstruction Loss: 12334267476992.0\n",
      "2023-07-19 19:59:38,729 - INFO - Save model at epoch 549\n",
      "0it [00:00, ?it/s]2023-07-19 19:59:38,836 - INFO - Epoch: [550/600], Step: [1/591], Loss: 104590112.0, KL Divergence: 1151.798828125, Reconstruction Loss: 104588960.0\n",
      "117it [00:11, 10.84it/s]2023-07-19 19:59:49,944 - INFO - Epoch: [550/600], Step: [119/591], Loss: 229954880.0, KL Divergence: 1125.109619140625, Reconstruction Loss: 229953760.0\n",
      "235it [00:22, 10.48it/s]2023-07-19 20:00:00,999 - INFO - Epoch: [550/600], Step: [237/591], Loss: 175598128.0, KL Divergence: 1148.013671875, Reconstruction Loss: 175596976.0\n",
      "353it [00:33, 10.87it/s]2023-07-19 20:00:12,075 - INFO - Epoch: [550/600], Step: [355/591], Loss: 219328544.0, KL Divergence: 1137.968994140625, Reconstruction Loss: 219327408.0\n",
      "471it [00:44, 10.75it/s]2023-07-19 20:00:23,203 - INFO - Epoch: [550/600], Step: [473/591], Loss: 183615440.0, KL Divergence: 1143.280517578125, Reconstruction Loss: 183614304.0\n",
      "589it [00:55, 10.86it/s]2023-07-19 20:00:34,147 - INFO - Epoch: [550/600], Step: [591/591], Loss: 151383648.0, KL Divergence: 1136.1068115234375, Reconstruction Loss: 151382512.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 20:00:34,149 - INFO - Epoch: [550/600], Total Loss: 12334167720960.0, Total KL Divergence: 85943954.125, Total Reconstruction Loss: 12334081773568.0\n",
      "2023-07-19 20:00:34,203 - INFO - Save model at epoch 550\n",
      "0it [00:00, ?it/s]2023-07-19 20:00:34,308 - INFO - Epoch: [551/600], Step: [1/591], Loss: 98244480.0, KL Divergence: 1153.057373046875, Reconstruction Loss: 98243328.0\n",
      "118it [00:11, 10.66it/s]2023-07-19 20:00:45,550 - INFO - Epoch: [551/600], Step: [119/591], Loss: 238058016.0, KL Divergence: 1140.7520751953125, Reconstruction Loss: 238056880.0\n",
      "236it [00:22, 11.01it/s]2023-07-19 20:00:56,586 - INFO - Epoch: [551/600], Step: [237/591], Loss: 179520960.0, KL Divergence: 1158.937255859375, Reconstruction Loss: 179519808.0\n",
      "354it [00:33, 11.11it/s]2023-07-19 20:01:07,716 - INFO - Epoch: [551/600], Step: [355/591], Loss: 223016592.0, KL Divergence: 1149.1884765625, Reconstruction Loss: 223015440.0\n",
      "472it [00:44, 10.55it/s]2023-07-19 20:01:18,937 - INFO - Epoch: [551/600], Step: [473/591], Loss: 180766464.0, KL Divergence: 1156.255126953125, Reconstruction Loss: 180765312.0\n",
      "590it [00:55, 10.54it/s]2023-07-19 20:01:29,962 - INFO - Epoch: [551/600], Step: [591/591], Loss: 150181296.0, KL Divergence: 1136.15966796875, Reconstruction Loss: 150180160.0\n",
      "591it [00:55, 10.60it/s]\n",
      "2023-07-19 20:01:29,964 - INFO - Epoch: [551/600], Total Loss: 12322923152384.0, Total KL Divergence: 86771515.375, Total Reconstruction Loss: 12322836384768.0\n",
      "2023-07-19 20:01:30,010 - INFO - Save model at epoch 551\n",
      "0it [00:00, ?it/s]2023-07-19 20:01:30,115 - INFO - Epoch: [552/600], Step: [1/591], Loss: 111167296.0, KL Divergence: 1156.3447265625, Reconstruction Loss: 111166136.0\n",
      "118it [00:11, 10.42it/s]2023-07-19 20:01:41,217 - INFO - Epoch: [552/600], Step: [119/591], Loss: 212463808.0, KL Divergence: 1133.7646484375, Reconstruction Loss: 212462672.0\n",
      "236it [00:22, 10.37it/s]2023-07-19 20:01:52,589 - INFO - Epoch: [552/600], Step: [237/591], Loss: 173336640.0, KL Divergence: 1157.0028076171875, Reconstruction Loss: 173335488.0\n",
      "354it [00:33, 10.57it/s]2023-07-19 20:02:03,810 - INFO - Epoch: [552/600], Step: [355/591], Loss: 219815072.0, KL Divergence: 1155.7926025390625, Reconstruction Loss: 219813920.0\n",
      "472it [00:45, 10.39it/s]2023-07-19 20:02:15,140 - INFO - Epoch: [552/600], Step: [473/591], Loss: 185007232.0, KL Divergence: 1163.62158203125, Reconstruction Loss: 185006064.0\n",
      "590it [00:56, 10.74it/s]2023-07-19 20:02:26,231 - INFO - Epoch: [552/600], Step: [591/591], Loss: 177064592.0, KL Divergence: 1143.775634765625, Reconstruction Loss: 177063456.0\n",
      "591it [00:56, 10.52it/s]\n",
      "2023-07-19 20:02:26,233 - INFO - Epoch: [552/600], Total Loss: 12399333880832.0, Total KL Divergence: 86871178.765625, Total Reconstruction Loss: 12399247026176.0\n",
      "2023-07-19 20:02:26,272 - INFO - Save model at epoch 552\n",
      "0it [00:00, ?it/s]2023-07-19 20:02:26,387 - INFO - Epoch: [553/600], Step: [1/591], Loss: 98998152.0, KL Divergence: 1160.640625, Reconstruction Loss: 98996992.0\n",
      "117it [00:11, 10.69it/s]2023-07-19 20:02:37,511 - INFO - Epoch: [553/600], Step: [119/591], Loss: 214340112.0, KL Divergence: 1139.060791015625, Reconstruction Loss: 214338976.0\n",
      "235it [00:22, 10.51it/s]2023-07-19 20:02:48,801 - INFO - Epoch: [553/600], Step: [237/591], Loss: 176393552.0, KL Divergence: 1161.7796630859375, Reconstruction Loss: 176392384.0\n",
      "353it [00:33, 11.06it/s]2023-07-19 20:02:59,902 - INFO - Epoch: [553/600], Step: [355/591], Loss: 211941248.0, KL Divergence: 1158.200439453125, Reconstruction Loss: 211940096.0\n",
      "471it [00:44, 10.77it/s]2023-07-19 20:03:11,079 - INFO - Epoch: [553/600], Step: [473/591], Loss: 190730576.0, KL Divergence: 1160.630859375, Reconstruction Loss: 190729408.0\n",
      "589it [00:55, 10.78it/s]2023-07-19 20:03:22,171 - INFO - Epoch: [553/600], Step: [591/591], Loss: 162271600.0, KL Divergence: 1152.3712158203125, Reconstruction Loss: 162270448.0\n",
      "591it [00:55, 10.57it/s]\n",
      "2023-07-19 20:03:22,173 - INFO - Epoch: [553/600], Total Loss: 12430101912576.0, Total KL Divergence: 87287109.546875, Total Reconstruction Loss: 12430014616576.0\n",
      "2023-07-19 20:03:22,217 - INFO - Save model at epoch 553\n",
      "0it [00:00, ?it/s]2023-07-19 20:03:22,345 - INFO - Epoch: [554/600], Step: [1/591], Loss: 106192544.0, KL Divergence: 1166.589111328125, Reconstruction Loss: 106191376.0\n",
      "118it [00:11, 10.73it/s]2023-07-19 20:03:33,484 - INFO - Epoch: [554/600], Step: [119/591], Loss: 205852496.0, KL Divergence: 1149.8154296875, Reconstruction Loss: 205851344.0\n",
      "236it [00:22, 10.94it/s]2023-07-19 20:03:44,367 - INFO - Epoch: [554/600], Step: [237/591], Loss: 174746784.0, KL Divergence: 1173.68212890625, Reconstruction Loss: 174745616.0\n",
      "354it [00:33, 10.83it/s]2023-07-19 20:03:55,473 - INFO - Epoch: [554/600], Step: [355/591], Loss: 210965392.0, KL Divergence: 1165.841064453125, Reconstruction Loss: 210964224.0\n",
      "472it [00:44, 11.07it/s]2023-07-19 20:04:06,540 - INFO - Epoch: [554/600], Step: [473/591], Loss: 188432368.0, KL Divergence: 1168.1971435546875, Reconstruction Loss: 188431200.0\n",
      "590it [00:55, 10.54it/s]2023-07-19 20:04:17,633 - INFO - Epoch: [554/600], Step: [591/591], Loss: 153118384.0, KL Divergence: 1167.4267578125, Reconstruction Loss: 153117216.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 20:04:17,635 - INFO - Epoch: [554/600], Total Loss: 12359059617792.0, Total KL Divergence: 87819515.15625, Total Reconstruction Loss: 12358971777024.0\n",
      "2023-07-19 20:04:17,673 - INFO - Save model at epoch 554\n",
      "0it [00:00, ?it/s]2023-07-19 20:04:17,785 - INFO - Epoch: [555/600], Step: [1/591], Loss: 102572136.0, KL Divergence: 1180.6220703125, Reconstruction Loss: 102570952.0\n",
      "118it [00:11, 10.57it/s]2023-07-19 20:04:28,966 - INFO - Epoch: [555/600], Step: [119/591], Loss: 220517440.0, KL Divergence: 1158.93896484375, Reconstruction Loss: 220516288.0\n",
      "236it [00:22, 10.54it/s]2023-07-19 20:04:39,997 - INFO - Epoch: [555/600], Step: [237/591], Loss: 179940800.0, KL Divergence: 1182.730224609375, Reconstruction Loss: 179939616.0\n",
      "354it [00:33, 10.23it/s]2023-07-19 20:04:51,079 - INFO - Epoch: [555/600], Step: [355/591], Loss: 217316096.0, KL Divergence: 1168.105712890625, Reconstruction Loss: 217314928.0\n",
      "472it [00:44, 10.59it/s]2023-07-19 20:05:02,241 - INFO - Epoch: [555/600], Step: [473/591], Loss: 214577088.0, KL Divergence: 1170.6866455078125, Reconstruction Loss: 214575920.0\n",
      "590it [00:55, 10.53it/s]2023-07-19 20:05:13,408 - INFO - Epoch: [555/600], Step: [591/591], Loss: 168223792.0, KL Divergence: 1163.0941162109375, Reconstruction Loss: 168222624.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 20:05:13,410 - INFO - Epoch: [555/600], Total Loss: 12587011555328.0, Total KL Divergence: 88239579.4375, Total Reconstruction Loss: 12586923321344.0\n",
      "2023-07-19 20:05:13,451 - INFO - Save model at epoch 555\n",
      "0it [00:00, ?it/s]2023-07-19 20:05:13,566 - INFO - Epoch: [556/600], Step: [1/591], Loss: 104063840.0, KL Divergence: 1180.98681640625, Reconstruction Loss: 104062656.0\n",
      "118it [00:11, 10.68it/s]2023-07-19 20:05:24,652 - INFO - Epoch: [556/600], Step: [119/591], Loss: 211188176.0, KL Divergence: 1161.451171875, Reconstruction Loss: 211187008.0\n",
      "236it [00:22, 10.77it/s]2023-07-19 20:05:35,754 - INFO - Epoch: [556/600], Step: [237/591], Loss: 182430624.0, KL Divergence: 1191.220458984375, Reconstruction Loss: 182429440.0\n",
      "354it [00:33, 10.56it/s]2023-07-19 20:05:46,763 - INFO - Epoch: [556/600], Step: [355/591], Loss: 213617152.0, KL Divergence: 1178.0172119140625, Reconstruction Loss: 213615968.0\n",
      "472it [00:44, 10.78it/s]2023-07-19 20:05:57,781 - INFO - Epoch: [556/600], Step: [473/591], Loss: 194523840.0, KL Divergence: 1175.8857421875, Reconstruction Loss: 194522672.0\n",
      "590it [00:55, 10.48it/s]2023-07-19 20:06:08,811 - INFO - Epoch: [556/600], Step: [591/591], Loss: 161111568.0, KL Divergence: 1168.35888671875, Reconstruction Loss: 161110400.0\n",
      "591it [00:55, 10.68it/s]\n",
      "2023-07-19 20:06:08,813 - INFO - Epoch: [556/600], Total Loss: 12632651319296.0, Total KL Divergence: 88605577.953125, Total Reconstruction Loss: 12632562707456.0\n",
      "2023-07-19 20:06:08,852 - INFO - Save model at epoch 556\n",
      "0it [00:00, ?it/s]2023-07-19 20:06:08,976 - INFO - Epoch: [557/600], Step: [1/591], Loss: 111886176.0, KL Divergence: 1184.6708984375, Reconstruction Loss: 111884992.0\n",
      "117it [00:11, 11.15it/s]2023-07-19 20:06:20,115 - INFO - Epoch: [557/600], Step: [119/591], Loss: 208957056.0, KL Divergence: 1163.538330078125, Reconstruction Loss: 208955888.0\n",
      "236it [00:22, 10.34it/s]2023-07-19 20:06:31,326 - INFO - Epoch: [557/600], Step: [237/591], Loss: 182564544.0, KL Divergence: 1184.93896484375, Reconstruction Loss: 182563360.0\n",
      "354it [00:33, 10.01it/s]2023-07-19 20:06:42,431 - INFO - Epoch: [557/600], Step: [355/591], Loss: 213537152.0, KL Divergence: 1178.5762939453125, Reconstruction Loss: 213535968.0\n",
      "472it [00:44, 10.25it/s]2023-07-19 20:06:53,641 - INFO - Epoch: [557/600], Step: [473/591], Loss: 194788624.0, KL Divergence: 1172.6239013671875, Reconstruction Loss: 194787456.0\n",
      "590it [00:55, 10.70it/s]2023-07-19 20:07:04,747 - INFO - Epoch: [557/600], Step: [591/591], Loss: 164142016.0, KL Divergence: 1154.743896484375, Reconstruction Loss: 164140864.0\n",
      "591it [00:55, 10.58it/s]\n",
      "2023-07-19 20:07:04,749 - INFO - Epoch: [557/600], Total Loss: 12570978459648.0, Total KL Divergence: 88322017.984375, Total Reconstruction Loss: 12570890127360.0\n",
      "2023-07-19 20:07:04,788 - INFO - Save model at epoch 557\n",
      "0it [00:00, ?it/s]2023-07-19 20:07:04,896 - INFO - Epoch: [558/600], Step: [1/591], Loss: 108139952.0, KL Divergence: 1171.048095703125, Reconstruction Loss: 108138784.0\n",
      "118it [00:11, 10.55it/s]2023-07-19 20:07:16,192 - INFO - Epoch: [558/600], Step: [119/591], Loss: 210276064.0, KL Divergence: 1159.1883544921875, Reconstruction Loss: 210274912.0\n",
      "236it [00:22, 10.43it/s]2023-07-19 20:07:27,273 - INFO - Epoch: [558/600], Step: [237/591], Loss: 174604800.0, KL Divergence: 1179.390869140625, Reconstruction Loss: 174603616.0\n",
      "354it [00:33, 10.68it/s]2023-07-19 20:07:38,339 - INFO - Epoch: [558/600], Step: [355/591], Loss: 216295120.0, KL Divergence: 1174.0048828125, Reconstruction Loss: 216293952.0\n",
      "472it [00:44, 11.02it/s]2023-07-19 20:07:49,357 - INFO - Epoch: [558/600], Step: [473/591], Loss: 192839856.0, KL Divergence: 1179.34765625, Reconstruction Loss: 192838672.0\n",
      "590it [00:55, 10.59it/s]2023-07-19 20:08:00,413 - INFO - Epoch: [558/600], Step: [591/591], Loss: 158641856.0, KL Divergence: 1169.6494140625, Reconstruction Loss: 158640688.0\n",
      "591it [00:55, 10.63it/s]\n",
      "2023-07-19 20:08:00,415 - INFO - Epoch: [558/600], Total Loss: 12471274996736.0, Total KL Divergence: 88428179.53125, Total Reconstruction Loss: 12471186554880.0\n",
      "2023-07-19 20:08:00,457 - INFO - Save model at epoch 558\n",
      "0it [00:00, ?it/s]2023-07-19 20:08:00,569 - INFO - Epoch: [559/600], Step: [1/591], Loss: 106400216.0, KL Divergence: 1182.10107421875, Reconstruction Loss: 106399032.0\n",
      "118it [00:11, 10.95it/s]2023-07-19 20:08:11,671 - INFO - Epoch: [559/600], Step: [119/591], Loss: 217361792.0, KL Divergence: 1168.2685546875, Reconstruction Loss: 217360624.0\n",
      "236it [00:22, 10.58it/s]2023-07-19 20:08:22,746 - INFO - Epoch: [559/600], Step: [237/591], Loss: 174725344.0, KL Divergence: 1183.699462890625, Reconstruction Loss: 174724160.0\n",
      "354it [00:33, 10.70it/s]2023-07-19 20:08:33,785 - INFO - Epoch: [559/600], Step: [355/591], Loss: 222447840.0, KL Divergence: 1171.382568359375, Reconstruction Loss: 222446672.0\n",
      "472it [00:44, 10.75it/s]2023-07-19 20:08:44,897 - INFO - Epoch: [559/600], Step: [473/591], Loss: 189023680.0, KL Divergence: 1186.593505859375, Reconstruction Loss: 189022496.0\n",
      "590it [00:55, 10.89it/s]2023-07-19 20:08:55,929 - INFO - Epoch: [559/600], Step: [591/591], Loss: 152362256.0, KL Divergence: 1170.001220703125, Reconstruction Loss: 152361088.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 20:08:55,931 - INFO - Epoch: [559/600], Total Loss: 12473192320000.0, Total KL Divergence: 88517005.109375, Total Reconstruction Loss: 12473103782912.0\n",
      "2023-07-19 20:08:55,970 - INFO - Save model at epoch 559\n",
      "0it [00:00, ?it/s]2023-07-19 20:08:56,090 - INFO - Epoch: [560/600], Step: [1/591], Loss: 96730392.0, KL Divergence: 1183.5836181640625, Reconstruction Loss: 96729208.0\n",
      "117it [00:11, 10.55it/s]2023-07-19 20:09:07,274 - INFO - Epoch: [560/600], Step: [119/591], Loss: 213448432.0, KL Divergence: 1165.995849609375, Reconstruction Loss: 213447264.0\n",
      "235it [00:22, 10.71it/s]2023-07-19 20:09:18,489 - INFO - Epoch: [560/600], Step: [237/591], Loss: 176356880.0, KL Divergence: 1173.8800048828125, Reconstruction Loss: 176355712.0\n",
      "353it [00:33, 10.54it/s]2023-07-19 20:09:29,485 - INFO - Epoch: [560/600], Step: [355/591], Loss: 229117856.0, KL Divergence: 1167.095703125, Reconstruction Loss: 229116688.0\n",
      "471it [00:44, 10.22it/s]2023-07-19 20:09:40,760 - INFO - Epoch: [560/600], Step: [473/591], Loss: 188967328.0, KL Divergence: 1181.947021484375, Reconstruction Loss: 188966144.0\n",
      "589it [00:55, 10.64it/s]2023-07-19 20:09:51,848 - INFO - Epoch: [560/600], Step: [591/591], Loss: 153428816.0, KL Divergence: 1166.93017578125, Reconstruction Loss: 153427648.0\n",
      "591it [00:55, 10.58it/s]\n",
      "2023-07-19 20:09:51,850 - INFO - Epoch: [560/600], Total Loss: 12431391235072.0, Total KL Divergence: 88299352.703125, Total Reconstruction Loss: 12431302935552.0\n",
      "2023-07-19 20:09:51,898 - INFO - Save model at epoch 560\n",
      "0it [00:00, ?it/s]2023-07-19 20:09:52,015 - INFO - Epoch: [561/600], Step: [1/591], Loss: 96689552.0, KL Divergence: 1182.4163818359375, Reconstruction Loss: 96688368.0\n",
      "118it [00:11, 10.74it/s]2023-07-19 20:10:03,239 - INFO - Epoch: [561/600], Step: [119/591], Loss: 219138464.0, KL Divergence: 1160.62158203125, Reconstruction Loss: 219137296.0\n",
      "236it [00:22, 10.45it/s]2023-07-19 20:10:14,252 - INFO - Epoch: [561/600], Step: [237/591], Loss: 177314544.0, KL Divergence: 1166.705322265625, Reconstruction Loss: 177313376.0\n",
      "354it [00:33, 10.64it/s]2023-07-19 20:10:25,334 - INFO - Epoch: [561/600], Step: [355/591], Loss: 222734768.0, KL Divergence: 1169.11279296875, Reconstruction Loss: 222733600.0\n",
      "472it [00:44, 10.82it/s]2023-07-19 20:10:36,507 - INFO - Epoch: [561/600], Step: [473/591], Loss: 188224192.0, KL Divergence: 1173.469970703125, Reconstruction Loss: 188223024.0\n",
      "590it [00:55, 10.83it/s]2023-07-19 20:10:47,426 - INFO - Epoch: [561/600], Step: [591/591], Loss: 159520240.0, KL Divergence: 1170.1541748046875, Reconstruction Loss: 159519072.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 20:10:47,428 - INFO - Epoch: [561/600], Total Loss: 12387164390400.0, Total KL Divergence: 88004382.625, Total Reconstruction Loss: 12387076408320.0\n",
      "2023-07-19 20:10:47,507 - INFO - Save model at epoch 561\n",
      "0it [00:00, ?it/s]2023-07-19 20:10:47,615 - INFO - Epoch: [562/600], Step: [1/591], Loss: 120697264.0, KL Divergence: 1186.058349609375, Reconstruction Loss: 120696080.0\n",
      "117it [00:10, 10.85it/s]2023-07-19 20:10:58,674 - INFO - Epoch: [562/600], Step: [119/591], Loss: 212020000.0, KL Divergence: 1157.800537109375, Reconstruction Loss: 212018848.0\n",
      "235it [00:22, 10.58it/s]2023-07-19 20:11:09,864 - INFO - Epoch: [562/600], Step: [237/591], Loss: 182227952.0, KL Divergence: 1168.953857421875, Reconstruction Loss: 182226784.0\n",
      "353it [00:33, 10.54it/s]2023-07-19 20:11:21,001 - INFO - Epoch: [562/600], Step: [355/591], Loss: 227096656.0, KL Divergence: 1171.4549560546875, Reconstruction Loss: 227095488.0\n",
      "471it [00:44, 10.62it/s]2023-07-19 20:11:32,114 - INFO - Epoch: [562/600], Step: [473/591], Loss: 183442544.0, KL Divergence: 1173.4014892578125, Reconstruction Loss: 183441376.0\n",
      "589it [00:55, 10.83it/s]2023-07-19 20:11:43,074 - INFO - Epoch: [562/600], Step: [591/591], Loss: 164985984.0, KL Divergence: 1159.954833984375, Reconstruction Loss: 164984832.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 20:11:43,076 - INFO - Epoch: [562/600], Total Loss: 12400569691136.0, Total KL Divergence: 88108583.0, Total Reconstruction Loss: 12400481572864.0\n",
      "2023-07-19 20:11:43,116 - INFO - Save model at epoch 562\n",
      "0it [00:00, ?it/s]2023-07-19 20:11:43,219 - INFO - Epoch: [563/600], Step: [1/591], Loss: 114665040.0, KL Divergence: 1175.900634765625, Reconstruction Loss: 114663864.0\n",
      "117it [00:11, 10.69it/s]2023-07-19 20:11:54,476 - INFO - Epoch: [563/600], Step: [119/591], Loss: 212473952.0, KL Divergence: 1155.236328125, Reconstruction Loss: 212472800.0\n",
      "235it [00:22, 10.41it/s]2023-07-19 20:12:05,798 - INFO - Epoch: [563/600], Step: [237/591], Loss: 175718848.0, KL Divergence: 1177.1629638671875, Reconstruction Loss: 175717664.0\n",
      "354it [00:33, 10.16it/s]2023-07-19 20:12:17,096 - INFO - Epoch: [563/600], Step: [355/591], Loss: 221544464.0, KL Divergence: 1174.539306640625, Reconstruction Loss: 221543296.0\n",
      "472it [00:45, 10.61it/s]2023-07-19 20:12:28,383 - INFO - Epoch: [563/600], Step: [473/591], Loss: 187928928.0, KL Divergence: 1178.1783447265625, Reconstruction Loss: 187927744.0\n",
      "590it [00:56, 10.32it/s]2023-07-19 20:12:39,581 - INFO - Epoch: [563/600], Step: [591/591], Loss: 174975600.0, KL Divergence: 1167.146728515625, Reconstruction Loss: 174974432.0\n",
      "591it [00:56, 10.47it/s]\n",
      "2023-07-19 20:12:39,583 - INFO - Epoch: [563/600], Total Loss: 12470945351680.0, Total KL Divergence: 88241820.5, Total Reconstruction Loss: 12470857113600.0\n",
      "2023-07-19 20:12:39,627 - INFO - Save model at epoch 563\n",
      "0it [00:00, ?it/s]2023-07-19 20:12:39,740 - INFO - Epoch: [564/600], Step: [1/591], Loss: 107854816.0, KL Divergence: 1182.3848876953125, Reconstruction Loss: 107853632.0\n",
      "118it [00:11, 10.70it/s]2023-07-19 20:12:50,931 - INFO - Epoch: [564/600], Step: [119/591], Loss: 208681296.0, KL Divergence: 1163.45068359375, Reconstruction Loss: 208680128.0\n",
      "236it [00:22, 10.90it/s]2023-07-19 20:13:02,064 - INFO - Epoch: [564/600], Step: [237/591], Loss: 175630944.0, KL Divergence: 1180.8084716796875, Reconstruction Loss: 175629760.0\n",
      "354it [00:33, 10.61it/s]2023-07-19 20:13:13,141 - INFO - Epoch: [564/600], Step: [355/591], Loss: 220962496.0, KL Divergence: 1172.3709716796875, Reconstruction Loss: 220961328.0\n",
      "472it [00:44, 10.98it/s]2023-07-19 20:13:24,307 - INFO - Epoch: [564/600], Step: [473/591], Loss: 182092960.0, KL Divergence: 1172.55810546875, Reconstruction Loss: 182091792.0\n",
      "590it [00:55, 10.90it/s]2023-07-19 20:13:35,278 - INFO - Epoch: [564/600], Step: [591/591], Loss: 164594304.0, KL Divergence: 1160.830322265625, Reconstruction Loss: 164593136.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 20:13:35,279 - INFO - Epoch: [564/600], Total Loss: 12477115387904.0, Total KL Divergence: 88362655.15625, Total Reconstruction Loss: 12477027007488.0\n",
      "2023-07-19 20:13:35,323 - INFO - Save model at epoch 564\n",
      "0it [00:00, ?it/s]2023-07-19 20:13:35,432 - INFO - Epoch: [565/600], Step: [1/591], Loss: 123893384.0, KL Divergence: 1174.6533203125, Reconstruction Loss: 123892208.0\n",
      "118it [00:11, 10.30it/s]2023-07-19 20:13:46,613 - INFO - Epoch: [565/600], Step: [119/591], Loss: 207223568.0, KL Divergence: 1163.23779296875, Reconstruction Loss: 207222400.0\n",
      "236it [00:22, 10.53it/s]2023-07-19 20:13:57,676 - INFO - Epoch: [565/600], Step: [237/591], Loss: 179962560.0, KL Divergence: 1187.2027587890625, Reconstruction Loss: 179961376.0\n",
      "354it [00:33, 10.75it/s]2023-07-19 20:14:08,763 - INFO - Epoch: [565/600], Step: [355/591], Loss: 226313440.0, KL Divergence: 1182.339599609375, Reconstruction Loss: 226312256.0\n",
      "472it [00:44, 10.60it/s]2023-07-19 20:14:20,053 - INFO - Epoch: [565/600], Step: [473/591], Loss: 179667584.0, KL Divergence: 1184.90380859375, Reconstruction Loss: 179666400.0\n",
      "590it [00:55, 11.01it/s]2023-07-19 20:14:31,072 - INFO - Epoch: [565/600], Step: [591/591], Loss: 158253248.0, KL Divergence: 1173.9716796875, Reconstruction Loss: 158252080.0\n",
      "591it [00:55, 10.60it/s]\n",
      "2023-07-19 20:14:31,074 - INFO - Epoch: [565/600], Total Loss: 12346859686912.0, Total KL Divergence: 88861728.09375, Total Reconstruction Loss: 12346770835456.0\n",
      "2023-07-19 20:14:31,132 - INFO - Save model at epoch 565\n",
      "0it [00:00, ?it/s]2023-07-19 20:14:31,249 - INFO - Epoch: [566/600], Step: [1/591], Loss: 99131456.0, KL Divergence: 1193.71923828125, Reconstruction Loss: 99130264.0\n",
      "117it [00:11, 10.13it/s]2023-07-19 20:14:42,389 - INFO - Epoch: [566/600], Step: [119/591], Loss: 208020576.0, KL Divergence: 1177.84912109375, Reconstruction Loss: 208019392.0\n",
      "235it [00:22, 10.84it/s]2023-07-19 20:14:53,499 - INFO - Epoch: [566/600], Step: [237/591], Loss: 177908928.0, KL Divergence: 1186.5003662109375, Reconstruction Loss: 177907744.0\n",
      "353it [00:33, 10.66it/s]2023-07-19 20:15:04,559 - INFO - Epoch: [566/600], Step: [355/591], Loss: 211566304.0, KL Divergence: 1179.18603515625, Reconstruction Loss: 211565120.0\n",
      "471it [00:44, 10.81it/s]2023-07-19 20:15:15,674 - INFO - Epoch: [566/600], Step: [473/591], Loss: 189630112.0, KL Divergence: 1173.7611083984375, Reconstruction Loss: 189628944.0\n",
      "589it [00:55, 10.56it/s]2023-07-19 20:15:26,751 - INFO - Epoch: [566/600], Step: [591/591], Loss: 167713008.0, KL Divergence: 1155.7432861328125, Reconstruction Loss: 167711856.0\n",
      "591it [00:55, 10.63it/s]\n",
      "2023-07-19 20:15:26,753 - INFO - Epoch: [566/600], Total Loss: 12321636392960.0, Total KL Divergence: 88719068.484375, Total Reconstruction Loss: 12321547681792.0\n",
      "2023-07-19 20:15:26,792 - INFO - Save model at epoch 566\n",
      "0it [00:00, ?it/s]2023-07-19 20:15:26,893 - INFO - Epoch: [567/600], Step: [1/591], Loss: 99361992.0, KL Divergence: 1176.29541015625, Reconstruction Loss: 99360816.0\n",
      "118it [00:11, 10.53it/s]2023-07-19 20:15:37,982 - INFO - Epoch: [567/600], Step: [119/591], Loss: 209498944.0, KL Divergence: 1156.2623291015625, Reconstruction Loss: 209497792.0\n",
      "236it [00:22, 10.63it/s]2023-07-19 20:15:49,097 - INFO - Epoch: [567/600], Step: [237/591], Loss: 174952128.0, KL Divergence: 1182.5528564453125, Reconstruction Loss: 174950944.0\n",
      "354it [00:33, 10.78it/s]2023-07-19 20:16:00,290 - INFO - Epoch: [567/600], Step: [355/591], Loss: 212347920.0, KL Divergence: 1173.775634765625, Reconstruction Loss: 212346752.0\n",
      "471it [00:44, 10.62it/s]2023-07-19 20:16:11,361 - INFO - Epoch: [567/600], Step: [473/591], Loss: 186060256.0, KL Divergence: 1179.04052734375, Reconstruction Loss: 186059072.0\n",
      "589it [00:55, 10.38it/s]2023-07-19 20:16:22,450 - INFO - Epoch: [567/600], Step: [591/591], Loss: 149220272.0, KL Divergence: 1167.65673828125, Reconstruction Loss: 149219104.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 20:16:22,452 - INFO - Epoch: [567/600], Total Loss: 12196383383552.0, Total KL Divergence: 88256869.75, Total Reconstruction Loss: 12196295146496.0\n",
      "2023-07-19 20:16:22,494 - INFO - Save model at epoch 567\n",
      "0it [00:00, ?it/s]2023-07-19 20:16:22,604 - INFO - Epoch: [568/600], Step: [1/591], Loss: 105374264.0, KL Divergence: 1182.0162353515625, Reconstruction Loss: 105373080.0\n",
      "118it [00:11, 10.41it/s]2023-07-19 20:16:33,852 - INFO - Epoch: [568/600], Step: [119/591], Loss: 209635184.0, KL Divergence: 1164.333251953125, Reconstruction Loss: 209634016.0\n",
      "236it [00:22, 10.45it/s]2023-07-19 20:16:44,920 - INFO - Epoch: [568/600], Step: [237/591], Loss: 176405600.0, KL Divergence: 1180.1734619140625, Reconstruction Loss: 176404416.0\n",
      "354it [00:33, 10.64it/s]2023-07-19 20:16:55,972 - INFO - Epoch: [568/600], Step: [355/591], Loss: 215511872.0, KL Divergence: 1171.9344482421875, Reconstruction Loss: 215510704.0\n",
      "472it [00:44, 10.49it/s]2023-07-19 20:17:07,220 - INFO - Epoch: [568/600], Step: [473/591], Loss: 184742704.0, KL Divergence: 1168.1973876953125, Reconstruction Loss: 184741536.0\n",
      "590it [00:55, 10.52it/s]2023-07-19 20:17:18,288 - INFO - Epoch: [568/600], Step: [591/591], Loss: 149364160.0, KL Divergence: 1162.479736328125, Reconstruction Loss: 149362992.0\n",
      "591it [00:55, 10.59it/s]\n",
      "2023-07-19 20:17:18,291 - INFO - Epoch: [568/600], Total Loss: 12160841365504.0, Total KL Divergence: 88288437.421875, Total Reconstruction Loss: 12160753051648.0\n",
      "2023-07-19 20:17:18,335 - INFO - Save model at epoch 568\n",
      "0it [00:00, ?it/s]2023-07-19 20:17:18,451 - INFO - Epoch: [569/600], Step: [1/591], Loss: 94240368.0, KL Divergence: 1176.5615234375, Reconstruction Loss: 94239192.0\n",
      "118it [00:11, 10.30it/s]2023-07-19 20:17:29,501 - INFO - Epoch: [569/600], Step: [119/591], Loss: 221751968.0, KL Divergence: 1156.6669921875, Reconstruction Loss: 221750816.0\n",
      "236it [00:22, 10.50it/s]2023-07-19 20:17:40,616 - INFO - Epoch: [569/600], Step: [237/591], Loss: 181449184.0, KL Divergence: 1189.0897216796875, Reconstruction Loss: 181448000.0\n",
      "354it [00:33, 10.78it/s]2023-07-19 20:17:51,776 - INFO - Epoch: [569/600], Step: [355/591], Loss: 215946768.0, KL Divergence: 1173.7225341796875, Reconstruction Loss: 215945600.0\n",
      "472it [00:44, 10.79it/s]2023-07-19 20:18:02,988 - INFO - Epoch: [569/600], Step: [473/591], Loss: 183716576.0, KL Divergence: 1173.6162109375, Reconstruction Loss: 183715408.0\n",
      "590it [00:55, 10.57it/s]2023-07-19 20:18:14,062 - INFO - Epoch: [569/600], Step: [591/591], Loss: 143782224.0, KL Divergence: 1164.177001953125, Reconstruction Loss: 143781056.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 20:18:14,063 - INFO - Epoch: [569/600], Total Loss: 12208091152384.0, Total KL Divergence: 88330976.640625, Total Reconstruction Loss: 12208002823168.0\n",
      "2023-07-19 20:18:14,109 - INFO - Save model at epoch 569\n",
      "0it [00:00, ?it/s]2023-07-19 20:18:14,208 - INFO - Epoch: [570/600], Step: [1/591], Loss: 95834416.0, KL Divergence: 1181.0406494140625, Reconstruction Loss: 95833232.0\n",
      "118it [00:11,  9.71it/s]2023-07-19 20:18:25,451 - INFO - Epoch: [570/600], Step: [119/591], Loss: 227008080.0, KL Divergence: 1160.6837158203125, Reconstruction Loss: 227006912.0\n",
      "236it [00:22, 10.63it/s]2023-07-19 20:18:36,536 - INFO - Epoch: [570/600], Step: [237/591], Loss: 176442208.0, KL Divergence: 1175.427734375, Reconstruction Loss: 176441040.0\n",
      "354it [00:33, 10.93it/s]2023-07-19 20:18:47,599 - INFO - Epoch: [570/600], Step: [355/591], Loss: 218628208.0, KL Divergence: 1171.636474609375, Reconstruction Loss: 218627040.0\n",
      "472it [00:44, 10.81it/s]2023-07-19 20:18:58,785 - INFO - Epoch: [570/600], Step: [473/591], Loss: 180383504.0, KL Divergence: 1173.716796875, Reconstruction Loss: 180382336.0\n",
      "590it [00:55, 10.60it/s]2023-07-19 20:19:09,958 - INFO - Epoch: [570/600], Step: [591/591], Loss: 152380288.0, KL Divergence: 1152.0457763671875, Reconstruction Loss: 152379136.0\n",
      "591it [00:55, 10.58it/s]\n",
      "2023-07-19 20:19:09,959 - INFO - Epoch: [570/600], Total Loss: 12107085498368.0, Total KL Divergence: 88179642.953125, Total Reconstruction Loss: 12106997291008.0\n",
      "2023-07-19 20:19:10,002 - INFO - Save model at epoch 570\n",
      "0it [00:00, ?it/s]2023-07-19 20:19:10,125 - INFO - Epoch: [571/600], Step: [1/591], Loss: 96465720.0, KL Divergence: 1170.224853515625, Reconstruction Loss: 96464552.0\n",
      "117it [00:11, 10.67it/s]2023-07-19 20:19:21,255 - INFO - Epoch: [571/600], Step: [119/591], Loss: 214923552.0, KL Divergence: 1150.60986328125, Reconstruction Loss: 214922400.0\n",
      "235it [00:22, 10.10it/s]2023-07-19 20:19:32,532 - INFO - Epoch: [571/600], Step: [237/591], Loss: 172673984.0, KL Divergence: 1172.24169921875, Reconstruction Loss: 172672816.0\n",
      "353it [00:33, 10.63it/s]2023-07-19 20:19:43,775 - INFO - Epoch: [571/600], Step: [355/591], Loss: 217072784.0, KL Divergence: 1168.74658203125, Reconstruction Loss: 217071616.0\n",
      "471it [00:44, 10.59it/s]2023-07-19 20:19:54,882 - INFO - Epoch: [571/600], Step: [473/591], Loss: 181397312.0, KL Divergence: 1162.790771484375, Reconstruction Loss: 181396144.0\n",
      "589it [00:55, 10.84it/s]2023-07-19 20:20:05,870 - INFO - Epoch: [571/600], Step: [591/591], Loss: 146545216.0, KL Divergence: 1151.9140625, Reconstruction Loss: 146544064.0\n",
      "591it [00:55, 10.58it/s]\n",
      "2023-07-19 20:20:05,872 - INFO - Epoch: [571/600], Total Loss: 12109482775552.0, Total KL Divergence: 87725435.53125, Total Reconstruction Loss: 12109395061760.0\n",
      "2023-07-19 20:20:05,924 - INFO - Save model at epoch 571\n",
      "0it [00:00, ?it/s]2023-07-19 20:20:06,050 - INFO - Epoch: [572/600], Step: [1/591], Loss: 96755600.0, KL Divergence: 1166.51123046875, Reconstruction Loss: 96754432.0\n",
      "118it [00:11, 10.54it/s]2023-07-19 20:20:17,134 - INFO - Epoch: [572/600], Step: [119/591], Loss: 214701376.0, KL Divergence: 1145.6116943359375, Reconstruction Loss: 214700224.0\n",
      "236it [00:22, 10.81it/s]2023-07-19 20:20:28,279 - INFO - Epoch: [572/600], Step: [237/591], Loss: 184431840.0, KL Divergence: 1175.5423583984375, Reconstruction Loss: 184430672.0\n",
      "354it [00:33, 10.91it/s]2023-07-19 20:20:39,269 - INFO - Epoch: [572/600], Step: [355/591], Loss: 210870128.0, KL Divergence: 1165.6201171875, Reconstruction Loss: 210868960.0\n",
      "472it [00:44, 10.70it/s]2023-07-19 20:20:50,357 - INFO - Epoch: [572/600], Step: [473/591], Loss: 186305072.0, KL Divergence: 1171.044677734375, Reconstruction Loss: 186303904.0\n",
      "590it [00:55, 10.87it/s]2023-07-19 20:21:01,339 - INFO - Epoch: [572/600], Step: [591/591], Loss: 146634544.0, KL Divergence: 1155.6448974609375, Reconstruction Loss: 146633392.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 20:21:01,341 - INFO - Epoch: [572/600], Total Loss: 12337870906368.0, Total KL Divergence: 87526869.734375, Total Reconstruction Loss: 12337783373824.0\n",
      "2023-07-19 20:21:01,393 - INFO - Save model at epoch 572\n",
      "0it [00:00, ?it/s]2023-07-19 20:21:01,502 - INFO - Epoch: [573/600], Step: [1/591], Loss: 95933272.0, KL Divergence: 1172.5426025390625, Reconstruction Loss: 95932096.0\n",
      "118it [00:11, 11.08it/s]2023-07-19 20:21:12,568 - INFO - Epoch: [573/600], Step: [119/591], Loss: 207358352.0, KL Divergence: 1155.3492431640625, Reconstruction Loss: 207357200.0\n",
      "236it [00:22, 10.60it/s]2023-07-19 20:21:23,691 - INFO - Epoch: [573/600], Step: [237/591], Loss: 184672480.0, KL Divergence: 1174.8934326171875, Reconstruction Loss: 184671312.0\n",
      "354it [00:33, 10.89it/s]2023-07-19 20:21:34,849 - INFO - Epoch: [573/600], Step: [355/591], Loss: 216984304.0, KL Divergence: 1168.512451171875, Reconstruction Loss: 216983136.0\n",
      "472it [00:44, 11.03it/s]2023-07-19 20:21:45,902 - INFO - Epoch: [573/600], Step: [473/591], Loss: 176420272.0, KL Divergence: 1166.0308837890625, Reconstruction Loss: 176419104.0\n",
      "590it [00:55, 10.75it/s]2023-07-19 20:21:56,838 - INFO - Epoch: [573/600], Step: [591/591], Loss: 157030016.0, KL Divergence: 1149.6778564453125, Reconstruction Loss: 157028864.0\n",
      "591it [00:55, 10.66it/s]\n",
      "2023-07-19 20:21:56,840 - INFO - Epoch: [573/600], Total Loss: 12167304691712.0, Total KL Divergence: 87637557.890625, Total Reconstruction Loss: 12167217078272.0\n",
      "2023-07-19 20:21:56,882 - INFO - Save model at epoch 573\n",
      "0it [00:00, ?it/s]2023-07-19 20:21:57,004 - INFO - Epoch: [574/600], Step: [1/591], Loss: 101112056.0, KL Divergence: 1167.918212890625, Reconstruction Loss: 101110888.0\n",
      "117it [00:10, 10.79it/s]2023-07-19 20:22:08,118 - INFO - Epoch: [574/600], Step: [119/591], Loss: 208595248.0, KL Divergence: 1143.2578125, Reconstruction Loss: 208594112.0\n",
      "235it [00:22, 10.81it/s]2023-07-19 20:22:19,190 - INFO - Epoch: [574/600], Step: [237/591], Loss: 177740624.0, KL Divergence: 1170.1483154296875, Reconstruction Loss: 177739456.0\n",
      "353it [00:33, 10.38it/s]2023-07-19 20:22:30,410 - INFO - Epoch: [574/600], Step: [355/591], Loss: 216973872.0, KL Divergence: 1164.360595703125, Reconstruction Loss: 216972704.0\n",
      "471it [00:44, 10.63it/s]2023-07-19 20:22:41,521 - INFO - Epoch: [574/600], Step: [473/591], Loss: 184831568.0, KL Divergence: 1165.9560546875, Reconstruction Loss: 184830400.0\n",
      "589it [00:55, 10.91it/s]2023-07-19 20:22:52,721 - INFO - Epoch: [574/600], Step: [591/591], Loss: 153557152.0, KL Divergence: 1156.2064208984375, Reconstruction Loss: 153556000.0\n",
      "591it [00:55, 10.59it/s]\n",
      "2023-07-19 20:22:52,723 - INFO - Epoch: [574/600], Total Loss: 12225057897472.0, Total KL Divergence: 87460452.984375, Total Reconstruction Loss: 12224970409984.0\n",
      "2023-07-19 20:22:52,764 - INFO - Save model at epoch 574\n",
      "0it [00:00, ?it/s]2023-07-19 20:22:52,890 - INFO - Epoch: [575/600], Step: [1/591], Loss: 97758088.0, KL Divergence: 1173.351806640625, Reconstruction Loss: 97756912.0\n",
      "118it [00:11, 10.97it/s]2023-07-19 20:23:03,891 - INFO - Epoch: [575/600], Step: [119/591], Loss: 208987936.0, KL Divergence: 1150.9957275390625, Reconstruction Loss: 208986784.0\n",
      "236it [00:21, 10.97it/s]2023-07-19 20:23:14,847 - INFO - Epoch: [575/600], Step: [237/591], Loss: 176598688.0, KL Divergence: 1174.17919921875, Reconstruction Loss: 176597520.0\n",
      "354it [00:33, 10.20it/s]2023-07-19 20:23:25,976 - INFO - Epoch: [575/600], Step: [355/591], Loss: 225910912.0, KL Divergence: 1159.905517578125, Reconstruction Loss: 225909760.0\n",
      "472it [00:44, 11.07it/s]2023-07-19 20:23:37,109 - INFO - Epoch: [575/600], Step: [473/591], Loss: 180768544.0, KL Divergence: 1162.655517578125, Reconstruction Loss: 180767376.0\n",
      "590it [00:55, 10.69it/s]2023-07-19 20:23:48,080 - INFO - Epoch: [575/600], Step: [591/591], Loss: 152806464.0, KL Divergence: 1157.039306640625, Reconstruction Loss: 152805312.0\n",
      "591it [00:55, 10.69it/s]\n",
      "2023-07-19 20:23:48,082 - INFO - Epoch: [575/600], Total Loss: 12342650215424.0, Total KL Divergence: 87639472.28125, Total Reconstruction Loss: 12342562572288.0\n",
      "2023-07-19 20:23:48,122 - INFO - Save model at epoch 575\n",
      "0it [00:00, ?it/s]2023-07-19 20:23:48,241 - INFO - Epoch: [576/600], Step: [1/591], Loss: 97471544.0, KL Divergence: 1175.824462890625, Reconstruction Loss: 97470368.0\n",
      "117it [00:11, 10.91it/s]2023-07-19 20:23:59,367 - INFO - Epoch: [576/600], Step: [119/591], Loss: 211050608.0, KL Divergence: 1142.2777099609375, Reconstruction Loss: 211049472.0\n",
      "236it [00:22, 10.59it/s]2023-07-19 20:24:10,576 - INFO - Epoch: [576/600], Step: [237/591], Loss: 184918160.0, KL Divergence: 1169.2640380859375, Reconstruction Loss: 184916992.0\n",
      "354it [00:33, 10.77it/s]2023-07-19 20:24:21,597 - INFO - Epoch: [576/600], Step: [355/591], Loss: 227475360.0, KL Divergence: 1163.0274658203125, Reconstruction Loss: 227474192.0\n",
      "472it [00:44, 10.89it/s]2023-07-19 20:24:32,682 - INFO - Epoch: [576/600], Step: [473/591], Loss: 177754032.0, KL Divergence: 1167.869140625, Reconstruction Loss: 177752864.0\n",
      "590it [00:55, 10.98it/s]2023-07-19 20:24:43,650 - INFO - Epoch: [576/600], Step: [591/591], Loss: 152034144.0, KL Divergence: 1160.0208740234375, Reconstruction Loss: 152032976.0\n",
      "591it [00:55, 10.65it/s]\n",
      "2023-07-19 20:24:43,653 - INFO - Epoch: [576/600], Total Loss: 12298392943616.0, Total KL Divergence: 87547251.421875, Total Reconstruction Loss: 12298305394688.0\n",
      "2023-07-19 20:24:43,704 - INFO - Save model at epoch 576\n",
      "0it [00:00, ?it/s]2023-07-19 20:24:43,814 - INFO - Epoch: [577/600], Step: [1/591], Loss: 96434112.0, KL Divergence: 1177.689697265625, Reconstruction Loss: 96432936.0\n",
      "118it [00:11, 10.78it/s]2023-07-19 20:24:54,860 - INFO - Epoch: [577/600], Step: [119/591], Loss: 214342480.0, KL Divergence: 1160.51025390625, Reconstruction Loss: 214341312.0\n",
      "236it [00:22, 10.30it/s]2023-07-19 20:25:06,091 - INFO - Epoch: [577/600], Step: [237/591], Loss: 175983408.0, KL Divergence: 1177.6334228515625, Reconstruction Loss: 175982224.0\n",
      "354it [00:33, 10.54it/s]2023-07-19 20:25:17,241 - INFO - Epoch: [577/600], Step: [355/591], Loss: 228784032.0, KL Divergence: 1169.55517578125, Reconstruction Loss: 228782864.0\n",
      "471it [00:44, 10.38it/s]2023-07-19 20:25:28,489 - INFO - Epoch: [577/600], Step: [473/591], Loss: 182372480.0, KL Divergence: 1179.744873046875, Reconstruction Loss: 182371296.0\n",
      "589it [00:55, 10.81it/s]2023-07-19 20:25:39,506 - INFO - Epoch: [577/600], Step: [591/591], Loss: 162783120.0, KL Divergence: 1161.563720703125, Reconstruction Loss: 162781952.0\n",
      "591it [00:55, 10.59it/s]\n",
      "2023-07-19 20:25:39,508 - INFO - Epoch: [577/600], Total Loss: 12465542569984.0, Total KL Divergence: 88279862.90625, Total Reconstruction Loss: 12465454306304.0\n",
      "2023-07-19 20:25:39,551 - INFO - Save model at epoch 577\n",
      "0it [00:00, ?it/s]2023-07-19 20:25:39,668 - INFO - Epoch: [578/600], Step: [1/591], Loss: 104314488.0, KL Divergence: 1181.8212890625, Reconstruction Loss: 104313304.0\n",
      "117it [00:11, 10.94it/s]2023-07-19 20:25:50,784 - INFO - Epoch: [578/600], Step: [119/591], Loss: 210646576.0, KL Divergence: 1161.311279296875, Reconstruction Loss: 210645408.0\n",
      "235it [00:22, 10.72it/s]2023-07-19 20:26:01,906 - INFO - Epoch: [578/600], Step: [237/591], Loss: 175215232.0, KL Divergence: 1182.5537109375, Reconstruction Loss: 175214048.0\n",
      "353it [00:33, 10.63it/s]2023-07-19 20:26:12,916 - INFO - Epoch: [578/600], Step: [355/591], Loss: 219241840.0, KL Divergence: 1168.119384765625, Reconstruction Loss: 219240672.0\n",
      "471it [00:44, 11.09it/s]2023-07-19 20:26:23,944 - INFO - Epoch: [578/600], Step: [473/591], Loss: 182303632.0, KL Divergence: 1183.3939208984375, Reconstruction Loss: 182302448.0\n",
      "589it [00:55, 10.31it/s]2023-07-19 20:26:34,962 - INFO - Epoch: [578/600], Step: [591/591], Loss: 171117600.0, KL Divergence: 1168.6922607421875, Reconstruction Loss: 171116432.0\n",
      "591it [00:55, 10.67it/s]\n",
      "2023-07-19 20:26:34,964 - INFO - Epoch: [578/600], Total Loss: 12276333102080.0, Total KL Divergence: 88597946.28125, Total Reconstruction Loss: 12276244521984.0\n",
      "2023-07-19 20:26:35,013 - INFO - Save model at epoch 578\n",
      "0it [00:00, ?it/s]2023-07-19 20:26:35,126 - INFO - Epoch: [579/600], Step: [1/591], Loss: 108397272.0, KL Divergence: 1188.115478515625, Reconstruction Loss: 108396080.0\n",
      "118it [00:11, 10.76it/s]2023-07-19 20:26:46,297 - INFO - Epoch: [579/600], Step: [119/591], Loss: 206655488.0, KL Divergence: 1164.19677734375, Reconstruction Loss: 206654320.0\n",
      "236it [00:22, 10.72it/s]2023-07-19 20:26:57,432 - INFO - Epoch: [579/600], Step: [237/591], Loss: 172477680.0, KL Divergence: 1190.174560546875, Reconstruction Loss: 172476496.0\n",
      "354it [00:33, 10.78it/s]2023-07-19 20:27:08,516 - INFO - Epoch: [579/600], Step: [355/591], Loss: 216185648.0, KL Divergence: 1172.4677734375, Reconstruction Loss: 216184480.0\n",
      "472it [00:44, 10.11it/s]2023-07-19 20:27:19,762 - INFO - Epoch: [579/600], Step: [473/591], Loss: 181140352.0, KL Divergence: 1185.4178466796875, Reconstruction Loss: 181139168.0\n",
      "590it [00:55, 10.57it/s]2023-07-19 20:27:30,742 - INFO - Epoch: [579/600], Step: [591/591], Loss: 162776608.0, KL Divergence: 1178.142578125, Reconstruction Loss: 162775424.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 20:27:30,744 - INFO - Epoch: [579/600], Total Loss: 12273090873344.0, Total KL Divergence: 88904606.640625, Total Reconstruction Loss: 12273002001408.0\n",
      "2023-07-19 20:27:30,785 - INFO - Save model at epoch 579\n",
      "0it [00:00, ?it/s]2023-07-19 20:27:30,905 - INFO - Epoch: [580/600], Step: [1/591], Loss: 117510024.0, KL Divergence: 1194.7022705078125, Reconstruction Loss: 117508832.0\n",
      "118it [00:11, 10.53it/s]2023-07-19 20:27:42,030 - INFO - Epoch: [580/600], Step: [119/591], Loss: 207436624.0, KL Divergence: 1166.1844482421875, Reconstruction Loss: 207435456.0\n",
      "236it [00:22, 10.92it/s]2023-07-19 20:27:53,286 - INFO - Epoch: [580/600], Step: [237/591], Loss: 172222768.0, KL Divergence: 1186.4766845703125, Reconstruction Loss: 172221584.0\n",
      "354it [00:33, 10.75it/s]2023-07-19 20:28:04,401 - INFO - Epoch: [580/600], Step: [355/591], Loss: 214816944.0, KL Divergence: 1178.991943359375, Reconstruction Loss: 214815760.0\n",
      "472it [00:44, 10.33it/s]2023-07-19 20:28:15,545 - INFO - Epoch: [580/600], Step: [473/591], Loss: 196236608.0, KL Divergence: 1182.6378173828125, Reconstruction Loss: 196235424.0\n",
      "590it [00:55, 10.93it/s]2023-07-19 20:28:26,521 - INFO - Epoch: [580/600], Step: [591/591], Loss: 164901856.0, KL Divergence: 1168.90283203125, Reconstruction Loss: 164900688.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 20:28:26,523 - INFO - Epoch: [580/600], Total Loss: 12283878805504.0, Total KL Divergence: 88819623.78125, Total Reconstruction Loss: 12283789971456.0\n",
      "2023-07-19 20:28:26,568 - INFO - Save model at epoch 580\n",
      "0it [00:00, ?it/s]2023-07-19 20:28:26,688 - INFO - Epoch: [581/600], Step: [1/591], Loss: 99191568.0, KL Divergence: 1189.704833984375, Reconstruction Loss: 99190376.0\n",
      "117it [00:11, 10.61it/s]2023-07-19 20:28:37,777 - INFO - Epoch: [581/600], Step: [119/591], Loss: 215031152.0, KL Divergence: 1172.85595703125, Reconstruction Loss: 215029984.0\n",
      "235it [00:22, 10.68it/s]2023-07-19 20:28:48,854 - INFO - Epoch: [581/600], Step: [237/591], Loss: 171888016.0, KL Divergence: 1192.91748046875, Reconstruction Loss: 171886816.0\n",
      "353it [00:33, 10.83it/s]2023-07-19 20:28:59,856 - INFO - Epoch: [581/600], Step: [355/591], Loss: 219957968.0, KL Divergence: 1182.672607421875, Reconstruction Loss: 219956784.0\n",
      "472it [00:44, 11.10it/s]2023-07-19 20:29:11,011 - INFO - Epoch: [581/600], Step: [473/591], Loss: 185165568.0, KL Divergence: 1183.523681640625, Reconstruction Loss: 185164384.0\n",
      "590it [00:55, 10.90it/s]2023-07-19 20:29:22,118 - INFO - Epoch: [581/600], Step: [591/591], Loss: 147833664.0, KL Divergence: 1165.578857421875, Reconstruction Loss: 147832496.0\n",
      "591it [00:55, 10.64it/s]\n",
      "2023-07-19 20:29:22,120 - INFO - Epoch: [581/600], Total Loss: 12462221618176.0, Total KL Divergence: 89157064.25, Total Reconstruction Loss: 12462132469760.0\n",
      "2023-07-19 20:29:22,164 - INFO - Save model at epoch 581\n",
      "0it [00:00, ?it/s]2023-07-19 20:29:22,311 - INFO - Epoch: [582/600], Step: [1/591], Loss: 99729664.0, KL Divergence: 1185.64794921875, Reconstruction Loss: 99728480.0\n",
      "118it [00:11, 10.63it/s]2023-07-19 20:29:33,472 - INFO - Epoch: [582/600], Step: [119/591], Loss: 217521008.0, KL Divergence: 1177.0213623046875, Reconstruction Loss: 217519824.0\n",
      "235it [00:22, 10.52it/s]2023-07-19 20:29:44,695 - INFO - Epoch: [582/600], Step: [237/591], Loss: 175785696.0, KL Divergence: 1186.007080078125, Reconstruction Loss: 175784512.0\n",
      "353it [00:33, 10.11it/s]2023-07-19 20:29:55,748 - INFO - Epoch: [582/600], Step: [355/591], Loss: 212306304.0, KL Divergence: 1187.91943359375, Reconstruction Loss: 212305120.0\n",
      "471it [00:44, 10.80it/s]2023-07-19 20:30:06,985 - INFO - Epoch: [582/600], Step: [473/591], Loss: 186123040.0, KL Divergence: 1165.62353515625, Reconstruction Loss: 186121872.0\n",
      "589it [00:55, 10.91it/s]2023-07-19 20:30:17,957 - INFO - Epoch: [582/600], Step: [591/591], Loss: 150536160.0, KL Divergence: 1156.582763671875, Reconstruction Loss: 150535008.0\n",
      "591it [00:55, 10.60it/s]\n",
      "2023-07-19 20:30:17,959 - INFO - Epoch: [582/600], Total Loss: 12356420252672.0, Total KL Divergence: 88838567.21875, Total Reconstruction Loss: 12356331420672.0\n",
      "2023-07-19 20:30:18,004 - INFO - Save model at epoch 582\n",
      "0it [00:00, ?it/s]2023-07-19 20:30:18,128 - INFO - Epoch: [583/600], Step: [1/591], Loss: 98306024.0, KL Divergence: 1174.609130859375, Reconstruction Loss: 98304848.0\n",
      "117it [00:10, 10.83it/s]2023-07-19 20:30:29,201 - INFO - Epoch: [583/600], Step: [119/591], Loss: 222321792.0, KL Divergence: 1161.12744140625, Reconstruction Loss: 222320624.0\n",
      "235it [00:22, 10.60it/s]2023-07-19 20:30:40,332 - INFO - Epoch: [583/600], Step: [237/591], Loss: 171029968.0, KL Divergence: 1178.033935546875, Reconstruction Loss: 171028784.0\n",
      "353it [00:33, 10.66it/s]2023-07-19 20:30:51,514 - INFO - Epoch: [583/600], Step: [355/591], Loss: 211664944.0, KL Divergence: 1174.47119140625, Reconstruction Loss: 211663776.0\n",
      "471it [00:44, 10.65it/s]2023-07-19 20:31:02,642 - INFO - Epoch: [583/600], Step: [473/591], Loss: 184603424.0, KL Divergence: 1168.578369140625, Reconstruction Loss: 184602256.0\n",
      "589it [00:55, 10.70it/s]2023-07-19 20:31:13,671 - INFO - Epoch: [583/600], Step: [591/591], Loss: 159137152.0, KL Divergence: 1154.28173828125, Reconstruction Loss: 159136000.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 20:31:13,673 - INFO - Epoch: [583/600], Total Loss: 12181036158976.0, Total KL Divergence: 88190782.65625, Total Reconstruction Loss: 12180947968000.0\n",
      "2023-07-19 20:31:13,742 - INFO - Save model at epoch 583\n",
      "0it [00:00, ?it/s]2023-07-19 20:31:13,852 - INFO - Epoch: [584/600], Step: [1/591], Loss: 98325608.0, KL Divergence: 1173.806640625, Reconstruction Loss: 98324432.0\n",
      "118it [00:11, 10.03it/s]2023-07-19 20:31:25,158 - INFO - Epoch: [584/600], Step: [119/591], Loss: 216804032.0, KL Divergence: 1159.118896484375, Reconstruction Loss: 216802880.0\n",
      "236it [00:22, 10.35it/s]2023-07-19 20:31:36,497 - INFO - Epoch: [584/600], Step: [237/591], Loss: 177741504.0, KL Divergence: 1191.5950927734375, Reconstruction Loss: 177740320.0\n",
      "354it [00:33, 10.31it/s]2023-07-19 20:31:47,633 - INFO - Epoch: [584/600], Step: [355/591], Loss: 211298688.0, KL Divergence: 1179.041748046875, Reconstruction Loss: 211297504.0\n",
      "471it [00:44, 10.56it/s]2023-07-19 20:31:58,901 - INFO - Epoch: [584/600], Step: [473/591], Loss: 186576032.0, KL Divergence: 1175.161865234375, Reconstruction Loss: 186574864.0\n",
      "589it [00:56, 10.82it/s]2023-07-19 20:32:09,940 - INFO - Epoch: [584/600], Step: [591/591], Loss: 151606656.0, KL Divergence: 1167.678955078125, Reconstruction Loss: 151605488.0\n",
      "591it [00:56, 10.52it/s]\n",
      "2023-07-19 20:32:09,943 - INFO - Epoch: [584/600], Total Loss: 12203999308800.0, Total KL Divergence: 88556122.484375, Total Reconstruction Loss: 12203910732800.0\n",
      "2023-07-19 20:32:09,984 - INFO - Save model at epoch 584\n",
      "0it [00:00, ?it/s]2023-07-19 20:32:10,105 - INFO - Epoch: [585/600], Step: [1/591], Loss: 106356496.0, KL Divergence: 1183.6619873046875, Reconstruction Loss: 106355312.0\n",
      "118it [00:11, 10.04it/s]2023-07-19 20:32:21,348 - INFO - Epoch: [585/600], Step: [119/591], Loss: 216252032.0, KL Divergence: 1162.447265625, Reconstruction Loss: 216250864.0\n",
      "236it [00:22, 10.59it/s]2023-07-19 20:32:32,625 - INFO - Epoch: [585/600], Step: [237/591], Loss: 176826720.0, KL Divergence: 1190.046630859375, Reconstruction Loss: 176825536.0\n",
      "354it [00:33, 10.45it/s]2023-07-19 20:32:43,796 - INFO - Epoch: [585/600], Step: [355/591], Loss: 211990512.0, KL Divergence: 1188.498291015625, Reconstruction Loss: 211989328.0\n",
      "472it [00:44, 10.32it/s]2023-07-19 20:32:54,983 - INFO - Epoch: [585/600], Step: [473/591], Loss: 179657472.0, KL Divergence: 1186.44091796875, Reconstruction Loss: 179656288.0\n",
      "590it [00:55, 10.94it/s]2023-07-19 20:33:06,005 - INFO - Epoch: [585/600], Step: [591/591], Loss: 142201568.0, KL Divergence: 1170.5982666015625, Reconstruction Loss: 142200400.0\n",
      "591it [00:56, 10.55it/s]\n",
      "2023-07-19 20:33:06,007 - INFO - Epoch: [585/600], Total Loss: 12135031982080.0, Total KL Divergence: 89028955.453125, Total Reconstruction Loss: 12134942958592.0\n",
      "2023-07-19 20:33:06,050 - INFO - Save model at epoch 585\n",
      "0it [00:00, ?it/s]2023-07-19 20:33:06,153 - INFO - Epoch: [586/600], Step: [1/591], Loss: 93220592.0, KL Divergence: 1185.4559326171875, Reconstruction Loss: 93219408.0\n",
      "118it [00:11, 10.92it/s]2023-07-19 20:33:17,157 - INFO - Epoch: [586/600], Step: [119/591], Loss: 218639776.0, KL Divergence: 1171.268310546875, Reconstruction Loss: 218638608.0\n",
      "236it [00:22, 10.63it/s]2023-07-19 20:33:28,377 - INFO - Epoch: [586/600], Step: [237/591], Loss: 171074464.0, KL Divergence: 1188.80419921875, Reconstruction Loss: 171073280.0\n",
      "354it [00:33, 10.51it/s]2023-07-19 20:33:39,560 - INFO - Epoch: [586/600], Step: [355/591], Loss: 209010496.0, KL Divergence: 1188.9388427734375, Reconstruction Loss: 209009312.0\n",
      "472it [00:44, 10.62it/s]2023-07-19 20:33:50,689 - INFO - Epoch: [586/600], Step: [473/591], Loss: 189585552.0, KL Divergence: 1176.3607177734375, Reconstruction Loss: 189584368.0\n",
      "590it [00:55, 10.58it/s]2023-07-19 20:34:01,747 - INFO - Epoch: [586/600], Step: [591/591], Loss: 148958544.0, KL Divergence: 1165.9334716796875, Reconstruction Loss: 148957376.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 20:34:01,748 - INFO - Epoch: [586/600], Total Loss: 12135306921984.0, Total KL Divergence: 89105671.953125, Total Reconstruction Loss: 12135217840128.0\n",
      "2023-07-19 20:34:01,790 - INFO - Save model at epoch 586\n",
      "0it [00:00, ?it/s]2023-07-19 20:34:01,894 - INFO - Epoch: [587/600], Step: [1/591], Loss: 93880744.0, KL Divergence: 1182.572998046875, Reconstruction Loss: 93879560.0\n",
      "118it [00:11, 10.36it/s]2023-07-19 20:34:13,001 - INFO - Epoch: [587/600], Step: [119/591], Loss: 207553504.0, KL Divergence: 1176.4136962890625, Reconstruction Loss: 207552320.0\n",
      "236it [00:22, 10.68it/s]2023-07-19 20:34:24,131 - INFO - Epoch: [587/600], Step: [237/591], Loss: 176882976.0, KL Divergence: 1187.0343017578125, Reconstruction Loss: 176881792.0\n",
      "354it [00:33, 10.78it/s]2023-07-19 20:34:35,286 - INFO - Epoch: [587/600], Step: [355/591], Loss: 211309072.0, KL Divergence: 1184.3046875, Reconstruction Loss: 211307888.0\n",
      "471it [00:44, 10.25it/s]2023-07-19 20:34:46,558 - INFO - Epoch: [587/600], Step: [473/591], Loss: 188721408.0, KL Divergence: 1189.128662109375, Reconstruction Loss: 188720224.0\n",
      "589it [00:55, 10.70it/s]2023-07-19 20:34:57,553 - INFO - Epoch: [587/600], Step: [591/591], Loss: 145917744.0, KL Divergence: 1171.872314453125, Reconstruction Loss: 145916576.0\n",
      "591it [00:55, 10.60it/s]\n",
      "2023-07-19 20:34:57,555 - INFO - Epoch: [587/600], Total Loss: 12157239340032.0, Total KL Divergence: 88943145.234375, Total Reconstruction Loss: 12157150394368.0\n",
      "2023-07-19 20:34:57,597 - INFO - Save model at epoch 587\n",
      "0it [00:00, ?it/s]2023-07-19 20:34:57,706 - INFO - Epoch: [588/600], Step: [1/591], Loss: 92877528.0, KL Divergence: 1190.059326171875, Reconstruction Loss: 92876336.0\n",
      "118it [00:11, 10.81it/s]2023-07-19 20:35:08,784 - INFO - Epoch: [588/600], Step: [119/591], Loss: 214613120.0, KL Divergence: 1167.0966796875, Reconstruction Loss: 214611952.0\n",
      "236it [00:22, 10.60it/s]2023-07-19 20:35:19,940 - INFO - Epoch: [588/600], Step: [237/591], Loss: 179181904.0, KL Divergence: 1186.525146484375, Reconstruction Loss: 179180720.0\n",
      "354it [00:33, 10.67it/s]2023-07-19 20:35:31,172 - INFO - Epoch: [588/600], Step: [355/591], Loss: 210770816.0, KL Divergence: 1192.988037109375, Reconstruction Loss: 210769616.0\n",
      "472it [00:44, 10.25it/s]2023-07-19 20:35:42,367 - INFO - Epoch: [588/600], Step: [473/591], Loss: 185805024.0, KL Divergence: 1187.421142578125, Reconstruction Loss: 185803840.0\n",
      "590it [00:55, 10.71it/s]2023-07-19 20:35:53,480 - INFO - Epoch: [588/600], Step: [591/591], Loss: 147855392.0, KL Divergence: 1182.18798828125, Reconstruction Loss: 147854208.0\n",
      "591it [00:55, 10.58it/s]\n",
      "2023-07-19 20:35:53,482 - INFO - Epoch: [588/600], Total Loss: 12149670843392.0, Total KL Divergence: 89283474.3125, Total Reconstruction Loss: 12149581572096.0\n",
      "2023-07-19 20:35:53,542 - INFO - Save model at epoch 588\n",
      "0it [00:00, ?it/s]2023-07-19 20:35:53,649 - INFO - Epoch: [589/600], Step: [1/591], Loss: 98618120.0, KL Divergence: 1194.0848388671875, Reconstruction Loss: 98616928.0\n",
      "118it [00:11, 10.84it/s]2023-07-19 20:36:04,719 - INFO - Epoch: [589/600], Step: [119/591], Loss: 206926160.0, KL Divergence: 1174.378173828125, Reconstruction Loss: 206924992.0\n",
      "236it [00:22, 10.54it/s]2023-07-19 20:36:15,858 - INFO - Epoch: [589/600], Step: [237/591], Loss: 174831056.0, KL Divergence: 1193.1080322265625, Reconstruction Loss: 174829856.0\n",
      "354it [00:33, 10.29it/s]2023-07-19 20:36:27,069 - INFO - Epoch: [589/600], Step: [355/591], Loss: 211274608.0, KL Divergence: 1194.388916015625, Reconstruction Loss: 211273408.0\n",
      "471it [00:44, 10.72it/s]2023-07-19 20:36:38,287 - INFO - Epoch: [589/600], Step: [473/591], Loss: 183597808.0, KL Divergence: 1189.8466796875, Reconstruction Loss: 183596624.0\n",
      "589it [00:55, 10.41it/s]2023-07-19 20:36:49,347 - INFO - Epoch: [589/600], Step: [591/591], Loss: 150242960.0, KL Divergence: 1181.9140625, Reconstruction Loss: 150241776.0\n",
      "591it [00:55, 10.59it/s]\n",
      "2023-07-19 20:36:49,349 - INFO - Epoch: [589/600], Total Loss: 12170665378816.0, Total KL Divergence: 89619629.171875, Total Reconstruction Loss: 12170575757312.0\n",
      "2023-07-19 20:36:49,391 - INFO - Save model at epoch 589\n",
      "0it [00:00, ?it/s]2023-07-19 20:36:49,531 - INFO - Epoch: [590/600], Step: [1/591], Loss: 93727392.0, KL Divergence: 1199.98388671875, Reconstruction Loss: 93726192.0\n",
      "118it [00:11, 10.27it/s]2023-07-19 20:37:00,647 - INFO - Epoch: [590/600], Step: [119/591], Loss: 200244560.0, KL Divergence: 1181.7607421875, Reconstruction Loss: 200243376.0\n",
      "235it [00:22, 10.56it/s]2023-07-19 20:37:11,752 - INFO - Epoch: [590/600], Step: [237/591], Loss: 173205488.0, KL Divergence: 1198.564697265625, Reconstruction Loss: 173204288.0\n",
      "353it [00:33, 10.52it/s]2023-07-19 20:37:22,913 - INFO - Epoch: [590/600], Step: [355/591], Loss: 210194512.0, KL Divergence: 1194.932373046875, Reconstruction Loss: 210193312.0\n",
      "471it [00:44, 10.61it/s]2023-07-19 20:37:34,131 - INFO - Epoch: [590/600], Step: [473/591], Loss: 179562032.0, KL Divergence: 1203.3878173828125, Reconstruction Loss: 179560832.0\n",
      "589it [00:55, 10.57it/s]2023-07-19 20:37:45,063 - INFO - Epoch: [590/600], Step: [591/591], Loss: 153426400.0, KL Divergence: 1185.376220703125, Reconstruction Loss: 153425216.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 20:37:45,065 - INFO - Epoch: [590/600], Total Loss: 12129767609344.0, Total KL Divergence: 89975315.953125, Total Reconstruction Loss: 12129677658112.0\n",
      "2023-07-19 20:37:45,107 - INFO - Save model at epoch 590\n",
      "0it [00:00, ?it/s]2023-07-19 20:37:45,244 - INFO - Epoch: [591/600], Step: [1/591], Loss: 99409328.0, KL Divergence: 1202.713134765625, Reconstruction Loss: 99408128.0\n",
      "117it [00:11, 10.25it/s]2023-07-19 20:37:56,349 - INFO - Epoch: [591/600], Step: [119/591], Loss: 202647776.0, KL Divergence: 1180.6376953125, Reconstruction Loss: 202646592.0\n",
      "235it [00:22, 10.44it/s]2023-07-19 20:38:07,544 - INFO - Epoch: [591/600], Step: [237/591], Loss: 174247120.0, KL Divergence: 1196.392822265625, Reconstruction Loss: 174245920.0\n",
      "353it [00:33, 10.76it/s]2023-07-19 20:38:18,765 - INFO - Epoch: [591/600], Step: [355/591], Loss: 217536272.0, KL Divergence: 1195.6654052734375, Reconstruction Loss: 217535072.0\n",
      "471it [00:44, 10.86it/s]2023-07-19 20:38:30,026 - INFO - Epoch: [591/600], Step: [473/591], Loss: 180433520.0, KL Divergence: 1193.64306640625, Reconstruction Loss: 180432320.0\n",
      "589it [00:55, 10.26it/s]2023-07-19 20:38:41,142 - INFO - Epoch: [591/600], Step: [591/591], Loss: 152872512.0, KL Divergence: 1185.15478515625, Reconstruction Loss: 152871328.0\n",
      "591it [00:56, 10.55it/s]\n",
      "2023-07-19 20:38:41,144 - INFO - Epoch: [591/600], Total Loss: 12212373754880.0, Total KL Divergence: 90006756.609375, Total Reconstruction Loss: 12212283735040.0\n",
      "2023-07-19 20:38:41,189 - INFO - Save model at epoch 591\n",
      "0it [00:00, ?it/s]2023-07-19 20:38:41,300 - INFO - Epoch: [592/600], Step: [1/591], Loss: 97016032.0, KL Divergence: 1202.295654296875, Reconstruction Loss: 97014832.0\n",
      "117it [00:11, 10.61it/s]2023-07-19 20:38:52,494 - INFO - Epoch: [592/600], Step: [119/591], Loss: 200549664.0, KL Divergence: 1182.6690673828125, Reconstruction Loss: 200548480.0\n",
      "235it [00:22, 10.53it/s]2023-07-19 20:39:03,604 - INFO - Epoch: [592/600], Step: [237/591], Loss: 170357424.0, KL Divergence: 1199.2755126953125, Reconstruction Loss: 170356224.0\n",
      "353it [00:33, 10.32it/s]2023-07-19 20:39:14,782 - INFO - Epoch: [592/600], Step: [355/591], Loss: 211598992.0, KL Divergence: 1195.2191162109375, Reconstruction Loss: 211597792.0\n",
      "472it [00:44, 10.85it/s]2023-07-19 20:39:25,906 - INFO - Epoch: [592/600], Step: [473/591], Loss: 189258864.0, KL Divergence: 1201.3311767578125, Reconstruction Loss: 189257664.0\n",
      "590it [00:55, 10.51it/s]2023-07-19 20:39:37,054 - INFO - Epoch: [592/600], Step: [591/591], Loss: 144040400.0, KL Divergence: 1200.56787109375, Reconstruction Loss: 144039200.0\n",
      "591it [00:55, 10.58it/s]\n",
      "2023-07-19 20:39:37,056 - INFO - Epoch: [592/600], Total Loss: 12240133757952.0, Total KL Divergence: 90059908.125, Total Reconstruction Loss: 12240043718656.0\n",
      "2023-07-19 20:39:37,119 - INFO - Save model at epoch 592\n",
      "0it [00:00, ?it/s]2023-07-19 20:39:37,231 - INFO - Epoch: [593/600], Step: [1/591], Loss: 96623152.0, KL Divergence: 1213.501220703125, Reconstruction Loss: 96621936.0\n",
      "117it [00:11, 10.23it/s]2023-07-19 20:39:48,456 - INFO - Epoch: [593/600], Step: [119/591], Loss: 205154048.0, KL Divergence: 1192.637451171875, Reconstruction Loss: 205152848.0\n",
      "235it [00:22, 10.64it/s]2023-07-19 20:39:59,552 - INFO - Epoch: [593/600], Step: [237/591], Loss: 180176176.0, KL Divergence: 1213.8843994140625, Reconstruction Loss: 180174960.0\n",
      "353it [00:33, 10.48it/s]2023-07-19 20:40:10,690 - INFO - Epoch: [593/600], Step: [355/591], Loss: 209713552.0, KL Divergence: 1212.7684326171875, Reconstruction Loss: 209712336.0\n",
      "471it [00:44, 10.44it/s]2023-07-19 20:40:21,773 - INFO - Epoch: [593/600], Step: [473/591], Loss: 189089264.0, KL Divergence: 1220.428955078125, Reconstruction Loss: 189088048.0\n",
      "589it [00:55, 10.41it/s]2023-07-19 20:40:32,841 - INFO - Epoch: [593/600], Step: [591/591], Loss: 152705504.0, KL Divergence: 1211.82275390625, Reconstruction Loss: 152704288.0\n",
      "591it [00:55, 10.61it/s]\n",
      "2023-07-19 20:40:32,844 - INFO - Epoch: [593/600], Total Loss: 12307600401408.0, Total KL Divergence: 91172211.703125, Total Reconstruction Loss: 12307509234688.0\n",
      "2023-07-19 20:40:32,882 - INFO - Save model at epoch 593\n",
      "0it [00:00, ?it/s]2023-07-19 20:40:32,997 - INFO - Epoch: [594/600], Step: [1/591], Loss: 95828608.0, KL Divergence: 1230.7955322265625, Reconstruction Loss: 95827376.0\n",
      "118it [00:11, 10.59it/s]2023-07-19 20:40:44,097 - INFO - Epoch: [594/600], Step: [119/591], Loss: 207959856.0, KL Divergence: 1203.89990234375, Reconstruction Loss: 207958656.0\n",
      "235it [00:22, 10.72it/s]2023-07-19 20:40:55,209 - INFO - Epoch: [594/600], Step: [237/591], Loss: 173972128.0, KL Divergence: 1214.09912109375, Reconstruction Loss: 173970912.0\n",
      "353it [00:33, 10.79it/s]2023-07-19 20:41:06,348 - INFO - Epoch: [594/600], Step: [355/591], Loss: 214577568.0, KL Divergence: 1218.9334716796875, Reconstruction Loss: 214576352.0\n",
      "471it [00:44, 10.35it/s]2023-07-19 20:41:17,543 - INFO - Epoch: [594/600], Step: [473/591], Loss: 202233232.0, KL Divergence: 1226.938232421875, Reconstruction Loss: 202232000.0\n",
      "589it [00:55, 10.71it/s]2023-07-19 20:41:28,537 - INFO - Epoch: [594/600], Step: [591/591], Loss: 164894064.0, KL Divergence: 1219.0611572265625, Reconstruction Loss: 164892848.0\n",
      "591it [00:55, 10.62it/s]\n",
      "2023-07-19 20:41:28,539 - INFO - Epoch: [594/600], Total Loss: 12428754993152.0, Total KL Divergence: 91611061.0625, Total Reconstruction Loss: 12428663363584.0\n",
      "2023-07-19 20:41:28,579 - INFO - Save model at epoch 594\n",
      "0it [00:00, ?it/s]2023-07-19 20:41:28,695 - INFO - Epoch: [595/600], Step: [1/591], Loss: 103016320.0, KL Divergence: 1236.611083984375, Reconstruction Loss: 103015080.0\n",
      "118it [00:11, 10.61it/s]2023-07-19 20:41:39,874 - INFO - Epoch: [595/600], Step: [119/591], Loss: 214852576.0, KL Divergence: 1200.8485107421875, Reconstruction Loss: 214851376.0\n",
      "235it [00:22, 10.25it/s]2023-07-19 20:41:51,060 - INFO - Epoch: [595/600], Step: [237/591], Loss: 172784672.0, KL Divergence: 1229.2841796875, Reconstruction Loss: 172783440.0\n",
      "353it [00:33, 10.62it/s]2023-07-19 20:42:02,151 - INFO - Epoch: [595/600], Step: [355/591], Loss: 214679104.0, KL Divergence: 1218.008544921875, Reconstruction Loss: 214677888.0\n",
      "471it [00:44, 10.96it/s]2023-07-19 20:42:13,339 - INFO - Epoch: [595/600], Step: [473/591], Loss: 187297600.0, KL Divergence: 1223.7569580078125, Reconstruction Loss: 187296384.0\n",
      "589it [00:55, 10.58it/s]2023-07-19 20:42:24,424 - INFO - Epoch: [595/600], Step: [591/591], Loss: 151829600.0, KL Divergence: 1201.6522216796875, Reconstruction Loss: 151828400.0\n",
      "591it [00:55, 10.58it/s]\n",
      "2023-07-19 20:42:24,426 - INFO - Epoch: [595/600], Total Loss: 12313025042432.0, Total KL Divergence: 91767220.015625, Total Reconstruction Loss: 12312933294080.0\n",
      "2023-07-19 20:42:24,500 - INFO - Save model at epoch 595\n",
      "0it [00:00, ?it/s]2023-07-19 20:42:24,604 - INFO - Epoch: [596/600], Step: [1/591], Loss: 104314320.0, KL Divergence: 1220.665771484375, Reconstruction Loss: 104313096.0\n",
      "118it [00:11, 10.22it/s]2023-07-19 20:42:35,887 - INFO - Epoch: [596/600], Step: [119/591], Loss: 211490448.0, KL Divergence: 1213.904541015625, Reconstruction Loss: 211489232.0\n",
      "235it [00:22, 10.35it/s]2023-07-19 20:42:47,189 - INFO - Epoch: [596/600], Step: [237/591], Loss: 183692336.0, KL Divergence: 1223.783203125, Reconstruction Loss: 183691120.0\n",
      "353it [00:33, 10.55it/s]2023-07-19 20:42:58,308 - INFO - Epoch: [596/600], Step: [355/591], Loss: 212949024.0, KL Divergence: 1211.8585205078125, Reconstruction Loss: 212947808.0\n",
      "472it [00:44, 10.28it/s]2023-07-19 20:43:09,559 - INFO - Epoch: [596/600], Step: [473/591], Loss: 183203840.0, KL Divergence: 1212.470458984375, Reconstruction Loss: 183202624.0\n",
      "590it [00:56, 10.60it/s]2023-07-19 20:43:20,724 - INFO - Epoch: [596/600], Step: [591/591], Loss: 145652848.0, KL Divergence: 1205.564697265625, Reconstruction Loss: 145651648.0\n",
      "591it [00:56, 10.51it/s]\n",
      "2023-07-19 20:43:20,726 - INFO - Epoch: [596/600], Total Loss: 12364598131712.0, Total KL Divergence: 91491748.46875, Total Reconstruction Loss: 12364506665984.0\n",
      "2023-07-19 20:43:20,796 - INFO - Save model at epoch 596\n",
      "0it [00:00, ?it/s]2023-07-19 20:43:20,905 - INFO - Epoch: [597/600], Step: [1/591], Loss: 98544376.0, KL Divergence: 1220.2437744140625, Reconstruction Loss: 98543152.0\n",
      "117it [00:11, 10.62it/s]2023-07-19 20:43:32,024 - INFO - Epoch: [597/600], Step: [119/591], Loss: 217677024.0, KL Divergence: 1199.901611328125, Reconstruction Loss: 217675824.0\n",
      "235it [00:22, 10.44it/s]2023-07-19 20:43:43,312 - INFO - Epoch: [597/600], Step: [237/591], Loss: 171934464.0, KL Divergence: 1218.5255126953125, Reconstruction Loss: 171933248.0\n",
      "354it [00:33, 10.51it/s]2023-07-19 20:43:54,595 - INFO - Epoch: [597/600], Step: [355/591], Loss: 222687360.0, KL Divergence: 1209.4100341796875, Reconstruction Loss: 222686144.0\n",
      "472it [00:44, 10.59it/s]2023-07-19 20:44:05,766 - INFO - Epoch: [597/600], Step: [473/591], Loss: 187649792.0, KL Divergence: 1215.94921875, Reconstruction Loss: 187648576.0\n",
      "590it [00:55, 10.42it/s]2023-07-19 20:44:16,783 - INFO - Epoch: [597/600], Step: [591/591], Loss: 150993216.0, KL Divergence: 1207.8900146484375, Reconstruction Loss: 150992016.0\n",
      "591it [00:55, 10.56it/s]\n",
      "2023-07-19 20:44:16,785 - INFO - Epoch: [597/600], Total Loss: 12441893368832.0, Total KL Divergence: 91294874.796875, Total Reconstruction Loss: 12441802082304.0\n",
      "2023-07-19 20:44:16,824 - INFO - Save model at epoch 597\n",
      "0it [00:00, ?it/s]2023-07-19 20:44:16,930 - INFO - Epoch: [598/600], Step: [1/591], Loss: 96370008.0, KL Divergence: 1225.536865234375, Reconstruction Loss: 96368784.0\n",
      "117it [00:11, 10.87it/s]2023-07-19 20:44:28,208 - INFO - Epoch: [598/600], Step: [119/591], Loss: 216186400.0, KL Divergence: 1199.737060546875, Reconstruction Loss: 216185200.0\n",
      "236it [00:22, 10.91it/s]2023-07-19 20:44:39,488 - INFO - Epoch: [598/600], Step: [237/591], Loss: 171381888.0, KL Divergence: 1218.3447265625, Reconstruction Loss: 171380672.0\n",
      "354it [00:33, 10.60it/s]2023-07-19 20:44:50,674 - INFO - Epoch: [598/600], Step: [355/591], Loss: 212189632.0, KL Divergence: 1220.5030517578125, Reconstruction Loss: 212188416.0\n",
      "472it [00:44, 10.66it/s]2023-07-19 20:45:01,846 - INFO - Epoch: [598/600], Step: [473/591], Loss: 181188832.0, KL Divergence: 1216.39208984375, Reconstruction Loss: 181187616.0\n",
      "590it [00:56, 10.83it/s]2023-07-19 20:45:12,993 - INFO - Epoch: [598/600], Step: [591/591], Loss: 154597920.0, KL Divergence: 1208.06689453125, Reconstruction Loss: 154596704.0\n",
      "591it [00:56, 10.52it/s]\n",
      "2023-07-19 20:45:12,995 - INFO - Epoch: [598/600], Total Loss: 12261144998912.0, Total KL Divergence: 91634519.203125, Total Reconstruction Loss: 12261053368320.0\n",
      "2023-07-19 20:45:13,038 - INFO - Save model at epoch 598\n",
      "0it [00:00, ?it/s]2023-07-19 20:45:13,161 - INFO - Epoch: [599/600], Step: [1/591], Loss: 96789240.0, KL Divergence: 1222.9749755859375, Reconstruction Loss: 96788016.0\n",
      "118it [00:11, 10.80it/s]2023-07-19 20:45:24,247 - INFO - Epoch: [599/600], Step: [119/591], Loss: 211180464.0, KL Divergence: 1208.559814453125, Reconstruction Loss: 211179248.0\n",
      "235it [00:22, 10.86it/s]2023-07-19 20:45:35,549 - INFO - Epoch: [599/600], Step: [237/591], Loss: 170564448.0, KL Divergence: 1220.65380859375, Reconstruction Loss: 170563232.0\n",
      "354it [00:33, 10.51it/s]2023-07-19 20:45:46,855 - INFO - Epoch: [599/600], Step: [355/591], Loss: 213401968.0, KL Divergence: 1221.439453125, Reconstruction Loss: 213400752.0\n",
      "472it [00:44, 10.56it/s]2023-07-19 20:45:58,122 - INFO - Epoch: [599/600], Step: [473/591], Loss: 177212416.0, KL Divergence: 1213.67724609375, Reconstruction Loss: 177211200.0\n",
      "590it [00:56, 10.83it/s]2023-07-19 20:46:09,142 - INFO - Epoch: [599/600], Step: [591/591], Loss: 143052416.0, KL Divergence: 1203.68359375, Reconstruction Loss: 143051216.0\n",
      "591it [00:56, 10.54it/s]\n",
      "2023-07-19 20:46:09,144 - INFO - Epoch: [599/600], Total Loss: 11999994606592.0, Total KL Divergence: 91632554.34375, Total Reconstruction Loss: 11999902950400.0\n",
      "2023-07-19 20:46:09,187 - INFO - Save model at epoch 599\n",
      "0it [00:00, ?it/s]2023-07-19 20:46:09,316 - INFO - Epoch: [600/600], Step: [1/591], Loss: 96179896.0, KL Divergence: 1222.103759765625, Reconstruction Loss: 96178672.0\n",
      "117it [00:11, 10.77it/s]2023-07-19 20:46:20,401 - INFO - Epoch: [600/600], Step: [119/591], Loss: 211208656.0, KL Divergence: 1197.833984375, Reconstruction Loss: 211207456.0\n",
      "235it [00:22, 10.63it/s]2023-07-19 20:46:31,545 - INFO - Epoch: [600/600], Step: [237/591], Loss: 172586080.0, KL Divergence: 1213.4310302734375, Reconstruction Loss: 172584864.0\n",
      "353it [00:33, 10.77it/s]2023-07-19 20:46:42,722 - INFO - Epoch: [600/600], Step: [355/591], Loss: 219741824.0, KL Divergence: 1216.549072265625, Reconstruction Loss: 219740608.0\n",
      "471it [00:44, 10.57it/s]2023-07-19 20:46:53,913 - INFO - Epoch: [600/600], Step: [473/591], Loss: 178227840.0, KL Divergence: 1211.822998046875, Reconstruction Loss: 178226624.0\n",
      "589it [00:55, 10.60it/s]2023-07-19 20:47:05,021 - INFO - Epoch: [600/600], Step: [591/591], Loss: 144493680.0, KL Divergence: 1202.691650390625, Reconstruction Loss: 144492480.0\n",
      "591it [00:55, 10.59it/s]\n",
      "2023-07-19 20:47:05,023 - INFO - Epoch: [600/600], Total Loss: 11909408899072.0, Total KL Divergence: 91269965.390625, Total Reconstruction Loss: 11909317610496.0\n",
      "2023-07-19 20:47:05,066 - INFO - Save model at epoch 600\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    for i, data in tqdm.tqdm(enumerate(dataloader)):\n",
    "        data = data.to(device)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss, kl_loss, recon_loss = criterion(recon_batch, data, mu, logvar)\n",
    "        total_loss += (loss.item()*batch_size)\n",
    "        total_kl_loss += (kl_loss.item()*batch_size)\n",
    "        total_recon_loss += (recon_loss.item()*batch_size)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % (len(dataloader)//5) == 0:\n",
    "            writer.add_scalar('loss', loss.item(), epoch*len(dataloader)+i)\n",
    "            writer.add_scalar('kl_loss', kl_loss.item(), epoch*len(dataloader)+i)\n",
    "            writer.add_scalar('recon_loss', recon_loss.item(), epoch*len(dataloader)+i)\n",
    "            logger.info('Epoch: [{}/{}], Step: [{}/{}], Loss: {}, KL Divergence: {}, Reconstruction Loss: {}'.format(epoch+1, num_epochs, i+1, len(dataloader), loss.item(), kl_loss.item(), recon_loss.item()))\n",
    "            # print('Epoch: [{}/{}], Step: [{}/{}], Loss: {}'.format(epoch+1, num_epochs, i+1, len(dataloader), loss.item()))\n",
    "\n",
    "    writer.add_scalar('total_loss', total_loss, epoch)\n",
    "    writer.add_scalar('total_kl_loss', total_kl_loss, epoch)\n",
    "    writer.add_scalar('total_recon_loss', total_recon_loss, epoch)\n",
    "    logger.info('Epoch: [{}/{}], Total Loss: {}, Total KL Divergence: {}, Total Reconstruction Loss: {}'.format(epoch+1, num_epochs, total_loss, total_kl_loss, total_recon_loss))\n",
    "    # print('Epoch: [{}/{}], Total Loss: {}'.format(epoch+1, num_epochs, total_loss))\n",
    "    \n",
    "    # save model\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        idx = np.random.randint(0, len(data))\n",
    "        # print(data.shape, recon_batch.shape)\n",
    "        original = data[idx].view(4, 32, 32).cpu().detach()\n",
    "        reconstruction = recon_batch[idx].view(4, 32, 32).cpu().detach()\n",
    "        writer.add_image('original1', original[0].unsqueeze(0), epoch+1)\n",
    "        writer.add_image('reconstruction1', reconstruction[0].unsqueeze(0), epoch+1)\n",
    "        writer.add_image('original2', original[1].unsqueeze(0), epoch+1)\n",
    "        writer.add_image('reconstruction2', reconstruction[1].unsqueeze(0), epoch+1)\n",
    "        writer.add_image('original3', original[2].unsqueeze(0), epoch+1)\n",
    "        writer.add_image('reconstruction3', reconstruction[2].unsqueeze(0), epoch+1)\n",
    "        writer.add_image('original4', original[3].unsqueeze(0), epoch+1)\n",
    "        writer.add_image('reconstruction4', reconstruction[3].unsqueeze(0), epoch+1)\n",
    "        torch.save(model.state_dict(), os.path.join(checkpoint_dir, 'VAE_Epoch_{}_Loss_{}.pth'.format(epoch+1, total_loss)))\n",
    "        logger.info('Save model at epoch {}'.format(epoch+1))\n",
    "        for i in range(4):\n",
    "            original[i] = original[i] * std[i] + mean[i]\n",
    "            reconstruction[i] = reconstruction[i] * std[i] + mean[i]\n",
    "        tifffile.imwrite(os.path.join(log_dir, 'original_{}.tif'.format(epoch+1)), original.cpu().numpy())\n",
    "        tifffile.imwrite(os.path.join(log_dir, 'reconstruction_{}.tif'.format(epoch+1)), reconstruction.cpu().detach().numpy())\n",
    "\n",
    "# close writer\n",
    "writer.close()\n",
    "\n",
    "#close logger\n",
    "logger.removeHandler(logger.handlers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize latent space\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for i, data in tqdm.tqdm(enumerate(dataloader)):\n",
    "#         data = data.to(device)\n",
    "#         recon_batch, mu, logvar = model(data)\n",
    "#         if i == 0:\n",
    "#             z = mu\n",
    "#             label = torch.zeros(batch_size)\n",
    "#         else:\n",
    "#             z = torch.cat((z, mu), dim=0)\n",
    "#             label = torch.cat((label, torch.zeros(batch_size)+i), dim=0)\n",
    "#     z = z.cpu().numpy()\n",
    "#     label = label.cpu().numpy()\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.scatter(z[:, 0], z[:, 1], c=label, cmap='tab10')\n",
    "# plt.colorbar()\n",
    "# plt.savefig(os.path.join(log_dir, 'latent_space.png'))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_dim = 32\n",
    "# layer_list = [1, 1, 1, 1]\n",
    "# checkpoint_dir = os.path.join('checkpoints', task, '2023-07-17_12-30-20')\n",
    "# # load model\n",
    "# model = ResVAE(latent_dim=latent_dim, use_batch_norm=True, dropout=0.0, layer_list=layer_list)\n",
    "# model.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'VAE_Epoch_490_Loss_-698832042.625.pth')))\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "591it [00:45, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 4, 32, 32) torch.Size([48, 4, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# visualize reconstruction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm.tqdm(enumerate(dataloader)):\n",
    "        data = data.to(device)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        # if i == 0:\n",
    "        #     recon = recon_batch\n",
    "        # else:\n",
    "        #     recon = torch.cat((recon, recon_batch), dim=0)\n",
    "    recon_batch = recon_batch.cpu().numpy()\n",
    "print(recon_batch.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log_dir = os.path.join('logs', task, '2023-07-17_12-30-20')\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(recon_batch[i][0])\n",
    "plt.savefig(os.path.join(log_dir, 'reconstruction.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.cpu().numpy()\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(data[i][0])\n",
    "plt.savefig(os.path.join(log_dir, 'original.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
